{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL Brain project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O10test1.txt   O2valid3.txt  O4valid2.txt  O6valid1.txt  O8train.txt\r\n",
      "O10test2.txt   O3test1.txt   O4valid3.txt  O6valid2.txt  O8valid1.txt\r\n",
      "O10test3.txt   O3test2.txt   O5test1.txt   O6valid3.txt  O8valid2.txt\r\n",
      "O10train.txt   O3test3.txt   O5test2.txt   O7test1.txt   O8valid3.txt\r\n",
      "O10valid1.txt  O3train.txt   O5test3.txt   O7test2.txt   O9test1.txt\r\n",
      "O10valid2.txt  O3valid1.txt  O5train.txt   O7test3.txt   O9test2.txt\r\n",
      "O10valid3.txt  O3valid2.txt  O5valid1.txt  O7train.txt   O9test3.txt\r\n",
      "O2test1.txt    O3valid3.txt  O5valid2.txt  O7valid1.txt  O9train.txt\r\n",
      "O2test2.txt    O4test1.txt   O5valid3.txt  O7valid2.txt  O9valid1.txt\r\n",
      "O2test3.txt    O4test2.txt   O6test1.txt   O7valid3.txt  O9valid2.txt\r\n",
      "O2train.txt    O4test3.txt   O6test2.txt   O8test1.txt   O9valid3.txt\r\n",
      "O2valid1.txt   O4train.txt   O6test3.txt   O8test2.txt\r\n",
      "O2valid2.txt   O4valid1.txt  O6train.txt   O8test3.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls /home/arasdar/datasets/DL-BrainBody/Control/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P10test1.txt   P11valid3.txt  P4valid2.txt  P6valid1.txt  P8train.txt\r\n",
      "P10test2.txt   P1test1.txt    P4valid3.txt  P6valid2.txt  P8valid1.txt\r\n",
      "P10test3.txt   P1test2.txt    P5test1.txt   P6valid3.txt  P8valid2.txt\r\n",
      "P10train.txt   P1test3.txt    P5test2.txt   P7test1.txt   P8valid3.txt\r\n",
      "P10valid1.txt  P1train.txt    P5test3.txt   P7test2.txt   P9test1.txt\r\n",
      "P10valid2.txt  P1valid1.txt   P5train.txt   P7test3.txt   P9test2.txt\r\n",
      "P10valid3.txt  P1valid2.txt   P5valid1.txt  P7train.txt   P9test3.txt\r\n",
      "P11test1.txt   P1valid3.txt   P5valid2.txt  P7valid1.txt  P9train.txt\r\n",
      "P11test2.txt   P4test1.txt    P5valid3.txt  P7valid2.txt  P9valid1.txt\r\n",
      "P11test3.txt   P4test2.txt    P6test1.txt   P7valid3.txt  P9valid2.txt\r\n",
      "P11train.txt   P4test3.txt    P6test2.txt   P8test1.txt   P9valid3.txt\r\n",
      "P11valid1.txt  P4train.txt    P6test3.txt   P8test2.txt\r\n",
      "P11valid2.txt  P4valid1.txt   P6train.txt   P8test3.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls /home/arasdar/datasets/DL-BrainBody/PD/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 81920, 56) (18, 40, 8, 256, 56)\n",
      "(18, 40960, 56) (18, 20, 8, 256, 56)\n",
      "(18, 40960, 56) (18, 20, 8, 256, 56)\n",
      "(18, 38912, 56) (18, 19, 8, 256, 56)\n",
      "(18, 79872, 56) (18, 39, 8, 256, 56)\n",
      "(18, 79872, 56) (18, 39, 8, 256, 56)\n",
      "(18, 81920, 56) (18, 40, 8, 256, 56)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "############################################# Training ##############################################################\n",
    "############################################# Training ##############################################################\n",
    "############################################# Training ##############################################################\n",
    "Xctr2 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr3 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O3train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O4train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O5train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O6train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O7train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O8train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O9train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O10train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xptr1 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P1train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P4train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P5train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P6train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P7train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P8train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P9train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P10train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr11 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P11train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xctr = np.array([Xctr2.values, Xctr3.values, Xctr4.values, Xctr5.values, Xctr6.values, Xctr7.values, Xctr8.values, \n",
    "                 Xctr9.values, Xctr10.values])\n",
    "Xptr = np.array([Xptr1.values, Xptr4.values, Xptr5.values, Xptr6.values, Xptr7.values, Xptr8.values, Xptr9.values, \n",
    "                 Xptr10.values, Xptr11.values])\n",
    "Xtr = np.concatenate([Xctr, Xptr], axis=0)\n",
    "# 'Training data:', Xctr.shape, Xptr.shape, \\\n",
    "# Xctr.dtype, Xptr.dtype, \\\n",
    "print(Xtr.shape, Xtr.reshape(18, -1, 8, 256, 56).shape)\n",
    "############################################# Validation1 ##############################################################\n",
    "############################################# Validation1 ##############################################################\n",
    "############################################# Validation1 ##############################################################\n",
    "Xctr2 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr3 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O3valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O4valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O5valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O6valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O7valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O8valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O9valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O10valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xptr1 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P1valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P4valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P5valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P6valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P7valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P8valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P9valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P10valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr11 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P11valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xcval = np.array([Xctr2.values, Xctr3.values, Xctr4.values, Xctr5.values, Xctr6.values, Xctr7.values, Xctr8.values,\n",
    "                  Xctr9.values, Xctr10.values])\n",
    "Xpval = np.array([Xptr1.values, Xptr4.values, Xptr5.values, Xptr6.values, Xptr7.values, Xptr8.values, Xptr9.values, \n",
    "                  Xptr10.values, Xptr11.values])\n",
    "Xval1 = np.concatenate([Xcval, Xpval], axis=0)\n",
    "# Xcval.shape, Xpval.shape, \\\n",
    "# Xcval.dtype, Xpval.dtype, \\\n",
    "print(Xval1.shape, Xval1.reshape(18, -1, 8, 256, 56).shape)\n",
    "############################################# Validation2 ##############################################################\n",
    "############################################# Validation2 ##############################################################\n",
    "############################################# Validation2 ##############################################################\n",
    "Xctr2 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr3 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O3valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O4valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O5valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O6valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O7valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O8valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O9valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O10valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xptr1 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P1valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P4valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P5valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P6valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P7valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P8valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P9valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P10valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr11 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P11valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xcval = np.array([Xctr2.values, Xctr3.values, Xctr4.values, Xctr5.values, Xctr6.values, Xctr7.values, Xctr8.values, \n",
    "                  Xctr9.values, Xctr10.values])\n",
    "Xpval = np.array([Xptr1.values, Xptr4.values, Xptr5.values, Xptr6.values, Xptr7.values, Xptr8.values, Xptr9.values, \n",
    "                  Xptr10.values, Xptr11.values])\n",
    "Xval2 = np.concatenate([Xcval, Xpval], axis=0)\n",
    "# Xcval.shape, Xpval.shape, \\\n",
    "# Xcval.dtype, Xpval.dtype, \\\n",
    "print(Xval2.shape, Xval2.reshape(18, -1, 8, 256, 56).shape)\n",
    "########################################### Validation3 ################################################################\n",
    "########################################### Validation3 ################################################################\n",
    "########################################### Validation3 ################################################################\n",
    "Xctr2 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr3 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O3valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O4valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O5valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O6valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O7valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O8valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O9valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O10valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xptr1 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P1valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P4valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P5valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P6valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P7valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P8valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P9valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P10valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr11 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P11valid3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xcval = np.array([Xctr2.values, Xctr3.values, Xctr4.values, Xctr5.values, Xctr6.values, Xctr7.values, Xctr8.values, \n",
    "                  Xctr9.values, Xctr10.values])\n",
    "Xpval = np.array([Xptr1.values, Xptr4.values, Xptr5.values, Xptr6.values, Xptr7.values, Xptr8.values, Xptr9.values, \n",
    "                  Xptr10.values, Xptr11.values])\n",
    "Xval3 = np.concatenate([Xcval, Xpval], axis=0)\n",
    "# Xcval.shape, Xpval.shape, \\\n",
    "# Xcval.dtype, Xpval.dtype, \\\n",
    "print(Xval3.shape, Xval3.reshape(18, -1, 8, 256, 56).shape)\n",
    "########################################### Test1 ################################################################\n",
    "########################################### Test1 ################################################################\n",
    "########################################### Test1 ################################################################\n",
    "Xctr2 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr3 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O3test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O4test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O5test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O6test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O7test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O8test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O9test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O10test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xptr1 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P1test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P4test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P5test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P6test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P7test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P8test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P9test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P10test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr11 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P11test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xcval = np.array([Xctr2.values, Xctr3.values, Xctr4.values, Xctr5.values, Xctr6.values, Xctr7.values, Xctr8.values, \n",
    "                  Xctr9.values, Xctr10.values])\n",
    "Xpval = np.array([Xptr1.values, Xptr4.values, Xptr5.values, Xptr6.values, Xptr7.values, Xptr8.values, Xptr9.values, \n",
    "                  Xptr10.values, Xptr11.values])\n",
    "Xtest1 = np.concatenate([Xcval, Xpval], axis=0)\n",
    "# Xcval.shape, Xpval.shape, \\\n",
    "# Xcval.dtype, Xpval.dtype, \\\n",
    "print(Xtest1.shape, Xtest1.reshape(18, -1, 8, 256, 56).shape)\n",
    "############################################ Test2 ###############################################################\n",
    "############################################ Test2 ###############################################################\n",
    "############################################ Test2 ###############################################################\n",
    "Xctr2 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr3 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O3test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O4test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O5test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O6test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O7test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O8test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O9test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O10test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xptr1 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P1test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P4test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P5test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P6test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P7test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P8test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P9test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P10test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr11 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P11test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xcval = np.array([Xctr2.values, Xctr3.values, Xctr4.values, Xctr5.values, Xctr6.values, Xctr7.values, Xctr8.values, \n",
    "                  Xctr9.values, Xctr10.values])\n",
    "Xpval = np.array([Xptr1.values, Xptr4.values, Xptr5.values, Xptr6.values, Xptr7.values, Xptr8.values, Xptr9.values, \n",
    "                  Xptr10.values, Xptr11.values])\n",
    "Xtest2 = np.concatenate([Xcval, Xpval], axis=0)\n",
    "# Xcval.shape, Xpval.shape, \\\n",
    "# Xcval.dtype, Xpval.dtype, \\\n",
    "print(Xtest2.shape, Xtest2.reshape(18, -1, 8, 256, 56).shape)\n",
    "############################################# Test3 ##############################################################\n",
    "############################################# Test3 ##############################################################\n",
    "############################################# Test3 ##############################################################\n",
    "Xctr2 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr3 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O3test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O4test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O5test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O6test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O7test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O8test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O9test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xctr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O10test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xptr1 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P1test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr4 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P4test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr5 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P5test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr6 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P6test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr7 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P7test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr8 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P8test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr9 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P9test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr10 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P10test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "Xptr11 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P11test3.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "###########################################################################################################\n",
    "Xcval = np.array([Xctr2.values, Xctr3.values, Xctr4.values, Xctr5.values, Xctr6.values, Xctr7.values, Xctr8.values, \n",
    "                  Xctr9.values, Xctr10.values])\n",
    "Xpval = np.array([Xptr1.values, Xptr4.values, Xptr5.values, Xptr6.values, Xptr7.values, Xptr8.values, Xptr9.values, \n",
    "                  Xptr10.values, Xptr11.values])\n",
    "Xtest3 = np.concatenate([Xcval, Xpval], axis=0)\n",
    "# Xcval.shape, Xpval.shape, \\\n",
    "# Xcval.dtype, Xpval.dtype, \\\n",
    "print(Xtest3.shape, Xtest3.reshape(18, -1, 8, 256, 56).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 8, 256, 56) float64\n",
      "(360, 8, 256, 56) float64\n",
      "(360, 8, 256, 56) float64\n",
      "(342, 8, 256, 56) float64\n",
      "(702, 8, 256, 56) float64\n",
      "(702, 8, 256, 56) float64\n",
      "(720, 8, 256, 56) float64\n"
     ]
    }
   ],
   "source": [
    "inputs_tr = Xtr.reshape([-1, 8, 256, 56])\n",
    "inputs_val1 = Xval1.reshape([-1, 8, 256, 56])\n",
    "inputs_val2 = Xval2.reshape([-1, 8, 256, 56])\n",
    "inputs_val3 = Xval3.reshape([-1, 8, 256, 56])\n",
    "inputs_test1 = Xtest1.reshape([-1, 8, 256, 56])\n",
    "inputs_test2 = Xtest2.reshape([-1, 8, 256, 56])\n",
    "inputs_test3 = Xtest3.reshape([-1, 8, 256, 56])\n",
    "print(inputs_tr.shape, inputs_tr.dtype)\n",
    "print(inputs_val1.shape, inputs_val1.dtype)\n",
    "print(inputs_val2.shape, inputs_val2.dtype)\n",
    "print(inputs_val3.shape, inputs_val3.dtype)\n",
    "print(inputs_test1.shape, inputs_test1.dtype)\n",
    "print(inputs_test2.shape, inputs_test2.dtype)\n",
    "print(inputs_test3.shape, inputs_test3.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720,) float64\n",
      "(360,) float64\n",
      "(360,) float64\n",
      "(342,) float64\n",
      "(702,) float64\n",
      "(702,) float64\n",
      "(720,) float64\n"
     ]
    }
   ],
   "source": [
    "# (720, 8, 256, 56) float64\n",
    "Yctr = np.zeros(720//2) # control labels: False\n",
    "Yptr = np.ones(720//2) # pd labels: True\n",
    "indices_tr = np.concatenate([Yctr, Yptr], axis=0)\n",
    "# (360, 8, 256, 56) float64\n",
    "# (360, 8, 256, 56) float64\n",
    "Yctr = np.zeros(360//2) # control labels: False\n",
    "Yptr = np.ones(360//2) # pd labels: True\n",
    "indices_val1 = np.concatenate([Yctr, Yptr], axis=0)\n",
    "indices_val2 = np.concatenate([Yctr, Yptr], axis=0)\n",
    "# (342, 8, 256, 56) float64\n",
    "Yctr = np.zeros(342//2) # control labels: False\n",
    "Yptr = np.ones(342//2) # pd labels: True\n",
    "indices_val3 = np.concatenate([Yctr, Yptr], axis=0)\n",
    "# (702, 8, 256, 56) float64\n",
    "# (702, 8, 256, 56) float64\n",
    "Yctr = np.zeros(702//2) # control labels: False\n",
    "Yptr = np.ones(702//2) # pd labels: True\n",
    "indices_test1 = np.concatenate([Yctr, Yptr], axis=0)\n",
    "indices_test2 = np.concatenate([Yctr, Yptr], axis=0)\n",
    "# (720, 8, 256, 56) float64\n",
    "Yctr = np.zeros(720//2) # control labels: False\n",
    "Yptr = np.ones(720//2) # pd labels: True\n",
    "indices_test3 = np.concatenate([Yctr, Yptr], axis=0)\n",
    "print(indices_tr.shape, indices_tr.dtype)\n",
    "print(indices_val1.shape, indices_val1.dtype)\n",
    "print(indices_val2.shape, indices_val2.dtype)\n",
    "print(indices_val3.shape, indices_val3.dtype)\n",
    "print(indices_test1.shape, indices_test1.dtype)\n",
    "print(indices_test2.shape, indices_test2.dtype)\n",
    "print(indices_test3.shape, indices_test3.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 18 # number of subjects\n",
    "# seq_length = 40/39/20/19 # dynamic/static rnn\n",
    "input_size = (8, 256, 56) # one second of each activity which is 1024=256sample/sec*4sec\n",
    "output_size = 2 # number of classes\n",
    "hidden_size = 1024\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(input_size, hidden_size, batch_size):\n",
    "    # CNN and MLP\n",
    "    inputs = tf.placeholder(dtype=tf.float32, shape=[None, *input_size], name='inputs')\n",
    "    indices = tf.placeholder(dtype=tf.int32, shape=[None], name='indices')    \n",
    "    training = tf.placeholder(dtype=tf.bool, shape=[], name='training') # batchnorm\n",
    "    # RNN\n",
    "    cell = tf.nn.rnn_cell.GRUCell(num_units=hidden_size)\n",
    "    #cell = tf.nn.rnn_cell.LSTMCell(hidden_size)\n",
    "    cells = tf.nn.rnn_cell.MultiRNNCell(cells=[cell], state_is_tuple=True)\n",
    "    initial_state = cells.zero_state(batch_size, tf.float32) # ??? None/batch size\n",
    "    return inputs, indices, training, cells, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(inputs, input_size, output_size, # CNN\n",
    "                  batch_size, initial_state, cells, # RNN/MLP/FC\n",
    "                  alpha=0.1, training=False, reuse=False): # NL/BN\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # CNN\n",
    "        # NHWC format\n",
    "        #?, 8, 256, 56\n",
    "        filters = 56\n",
    "        print(inputs.shape)\n",
    "        filters *= 2 # 112\n",
    "        h1 = tf.layers.conv2d(inputs=inputs, filters=filters, kernel_size=[8, 3], strides=[1, 2], padding='same')\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)\n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        print(nl1.shape) # 128\n",
    "        filters *= 2 # 224\n",
    "        h1 = tf.layers.conv2d(inputs=nl1, filters=filters, kernel_size=[8, 3], strides=[1, 2], padding='same')\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)\n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        print(nl1.shape) # 64\n",
    "        filters *= 2 # 448\n",
    "        h1 = tf.layers.conv2d(inputs=nl1, filters=filters, kernel_size=[8, 3], strides=[1, 2], padding='same')\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)\n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        print(nl1.shape) # 32\n",
    "        filters *= 1 # 448\n",
    "        h1 = tf.layers.conv2d(inputs=nl1, filters=hidden_size, kernel_size=[8, 3], strides=[1, 2], padding='same')\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)\n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        print(nl1.shape) # 16\n",
    "        filters *= 1 # 448\n",
    "        h1 = tf.layers.conv2d(inputs=nl1, filters=hidden_size, kernel_size=[8, 3], strides=[1, 2], padding='same')\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)\n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        print(nl1.shape) # 8\n",
    "        filters *= 1 # 448\n",
    "        h1 = tf.layers.conv2d(inputs=nl1, filters=hidden_size, kernel_size=[8, 3], strides=[2, 2], padding='same')\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)\n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        print(nl1.shape) # 4\n",
    "        filters *= 1 # 448\n",
    "        h1 = tf.layers.conv2d(inputs=nl1, filters=hidden_size, kernel_size=[8, 3], strides=[2, 2], padding='same')\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)\n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        print(nl1.shape) # 2\n",
    "        filters *= 1 # 448\n",
    "        h1 = tf.layers.conv2d(inputs=nl1, filters=hidden_size, kernel_size=[8, 3], strides=[2, 2], padding='same')\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)\n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        filters *= 1 # 448\n",
    "        print(nl1.shape) # 2\n",
    "\n",
    "        # RNN/MLP/Fully Connected\n",
    "        inputs_rnn = tf.reshape(tensor=nl1, shape=[batch_size, -1, hidden_size]) # ?, 40, VEC\n",
    "        print('inputs_rnn.shape, initial_state[0].shape', \n",
    "              inputs_rnn.shape, initial_state[0].shape) # tuple=True\n",
    "        # uni-directional/bi-directional: dynamic/static on sequence length\n",
    "        outputs_rnn, final_state = tf.nn.dynamic_rnn(cell=cells, inputs=inputs_rnn, initial_state=initial_state)\n",
    "        print('outputs_rnn.shape, final_state[0].shape',\n",
    "              outputs_rnn.shape, final_state[0].shape) # tuple=True\n",
    "        outputs = tf.reshape(outputs_rnn, [-1, hidden_size]) # ?x40, VEC\n",
    "        print('outputs.shape', outputs.shape)\n",
    "\n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=outputs, units=output_size)\n",
    "        print(logits.shape)\n",
    "        return logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(inputs, indices, input_size, output_size, hidden_size, batch_size, cells, initial_state, training):\n",
    "    logits, final_state = discriminator(inputs=inputs, input_size=input_size, output_size=output_size, \n",
    "                                        cells=cells, initial_state=initial_state, batch_size=batch_size, \n",
    "                                        training=training)\n",
    "    labels = tf.one_hot(indices=indices, depth=output_size, dtype=logits.dtype)\n",
    "    print(logits.shape, labels.shape)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
    "    # If argmax label and argmax logits are equal: true/false\n",
    "    if_equal_bool = tf.equal(x=tf.argmax(axis=1, input=logits), y=tf.argmax(axis=1, input=labels))\n",
    "    accuracy = tf.reduce_mean(axis=0, input_tensor=tf.cast(dtype=tf.float32, x=if_equal_bool))\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    tvars = tf.trainable_variables()\n",
    "    dvars = [var for var in tvars if var.name.startswith('discriminator')]\n",
    "    # dvars = []\n",
    "    # for var in tvars: \n",
    "    #     if var.name.startswith('discriminator'):\n",
    "    #         dvars.append(var)\n",
    "\n",
    "    # Optimize MLP/CNN\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        #opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars) # CNN\n",
    "        grads, _ = tf.clip_by_global_norm(t_list=tf.gradients(loss, dvars), clip_norm=5) # usually around 1-5\n",
    "        #grads = tf.gradients(loss, dvars) # RNN\n",
    "        opt = tf.train.AdamOptimizer(learning_rate).apply_gradients(grads_and_vars=zip(grads, dvars))\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, input_size, output_size, hidden_size, batch_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.inputs, self.indices, self.training, cells, self.initial_state = model_input(input_size=input_size, \n",
    "                                                                                          batch_size=batch_size, \n",
    "                                                                                          hidden_size=hidden_size)\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.loss, self.acc = model_loss(inputs=self.inputs, indices=self.indices, batch_size=batch_size, \n",
    "                                         input_size=input_size, output_size=output_size, hidden_size=hidden_size,\n",
    "                                         cells=cells, initial_state=self.initial_state, training=self.training)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 8, 256, 56)\n",
      "(?, 8, 128, 112)\n",
      "(?, 8, 64, 224)\n",
      "(?, 8, 32, 448)\n",
      "(?, 8, 16, 1024)\n",
      "(?, 8, 8, 1024)\n",
      "(?, 4, 4, 1024)\n",
      "(?, 2, 2, 1024)\n",
      "(?, 1, 1, 1024)\n",
      "inputs_rnn.shape, initial_state[0].shape (18, ?, 1024) (18, 1024)\n",
      "outputs_rnn.shape, final_state[0].shape (18, ?, 1024) (18, 1024)\n",
      "outputs.shape (?, 1024)\n",
      "(?, 2)\n",
      "(?, 2) (?, 2)\n"
     ]
    }
   ],
   "source": [
    "graph = tf.reset_default_graph()\n",
    "\n",
    "model = Model(input_size=input_size, hidden_size=hidden_size, output_size=output_size, \n",
    "              learning_rate=learning_rate, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(8), Dimension(256), Dimension(56)]),\n",
       " (720, 8, 256, 56),\n",
       " (360, 8, 256, 56),\n",
       " (360, 8, 256, 56),\n",
       " (342, 8, 256, 56),\n",
       " TensorShape([Dimension(None)]),\n",
       " (720,),\n",
       " (360,),\n",
       " (360,),\n",
       " (342,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inputs.shape, inputs_tr.shape, inputs_val1.shape, inputs_val2.shape, inputs_val3.shape, \\\n",
    "model.indices.shape, indices_tr.shape, indices_val1.shape, indices_val2.shape, indices_val3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "    initial_state = sess.run(model.initial_state)\n",
    "    for epoch in range(11):\n",
    "        losses, accs = [], []\n",
    "        ######################################## Training ##############################################\n",
    "        loss, acc, _ = sess.run(fetches=[model.loss, model.acc, model.opt], \n",
    "                                feed_dict={model.inputs: inputs_tr, \n",
    "                                           model.indices: indices_tr, \n",
    "                                           model.initial_state: initial_state,\n",
    "                                           model.training: True})\n",
    "        print('Training loss:{:.4f}'.format(loss), 'accuracy:{:.4f}'.format(acc))\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        ######################################## Validation ##############################################\n",
    "        loss, acc = sess.run(fetches=[model.loss, model.acc],\n",
    "                             feed_dict={model.inputs: inputs_val1, \n",
    "                                        model.indices: indices_val1, \n",
    "                                        model.initial_state: initial_state,\n",
    "                                        model.training: False})\n",
    "        print('Validation1 loss:{:.4f}'.format(loss), 'accuracy:{:.4f}'.format(acc))\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        loss, acc = sess.run(fetches=[model.loss, model.acc], \n",
    "                             feed_dict={model.inputs: inputs_val2, \n",
    "                                        model.indices: indices_val2, \n",
    "                                        model.initial_state: initial_state,\n",
    "                                        model.training: False})\n",
    "        print('Validation2 loss:{:.4f}'.format(loss), 'accuracy:{:.4f}'.format(acc))\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        loss, acc = sess.run(fetches=[model.loss, model.acc], \n",
    "                             feed_dict={model.inputs: inputs_val3, \n",
    "                                        model.indices: indices_val3, \n",
    "                                        model.initial_state: initial_state,\n",
    "                                        model.training: False})\n",
    "        print('Validation3 loss:{:.4f}'.format(loss), 'accuracy:{:.4f}'.format(acc))\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        ######################################## Test ##############################################\n",
    "        loss, acc = sess.run(fetches=[model.loss, model.acc],\n",
    "                             feed_dict={model.inputs: inputs_test1, \n",
    "                                        model.indices: indices_test1, \n",
    "                                        model.initial_state: initial_state,\n",
    "                                        model.training: False})\n",
    "        print('Test1 loss:{:.4f}'.format(loss), 'accuracy:{:.4f}'.format(acc))\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        loss, acc = sess.run(fetches=[model.loss, model.acc],\n",
    "                             feed_dict={model.inputs: inputs_test2, \n",
    "                                        model.indices: indices_test2, \n",
    "                                        model.initial_state: initial_state,\n",
    "                                        model.training: False})\n",
    "        print('Test2 loss:{:.4f}'.format(loss), 'accuracy:{:.4f}'.format(acc))\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        loss, acc = sess.run(fetches=[model.loss, model.acc],\n",
    "                             feed_dict={model.inputs: inputs_test3, \n",
    "                                        model.indices: indices_test3, \n",
    "                                        model.initial_state: initial_state,\n",
    "                                        model.training: False})\n",
    "        print('Test3 loss:{:.4f}'.format(loss), 'accuracy:{:.4f}'.format(acc))\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        ######################################## Printing out losses ###################################\n",
    "        print('Episode losses:', losses)\n",
    "        print('Episode accuracies: ', accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
