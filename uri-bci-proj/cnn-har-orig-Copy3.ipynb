{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.16675734494015235 0.1459466811751904 0.13411316648531013 0.1749183895538629 0.1868879216539717 0.1913764961915125 0.0\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "import numpy as np\n",
    "from utilities import *\n",
    "\n",
    "# test and train read\n",
    "X_train_valid, Y_train_valid, list_ch_train_valid = read_data(data_path=\"../../../datasets/har/har-data/\", \n",
    "                                                              split=\"train\")\n",
    "X_test, Y_test, list_ch_test = read_data(data_path=\"../../../datasets/har/har-data/\", split=\"test\")\n",
    "\n",
    "assert list_ch_train_valid == list_ch_test, \"Mistmatch in channels!\"\n",
    "assert Y_train_valid.max(axis=0) == Y_test.max(axis=0)\n",
    "\n",
    "print(np.mean(Y_train_valid==0), np.mean(Y_train_valid==1), np.mean(Y_train_valid==2), \n",
    "      np.mean(Y_train_valid==3), np.mean(Y_train_valid==4), np.mean(Y_train_valid==5),\n",
    "      np.mean(Y_train_valid==6), np.mean(Y_train_valid==7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.16675734494015235 0.1459466811751904 0.13411316648531013 0.1749183895538629 0.1868879216539717 0.1913764961915125 0.0\n",
      "(7352, 6) float64 (2947, 6) float64\n"
     ]
    }
   ],
   "source": [
    "# Preparing input and output data\n",
    "# from utilities import *\n",
    "\n",
    "# Normalizing/standardizing the input data features\n",
    "X_train_valid_norm, X_test_norm = standardize(test=X_test, train=X_train_valid)\n",
    "\n",
    "# Onehot encoding/vectorizing the output data labels\n",
    "print(np.mean((Y_train_valid).reshape(-1)==0), np.mean((Y_train_valid).reshape(-1)==1),\n",
    "     np.mean((Y_train_valid).reshape(-1)==2), np.mean((Y_train_valid).reshape(-1)==3),\n",
    "     np.mean((Y_train_valid).reshape(-1)==4), np.mean((Y_train_valid).reshape(-1)==5),\n",
    "     np.mean((Y_train_valid).reshape(-1)==6), np.mean((Y_train_valid).reshape(-1)==7))\n",
    "\n",
    "Y_train_valid_onehot = one_hot(labels=Y_train_valid.reshape(-1), n_class=6) \n",
    "Y_test_onehot = one_hot(labels=Y_test.reshape(-1), n_class=6) \n",
    "\n",
    "print(Y_train_valid_onehot.shape, Y_train_valid_onehot.dtype, \n",
    "      Y_test_onehot.shape, Y_test_onehot.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5146, 128, 9) (2206, 128, 9) (5146, 6) (2206, 6)\n"
     ]
    }
   ],
   "source": [
    "# Train and valid split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_norm, X_valid_norm, Y_train_onehot, Y_valid_onehot = train_test_split(X_train_valid_norm, \n",
    "                                                                              Y_train_valid_onehot,\n",
    "                                                                              test_size=0.30)\n",
    "\n",
    "print(X_train_norm.shape, X_valid_norm.shape, Y_train_onehot.shape, Y_valid_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Input data which is divided into train, valid, and testing.\n",
    "N, W, Cin = X_valid_norm.shape[0], X_train_norm.shape[1], X_train_norm.shape[2]\n",
    "X = tf.placeholder(dtype=tf.float32, name=None, shape=[N, W, Cin])\n",
    "print(X.shape, X.dtype)\n",
    "\n",
    "# Output data/labels\n",
    "assert Y_train_valid.max(axis=0)==Y_test.max(axis=0)\n",
    "Cout = Y_train_valid.max(axis=0)\n",
    "Y = tf.placeholder(dtype=tf.float32, name=None, shape=[N, Cout])\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(64, 9, 18) <dtype: 'float32_ref'>\n",
      "(2206, 64, 18) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# One convolution layer\n",
    "print(X.shape, X.dtype)\n",
    "# NWC: N is not important for weights/filters/kernels since it is not being convolved.\n",
    "Wwidth, Wchannels, Wnumber = X.shape[1].value//2, X.shape[2].value, X.shape[2].value*2\n",
    "shape = [Wwidth, Wchannels, Wnumber]\n",
    "initial_value = tf.random_normal(dtype=X.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "Wconv = tf.Variable(dtype=X.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(Wconv.shape, Wconv.dtype)\n",
    "Xconv = tf.nn.conv1d(data_format='NWC', filters=Wconv, name=None, padding='SAME', stride=2, use_cudnn_on_gpu=True, \n",
    "                     value=X)\n",
    "# Relu or nonlinearity/activation should also be implemnted\n",
    "# leaky relu is what I am interested in which is the simplest possible non-linearity and gets the job easily done.\n",
    "Xconv = tf.maximum(name=None, x=0.1*Xconv, y=1.0*Xconv)\n",
    "print(Xconv.shape, Xconv.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 1152) <dtype: 'float32'>\n",
      "(1152, 6) <dtype: 'float32_ref'>\n",
      "(2206, 6) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# This is a multiplication layer/ dense/fully-connected/gobal\n",
    "# shape = [-1, Xconv.shape[1].value*Xconv.shape[2].value] # N is None which is a value or creating an extra index\n",
    "shape = [Xconv.shape[0].value, Xconv.shape[1].value*Xconv.shape[2].value]\n",
    "Xconv_reshaped = tf.reshape(name=None, shape=shape, tensor=Xconv)\n",
    "print(Xconv_reshaped.shape, Xconv_reshaped.dtype)\n",
    "# print(Y.shape, Y.dtype)\n",
    "# In this layer there is not very much \n",
    "# Wwidth, Wchannels, Wnumber which is for a normal conv layer\n",
    "# NWC or WCN but for a dense layer, there is no W or H it is just CN or NC\n",
    "Wchannels, Wnumber = Xconv_reshaped.shape[1].value, Y.shape[1].value\n",
    "shape = [Wchannels, Wnumber]\n",
    "# print(shape)\n",
    "initial_value = tf.random_normal(dtype=Xconv_reshaped.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "W = tf.Variable(dtype=Xconv_reshaped.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(W.shape, W.dtype)\n",
    "logits = tf.matmul(a=Xconv_reshaped, b=W, name=None)\n",
    "print(logits.shape, logits.dtype)\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"softmax_cross_entropy_with_logits_4/Reshape_2:0\", shape=(2206,), dtype=float32)\n",
      "Tensor(\"Mean_3:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "loss_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y, name=None)\n",
    "print(loss_tensor)\n",
    "loss = tf.reduce_mean(axis=0, input_tensor=loss_tensor)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_Variable/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_2/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "# __init__(\n",
    "#     learning_rate=0.001,\n",
    "#     beta1=0.9,\n",
    "#     beta2=0.999,\n",
    "#     epsilon=1e-08,\n",
    "#     use_locking=False,\n",
    "#     name='Adam'\n",
    "# )\n",
    "# minimize(\n",
    "#     loss,\n",
    "#     global_step=None,\n",
    "#     var_list=None,\n",
    "#     gate_gradients=GATE_OP,\n",
    "#     aggregation_method=None,\n",
    "#     colocate_gradients_with_ops=False,\n",
    "#     name=None,\n",
    "#     grad_loss=None\n",
    "# )\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss=loss)\n",
    "print('optimizer', optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Accuracy\n",
    "# correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "# print('correct_pred, accuracy', correct_pred, accuracy)\n",
    "\n",
    "# # Confusion matrix\n",
    "# confusion_matrix = tf.confusion_matrix(predictions=tf.argmax(logits, 1),\n",
    "#                                        labels=tf.argmax(labels_, 1))\n",
    "# print('confusion_matrix', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minibatching techniques for online learning and offline learning of big dataset\n",
    "# for X, Y in get_batches(X=X_train_norm, batch_size=N, y=Y_train_onehot):\n",
    "#     print(X.shape, X.dtype, Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 training loss: 542.79504 validation loss: 526.4999\n",
      "epoch: 1 training loss: 515.9184 validation loss: 501.64417\n",
      "epoch: 2 training loss: 489.96838 validation loss: 477.48352\n",
      "epoch: 3 training loss: 464.84717 validation loss: 454.15613\n",
      "epoch: 4 training loss: 440.50757 validation loss: 431.68387\n",
      "epoch: 5 training loss: 417.0733 validation loss: 410.10068\n",
      "epoch: 6 training loss: 394.45428 validation loss: 389.3358\n",
      "epoch: 7 training loss: 372.67578 validation loss: 369.51956\n",
      "epoch: 8 training loss: 351.73694 validation loss: 350.6265\n",
      "epoch: 9 training loss: 331.6328 validation loss: 332.60657\n",
      "epoch: 10 training loss: 312.57733 validation loss: 316.24683\n",
      "epoch: 11 training loss: 295.37946 validation loss: 302.45642\n",
      "epoch: 12 training loss: 280.96423 validation loss: 291.04907\n",
      "epoch: 13 training loss: 269.44397 validation loss: 281.95306\n",
      "epoch: 14 training loss: 260.45303 validation loss: 274.35614\n",
      "epoch: 15 training loss: 252.99371 validation loss: 267.6144\n",
      "epoch: 16 training loss: 246.26756 validation loss: 261.3104\n",
      "epoch: 17 training loss: 240.01355 validation loss: 255.2236\n",
      "epoch: 18 training loss: 233.98611 validation loss: 249.32913\n",
      "epoch: 19 training loss: 228.1202 validation loss: 243.57338\n",
      "epoch: 20 training loss: 222.42062 validation loss: 238.00122\n",
      "epoch: 21 training loss: 216.88593 validation loss: 232.63\n",
      "epoch: 22 training loss: 211.52206 validation loss: 227.44559\n",
      "epoch: 23 training loss: 206.34137 validation loss: 222.47815\n",
      "epoch: 24 training loss: 201.38995 validation loss: 217.74397\n",
      "epoch: 25 training loss: 196.66331 validation loss: 213.273\n",
      "epoch: 26 training loss: 192.19635 validation loss: 209.10986\n",
      "epoch: 27 training loss: 188.04625 validation loss: 205.29292\n",
      "epoch: 28 training loss: 184.21661 validation loss: 201.76788\n",
      "epoch: 29 training loss: 180.63373 validation loss: 198.44907\n",
      "epoch: 30 training loss: 177.21596 validation loss: 195.25902\n",
      "epoch: 31 training loss: 173.91113 validation loss: 192.16049\n",
      "epoch: 32 training loss: 170.70999 validation loss: 189.15332\n",
      "epoch: 33 training loss: 167.5924 validation loss: 186.24976\n",
      "epoch: 34 training loss: 164.5503 validation loss: 183.44151\n",
      "epoch: 35 training loss: 161.59775 validation loss: 180.71953\n",
      "epoch: 36 training loss: 158.74619 validation loss: 178.07632\n",
      "epoch: 37 training loss: 155.99667 validation loss: 175.5076\n",
      "epoch: 38 training loss: 153.33997 validation loss: 173.03558\n",
      "epoch: 39 training loss: 150.76082 validation loss: 170.65657\n",
      "epoch: 40 training loss: 148.28741 validation loss: 168.36046\n",
      "epoch: 41 training loss: 145.90138 validation loss: 166.15486\n",
      "epoch: 42 training loss: 143.59338 validation loss: 164.0235\n",
      "epoch: 43 training loss: 141.35092 validation loss: 161.94582\n",
      "epoch: 44 training loss: 139.15385 validation loss: 159.9213\n",
      "epoch: 45 training loss: 137.00154 validation loss: 157.93706\n",
      "epoch: 46 training loss: 134.89624 validation loss: 155.99165\n",
      "epoch: 47 training loss: 132.82742 validation loss: 154.08095\n",
      "epoch: 48 training loss: 130.80629 validation loss: 152.20065\n",
      "epoch: 49 training loss: 128.83035 validation loss: 150.35355\n",
      "epoch: 50 training loss: 126.89932 validation loss: 148.54301\n",
      "epoch: 51 training loss: 125.012566 validation loss: 146.75787\n",
      "epoch: 52 training loss: 123.16055 validation loss: 144.99518\n",
      "epoch: 53 training loss: 121.3353 validation loss: 143.26785\n",
      "epoch: 54 training loss: 119.53361 validation loss: 141.57057\n",
      "epoch: 55 training loss: 117.76204 validation loss: 139.90623\n",
      "epoch: 56 training loss: 116.02428 validation loss: 138.27205\n",
      "epoch: 57 training loss: 114.313354 validation loss: 136.66809\n",
      "epoch: 58 training loss: 112.628105 validation loss: 135.09372\n",
      "epoch: 59 training loss: 110.97166 validation loss: 133.54915\n",
      "epoch: 60 training loss: 109.33684 validation loss: 132.04497\n",
      "epoch: 61 training loss: 107.737274 validation loss: 130.56638\n",
      "epoch: 62 training loss: 106.172424 validation loss: 129.0997\n",
      "epoch: 63 training loss: 104.64572 validation loss: 127.646416\n",
      "epoch: 64 training loss: 103.14481 validation loss: 126.219795\n",
      "epoch: 65 training loss: 101.670334 validation loss: 124.82164\n",
      "epoch: 66 training loss: 100.22108 validation loss: 123.44386\n",
      "epoch: 67 training loss: 98.80266 validation loss: 122.091736\n",
      "epoch: 68 training loss: 97.41164 validation loss: 120.757355\n",
      "epoch: 69 training loss: 96.041245 validation loss: 119.44634\n",
      "epoch: 70 training loss: 94.69037 validation loss: 118.17245\n",
      "epoch: 71 training loss: 93.36048 validation loss: 116.91549\n",
      "epoch: 72 training loss: 92.05265 validation loss: 115.672874\n",
      "epoch: 73 training loss: 90.77266 validation loss: 114.453804\n",
      "epoch: 74 training loss: 89.51955 validation loss: 113.25765\n",
      "epoch: 75 training loss: 88.28172 validation loss: 112.0875\n",
      "epoch: 76 training loss: 87.06624 validation loss: 110.94023\n",
      "epoch: 77 training loss: 85.866 validation loss: 109.804634\n",
      "epoch: 78 training loss: 84.67743 validation loss: 108.69141\n",
      "epoch: 79 training loss: 83.499344 validation loss: 107.593544\n",
      "epoch: 80 training loss: 82.33618 validation loss: 106.50624\n",
      "epoch: 81 training loss: 81.18572 validation loss: 105.432014\n",
      "epoch: 82 training loss: 80.044716 validation loss: 104.36572\n",
      "epoch: 83 training loss: 78.92199 validation loss: 103.31162\n",
      "epoch: 84 training loss: 77.81765 validation loss: 102.272385\n",
      "epoch: 85 training loss: 76.73552 validation loss: 101.24881\n",
      "epoch: 86 training loss: 75.667145 validation loss: 100.2494\n",
      "epoch: 87 training loss: 74.61113 validation loss: 99.27377\n",
      "epoch: 88 training loss: 73.56708 validation loss: 98.31948\n",
      "epoch: 89 training loss: 72.53294 validation loss: 97.387215\n",
      "epoch: 90 training loss: 71.51198 validation loss: 96.47057\n",
      "epoch: 91 training loss: 70.50503 validation loss: 95.558235\n",
      "epoch: 92 training loss: 69.5068 validation loss: 94.64953\n",
      "epoch: 93 training loss: 68.522995 validation loss: 93.74688\n",
      "epoch: 94 training loss: 67.549515 validation loss: 92.8548\n",
      "epoch: 95 training loss: 66.58699 validation loss: 91.97308\n",
      "epoch: 96 training loss: 65.63904 validation loss: 91.10045\n",
      "epoch: 97 training loss: 64.71048 validation loss: 90.23639\n",
      "epoch: 98 training loss: 63.79791 validation loss: 89.38553\n",
      "epoch: 99 training loss: 62.898254 validation loss: 88.54899\n"
     ]
    }
   ],
   "source": [
    "# Plotting the learning/loss curve\n",
    "train_loss, valid_loss = [], []\n",
    "\n",
    "# Save the training result or trained and validated model params\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "   \n",
    "    # Loop over epochs\n",
    "    epochs=100\n",
    "    for epoch in range(0, epochs, 1): # start=0, stop=epochs, step=1\n",
    "        \n",
    "        # Training\n",
    "        loss_batch = []\n",
    "        for Xarr, Yarr in get_batches(X=X_train_norm, batch_size=N, y=Y_train_onehot):\n",
    "\n",
    "            # feeding the input array into TF framework and fetche the output\n",
    "            feed_dict = {X:Xarr, Y:Yarr}\n",
    "            lossarr, _ = sess.run(feed_dict=feed_dict, fetches=[loss, optimizer])\n",
    "            loss_batch.append(lossarr)\n",
    "        \n",
    "        # Averaging the loss of the batch/minibatch\n",
    "        train_loss.append(np.mean(loss_batch))\n",
    "        \n",
    "        # validation\n",
    "        feed_dict = {X:X_valid_norm, Y:Y_valid_onehot}\n",
    "        lossarr = sess.run(feed_dict=feed_dict, fetches=[loss])\n",
    "        valid_loss.append(np.mean(lossarr))\n",
    "\n",
    "        # Printing out the training and validating loss\n",
    "        print('epoch:', epoch, 'training loss:', train_loss[epoch], 'validation loss:', valid_loss[epoch])\n",
    "            \n",
    "    saver.save(save_path='checkpoints/model.ckpt', sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "# % %matplotlib inline\n",
    "# this is keeping the mpl inline or outline\n",
    "# inline would inside this block and outline/out of block would be out of this block.\n",
    "# %matplotlib inline\n",
    "# %matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "mplot.plot(train_loss, label='har train_loss')\n",
    "mplot.plot(valid_loss, label='har valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing and playing around with checkpoints and trained model saved or saved trained model\n",
    "# loaded_ckpt = tf.train.load_checkpoint(ckpt_dir_or_file='checkpoints/cnn-har.ckpt')\n",
    "# loaded_ckpt.debug_string, \n",
    "# loaded_ckpt.get_variable_to_dtype_map()\n",
    "# loaded_ckpt.get_variable_to_shape_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "(2206, 128, 9) (2206, 6)\n",
      "test_loss: 111.4286\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Restore the validated model\n",
    "    save_path = tf.train.latest_checkpoint(checkpoint_dir='checkpoints')\n",
    "    saver.restore(save_path=save_path, sess=sess)\n",
    "    \n",
    "    loss_batch = []\n",
    "    for Xarr, Yarr in get_batches(X=X_test_norm, batch_size=N, y=Y_test_onehot):\n",
    "        print(Xarr.shape, Yarr.shape)\n",
    "        feed_dict = {X:Xarr, Y:Yarr}\n",
    "        lossarr = sess.run(feed_dict=feed_dict, fetches=[loss])\n",
    "        loss_batch.append(lossarr)\n",
    "\n",
    "    # Print info for every iter/epoch\n",
    "    print('test_loss:', np.mean(loss_batch))\n",
    "#     print(\"Test loss: {:6f}\".format(np.mean(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
