{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['body_acc_x', 'body_acc_y', 'body_acc_z', 'body_gyro_x', 'body_gyro_y', 'body_gyro_z', 'total_acc_x', 'total_acc_y', 'total_acc_z'] ['body_acc_x', 'body_acc_y', 'body_acc_z', 'body_gyro_x', 'body_gyro_y', 'body_gyro_z', 'total_acc_x', 'total_acc_y', 'total_acc_z']\n",
      "6 6\n",
      "0.0 0.16675734494015235 0.1459466811751904 0.13411316648531013 0.1749183895538629 0.1868879216539717 0.1913764961915125 0.0\n",
      "(7352,) (2947,)\n",
      "(7352, 6) (2947, 6)\n",
      "(5146, 128, 9) (2206, 128, 9) (5146, 6) (2206, 6)\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "import numpy as np\n",
    "from utilities import *\n",
    "\n",
    "# test and train read\n",
    "Xtrain, Ytrain, list_ch_train = read_data(data_path=\"../../../datasets/har/har-data/\", split=\"train\")\n",
    "Xtest, Ytest, list_ch_test = read_data(data_path=\"../../../datasets/har/har-data/\", split=\"test\")\n",
    "\n",
    "print(list_ch_test, list_ch_train)\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\"\n",
    "assert Ytrain.max(axis=0) == Ytest.max(axis=0)\n",
    "print(Ytrain.max(axis=0), Ytest.max(axis=0))\n",
    "\n",
    "print(np.mean(Ytrain==0), np.mean(Ytrain==1), np.mean(Ytrain==2), np.mean(Ytrain==3), np.mean(Ytrain==4), \n",
    "      np.mean(Ytrain==5), np.mean(Ytrain==6), np.mean(Ytrain==7))\n",
    "\n",
    "# Normalizing/standardizing the input data features\n",
    "Xtrain, Xtest = standardize(test=Xtest, train=Xtrain)\n",
    "\n",
    "# Onehot encoding of the output labels\n",
    "print(Ytrain.shape, Ytest.shape)\n",
    "Ytrain = one_hot(labels=Ytrain.reshape(-1), n_class=6) \n",
    "Ytest = one_hot(labels=Ytest.reshape(-1), n_class=6)\n",
    "print(Ytrain.shape, Ytest.shape)\n",
    "\n",
    "# Train and valid split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 30% of the training data/ entire training data is assigned to validation.\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtrain, Ytrain, test_size=0.30)\n",
    "print(Xtrain.shape, Xvalid.shape, Ytrain.shape, Yvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Input data which is divided into train, valid, and testing.\n",
    "N, W, Cin = Xvalid.shape[0], Xtrain.shape[1], Xtrain.shape[2]\n",
    "X = tf.placeholder(dtype=tf.float32, name=None, shape=[N, W, Cin])\n",
    "print(X.shape, X.dtype)\n",
    "\n",
    "# Output data/labels\n",
    "# assert Ytrain.max(axis=0)==Ytest.max(axis=0)\n",
    "# Cout = Ytrain.max(axis=0)\n",
    "# n_class=6\n",
    "Cout = 6\n",
    "Y = tf.placeholder(dtype=tf.float32, name=None, shape=[N, Cout])\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(64, 9, 18) <dtype: 'float32_ref'>\n",
      "(2206, 64, 18) <dtype: 'float32'>\n",
      "(2206, 1, 18) <dtype: 'float32_ref'>\n",
      "(2206, 64, 18) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# One convolution layer\n",
    "print(X.shape, X.dtype)\n",
    "Wwidth, Wchannels, Wnumber = X.shape[1].value//2, X.shape[2].value, X.shape[2].value*2\n",
    "shape = [Wwidth, Wchannels, Wnumber]\n",
    "initial_value = tf.random_normal(dtype=X.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "Wconv = tf.Variable(dtype=X.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(Wconv.shape, Wconv.dtype)\n",
    "Xconv = tf.nn.conv1d(data_format='NWC', filters=Wconv, name=None, padding='SAME', stride=2, use_cudnn_on_gpu=True, \n",
    "                     value=X)\n",
    "print(Xconv.shape, Xconv.dtype)\n",
    "# This is the place to add a bias to the equation\n",
    "# tf.zeros(\n",
    "#     shape,\n",
    "#     dtype=tf.float32,\n",
    "#     name=None\n",
    "# )\n",
    "shape = [Xconv.shape[0].value, 1, Xconv.shape[2].value]\n",
    "initial_value = tf.zeros(dtype=Xconv.dtype, shape=shape)\n",
    "Bconv = tf.Variable(dtype=Xconv.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(Bconv.shape, Bconv.dtype)\n",
    "Xconv += Bconv\n",
    "Xconv = tf.maximum(name=None, x=(-0.1*Xconv), y=Xconv)\n",
    "print(Xconv.shape, Xconv.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 1152) <dtype: 'float32'>\n",
      "(1152, 6) <dtype: 'float32_ref'>\n",
      "(2206, 6) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32_ref'>\n",
      "(2206, 6) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Multiplication layer\n",
    "# shape = [-1, Xconv.shape[1].value*Xconv.shape[2].value] # N is None which is a value or creating an extra index\n",
    "shape = [Xconv.shape[0].value, Xconv.shape[1].value*Xconv.shape[2].value]\n",
    "Xconv_reshaped = tf.reshape(name=None, shape=shape, tensor=Xconv)\n",
    "print(Xconv_reshaped.shape, Xconv_reshaped.dtype)\n",
    "Wchannels, Wnumber = Xconv_reshaped.shape[1].value, Y.shape[1].value\n",
    "shape = [Wchannels, Wnumber]\n",
    "initial_value = tf.random_normal(dtype=Xconv_reshaped.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "W = tf.Variable(dtype=Xconv_reshaped.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(W.shape, W.dtype)\n",
    "logits = tf.matmul(a=Xconv_reshaped, b=W, name=None)\n",
    "print(logits.shape, logits.dtype)\n",
    "shape = [logits.shape[0].value, logits.shape[1].value]\n",
    "initial_value = tf.zeros(dtype=logits.dtype, name=None, shape=shape)\n",
    "B = tf.Variable(dtype=logits.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(B.shape, B.dtype)\n",
    "logits += B\n",
    "print(logits.shape, logits.dtype)\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206,) <dtype: 'float32'>\n",
      "() <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "loss_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y, name=None)\n",
    "print(loss_tensor.shape, loss_tensor.dtype)\n",
    "loss = tf.reduce_mean(axis=0, input_tensor=loss_tensor)\n",
    "print(loss.shape, loss.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer name: \"Adam_1\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam_1/update_Variable_15/ApplyAdam\"\n",
      "input: \"^Adam_1/update_Variable_16/ApplyAdam\"\n",
      "input: \"^Adam_1/update_Variable_17/ApplyAdam\"\n",
      "input: \"^Adam_1/update_Variable_18/ApplyAdam\"\n",
      "input: \"^Adam_1/Assign\"\n",
      "input: \"^Adam_1/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "# __init__(\n",
    "#     learning_rate=0.001,\n",
    "#     beta1=0.9,\n",
    "#     beta2=0.999,\n",
    "#     epsilon=1e-08,\n",
    "#     use_locking=False,\n",
    "#     name='Adam'\n",
    "# )\n",
    "# minimize(\n",
    "#     loss,\n",
    "#     global_step=None,\n",
    "#     var_list=None,\n",
    "#     gate_gradients=GATE_OP,\n",
    "#     aggregation_method=None,\n",
    "#     colocate_gradients_with_ops=False,\n",
    "#     name=None,\n",
    "#     grad_loss=None\n",
    "# )\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss=loss)\n",
    "print('optimizer', optimizer)\n",
    "# adam = tf.train.AdamOptimizer\n",
    "# print(adam)\n",
    "# optimizer = adam.minimize(loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 6) <dtype: 'float32'>\n",
      "(2206,) <dtype: 'int32'>\n",
      "(2206, 6) <dtype: 'float32'>\n",
      "(2206,) <dtype: 'int32'>\n",
      "(2206, 6) <dtype: 'float32'>\n",
      "(2206,) <dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape, logits.dtype)\n",
    "# Accuracy\n",
    "# tf.argmax(\n",
    "#     input,\n",
    "#     axis=None,\n",
    "#     name=None,\n",
    "#     dimension=None,\n",
    "#     output_type=tf.int64\n",
    "# )\n",
    "Ypred = tf.argmax(axis=1, name=None, input=logits, output_type=tf.int32)\n",
    "# # tf.max is finding the max value among all the arguments and indices\n",
    "# # tf.argmax is finding the arg/index with the max value\n",
    "# Ylabel = tf.argmax()\n",
    "print(Ypred.shape, Ypred.dtype)\n",
    "\n",
    "# tf.nn.softmax(\n",
    "#     logits,\n",
    "#     axis=None,\n",
    "#     name=None,\n",
    "#     dim=None\n",
    "# )\n",
    "# softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
    "prob = tf.nn.softmax(axis=1, logits=logits, name=None)\n",
    "print(prob.shape, prob.dtype)\n",
    "Ypred2 = tf.argmax(axis=1, input=prob, name=None, output_type=tf.int32) \n",
    "print(Ypred2.shape, Ypred2.dtype)\n",
    "\n",
    "print(Y.shape, Y.dtype)\n",
    "Yref = tf.argmax(axis=1, input=Y, name=None, output_type=tf.int32)\n",
    "print(Yref.shape, Yref.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206,) <dtype: 'bool'>\n",
      "(2206,) <dtype: 'float16'>\n",
      "() <dtype: 'float16'>\n"
     ]
    }
   ],
   "source": [
    "acc_tensor = tf.equal(name=None, x=Ypred, y=Yref)\n",
    "print(acc_tensor.shape, acc_tensor.dtype)\n",
    "# cast bool to int datatype for equal\n",
    "acc_tensor = tf.cast(dtype=tf.float16, name=None, x=acc_tensor)\n",
    "print(acc_tensor.shape, acc_tensor.dtype)\n",
    "acc = tf.reduce_mean(axis=0, input_tensor=acc_tensor)\n",
    "print(acc.shape, acc.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206,) <dtype: 'bool'>\n",
      "(2206,) <dtype: 'float16'>\n",
      "() <dtype: 'float16'>\n"
     ]
    }
   ],
   "source": [
    "acc_tensor = tf.equal(name=None, x=Ypred2, y=Yref)\n",
    "print(acc_tensor.shape, acc_tensor.dtype)\n",
    "# cast bool to int datatype for equal\n",
    "acc_tensor = tf.cast(dtype=tf.float16, name=None, x=acc_tensor)\n",
    "print(acc_tensor.shape, acc_tensor.dtype)\n",
    "acc2 = tf.reduce_mean(axis=0, input_tensor=acc_tensor)\n",
    "print(acc2.shape, acc2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confusion matrix\n",
    "# confusion_matrix = tf.confusion_matrix(predictions=tf.argmax(logits, 1),\n",
    "#                                        labels=tf.argmax(labels_, 1))\n",
    "# print('confusion_matrix', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minibatching techniques for online learning and offline learning of big dataset\n",
    "# for X, Y in get_batches(X=X_train_norm, batch_size=N, y=Y_train_onehot):\n",
    "#     print(X.shape, X.dtype, Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 training loss: 561.2964 validation loss: 544.33466 training accuracy: 0.1594 validation accuracy: 0.1564\n",
      "epoch: 1 training loss: 530.44995 validation loss: 514.6064 training accuracy: 0.1532 validation accuracy: 0.1519\n",
      "epoch: 2 training loss: 500.82245 validation loss: 486.2585 training accuracy: 0.1465 validation accuracy: 0.1473\n",
      "epoch: 3 training loss: 472.7475 validation loss: 459.43063 training accuracy: 0.1407 validation accuracy: 0.1442\n",
      "epoch: 4 training loss: 446.10675 validation loss: 434.04224 training accuracy: 0.1389 validation accuracy: 0.1373\n",
      "epoch: 5 training loss: 421.02567 validation loss: 410.35565 training accuracy: 0.1365 validation accuracy: 0.1392\n",
      "epoch: 6 training loss: 397.63184 validation loss: 388.1362 training accuracy: 0.1349 validation accuracy: 0.1378\n",
      "epoch: 7 training loss: 375.4524 validation loss: 366.61246 training accuracy: 0.1355 validation accuracy: 0.141\n",
      "epoch: 8 training loss: 353.85007 validation loss: 345.35574 training accuracy: 0.1411 validation accuracy: 0.1464\n",
      "epoch: 9 training loss: 332.75897 validation loss: 324.3166 training accuracy: 0.1475 validation accuracy: 0.1537\n",
      "epoch: 10 training loss: 312.08273 validation loss: 303.9391 training accuracy: 0.1573 validation accuracy: 0.17\n",
      "epoch: 11 training loss: 292.6399 validation loss: 287.42715 training accuracy: 0.1907 validation accuracy: 0.2546\n",
      "epoch: 12 training loss: 278.26575 validation loss: 277.4187 training accuracy: 0.2769 validation accuracy: 0.32\n",
      "epoch: 13 training loss: 269.08282 validation loss: 270.4772 training accuracy: 0.3313 validation accuracy: 0.3523\n",
      "epoch: 14 training loss: 262.2364 validation loss: 264.28384 training accuracy: 0.3584 validation accuracy: 0.3677\n",
      "epoch: 15 training loss: 255.85172 validation loss: 258.26126 training accuracy: 0.3696 validation accuracy: 0.3762\n",
      "epoch: 16 training loss: 249.66272 validation loss: 252.32626 training accuracy: 0.3777 validation accuracy: 0.3853\n",
      "epoch: 17 training loss: 243.54492 validation loss: 246.56339 training accuracy: 0.3862 validation accuracy: 0.3948\n",
      "epoch: 18 training loss: 237.58597 validation loss: 240.95377 training accuracy: 0.3936 validation accuracy: 0.403\n",
      "epoch: 19 training loss: 231.81451 validation loss: 235.51796 training accuracy: 0.4038 validation accuracy: 0.41\n",
      "epoch: 20 training loss: 226.26855 validation loss: 230.26971 training accuracy: 0.4126 validation accuracy: 0.4175\n",
      "epoch: 21 training loss: 220.94687 validation loss: 225.23311 training accuracy: 0.4197 validation accuracy: 0.4202\n",
      "epoch: 22 training loss: 215.8472 validation loss: 220.42558 training accuracy: 0.4272 validation accuracy: 0.4285\n",
      "epoch: 23 training loss: 210.9423 validation loss: 215.84329 training accuracy: 0.435 validation accuracy: 0.4348\n",
      "epoch: 24 training loss: 206.24503 validation loss: 211.45401 training accuracy: 0.4448 validation accuracy: 0.4414\n",
      "epoch: 25 training loss: 201.74927 validation loss: 207.25665 training accuracy: 0.4512 validation accuracy: 0.4465\n",
      "epoch: 26 training loss: 197.44653 validation loss: 203.20338 training accuracy: 0.46 validation accuracy: 0.4546\n",
      "epoch: 27 training loss: 193.31108 validation loss: 199.28484 training accuracy: 0.467 validation accuracy: 0.463\n",
      "epoch: 28 training loss: 189.34093 validation loss: 195.53088 training accuracy: 0.4744 validation accuracy: 0.4688\n",
      "epoch: 29 training loss: 185.52754 validation loss: 191.90082 training accuracy: 0.4805 validation accuracy: 0.4724\n",
      "epoch: 30 training loss: 181.84135 validation loss: 188.38083 training accuracy: 0.4873 validation accuracy: 0.4763\n",
      "epoch: 31 training loss: 178.27872 validation loss: 184.99907 training accuracy: 0.4934 validation accuracy: 0.481\n",
      "epoch: 32 training loss: 174.83893 validation loss: 181.74571 training accuracy: 0.4983 validation accuracy: 0.4856\n",
      "epoch: 33 training loss: 171.5289 validation loss: 178.60966 training accuracy: 0.503 validation accuracy: 0.4922\n",
      "epoch: 34 training loss: 168.32837 validation loss: 175.57536 training accuracy: 0.508 validation accuracy: 0.4958\n",
      "epoch: 35 training loss: 165.22119 validation loss: 172.66466 training accuracy: 0.515 validation accuracy: 0.5024\n",
      "epoch: 36 training loss: 162.18813 validation loss: 169.84401 training accuracy: 0.5186 validation accuracy: 0.5063\n",
      "epoch: 37 training loss: 159.22604 validation loss: 167.1083 training accuracy: 0.5234 validation accuracy: 0.5073\n",
      "epoch: 38 training loss: 156.33104 validation loss: 164.43697 training accuracy: 0.5254 validation accuracy: 0.5093\n",
      "epoch: 39 training loss: 153.49174 validation loss: 161.83086 training accuracy: 0.5312 validation accuracy: 0.515\n",
      "epoch: 40 training loss: 150.71988 validation loss: 159.28317 training accuracy: 0.538 validation accuracy: 0.5195\n",
      "epoch: 41 training loss: 147.99966 validation loss: 156.78824 training accuracy: 0.541 validation accuracy: 0.526\n",
      "epoch: 42 training loss: 145.32849 validation loss: 154.35599 training accuracy: 0.5444 validation accuracy: 0.531\n",
      "epoch: 43 training loss: 142.72784 validation loss: 151.99309 training accuracy: 0.5503 validation accuracy: 0.5337\n",
      "epoch: 44 training loss: 140.19775 validation loss: 149.6925 training accuracy: 0.5547 validation accuracy: 0.5366\n",
      "epoch: 45 training loss: 137.71817 validation loss: 147.46475 training accuracy: 0.5586 validation accuracy: 0.5435\n",
      "epoch: 46 training loss: 135.29033 validation loss: 145.28503 training accuracy: 0.5615 validation accuracy: 0.5464\n",
      "epoch: 47 training loss: 132.90195 validation loss: 143.13478 training accuracy: 0.5645 validation accuracy: 0.5493\n",
      "epoch: 48 training loss: 130.55223 validation loss: 141.02701 training accuracy: 0.569 validation accuracy: 0.5547\n",
      "epoch: 49 training loss: 128.24106 validation loss: 138.95166 training accuracy: 0.5713 validation accuracy: 0.558\n",
      "epoch: 50 training loss: 125.96857 validation loss: 136.90514 training accuracy: 0.5747 validation accuracy: 0.5605\n",
      "epoch: 51 training loss: 123.73219 validation loss: 134.89342 training accuracy: 0.577 validation accuracy: 0.563\n",
      "epoch: 52 training loss: 121.53401 validation loss: 132.90564 training accuracy: 0.5796 validation accuracy: 0.565\n",
      "epoch: 53 training loss: 119.383995 validation loss: 130.94269 training accuracy: 0.583 validation accuracy: 0.566\n",
      "epoch: 54 training loss: 117.27748 validation loss: 129.00131 training accuracy: 0.5864 validation accuracy: 0.57\n",
      "epoch: 55 training loss: 115.204285 validation loss: 127.08352 training accuracy: 0.588 validation accuracy: 0.572\n",
      "epoch: 56 training loss: 113.15407 validation loss: 125.18995 training accuracy: 0.59 validation accuracy: 0.5723\n",
      "epoch: 57 training loss: 111.134384 validation loss: 123.32413 training accuracy: 0.5923 validation accuracy: 0.5747\n",
      "epoch: 58 training loss: 109.15311 validation loss: 121.50592 training accuracy: 0.595 validation accuracy: 0.5776\n",
      "epoch: 59 training loss: 107.21135 validation loss: 119.73986 training accuracy: 0.5996 validation accuracy: 0.581\n",
      "epoch: 60 training loss: 105.31727 validation loss: 118.00462 training accuracy: 0.601 validation accuracy: 0.5835\n",
      "epoch: 61 training loss: 103.4536 validation loss: 116.30972 training accuracy: 0.6035 validation accuracy: 0.5854\n",
      "epoch: 62 training loss: 101.62721 validation loss: 114.6587 training accuracy: 0.607 validation accuracy: 0.591\n",
      "epoch: 63 training loss: 99.84279 validation loss: 113.05285 training accuracy: 0.6104 validation accuracy: 0.5947\n",
      "epoch: 64 training loss: 98.10425 validation loss: 111.47808 training accuracy: 0.6133 validation accuracy: 0.598\n",
      "epoch: 65 training loss: 96.40621 validation loss: 109.92461 training accuracy: 0.616 validation accuracy: 0.599\n",
      "epoch: 66 training loss: 94.73473 validation loss: 108.385925 training accuracy: 0.619 validation accuracy: 0.603\n",
      "epoch: 67 training loss: 93.09408 validation loss: 106.87304 training accuracy: 0.621 validation accuracy: 0.605\n",
      "epoch: 68 training loss: 91.48772 validation loss: 105.39034 training accuracy: 0.625 validation accuracy: 0.606\n",
      "epoch: 69 training loss: 89.90749 validation loss: 103.92775 training accuracy: 0.629 validation accuracy: 0.6064\n",
      "epoch: 70 training loss: 88.34943 validation loss: 102.48262 training accuracy: 0.631 validation accuracy: 0.6094\n",
      "epoch: 71 training loss: 86.81457 validation loss: 101.07105 training accuracy: 0.6353 validation accuracy: 0.6123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 72 training loss: 85.30595 validation loss: 99.684 training accuracy: 0.6377 validation accuracy: 0.6157\n",
      "epoch: 73 training loss: 83.824486 validation loss: 98.31981 training accuracy: 0.6406 validation accuracy: 0.6187\n",
      "epoch: 74 training loss: 82.36993 validation loss: 96.97886 training accuracy: 0.6445 validation accuracy: 0.622\n",
      "epoch: 75 training loss: 80.93591 validation loss: 95.66609 training accuracy: 0.6475 validation accuracy: 0.6245\n",
      "epoch: 76 training loss: 79.52223 validation loss: 94.38031 training accuracy: 0.6514 validation accuracy: 0.6294\n",
      "epoch: 77 training loss: 78.13992 validation loss: 93.132996 training accuracy: 0.657 validation accuracy: 0.634\n",
      "epoch: 78 training loss: 76.78821 validation loss: 91.92237 training accuracy: 0.661 validation accuracy: 0.639\n",
      "epoch: 79 training loss: 75.46876 validation loss: 90.74803 training accuracy: 0.665 validation accuracy: 0.642\n",
      "epoch: 80 training loss: 74.18056 validation loss: 89.626656 training accuracy: 0.669 validation accuracy: 0.6455\n",
      "epoch: 81 training loss: 72.9185 validation loss: 88.53928 training accuracy: 0.674 validation accuracy: 0.648\n",
      "epoch: 82 training loss: 71.685936 validation loss: 87.479965 training accuracy: 0.6787 validation accuracy: 0.651\n",
      "epoch: 83 training loss: 70.47925 validation loss: 86.44172 training accuracy: 0.6807 validation accuracy: 0.6523\n",
      "epoch: 84 training loss: 69.29768 validation loss: 85.42415 training accuracy: 0.6846 validation accuracy: 0.6553\n",
      "epoch: 85 training loss: 68.138336 validation loss: 84.42917 training accuracy: 0.6885 validation accuracy: 0.6562\n",
      "epoch: 86 training loss: 67.002426 validation loss: 83.45084 training accuracy: 0.6904 validation accuracy: 0.6562\n",
      "epoch: 87 training loss: 65.88983 validation loss: 82.482285 training accuracy: 0.6934 validation accuracy: 0.658\n",
      "epoch: 88 training loss: 64.80013 validation loss: 81.52972 training accuracy: 0.6953 validation accuracy: 0.6587\n",
      "epoch: 89 training loss: 63.732292 validation loss: 80.59948 training accuracy: 0.6997 validation accuracy: 0.662\n",
      "epoch: 90 training loss: 62.684708 validation loss: 79.68837 training accuracy: 0.701 validation accuracy: 0.6655\n",
      "epoch: 91 training loss: 61.656143 validation loss: 78.78876 training accuracy: 0.705 validation accuracy: 0.6675\n",
      "epoch: 92 training loss: 60.646313 validation loss: 77.90483 training accuracy: 0.707 validation accuracy: 0.6694\n",
      "epoch: 93 training loss: 59.650696 validation loss: 77.04153 training accuracy: 0.709 validation accuracy: 0.671\n",
      "epoch: 94 training loss: 58.665035 validation loss: 76.192635 training accuracy: 0.71 validation accuracy: 0.674\n",
      "epoch: 95 training loss: 57.698692 validation loss: 75.35803 training accuracy: 0.715 validation accuracy: 0.6763\n",
      "epoch: 96 training loss: 56.753044 validation loss: 74.54267 training accuracy: 0.7188 validation accuracy: 0.678\n",
      "epoch: 97 training loss: 55.824368 validation loss: 73.740654 training accuracy: 0.7217 validation accuracy: 0.68\n",
      "epoch: 98 training loss: 54.913574 validation loss: 72.94873 training accuracy: 0.7246 validation accuracy: 0.6816\n",
      "epoch: 99 training loss: 54.023144 validation loss: 72.165375 training accuracy: 0.7275 validation accuracy: 0.684\n"
     ]
    }
   ],
   "source": [
    "# Plotting the learning/loss curve\n",
    "train_loss, valid_loss = [], []\n",
    "train_acc, valid_acc = [], []\n",
    "\n",
    "# Save the training result or trained and validated model params\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for epoch in range(0, 100, 1): # start=0, stop=epochs, step=1\n",
    "        \n",
    "        # Training\n",
    "        loss_batch = []\n",
    "        acc_batch = []\n",
    "        for Xarr, Yarr in get_batches(X=Xtrain, batch_size=N, y=Ytrain):\n",
    "\n",
    "            # feeding the input array into TF framework and fetche the output\n",
    "            feed_dict = {X:Xarr, Y:Yarr}\n",
    "            lossarr, _, accarr = sess.run(feed_dict=feed_dict, fetches=[loss, optimizer, acc])\n",
    "            loss_batch.append(np.mean(lossarr))\n",
    "            acc_batch.append(np.mean(accarr))\n",
    "        \n",
    "        # Averaging the loss of the batch/minibatch\n",
    "        train_loss.append(np.mean(loss_batch))\n",
    "        train_acc.append(np.mean(acc_batch))\n",
    "        \n",
    "        # validation\n",
    "        feed_dict = {X:Xvalid, Y:Yvalid}\n",
    "        lossarr, accarr = sess.run(feed_dict=feed_dict, fetches=[loss, acc])\n",
    "        valid_loss.append(np.mean(lossarr))\n",
    "        valid_acc.append(np.mean(accarr))\n",
    "\n",
    "        # Printing out the training and validating loss\n",
    "        print('epoch:', epoch, 'training loss:', train_loss[epoch], 'validation loss:', valid_loss[epoch], \n",
    "              'training accuracy:', train_acc[epoch], 'validation accuracy:', valid_acc[epoch])\n",
    "            \n",
    "    saver.save(save_path='checkpoints/model.ckpt', sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "%matplotlib inline\n",
    "\n",
    "mplot.plot(train_loss, label='har train_loss')\n",
    "mplot.plot(valid_loss, label='har valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beta2_power_1': [],\n",
       " 'beta2_power': [],\n",
       " 'beta1_power_2': [],\n",
       " 'beta1_power_1': [],\n",
       " 'beta1_power': [],\n",
       " 'Variable_7/Adam_1': [1152, 6],\n",
       " 'Variable_7/Adam': [1152, 6],\n",
       " 'Variable_6/Adam_1': [64, 9, 18],\n",
       " 'beta2_power_2': [],\n",
       " 'Variable_1/Adam': [1152, 6],\n",
       " 'Variable/Adam': [64, 9, 18],\n",
       " 'Variable': [64, 9, 18],\n",
       " 'Variable_1': [1152, 6],\n",
       " 'Variable/Adam_1': [64, 9, 18],\n",
       " 'Variable_3': [1152, 6],\n",
       " 'Variable_4': [1152, 6],\n",
       " 'Variable_7': [1152, 6],\n",
       " 'Variable_2/Adam_1': [64, 9, 18],\n",
       " 'Variable_2/Adam': [64, 9, 18],\n",
       " 'Variable_5/Adam': [1152, 6],\n",
       " 'Variable_2': [64, 9, 18],\n",
       " 'Variable_5': [1152, 6],\n",
       " 'Variable_6': [64, 9, 18],\n",
       " 'Variable_1/Adam_1': [1152, 6],\n",
       " 'Variable_5/Adam_1': [1152, 6],\n",
       " 'Variable_6/Adam': [64, 9, 18]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing and playing around with checkpoints and trained model saved or saved trained model\n",
    "loaded_ckpt = tf.train.load_checkpoint(ckpt_dir_or_file='checkpoints/cnn-har.ckpt')\n",
    "loaded_ckpt.get_variable_to_shape_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "test loss: 100.82767 test accuracy: 0.559\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Restore the validated model\n",
    "    save_path = tf.train.latest_checkpoint(checkpoint_dir='checkpoints/')\n",
    "    saver.restore(save_path=save_path, sess=sess)\n",
    "    \n",
    "    loss_batch = []\n",
    "    acc_batch = []\n",
    "    for Xarr, Yarr in get_batches(X=Xtest, batch_size=N, y=Ytest):\n",
    "        feed_dict = {X:Xarr, Y:Yarr}\n",
    "        lossarr, accarr = sess.run(feed_dict=feed_dict, fetches=[loss, acc])\n",
    "        loss_batch.append(np.mean(lossarr))\n",
    "        acc_batch.append(np.mean(accarr))\n",
    "\n",
    "    # Print info for every iter/epoch\n",
    "    print('test loss:', np.mean(loss_batch), 'test accuracy:', np.mean(acc_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
