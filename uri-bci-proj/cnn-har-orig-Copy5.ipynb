{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "import numpy as np\n",
    "from utilities import *\n",
    "\n",
    "# test and train read\n",
    "Xtrain, Ytrain, list_ch_train = read_data(data_path=\"../../../datasets/har/har-data/\", split=\"train\")\n",
    "Xtest, Ytest, list_ch_test = read_data(data_path=\"../../../datasets/har/har-data/\", split=\"test\")\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\"\n",
    "assert Ytrain.max(axis=0) == Ytest.max(axis=0)\n",
    "\n",
    "# print(np.mean(Y_train_valid==0), np.mean(Y_train_valid==1), np.mean(Y_train_valid==2), \n",
    "#       np.mean(Y_train_valid==3), np.mean(Y_train_valid==4), np.mean(Y_train_valid==5),\n",
    "#       np.mean(Y_train_valid==6), np.mean(Y_train_valid==7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing input and output data\n",
    "# from utilities import *\n",
    "\n",
    "# Normalizing/standardizing the input data features\n",
    "Xtrain, Xtest = standardize(test=Xtest, train=Xtrain)\n",
    "\n",
    "# # Onehot encoding/vectorizing the output data labels\n",
    "# print(np.mean((Y_train_valid).reshape(-1)==0), np.mean((Y_train_valid).reshape(-1)==1),\n",
    "#      np.mean((Y_train_valid).reshape(-1)==2), np.mean((Y_train_valid).reshape(-1)==3),\n",
    "#      np.mean((Y_train_valid).reshape(-1)==4), np.mean((Y_train_valid).reshape(-1)==5),\n",
    "#      np.mean((Y_train_valid).reshape(-1)==6), np.mean((Y_train_valid).reshape(-1)==7))\n",
    "\n",
    "Ytrain = one_hot(labels=Ytrain.reshape(-1), n_class=6) \n",
    "Ytest = one_hot(labels=Ytest.reshape(-1), n_class=6) \n",
    "\n",
    "# print(Y_train_valid_onehot.shape, Y_train_valid_onehot.dtype, \n",
    "#       Y_test_onehot.shape, Y_test_onehot.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and valid split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 30% of the training data/ entire training data is assigned to validation.\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtrain, Ytrain, test_size=0.30)\n",
    "\n",
    "# print(X_train_norm.shape, X_valid_norm.shape, Y_train_onehot.shape, Y_valid_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Input data which is divided into train, valid, and testing.\n",
    "N, W, Cin = Xvalid.shape[0], Xtrain.shape[1], Xtrain.shape[2]\n",
    "X = tf.placeholder(dtype=tf.float32, name=None, shape=[N, W, Cin])\n",
    "print(X.shape, X.dtype)\n",
    "\n",
    "# Output data/labels\n",
    "# assert Ytrain.max(axis=0)==Ytest.max(axis=0)\n",
    "# Cout = Ytrain.max(axis=0)\n",
    "n_class=6\n",
    "Cout = n_class\n",
    "Y = tf.placeholder(dtype=tf.float32, name=None, shape=[N, Cout])\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(64, 9, 18) <dtype: 'float32_ref'>\n",
      "(2206, 64, 18) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# One convolution layer\n",
    "print(X.shape, X.dtype)\n",
    "# NWC: N is not important for weights/filters/kernels since it is not being convolved.\n",
    "Wwidth, Wchannels, Wnumber = X.shape[1].value//2, X.shape[2].value, X.shape[2].value*2\n",
    "shape = [Wwidth, Wchannels, Wnumber]\n",
    "initial_value = tf.random_normal(dtype=X.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "Wconv = tf.Variable(dtype=X.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(Wconv.shape, Wconv.dtype)\n",
    "Xconv = tf.nn.conv1d(data_format='NWC', filters=Wconv, name=None, padding='SAME', stride=2, use_cudnn_on_gpu=True, \n",
    "                     value=X)\n",
    "# Relu or nonlinearity/activation should also be implemnted\n",
    "# leaky relu is what I am interested in which is the simplest possible non-linearity and gets the job easily done.\n",
    "Xconv = tf.maximum(name=None, x=(-0.1*Xconv), y=Xconv)\n",
    "print(Xconv.shape, Xconv.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 1152) <dtype: 'float32'>\n",
      "(1152, 6) <dtype: 'float32_ref'>\n",
      "(2206, 6) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# This is a multiplication layer/ dense/fully-connected/gobal\n",
    "# shape = [-1, Xconv.shape[1].value*Xconv.shape[2].value] # N is None which is a value or creating an extra index\n",
    "shape = [Xconv.shape[0].value, Xconv.shape[1].value*Xconv.shape[2].value]\n",
    "Xconv_reshaped = tf.reshape(name=None, shape=shape, tensor=Xconv)\n",
    "print(Xconv_reshaped.shape, Xconv_reshaped.dtype)\n",
    "# print(Y.shape, Y.dtype)\n",
    "# In this layer there is not very much \n",
    "# Wwidth, Wchannels, Wnumber which is for a normal conv layer\n",
    "# NWC or WCN but for a dense layer, there is no W or H it is just CN or NC\n",
    "Wchannels, Wnumber = Xconv_reshaped.shape[1].value, Y.shape[1].value\n",
    "shape = [Wchannels, Wnumber]\n",
    "# print(shape)\n",
    "initial_value = tf.random_normal(dtype=Xconv_reshaped.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "W = tf.Variable(dtype=Xconv_reshaped.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(W.shape, W.dtype)\n",
    "logits = tf.matmul(a=Xconv_reshaped, b=W, name=None)\n",
    "print(logits.shape, logits.dtype)\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"softmax_cross_entropy_with_logits_1/Reshape_2:0\", shape=(2206,), dtype=float32)\n",
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "loss_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y, name=None)\n",
    "print(loss_tensor)\n",
    "loss = tf.reduce_mean(axis=0, input_tensor=loss_tensor)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer name: \"Adam_1\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam_1/update_Variable_3/ApplyAdam\"\n",
      "input: \"^Adam_1/update_Variable_4/ApplyAdam\"\n",
      "input: \"^Adam_1/Assign\"\n",
      "input: \"^Adam_1/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "# __init__(\n",
    "#     learning_rate=0.001,\n",
    "#     beta1=0.9,\n",
    "#     beta2=0.999,\n",
    "#     epsilon=1e-08,\n",
    "#     use_locking=False,\n",
    "#     name='Adam'\n",
    "# )\n",
    "# minimize(\n",
    "#     loss,\n",
    "#     global_step=None,\n",
    "#     var_list=None,\n",
    "#     gate_gradients=GATE_OP,\n",
    "#     aggregation_method=None,\n",
    "#     colocate_gradients_with_ops=False,\n",
    "#     name=None,\n",
    "#     grad_loss=None\n",
    "# )\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss=loss)\n",
    "print('optimizer', optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Accuracy\n",
    "# correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "# print('correct_pred, accuracy', correct_pred, accuracy)\n",
    "\n",
    "# # Confusion matrix\n",
    "# confusion_matrix = tf.confusion_matrix(predictions=tf.argmax(logits, 1),\n",
    "#                                        labels=tf.argmax(labels_, 1))\n",
    "# print('confusion_matrix', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minibatching techniques for online learning and offline learning of big dataset\n",
    "# for X, Y in get_batches(X=X_train_norm, batch_size=N, y=Y_train_onehot):\n",
    "#     print(X.shape, X.dtype, Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 training loss: 551.70593 validation loss: 520.4429\n",
      "epoch: 1 training loss: 521.85095 validation loss: 492.37323\n",
      "epoch: 2 training loss: 492.92288 validation loss: 465.3807\n",
      "epoch: 3 training loss: 464.92856 validation loss: 439.5728\n",
      "epoch: 4 training loss: 438.09204 validation loss: 414.91467\n",
      "epoch: 5 training loss: 412.34625 validation loss: 391.4813\n",
      "epoch: 6 training loss: 387.78067 validation loss: 369.21475\n",
      "epoch: 7 training loss: 364.44543 validation loss: 348.13824\n",
      "epoch: 8 training loss: 342.55096 validation loss: 328.67422\n",
      "epoch: 9 training loss: 322.5265 validation loss: 311.41885\n",
      "epoch: 10 training loss: 304.78766 validation loss: 296.49655\n",
      "epoch: 11 training loss: 289.5243 validation loss: 283.7146\n",
      "epoch: 12 training loss: 276.18817 validation loss: 272.54263\n",
      "epoch: 13 training loss: 264.6064 validation loss: 262.91187\n",
      "epoch: 14 training loss: 254.6018 validation loss: 254.37656\n",
      "epoch: 15 training loss: 245.64352 validation loss: 246.5676\n",
      "epoch: 16 training loss: 237.46774 validation loss: 239.38132\n",
      "epoch: 17 training loss: 229.86797 validation loss: 232.70578\n",
      "epoch: 18 training loss: 222.79411 validation loss: 226.4974\n",
      "epoch: 19 training loss: 216.21123 validation loss: 220.72871\n",
      "epoch: 20 training loss: 210.09601 validation loss: 215.35324\n",
      "epoch: 21 training loss: 204.36197 validation loss: 210.29164\n",
      "epoch: 22 training loss: 198.97202 validation loss: 205.52054\n",
      "epoch: 23 training loss: 193.86475 validation loss: 201.03253\n",
      "epoch: 24 training loss: 189.03044 validation loss: 196.76172\n",
      "epoch: 25 training loss: 184.42764 validation loss: 192.66861\n",
      "epoch: 26 training loss: 180.05376 validation loss: 188.78079\n",
      "epoch: 27 training loss: 175.86569 validation loss: 185.0891\n",
      "epoch: 28 training loss: 171.83777 validation loss: 181.56367\n",
      "epoch: 29 training loss: 167.97928 validation loss: 178.187\n",
      "epoch: 30 training loss: 164.29425 validation loss: 174.95319\n",
      "epoch: 31 training loss: 160.75223 validation loss: 171.85962\n",
      "epoch: 32 training loss: 157.36151 validation loss: 168.91357\n",
      "epoch: 33 training loss: 154.12195 validation loss: 166.10193\n",
      "epoch: 34 training loss: 151.0217 validation loss: 163.39856\n",
      "epoch: 35 training loss: 148.02881 validation loss: 160.81084\n",
      "epoch: 36 training loss: 145.13446 validation loss: 158.37192\n",
      "epoch: 37 training loss: 142.33975 validation loss: 156.04532\n",
      "epoch: 38 training loss: 139.63083 validation loss: 153.79611\n",
      "epoch: 39 training loss: 137.00304 validation loss: 151.61792\n",
      "epoch: 40 training loss: 134.44133 validation loss: 149.50171\n",
      "epoch: 41 training loss: 131.93999 validation loss: 147.44151\n",
      "epoch: 42 training loss: 129.48926 validation loss: 145.43849\n",
      "epoch: 43 training loss: 127.08414 validation loss: 143.47089\n",
      "epoch: 44 training loss: 124.71798 validation loss: 141.53561\n",
      "epoch: 45 training loss: 122.40138 validation loss: 139.63751\n",
      "epoch: 46 training loss: 120.13019 validation loss: 137.76836\n",
      "epoch: 47 training loss: 117.912224 validation loss: 135.93387\n",
      "epoch: 48 training loss: 115.74098 validation loss: 134.13704\n",
      "epoch: 49 training loss: 113.62895 validation loss: 132.37071\n",
      "epoch: 50 training loss: 111.58035 validation loss: 130.63469\n",
      "epoch: 51 training loss: 109.589836 validation loss: 128.92755\n",
      "epoch: 52 training loss: 107.64351 validation loss: 127.248764\n",
      "epoch: 53 training loss: 105.72572 validation loss: 125.60188\n",
      "epoch: 54 training loss: 103.85266 validation loss: 123.986885\n",
      "epoch: 55 training loss: 102.02289 validation loss: 122.39758\n",
      "epoch: 56 training loss: 100.23334 validation loss: 120.842606\n",
      "epoch: 57 training loss: 98.48397 validation loss: 119.3205\n",
      "epoch: 58 training loss: 96.77908 validation loss: 117.83836\n",
      "epoch: 59 training loss: 95.1156 validation loss: 116.41693\n",
      "epoch: 60 training loss: 93.494316 validation loss: 115.03088\n",
      "epoch: 61 training loss: 91.908394 validation loss: 113.670395\n",
      "epoch: 62 training loss: 90.350555 validation loss: 112.34474\n",
      "epoch: 63 training loss: 88.8184 validation loss: 111.049706\n",
      "epoch: 64 training loss: 87.31096 validation loss: 109.78486\n",
      "epoch: 65 training loss: 85.84204 validation loss: 108.54027\n",
      "epoch: 66 training loss: 84.41585 validation loss: 107.31972\n",
      "epoch: 67 training loss: 83.01956 validation loss: 106.11926\n",
      "epoch: 68 training loss: 81.6485 validation loss: 104.93345\n",
      "epoch: 69 training loss: 80.29619 validation loss: 103.77107\n",
      "epoch: 70 training loss: 78.968506 validation loss: 102.62219\n",
      "epoch: 71 training loss: 77.667564 validation loss: 101.49589\n",
      "epoch: 72 training loss: 76.388306 validation loss: 100.386475\n",
      "epoch: 73 training loss: 75.127426 validation loss: 99.29426\n",
      "epoch: 74 training loss: 73.881546 validation loss: 98.21794\n",
      "epoch: 75 training loss: 72.650986 validation loss: 97.15261\n",
      "epoch: 76 training loss: 71.44274 validation loss: 96.10235\n",
      "epoch: 77 training loss: 70.26338 validation loss: 95.06141\n",
      "epoch: 78 training loss: 69.10364 validation loss: 94.03492\n",
      "epoch: 79 training loss: 67.96886 validation loss: 93.0388\n",
      "epoch: 80 training loss: 66.856346 validation loss: 92.06424\n",
      "epoch: 81 training loss: 65.77173 validation loss: 91.10375\n",
      "epoch: 82 training loss: 64.70093 validation loss: 90.16031\n",
      "epoch: 83 training loss: 63.646347 validation loss: 89.230385\n",
      "epoch: 84 training loss: 62.6111 validation loss: 88.30544\n",
      "epoch: 85 training loss: 61.595287 validation loss: 87.390076\n",
      "epoch: 86 training loss: 60.598343 validation loss: 86.48855\n",
      "epoch: 87 training loss: 59.618507 validation loss: 85.60114\n",
      "epoch: 88 training loss: 58.659767 validation loss: 84.738266\n",
      "epoch: 89 training loss: 57.715263 validation loss: 83.898476\n",
      "epoch: 90 training loss: 56.785454 validation loss: 83.07794\n",
      "epoch: 91 training loss: 55.87384 validation loss: 82.27665\n",
      "epoch: 92 training loss: 54.977913 validation loss: 81.49007\n",
      "epoch: 93 training loss: 54.097748 validation loss: 80.712585\n",
      "epoch: 94 training loss: 53.22972 validation loss: 79.94211\n",
      "epoch: 95 training loss: 52.376686 validation loss: 79.181915\n",
      "epoch: 96 training loss: 51.538795 validation loss: 78.43359\n",
      "epoch: 97 training loss: 50.712585 validation loss: 77.7064\n",
      "epoch: 98 training loss: 49.897926 validation loss: 76.98274\n",
      "epoch: 99 training loss: 49.0956 validation loss: 76.26558\n"
     ]
    }
   ],
   "source": [
    "# Plotting the learning/loss curve\n",
    "train_loss, valid_loss = [], []\n",
    "\n",
    "# Save the training result or trained and validated model params\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "   \n",
    "    # Loop over epochs\n",
    "    epochs=100\n",
    "    for epoch in range(0, epochs, 1): # start=0, stop=epochs, step=1\n",
    "        \n",
    "        # Training\n",
    "        loss_batch = []\n",
    "        for Xarr, Yarr in get_batches(X=Xtrain, batch_size=N, y=Ytrain):\n",
    "\n",
    "            # feeding the input array into TF framework and fetche the output\n",
    "            feed_dict = {X:Xarr, Y:Yarr}\n",
    "            lossarr, _ = sess.run(feed_dict=feed_dict, fetches=[loss, optimizer])\n",
    "            loss_batch.append(np.mean(lossarr))\n",
    "        \n",
    "        # Averaging the loss of the batch/minibatch\n",
    "        train_loss.append(np.mean(loss_batch))\n",
    "        \n",
    "        # validation\n",
    "        feed_dict = {X:Xvalid, Y:Yvalid}\n",
    "        lossarr = sess.run(feed_dict=feed_dict, fetches=[loss])\n",
    "        valid_loss.append(np.mean(lossarr))\n",
    "\n",
    "        # Printing out the training and validating loss\n",
    "        print('epoch:', epoch, 'training loss:', train_loss[epoch], 'validation loss:', valid_loss[epoch])\n",
    "            \n",
    "    saver.save(save_path='checkpoints/model.ckpt', sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "# % %matplotlib inline\n",
    "# this is keeping the mpl inline or outline\n",
    "# inline would inside this block and outline/out of block would be out of this block.\n",
    "# %matplotlib inline\n",
    "# %matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "mplot.plot(train_loss, label='har train_loss')\n",
    "mplot.plot(valid_loss, label='har valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing and playing around with checkpoints and trained model saved or saved trained model\n",
    "# loaded_ckpt = tf.train.load_checkpoint(ckpt_dir_or_file='checkpoints/cnn-har.ckpt')\n",
    "# loaded_ckpt.debug_string, \n",
    "# loaded_ckpt.get_variable_to_dtype_map()\n",
    "# loaded_ckpt.get_variable_to_shape_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "test_loss: 102.30233\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Restore the validated model\n",
    "#     save_path = tf.train.latest_checkpoint(checkpoint_dir='checkpoints')\n",
    "    save_path = tf.train.latest_checkpoint(checkpoint_dir='checkpoints/')\n",
    "    saver.restore(save_path=save_path, sess=sess)\n",
    "    \n",
    "    loss_batch = []\n",
    "    for Xarr, Yarr in get_batches(X=Xtest, batch_size=N, y=Ytest):\n",
    "#         print(Xarr.shape, Yarr.shape)\n",
    "        feed_dict = {X:Xarr, Y:Yarr}\n",
    "        lossarr = sess.run(feed_dict=feed_dict, fetches=[loss])\n",
    "        loss_batch.append(np.mean(lossarr))\n",
    "\n",
    "    # Print info for every iter/epoch\n",
    "    print('test_loss:', np.mean(loss_batch))\n",
    "#     print(\"Test loss: {:6f}\".format(np.mean(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
