{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['body_acc_x', 'body_acc_y', 'body_acc_z', 'body_gyro_x', 'body_gyro_y', 'body_gyro_z', 'total_acc_x', 'total_acc_y', 'total_acc_z'] ['body_acc_x', 'body_acc_y', 'body_acc_z', 'body_gyro_x', 'body_gyro_y', 'body_gyro_z', 'total_acc_x', 'total_acc_y', 'total_acc_z']\n",
      "6 6\n",
      "0.0 0.16675734494015235 0.1459466811751904 0.13411316648531013 0.1749183895538629 0.1868879216539717 0.1913764961915125 0.0\n",
      "(7352,) (2947,)\n",
      "(7352, 6) (2947, 6)\n",
      "(5146, 128, 9) (2206, 128, 9) (5146, 6) (2206, 6)\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "import numpy as np\n",
    "from utilities import *\n",
    "\n",
    "# test and train read\n",
    "Xtrain, Ytrain, list_ch_train = read_data(data_path=\"../../../datasets/har/har-data/\", split=\"train\")\n",
    "Xtest, Ytest, list_ch_test = read_data(data_path=\"../../../datasets/har/har-data/\", split=\"test\")\n",
    "\n",
    "print(list_ch_test, list_ch_train)\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\"\n",
    "assert Ytrain.max(axis=0) == Ytest.max(axis=0)\n",
    "print(Ytrain.max(axis=0), Ytest.max(axis=0))\n",
    "\n",
    "print(np.mean(Ytrain==0), np.mean(Ytrain==1), np.mean(Ytrain==2), np.mean(Ytrain==3), np.mean(Ytrain==4), \n",
    "      np.mean(Ytrain==5), np.mean(Ytrain==6), np.mean(Ytrain==7))\n",
    "\n",
    "# Normalizing/standardizing the input data features\n",
    "Xtrain, Xtest = standardize(test=Xtest, train=Xtrain)\n",
    "\n",
    "# Onehot encoding of the output labels\n",
    "print(Ytrain.shape, Ytest.shape)\n",
    "Ytrain = one_hot(labels=Ytrain.reshape(-1), n_class=6) \n",
    "Ytest = one_hot(labels=Ytest.reshape(-1), n_class=6)\n",
    "print(Ytrain.shape, Ytest.shape)\n",
    "\n",
    "# Train and valid split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 30% of the training data/ entire training data is assigned to validation.\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtrain, Ytrain, test_size=0.30)\n",
    "print(Xtrain.shape, Xvalid.shape, Ytrain.shape, Yvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Input data which is divided into train, valid, and testing.\n",
    "N, W, Cin = Xvalid.shape[0], Xtrain.shape[1], Xtrain.shape[2]\n",
    "X = tf.placeholder(dtype=tf.float32, name=None, shape=[N, W, Cin])\n",
    "print(X.shape, X.dtype)\n",
    "\n",
    "# Output data/labels\n",
    "# assert Ytrain.max(axis=0)==Ytest.max(axis=0)\n",
    "# Cout = Ytrain.max(axis=0)\n",
    "# n_class=6\n",
    "Cout = 6\n",
    "Y = tf.placeholder(dtype=tf.float32, name=None, shape=[N, Cout])\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(64, 9, 18) <dtype: 'float32_ref'>\n",
      "(2206, 64, 18) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# One convolution layer\n",
    "print(X.shape, X.dtype)\n",
    "Wwidth, Wchannels, Wnumber = X.shape[1].value//2, X.shape[2].value, X.shape[2].value*2\n",
    "shape = [Wwidth, Wchannels, Wnumber]\n",
    "initial_value = tf.random_normal(dtype=X.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "Wconv = tf.Variable(dtype=X.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(Wconv.shape, Wconv.dtype)\n",
    "Xconv = tf.nn.conv1d(data_format='NWC', filters=Wconv, name=None, padding='SAME', stride=2, use_cudnn_on_gpu=True, \n",
    "                     value=X)\n",
    "Xconv = tf.maximum(name=None, x=(-0.1*Xconv), y=Xconv)\n",
    "print(Xconv.shape, Xconv.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 1152) <dtype: 'float32'>\n",
      "(1152, 6) <dtype: 'float32_ref'>\n",
      "(2206, 6) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Multiplication layer\n",
    "# shape = [-1, Xconv.shape[1].value*Xconv.shape[2].value] # N is None which is a value or creating an extra index\n",
    "shape = [Xconv.shape[0].value, Xconv.shape[1].value*Xconv.shape[2].value]\n",
    "Xconv_reshaped = tf.reshape(name=None, shape=shape, tensor=Xconv)\n",
    "print(Xconv_reshaped.shape, Xconv_reshaped.dtype)\n",
    "Wchannels, Wnumber = Xconv_reshaped.shape[1].value, Y.shape[1].value\n",
    "shape = [Wchannels, Wnumber]\n",
    "initial_value = tf.random_normal(dtype=Xconv_reshaped.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "W = tf.Variable(dtype=Xconv_reshaped.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(W.shape, W.dtype)\n",
    "logits = tf.matmul(a=Xconv_reshaped, b=W, name=None)\n",
    "print(logits.shape, logits.dtype)\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206,) <dtype: 'float32'>\n",
      "() <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "loss_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y, name=None)\n",
    "print(loss_tensor.shape, loss_tensor.dtype)\n",
    "loss = tf.reduce_mean(axis=0, input_tensor=loss_tensor)\n",
    "print(loss.shape, loss.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer name: \"Adam_1\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam_1/update_Variable_2/ApplyAdam\"\n",
      "input: \"^Adam_1/update_Variable_3/ApplyAdam\"\n",
      "input: \"^Adam_1/Assign\"\n",
      "input: \"^Adam_1/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "# __init__(\n",
    "#     learning_rate=0.001,\n",
    "#     beta1=0.9,\n",
    "#     beta2=0.999,\n",
    "#     epsilon=1e-08,\n",
    "#     use_locking=False,\n",
    "#     name='Adam'\n",
    "# )\n",
    "# minimize(\n",
    "#     loss,\n",
    "#     global_step=None,\n",
    "#     var_list=None,\n",
    "#     gate_gradients=GATE_OP,\n",
    "#     aggregation_method=None,\n",
    "#     colocate_gradients_with_ops=False,\n",
    "#     name=None,\n",
    "#     grad_loss=None\n",
    "# )\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss=loss)\n",
    "print('optimizer', optimizer)\n",
    "# adam = tf.train.AdamOptimizer\n",
    "# print(adam)\n",
    "# optimizer = adam.minimize(loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 6) <dtype: 'float32'>\n",
      "(2206,) <dtype: 'int32'>\n",
      "(2206, 6) <dtype: 'float32'>\n",
      "(2206,) <dtype: 'int32'>\n",
      "(2206, 6) <dtype: 'float32'>\n",
      "(2206,) <dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape, logits.dtype)\n",
    "# Accuracy\n",
    "# tf.argmax(\n",
    "#     input,\n",
    "#     axis=None,\n",
    "#     name=None,\n",
    "#     dimension=None,\n",
    "#     output_type=tf.int64\n",
    "# )\n",
    "Ypred = tf.argmax(axis=1, name=None, input=logits, output_type=tf.int32)\n",
    "# # tf.max is finding the max value among all the arguments and indices\n",
    "# # tf.argmax is finding the arg/index with the max value\n",
    "# Ylabel = tf.argmax()\n",
    "print(Ypred.shape, Ypred.dtype)\n",
    "\n",
    "# tf.nn.softmax(\n",
    "#     logits,\n",
    "#     axis=None,\n",
    "#     name=None,\n",
    "#     dim=None\n",
    "# )\n",
    "# softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
    "prob = tf.nn.softmax(axis=1, logits=logits, name=None)\n",
    "print(prob.shape, prob.dtype)\n",
    "Ypred2 = tf.argmax(axis=1, input=prob, name=None, output_type=tf.int32) \n",
    "print(Ypred2.shape, Ypred2.dtype)\n",
    "\n",
    "print(Y.shape, Y.dtype)\n",
    "Yref = tf.argmax(axis=1, input=Y, name=None, output_type=tf.int32)\n",
    "print(Yref.shape, Yref.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206,) <dtype: 'bool'>\n",
      "(2206,) <dtype: 'float16'>\n",
      "() <dtype: 'float16'>\n"
     ]
    }
   ],
   "source": [
    "acc_tensor = tf.equal(name=None, x=Ypred, y=Yref)\n",
    "print(acc_tensor.shape, acc_tensor.dtype)\n",
    "# cast bool to int datatype for equal\n",
    "acc_tensor = tf.cast(dtype=tf.float16, name=None, x=acc_tensor)\n",
    "print(acc_tensor.shape, acc_tensor.dtype)\n",
    "acc = tf.reduce_mean(axis=0, input_tensor=acc_tensor)\n",
    "print(acc.shape, acc.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206,) <dtype: 'bool'>\n",
      "(2206,) <dtype: 'float16'>\n",
      "() <dtype: 'float16'>\n"
     ]
    }
   ],
   "source": [
    "acc_tensor = tf.equal(name=None, x=Ypred2, y=Yref)\n",
    "print(acc_tensor.shape, acc_tensor.dtype)\n",
    "# cast bool to int datatype for equal\n",
    "acc_tensor = tf.cast(dtype=tf.float16, name=None, x=acc_tensor)\n",
    "print(acc_tensor.shape, acc_tensor.dtype)\n",
    "acc2 = tf.reduce_mean(axis=0, input_tensor=acc_tensor)\n",
    "print(acc2.shape, acc2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "# print('correct_pred, accuracy', correct_pred, accuracy)\n",
    "\n",
    "# # Confusion matrix\n",
    "# confusion_matrix = tf.confusion_matrix(predictions=tf.argmax(logits, 1),\n",
    "#                                        labels=tf.argmax(labels_, 1))\n",
    "# print('confusion_matrix', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minibatching techniques for online learning and offline learning of big dataset\n",
    "# for X, Y in get_batches(X=X_train_norm, batch_size=N, y=Y_train_onehot):\n",
    "#     print(X.shape, X.dtype, Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 training loss: 847.8561 validation loss: 857.9289 training accuracy: 0.04578 validation accuracy: 0.04352\n",
      "epoch: 1 training loss: 804.94214 validation loss: 815.03656 training accuracy: 0.0553 validation accuracy: 0.04715\n",
      "epoch: 2 training loss: 763.3336 validation loss: 773.2393 training accuracy: 0.0646 validation accuracy: 0.0562\n",
      "epoch: 3 training loss: 723.04346 validation loss: 732.77606 training accuracy: 0.07544 validation accuracy: 0.068\n",
      "epoch: 4 training loss: 684.34985 validation loss: 693.8594 training accuracy: 0.08496 validation accuracy: 0.0807\n",
      "epoch: 5 training loss: 647.3578 validation loss: 656.5323 training accuracy: 0.1 validation accuracy: 0.09155\n",
      "epoch: 6 training loss: 611.96155 validation loss: 620.6414 training accuracy: 0.1113 validation accuracy: 0.0988\n",
      "epoch: 7 training loss: 577.9887 validation loss: 585.9383 training accuracy: 0.11896 validation accuracy: 0.10876\n",
      "epoch: 8 training loss: 545.193 validation loss: 552.41815 training accuracy: 0.1278 validation accuracy: 0.1165\n",
      "epoch: 9 training loss: 513.5715 validation loss: 520.0831 training accuracy: 0.137 validation accuracy: 0.1265\n",
      "epoch: 10 training loss: 483.1952 validation loss: 488.90958 training accuracy: 0.1426 validation accuracy: 0.1355\n",
      "epoch: 11 training loss: 453.9746 validation loss: 458.9386 training accuracy: 0.1499 validation accuracy: 0.1437\n",
      "epoch: 12 training loss: 426.29822 validation loss: 430.8426 training accuracy: 0.163 validation accuracy: 0.1659\n",
      "epoch: 13 training loss: 400.7544 validation loss: 405.86078 training accuracy: 0.1882 validation accuracy: 0.2013\n",
      "epoch: 14 training loss: 378.03955 validation loss: 384.0259 training accuracy: 0.2141 validation accuracy: 0.2294\n",
      "epoch: 15 training loss: 357.90732 validation loss: 364.56268 training accuracy: 0.2383 validation accuracy: 0.2452\n",
      "epoch: 16 training loss: 340.03717 validation loss: 347.0106 training accuracy: 0.2524 validation accuracy: 0.262\n",
      "epoch: 17 training loss: 324.1812 validation loss: 332.71692 training accuracy: 0.2705 validation accuracy: 0.2825\n",
      "epoch: 18 training loss: 310.81226 validation loss: 320.90674 training accuracy: 0.285 validation accuracy: 0.2979\n",
      "epoch: 19 training loss: 299.34625 validation loss: 310.56152 training accuracy: 0.2983 validation accuracy: 0.3054\n",
      "epoch: 20 training loss: 289.17072 validation loss: 301.14844 training accuracy: 0.3052 validation accuracy: 0.3086\n",
      "epoch: 21 training loss: 279.8065 validation loss: 292.40533 training accuracy: 0.313 validation accuracy: 0.3118\n",
      "epoch: 22 training loss: 271.06012 validation loss: 284.23746 training accuracy: 0.3167 validation accuracy: 0.3174\n",
      "epoch: 23 training loss: 262.91852 validation loss: 276.54886 training accuracy: 0.3213 validation accuracy: 0.3232\n",
      "epoch: 24 training loss: 255.18538 validation loss: 269.31586 training accuracy: 0.3254 validation accuracy: 0.3296\n",
      "epoch: 25 training loss: 247.82721 validation loss: 262.43146 training accuracy: 0.331 validation accuracy: 0.335\n",
      "epoch: 26 training loss: 240.8045 validation loss: 255.86488 training accuracy: 0.3362 validation accuracy: 0.339\n",
      "epoch: 27 training loss: 234.06993 validation loss: 249.53949 training accuracy: 0.3398 validation accuracy: 0.3445\n",
      "epoch: 28 training loss: 227.68275 validation loss: 243.46432 training accuracy: 0.3474 validation accuracy: 0.3513\n",
      "epoch: 29 training loss: 221.64117 validation loss: 237.70013 training accuracy: 0.355 validation accuracy: 0.3613\n",
      "epoch: 30 training loss: 215.91132 validation loss: 232.17455 training accuracy: 0.3645 validation accuracy: 0.3682\n",
      "epoch: 31 training loss: 210.45975 validation loss: 226.9092 training accuracy: 0.3733 validation accuracy: 0.3757\n",
      "epoch: 32 training loss: 205.22543 validation loss: 221.8667 training accuracy: 0.3794 validation accuracy: 0.3809\n",
      "epoch: 33 training loss: 200.19101 validation loss: 217.0243 training accuracy: 0.39 validation accuracy: 0.389\n",
      "epoch: 34 training loss: 195.36707 validation loss: 212.37729 training accuracy: 0.398 validation accuracy: 0.3967\n",
      "epoch: 35 training loss: 190.71542 validation loss: 207.92023 training accuracy: 0.402 validation accuracy: 0.403\n",
      "epoch: 36 training loss: 186.19974 validation loss: 203.63995 training accuracy: 0.4084 validation accuracy: 0.408\n",
      "epoch: 37 training loss: 181.82626 validation loss: 199.53325 training accuracy: 0.4155 validation accuracy: 0.417\n",
      "epoch: 38 training loss: 177.60178 validation loss: 195.54079 training accuracy: 0.4238 validation accuracy: 0.4216\n",
      "epoch: 39 training loss: 173.50652 validation loss: 191.71065 training accuracy: 0.4312 validation accuracy: 0.4255\n",
      "epoch: 40 training loss: 169.53574 validation loss: 188.02371 training accuracy: 0.438 validation accuracy: 0.4312\n",
      "epoch: 41 training loss: 165.67078 validation loss: 184.4522 training accuracy: 0.4434 validation accuracy: 0.437\n",
      "epoch: 42 training loss: 161.9075 validation loss: 180.97362 training accuracy: 0.4487 validation accuracy: 0.4424\n",
      "epoch: 43 training loss: 158.24387 validation loss: 177.55687 training accuracy: 0.456 validation accuracy: 0.446\n",
      "epoch: 44 training loss: 154.67682 validation loss: 174.224 training accuracy: 0.4624 validation accuracy: 0.451\n",
      "epoch: 45 training loss: 151.21164 validation loss: 170.97864 training accuracy: 0.4688 validation accuracy: 0.4546\n",
      "epoch: 46 training loss: 147.83405 validation loss: 167.82187 training accuracy: 0.4756 validation accuracy: 0.4587\n",
      "epoch: 47 training loss: 144.56589 validation loss: 164.7467 training accuracy: 0.482 validation accuracy: 0.4636\n",
      "epoch: 48 training loss: 141.39038 validation loss: 161.76361 training accuracy: 0.4897 validation accuracy: 0.4705\n",
      "epoch: 49 training loss: 138.30505 validation loss: 158.88747 training accuracy: 0.498 validation accuracy: 0.482\n",
      "epoch: 50 training loss: 135.3208 validation loss: 156.1334 training accuracy: 0.505 validation accuracy: 0.4922\n",
      "epoch: 51 training loss: 132.43079 validation loss: 153.50008 training accuracy: 0.5146 validation accuracy: 0.504\n",
      "epoch: 52 training loss: 129.65805 validation loss: 150.99747 training accuracy: 0.5234 validation accuracy: 0.5166\n",
      "epoch: 53 training loss: 126.991 validation loss: 148.61325 training accuracy: 0.5303 validation accuracy: 0.5293\n",
      "epoch: 54 training loss: 124.42186 validation loss: 146.33675 training accuracy: 0.541 validation accuracy: 0.538\n",
      "epoch: 55 training loss: 121.957535 validation loss: 144.13551 training accuracy: 0.5503 validation accuracy: 0.543\n",
      "epoch: 56 training loss: 119.57695 validation loss: 141.9942 training accuracy: 0.5576 validation accuracy: 0.5483\n",
      "epoch: 57 training loss: 117.29271 validation loss: 139.92505 training accuracy: 0.5684 validation accuracy: 0.5537\n",
      "epoch: 58 training loss: 115.08708 validation loss: 137.92467 training accuracy: 0.574 validation accuracy: 0.557\n",
      "epoch: 59 training loss: 112.95147 validation loss: 135.97809 training accuracy: 0.5815 validation accuracy: 0.5605\n",
      "epoch: 60 training loss: 110.88359 validation loss: 134.09267 training accuracy: 0.585 validation accuracy: 0.5664\n",
      "epoch: 61 training loss: 108.87201 validation loss: 132.26118 training accuracy: 0.592 validation accuracy: 0.5737\n",
      "epoch: 62 training loss: 106.92078 validation loss: 130.48793 training accuracy: 0.5986 validation accuracy: 0.579\n",
      "epoch: 63 training loss: 105.02841 validation loss: 128.76385 training accuracy: 0.6064 validation accuracy: 0.583\n",
      "epoch: 64 training loss: 103.18713 validation loss: 127.0853 training accuracy: 0.6123 validation accuracy: 0.5854\n",
      "epoch: 65 training loss: 101.39374 validation loss: 125.4482 training accuracy: 0.617 validation accuracy: 0.5874\n",
      "epoch: 66 training loss: 99.64868 validation loss: 123.8565 training accuracy: 0.6206 validation accuracy: 0.592\n",
      "epoch: 67 training loss: 97.95615 validation loss: 122.31361 training accuracy: 0.626 validation accuracy: 0.5967\n",
      "epoch: 68 training loss: 96.30658 validation loss: 120.83044 training accuracy: 0.631 validation accuracy: 0.6\n",
      "epoch: 69 training loss: 94.694145 validation loss: 119.391685 training accuracy: 0.6353 validation accuracy: 0.6016\n",
      "epoch: 70 training loss: 93.12341 validation loss: 117.98171 training accuracy: 0.6387 validation accuracy: 0.603\n",
      "epoch: 71 training loss: 91.6019 validation loss: 116.59417 training accuracy: 0.6445 validation accuracy: 0.606\n",
      "epoch: 72 training loss: 90.120476 validation loss: 115.23531 training accuracy: 0.6494 validation accuracy: 0.6094\n",
      "epoch: 73 training loss: 88.67254 validation loss: 113.906425 training accuracy: 0.6514 validation accuracy: 0.612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 74 training loss: 87.249985 validation loss: 112.60657 training accuracy: 0.6553 validation accuracy: 0.6157\n",
      "epoch: 75 training loss: 85.85715 validation loss: 111.33482 training accuracy: 0.66 validation accuracy: 0.6196\n",
      "epoch: 76 training loss: 84.486565 validation loss: 110.07998 training accuracy: 0.662 validation accuracy: 0.6226\n",
      "epoch: 77 training loss: 83.14101 validation loss: 108.842094 training accuracy: 0.666 validation accuracy: 0.6255\n",
      "epoch: 78 training loss: 81.81805 validation loss: 107.62314 training accuracy: 0.6694 validation accuracy: 0.629\n",
      "epoch: 79 training loss: 80.51817 validation loss: 106.42014 training accuracy: 0.671 validation accuracy: 0.63\n",
      "epoch: 80 training loss: 79.243546 validation loss: 105.23201 training accuracy: 0.675 validation accuracy: 0.631\n",
      "epoch: 81 training loss: 77.992874 validation loss: 104.06494 training accuracy: 0.6777 validation accuracy: 0.634\n",
      "epoch: 82 training loss: 76.77136 validation loss: 102.92587 training accuracy: 0.6807 validation accuracy: 0.638\n",
      "epoch: 83 training loss: 75.57615 validation loss: 101.803314 training accuracy: 0.6836 validation accuracy: 0.6387\n",
      "epoch: 84 training loss: 74.3995 validation loss: 100.69996 training accuracy: 0.6865 validation accuracy: 0.6426\n",
      "epoch: 85 training loss: 73.24361 validation loss: 99.624916 training accuracy: 0.6885 validation accuracy: 0.6455\n",
      "epoch: 86 training loss: 72.105064 validation loss: 98.56416 training accuracy: 0.691 validation accuracy: 0.646\n",
      "epoch: 87 training loss: 70.98134 validation loss: 97.51459 training accuracy: 0.6924 validation accuracy: 0.6494\n",
      "epoch: 88 training loss: 69.8679 validation loss: 96.480156 training accuracy: 0.695 validation accuracy: 0.653\n",
      "epoch: 89 training loss: 68.76735 validation loss: 95.458336 training accuracy: 0.6963 validation accuracy: 0.6543\n",
      "epoch: 90 training loss: 67.67953 validation loss: 94.45419 training accuracy: 0.699 validation accuracy: 0.656\n",
      "epoch: 91 training loss: 66.608505 validation loss: 93.4662 training accuracy: 0.701 validation accuracy: 0.6587\n",
      "epoch: 92 training loss: 65.5507 validation loss: 92.490295 training accuracy: 0.7036 validation accuracy: 0.6606\n",
      "epoch: 93 training loss: 64.50744 validation loss: 91.52514 training accuracy: 0.706 validation accuracy: 0.664\n",
      "epoch: 94 training loss: 63.48105 validation loss: 90.57485 training accuracy: 0.709 validation accuracy: 0.6665\n",
      "epoch: 95 training loss: 62.47471 validation loss: 89.63908 training accuracy: 0.712 validation accuracy: 0.668\n",
      "epoch: 96 training loss: 61.48456 validation loss: 88.7099 training accuracy: 0.714 validation accuracy: 0.6694\n",
      "epoch: 97 training loss: 60.515816 validation loss: 87.78658 training accuracy: 0.7183 validation accuracy: 0.67\n",
      "epoch: 98 training loss: 59.56987 validation loss: 86.8722 training accuracy: 0.7207 validation accuracy: 0.6704\n",
      "epoch: 99 training loss: 58.63824 validation loss: 85.9672 training accuracy: 0.722 validation accuracy: 0.673\n"
     ]
    }
   ],
   "source": [
    "# Plotting the learning/loss curve\n",
    "train_loss, valid_loss = [], []\n",
    "train_acc, valid_acc = [], []\n",
    "train_acc2, valid_acc2 = [], []\n",
    "\n",
    "# Save the training result or trained and validated model params\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "   \n",
    "    # Loop over epochs\n",
    "    epochs=100\n",
    "    for epoch in range(0, epochs, 1): # start=0, stop=epochs, step=1\n",
    "        \n",
    "        # Training\n",
    "        loss_batch = []\n",
    "        acc_batch, acc2_batch = [], []\n",
    "        for Xarr, Yarr in get_batches(X=Xtrain, batch_size=N, y=Ytrain):\n",
    "\n",
    "            # feeding the input array into TF framework and fetche the output\n",
    "            feed_dict = {X:Xarr, Y:Yarr}\n",
    "            lossarr, _, accarr, acc2arr = sess.run(feed_dict=feed_dict, fetches=[loss, optimizer, acc, acc2])\n",
    "            loss_batch.append(np.mean(lossarr))\n",
    "            acc_batch.append(np.mean(accarr))\n",
    "            acc2_batch.append(np.mean(acc2arr))\n",
    "        \n",
    "        # Averaging the loss of the batch/minibatch\n",
    "        train_loss.append(np.mean(loss_batch))\n",
    "        train_acc.append(np.mean(acc_batch))\n",
    "        train_acc2.append(np.mean(acc2_batch))\n",
    "        \n",
    "        # validation\n",
    "        feed_dict = {X:Xvalid, Y:Yvalid}\n",
    "        lossarr, accarr, acc2arr = sess.run(feed_dict=feed_dict, fetches=[loss, acc, acc2])\n",
    "        valid_loss.append(np.mean(lossarr))\n",
    "        valid_acc.append(np.mean(accarr))\n",
    "        valid_acc2.append(np.mean(acc2arr))\n",
    "\n",
    "        # Printing out the training and validating loss\n",
    "        print('epoch:', epoch, 'training loss:', train_loss[epoch], 'validation loss:', valid_loss[epoch], \n",
    "              'training accuracy:', train_acc[epoch], 'validation accuracy:', valid_acc[epoch])\n",
    "            \n",
    "    saver.save(save_path='checkpoints/model.ckpt', sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "# % %matplotlib inline\n",
    "# this is keeping the mpl inline or outline\n",
    "# inline would inside this block and outline/out of block would be out of this block.\n",
    "# %matplotlib inline\n",
    "# %matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "mplot.plot(train_loss, label='har train_loss')\n",
    "mplot.plot(valid_loss, label='har valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing and playing around with checkpoints and trained model saved or saved trained model\n",
    "# loaded_ckpt = tf.train.load_checkpoint(ckpt_dir_or_file='checkpoints/cnn-har.ckpt')\n",
    "# loaded_ckpt.debug_string, \n",
    "# loaded_ckpt.get_variable_to_dtype_map()\n",
    "# loaded_ckpt.get_variable_to_shape_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "test loss: 107.731285 test accuracy: 0.5835 0.5835\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Restore the validated model\n",
    "    save_path = tf.train.latest_checkpoint(checkpoint_dir='checkpoints/')\n",
    "    saver.restore(save_path=save_path, sess=sess)\n",
    "    \n",
    "    loss_batch = []\n",
    "    acc_batch, acc2_batch = [], []\n",
    "    for Xarr, Yarr in get_batches(X=Xtest, batch_size=N, y=Ytest):\n",
    "        feed_dict = {X:Xarr, Y:Yarr}\n",
    "        lossarr, accarr, acc2arr = sess.run(feed_dict=feed_dict, fetches=[loss, acc, acc2])\n",
    "        loss_batch.append(np.mean(lossarr))\n",
    "        acc_batch.append(np.mean(accarr))\n",
    "        acc2_batch.append(np.mean(acc2arr))\n",
    "\n",
    "    # Print info for every iter/epoch\n",
    "    print('test loss:', np.mean(loss_batch), 'test accuracy:', np.mean(acc_batch), np.mean(acc2_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('some variable {what type inside and how many digits}/{what s inside and how manu digits}'.format())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
