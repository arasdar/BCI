{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.16675734494015235 0.1459466811751904 0.13411316648531013 0.1749183895538629 0.1868879216539717 0.1913764961915125 0.0\n",
      "(7352, 128, 9) float64 (2947, 128, 9) float64\n",
      "(7352,) int64 (2947,) int64\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "import numpy as np\n",
    "from utilities import *\n",
    "\n",
    "# test and train read\n",
    "Xtrain, Ytrain, _ = read_data(data_path='/home/arasdar/datasets/har/har-data/', split='train')\n",
    "Xtest, Ytest, _ = read_data(data_path='/home/arasdar/datasets/har/har-data/', split='test')\n",
    "\n",
    "# assert list_ch_train_valid == list_ch_test, \"Mistmatch in channels!\"\n",
    "assert Ytrain.max(axis=0) == Ytest.max(axis=0), 'Mismatch in channels of Ytrain and Ytest'\n",
    "\n",
    "# balanced data or not\n",
    "print(np.mean(Ytrain==0), np.mean(Ytrain==1), np.mean(Ytrain==2), np.mean(Ytrain==3), np.mean(Ytrain==4), \n",
    "      np.mean(Ytrain==5), np.mean(Ytrain==6), np.mean(Ytrain==7))\n",
    "\n",
    "print(Xtrain.shape, Xtrain.dtype, Xtest.shape, Xtest.dtype)\n",
    "print(Ytrain.shape, Ytrain.dtype, Ytest.shape, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) float64 (2947, 128, 9) float64\n",
      "(7352, 6) float64 (2947, 6) float64\n"
     ]
    }
   ],
   "source": [
    "# Normalizing/standardizing the input data features\n",
    "Xtrain, Xtest = standardize(train=Xtrain, test=Xtest)\n",
    "\n",
    "Ytrain = one_hot(labels=Ytrain.reshape(-1), n_class=Ytrain.max(axis=0)) \n",
    "Ytest = one_hot(labels=Ytest.reshape(-1), n_class=Ytest.max(axis=0)) \n",
    "\n",
    "print(Xtrain.shape, Xtrain.dtype, Xtest.shape, Xtest.dtype)\n",
    "print(Ytrain.shape, Ytrain.dtype, Ytest.shape, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5146, 128, 9) float64 (2947, 128, 9) float64 (2206, 128, 9) float64\n",
      "(5146, 6) float64 (2947, 6) float64 (2206, 6) float64\n"
     ]
    }
   ],
   "source": [
    "# Train and valid split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtrain, Ytrain, test_size=0.30)\n",
    "\n",
    "print(Xtrain.shape, Xtrain.dtype, Xtest.shape, Xtest.dtype, Xvalid.shape, Xvalid.dtype)\n",
    "print(Ytrain.shape, Ytrain.dtype, Ytest.shape, Ytest.dtype, Yvalid.shape, Yvalid.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size, seq_len, n_channels 2206 128 9\n",
      "bach_size, n_classes 2206 6\n"
     ]
    }
   ],
   "source": [
    "assert Xvalid.shape[0]==Yvalid.shape[0], 'batch_size or N for Xvalid and Yvalid are not equal.'\n",
    "\n",
    "# Input data: NxWxCin\n",
    "batch_size = Xvalid.shape[0]\n",
    "seq_len = Xvalid.shape[1]\n",
    "n_channels = Xvalid.shape[2]\n",
    "print('batch_size, seq_len, n_channels', batch_size, seq_len, n_channels)\n",
    "\n",
    "# Output labels: NxCout\n",
    "batch_size = Yvalid.shape[0]\n",
    "n_classes = Yvalid.shape[1]\n",
    "print('bach_size, n_classes', batch_size, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Feed the data from python/numpy to tensorflow framework\n",
    "Xinput = tf.placeholder(dtype=tf.float32, shape=[batch_size, seq_len, n_channels], name=None)\n",
    "Ylabels = tf.placeholder(dtype=tf.float32, shape=[batch_size, n_classes], name=None)\n",
    "print(Xinput.shape, Xinput.dtype)\n",
    "print(Ylabels.shape, Ylabels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(128, 2206, 9) <dtype: 'float32'>\n",
      "(282368, 9) <dtype: 'float32'>\n",
      "128 (2206, 9) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# # Xinput NxWxCin => WxNxCin == (seq_len, N, n_channels)\n",
    "print(Xinput.shape, Xinput.dtype)\n",
    "\n",
    "lstm_in = tf.transpose(Xinput, [1,0,2]) # reshape into (seq_len, N, channels)\n",
    "print(lstm_in.shape, lstm_in.dtype)\n",
    "\n",
    "lstm_in = tf.reshape(lstm_in, [-1, n_channels]) # Now (seq_len*N, n_channels)\n",
    "print(lstm_in.shape, lstm_in.dtype)\n",
    "\n",
    "# Open up the tensor into a list of seq_len pieces\n",
    "lstm_in = tf.split(value=lstm_in, num_or_size_splits=seq_len, axis=0)\n",
    "print(len(lstm_in), lstm_in[0].shape, lstm_in[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "# RNN-LSTM parameters\n",
    "lstm_size = 3 * n_channels # 3 times the amount of channels\n",
    "print(lstm_size)\n",
    "\n",
    "# Add LSTM layers\n",
    "# lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "lstm = tf.nn.rnn_cell.BasicLSTMCell(num_units=lstm_size)\n",
    "\n",
    "# drop = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "lstm_layers = 1 # Number of layers\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell(cells=[lstm] * lstm_layers)\n",
    "\n",
    "initial_state = cell.zero_state(batch_size=batch_size, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, final_state = tf.nn.static_rnn(cell=cell, inputs=lstm_in, dtype=tf.float32, initial_state=initial_state)\n",
    "# print(outputs, final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# We only need the last output tensor to pass into a classifier\n",
    "Ylogits = tf.layers.dense(inputs=outputs[-1], units=n_classes, name=None)\n",
    "print(Ylogits.shape, Ylogits.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"softmax_cross_entropy_with_logits/Reshape_2:0\", shape=(2206,), dtype=float32)\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "optimizer name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_dense/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dense/bias/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n",
      "Tensor(\"Equal:0\", shape=(2206,), dtype=bool)\n",
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits, labels=Ylabels)\n",
    "print(loss)\n",
    "loss = tf.reduce_mean(input_tensor=loss)\n",
    "print(loss)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss=loss)\n",
    "print('optimizer', optimizer)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = tf.equal(x=tf.argmax(input=Ylogits, axis=1), y=tf.argmax(input=Ylabels, axis=1))\n",
    "print(accuracy)\n",
    "accuracy = tf.reduce_mean(input_tensor=tf.cast(x=accuracy, dtype=tf.float32), name=None)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confusion matrix\n",
    "# confusion_matrix = tf.confusion_matrix(predictions=tf.argmax(logits, 1),\n",
    "#                                        labels=tf.argmax(labels_, 1))\n",
    "# print('confusion_matrix', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000 Train loss: 1.806563 Valid loss: 1.778989 Train acc: 0.215775 Valid acc: 0.258840\n",
      "Epoch: 2/1000 Train loss: 1.770438 Valid loss: 1.745034 Train acc: 0.270399 Valid acc: 0.302811\n",
      "Epoch: 3/1000 Train loss: 1.734851 Valid loss: 1.711386 Train acc: 0.317996 Valid acc: 0.368994\n",
      "Epoch: 4/1000 Train loss: 1.699533 Valid loss: 1.677853 Train acc: 0.401632 Valid acc: 0.447869\n",
      "Epoch: 5/1000 Train loss: 1.664263 Valid loss: 1.644274 Train acc: 0.470308 Valid acc: 0.486401\n",
      "Epoch: 6/1000 Train loss: 1.628860 Valid loss: 1.610559 Train acc: 0.512013 Valid acc: 0.527652\n",
      "Epoch: 7/1000 Train loss: 1.593240 Valid loss: 1.576709 Train acc: 0.547144 Valid acc: 0.534451\n",
      "Epoch: 8/1000 Train loss: 1.557425 Valid loss: 1.542834 Train acc: 0.557344 Valid acc: 0.541704\n",
      "Epoch: 9/1000 Train loss: 1.521565 Valid loss: 1.509171 Train acc: 0.561423 Valid acc: 0.538531\n",
      "Epoch: 10/1000 Train loss: 1.485961 Valid loss: 1.476120 Train acc: 0.559157 Valid acc: 0.531278\n",
      "Epoch: 11/1000 Train loss: 1.451089 Valid loss: 1.444238 Train acc: 0.557797 Valid acc: 0.527199\n",
      "Epoch: 12/1000 Train loss: 1.417574 Valid loss: 1.414126 Train acc: 0.550317 Valid acc: 0.524932\n",
      "Epoch: 13/1000 Train loss: 1.386032 Valid loss: 1.386167 Train acc: 0.544878 Valid acc: 0.521306\n",
      "Epoch: 14/1000 Train loss: 1.356810 Valid loss: 1.360256 Train acc: 0.542384 Valid acc: 0.517679\n",
      "Epoch: 15/1000 Train loss: 1.329748 Valid loss: 1.335771 Train acc: 0.539665 Valid acc: 0.520852\n",
      "Epoch: 16/1000 Train loss: 1.304163 Valid loss: 1.311804 Train acc: 0.538078 Valid acc: 0.523572\n",
      "Epoch: 17/1000 Train loss: 1.279095 Valid loss: 1.287529 Train acc: 0.544424 Valid acc: 0.529465\n",
      "Epoch: 18/1000 Train loss: 1.253721 Valid loss: 1.262522 Train acc: 0.553491 Valid acc: 0.542611\n",
      "Epoch: 19/1000 Train loss: 1.227690 Valid loss: 1.236833 Train acc: 0.566410 Valid acc: 0.549411\n",
      "Epoch: 20/1000 Train loss: 1.201221 Valid loss: 1.210771 Train acc: 0.581596 Valid acc: 0.571170\n",
      "Epoch: 21/1000 Train loss: 1.174751 Valid loss: 1.184533 Train acc: 0.595422 Valid acc: 0.586129\n",
      "Epoch: 22/1000 Train loss: 1.148340 Valid loss: 1.157756 Train acc: 0.613554 Valid acc: 0.597915\n",
      "Epoch: 23/1000 Train loss: 1.121275 Valid loss: 1.129417 Train acc: 0.627153 Valid acc: 0.622847\n",
      "Epoch: 24/1000 Train loss: 1.093461 Valid loss: 1.100625 Train acc: 0.646192 Valid acc: 0.640526\n",
      "Epoch: 25/1000 Train loss: 1.065858 Valid loss: 1.072748 Train acc: 0.658432 Valid acc: 0.652312\n",
      "Epoch: 26/1000 Train loss: 1.038698 Valid loss: 1.045267 Train acc: 0.669311 Valid acc: 0.668631\n",
      "Epoch: 27/1000 Train loss: 1.011904 Valid loss: 1.017088 Train acc: 0.674071 Valid acc: 0.677697\n",
      "Epoch: 28/1000 Train loss: 0.985832 Valid loss: 0.988075 Train acc: 0.679284 Valid acc: 0.688123\n",
      "Epoch: 29/1000 Train loss: 0.959694 Valid loss: 0.962690 Train acc: 0.689257 Valid acc: 0.696736\n",
      "Epoch: 30/1000 Train loss: 0.935501 Valid loss: 0.938790 Train acc: 0.694470 Valid acc: 0.698096\n",
      "Epoch: 31/1000 Train loss: 0.912434 Valid loss: 0.916899 Train acc: 0.699683 Valid acc: 0.706256\n",
      "Epoch: 32/1000 Train loss: 0.891127 Valid loss: 0.894695 Train acc: 0.706936 Valid acc: 0.712602\n",
      "Epoch: 33/1000 Train loss: 0.870126 Valid loss: 0.876180 Train acc: 0.713735 Valid acc: 0.721215\n",
      "Epoch: 34/1000 Train loss: 0.851832 Valid loss: 0.858291 Train acc: 0.717135 Valid acc: 0.725748\n",
      "Epoch: 35/1000 Train loss: 0.833783 Valid loss: 0.841691 Train acc: 0.722575 Valid acc: 0.728468\n",
      "Epoch: 36/1000 Train loss: 0.817747 Valid loss: 0.825118 Train acc: 0.727108 Valid acc: 0.726201\n",
      "Epoch: 37/1000 Train loss: 0.801264 Valid loss: 0.810435 Train acc: 0.728694 Valid acc: 0.728015\n",
      "Epoch: 38/1000 Train loss: 0.784511 Valid loss: 0.794521 Train acc: 0.732548 Valid acc: 0.735721\n",
      "Epoch: 39/1000 Train loss: 0.770470 Valid loss: 0.782058 Train acc: 0.740707 Valid acc: 0.747507\n",
      "Epoch: 40/1000 Train loss: 0.758101 Valid loss: 0.772314 Train acc: 0.748187 Valid acc: 0.749773\n",
      "Epoch: 41/1000 Train loss: 0.746207 Valid loss: 0.756354 Train acc: 0.750907 Valid acc: 0.751587\n",
      "Epoch: 42/1000 Train loss: 0.732012 Valid loss: 0.744598 Train acc: 0.755440 Valid acc: 0.756120\n",
      "Epoch: 43/1000 Train loss: 0.719252 Valid loss: 0.732756 Train acc: 0.760199 Valid acc: 0.757933\n",
      "Epoch: 44/1000 Train loss: 0.708037 Valid loss: 0.721620 Train acc: 0.762239 Valid acc: 0.761106\n",
      "Epoch: 45/1000 Train loss: 0.696666 Valid loss: 0.710406 Train acc: 0.769039 Valid acc: 0.766092\n",
      "Epoch: 46/1000 Train loss: 0.685247 Valid loss: 0.698594 Train acc: 0.774705 Valid acc: 0.769266\n",
      "Epoch: 47/1000 Train loss: 0.674128 Valid loss: 0.688283 Train acc: 0.778558 Valid acc: 0.769266\n",
      "Epoch: 48/1000 Train loss: 0.663491 Valid loss: 0.677970 Train acc: 0.782412 Valid acc: 0.774705\n",
      "Epoch: 49/1000 Train loss: 0.652646 Valid loss: 0.668629 Train acc: 0.791931 Valid acc: 0.784225\n",
      "Epoch: 50/1000 Train loss: 0.642971 Valid loss: 0.658319 Train acc: 0.795104 Valid acc: 0.788305\n",
      "Epoch: 51/1000 Train loss: 0.632394 Valid loss: 0.648106 Train acc: 0.798957 Valid acc: 0.789665\n",
      "Epoch: 52/1000 Train loss: 0.621248 Valid loss: 0.638003 Train acc: 0.805077 Valid acc: 0.800091\n",
      "Epoch: 53/1000 Train loss: 0.610868 Valid loss: 0.627771 Train acc: 0.813463 Valid acc: 0.807344\n",
      "Epoch: 54/1000 Train loss: 0.600086 Valid loss: 0.617274 Train acc: 0.821623 Valid acc: 0.810970\n",
      "Epoch: 55/1000 Train loss: 0.589042 Valid loss: 0.606611 Train acc: 0.827516 Valid acc: 0.816410\n",
      "Epoch: 56/1000 Train loss: 0.578286 Valid loss: 0.595541 Train acc: 0.834315 Valid acc: 0.821850\n",
      "Epoch: 57/1000 Train loss: 0.567087 Valid loss: 0.583829 Train acc: 0.840435 Valid acc: 0.825929\n",
      "Epoch: 58/1000 Train loss: 0.555743 Valid loss: 0.572492 Train acc: 0.846102 Valid acc: 0.832729\n",
      "Epoch: 59/1000 Train loss: 0.544668 Valid loss: 0.561665 Train acc: 0.854714 Valid acc: 0.836809\n",
      "Epoch: 60/1000 Train loss: 0.533264 Valid loss: 0.549696 Train acc: 0.856754 Valid acc: 0.840889\n",
      "Epoch: 61/1000 Train loss: 0.521952 Valid loss: 0.540116 Train acc: 0.858568 Valid acc: 0.837715\n",
      "Epoch: 62/1000 Train loss: 0.511118 Valid loss: 0.530901 Train acc: 0.864687 Valid acc: 0.841342\n",
      "Epoch: 63/1000 Train loss: 0.500401 Valid loss: 0.519061 Train acc: 0.868994 Valid acc: 0.847688\n",
      "Epoch: 64/1000 Train loss: 0.489123 Valid loss: 0.508655 Train acc: 0.874207 Valid acc: 0.862647\n",
      "Epoch: 65/1000 Train loss: 0.477660 Valid loss: 0.497558 Train acc: 0.885766 Valid acc: 0.873980\n",
      "Epoch: 66/1000 Train loss: 0.467253 Valid loss: 0.486600 Train acc: 0.888259 Valid acc: 0.879420\n",
      "Epoch: 67/1000 Train loss: 0.456761 Valid loss: 0.477019 Train acc: 0.893699 Valid acc: 0.889846\n",
      "Epoch: 68/1000 Train loss: 0.445948 Valid loss: 0.465568 Train acc: 0.901179 Valid acc: 0.894379\n",
      "Epoch: 69/1000 Train loss: 0.435789 Valid loss: 0.453356 Train acc: 0.904578 Valid acc: 0.894379\n",
      "Epoch: 70/1000 Train loss: 0.424272 Valid loss: 0.443171 Train acc: 0.909338 Valid acc: 0.900725\n",
      "Epoch: 71/1000 Train loss: 0.413255 Valid loss: 0.433794 Train acc: 0.915911 Valid acc: 0.902085\n",
      "Epoch: 72/1000 Train loss: 0.402449 Valid loss: 0.421179 Train acc: 0.919084 Valid acc: 0.904805\n",
      "Epoch: 73/1000 Train loss: 0.391876 Valid loss: 0.411382 Train acc: 0.918404 Valid acc: 0.910245\n",
      "Epoch: 74/1000 Train loss: 0.384598 Valid loss: 0.406652 Train acc: 0.921124 Valid acc: 0.909791\n",
      "Epoch: 75/1000 Train loss: 0.377647 Valid loss: 0.403310 Train acc: 0.927924 Valid acc: 0.911605\n",
      "Epoch: 76/1000 Train loss: 0.369720 Valid loss: 0.391011 Train acc: 0.930417 Valid acc: 0.914325\n",
      "Epoch: 77/1000 Train loss: 0.360923 Valid loss: 0.378901 Train acc: 0.927471 Valid acc: 0.921124\n",
      "Epoch: 78/1000 Train loss: 0.348872 Valid loss: 0.373346 Train acc: 0.933137 Valid acc: 0.921578\n",
      "Epoch: 79/1000 Train loss: 0.343186 Valid loss: 0.362839 Train acc: 0.934950 Valid acc: 0.921124\n",
      "Epoch: 80/1000 Train loss: 0.333884 Valid loss: 0.352012 Train acc: 0.932457 Valid acc: 0.923844\n",
      "Epoch: 81/1000 Train loss: 0.323351 Valid loss: 0.345319 Train acc: 0.935177 Valid acc: 0.923844\n",
      "Epoch: 82/1000 Train loss: 0.316589 Valid loss: 0.338728 Train acc: 0.938123 Valid acc: 0.921578\n",
      "Epoch: 83/1000 Train loss: 0.310567 Valid loss: 0.330014 Train acc: 0.933137 Valid acc: 0.925204\n",
      "Epoch: 84/1000 Train loss: 0.301038 Valid loss: 0.319166 Train acc: 0.935857 Valid acc: 0.931097\n",
      "Epoch: 85/1000 Train loss: 0.293261 Valid loss: 0.313940 Train acc: 0.940616 Valid acc: 0.929737\n",
      "Epoch: 86/1000 Train loss: 0.289116 Valid loss: 0.305119 Train acc: 0.940390 Valid acc: 0.932004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/1000 Train loss: 0.282774 Valid loss: 0.297220 Train acc: 0.936990 Valid acc: 0.932910\n",
      "Epoch: 88/1000 Train loss: 0.273282 Valid loss: 0.292067 Train acc: 0.940616 Valid acc: 0.935177\n",
      "Epoch: 89/1000 Train loss: 0.267790 Valid loss: 0.287854 Train acc: 0.943110 Valid acc: 0.933817\n",
      "Epoch: 90/1000 Train loss: 0.263667 Valid loss: 0.281052 Train acc: 0.943563 Valid acc: 0.935177\n",
      "Epoch: 91/1000 Train loss: 0.257788 Valid loss: 0.274950 Train acc: 0.943110 Valid acc: 0.936537\n",
      "Epoch: 92/1000 Train loss: 0.253452 Valid loss: 0.271226 Train acc: 0.943336 Valid acc: 0.936537\n",
      "Epoch: 93/1000 Train loss: 0.249807 Valid loss: 0.268186 Train acc: 0.943790 Valid acc: 0.936990\n",
      "Epoch: 94/1000 Train loss: 0.246300 Valid loss: 0.262791 Train acc: 0.944923 Valid acc: 0.935630\n",
      "Epoch: 95/1000 Train loss: 0.242317 Valid loss: 0.258196 Train acc: 0.946283 Valid acc: 0.935630\n",
      "Epoch: 96/1000 Train loss: 0.238170 Valid loss: 0.256092 Train acc: 0.945603 Valid acc: 0.935630\n",
      "Epoch: 97/1000 Train loss: 0.234842 Valid loss: 0.253174 Train acc: 0.944923 Valid acc: 0.935177\n",
      "Epoch: 98/1000 Train loss: 0.231742 Valid loss: 0.250454 Train acc: 0.945150 Valid acc: 0.936990\n",
      "Epoch: 99/1000 Train loss: 0.228115 Valid loss: 0.250390 Train acc: 0.945150 Valid acc: 0.934270\n",
      "Epoch: 100/1000 Train loss: 0.226015 Valid loss: 0.248920 Train acc: 0.944243 Valid acc: 0.935177\n",
      "Epoch: 101/1000 Train loss: 0.223339 Valid loss: 0.246089 Train acc: 0.945376 Valid acc: 0.936537\n",
      "Epoch: 102/1000 Train loss: 0.221243 Valid loss: 0.243244 Train acc: 0.945830 Valid acc: 0.935630\n",
      "Epoch: 103/1000 Train loss: 0.218427 Valid loss: 0.240837 Train acc: 0.944016 Valid acc: 0.936083\n",
      "Epoch: 104/1000 Train loss: 0.215662 Valid loss: 0.238239 Train acc: 0.946283 Valid acc: 0.936083\n",
      "Epoch: 105/1000 Train loss: 0.214087 Valid loss: 0.234453 Train acc: 0.946283 Valid acc: 0.937443\n",
      "Epoch: 106/1000 Train loss: 0.211825 Valid loss: 0.238683 Train acc: 0.946056 Valid acc: 0.935177\n",
      "Epoch: 107/1000 Train loss: 0.213472 Valid loss: 0.239822 Train acc: 0.944470 Valid acc: 0.934270\n",
      "Epoch: 108/1000 Train loss: 0.210537 Valid loss: 0.238680 Train acc: 0.945830 Valid acc: 0.935177\n",
      "Epoch: 109/1000 Train loss: 0.207967 Valid loss: 0.228880 Train acc: 0.946736 Valid acc: 0.937897\n",
      "Epoch: 110/1000 Train loss: 0.205896 Valid loss: 0.225451 Train acc: 0.946963 Valid acc: 0.940616\n",
      "Epoch: 111/1000 Train loss: 0.204881 Valid loss: 0.225331 Train acc: 0.946736 Valid acc: 0.938803\n",
      "Epoch: 112/1000 Train loss: 0.204263 Valid loss: 0.225547 Train acc: 0.946056 Valid acc: 0.937443\n",
      "Epoch: 113/1000 Train loss: 0.203952 Valid loss: 0.224431 Train acc: 0.946510 Valid acc: 0.937897\n",
      "Epoch: 114/1000 Train loss: 0.202384 Valid loss: 0.221856 Train acc: 0.947416 Valid acc: 0.938350\n",
      "Epoch: 115/1000 Train loss: 0.200114 Valid loss: 0.218211 Train acc: 0.947189 Valid acc: 0.939257\n",
      "Epoch: 116/1000 Train loss: 0.197718 Valid loss: 0.215525 Train acc: 0.946736 Valid acc: 0.941070\n",
      "Epoch: 117/1000 Train loss: 0.195598 Valid loss: 0.213117 Train acc: 0.947416 Valid acc: 0.941070\n",
      "Epoch: 118/1000 Train loss: 0.193347 Valid loss: 0.210976 Train acc: 0.947869 Valid acc: 0.941976\n",
      "Epoch: 119/1000 Train loss: 0.191035 Valid loss: 0.208167 Train acc: 0.947643 Valid acc: 0.942430\n",
      "Epoch: 120/1000 Train loss: 0.189016 Valid loss: 0.207087 Train acc: 0.947869 Valid acc: 0.941976\n",
      "Epoch: 121/1000 Train loss: 0.187274 Valid loss: 0.205762 Train acc: 0.948323 Valid acc: 0.941523\n",
      "Epoch: 122/1000 Train loss: 0.185209 Valid loss: 0.204298 Train acc: 0.948776 Valid acc: 0.941523\n",
      "Epoch: 123/1000 Train loss: 0.184979 Valid loss: 0.203008 Train acc: 0.949229 Valid acc: 0.942430\n",
      "Epoch: 124/1000 Train loss: 0.183186 Valid loss: 0.201703 Train acc: 0.949683 Valid acc: 0.941976\n",
      "Epoch: 125/1000 Train loss: 0.181349 Valid loss: 0.203727 Train acc: 0.949683 Valid acc: 0.939257\n",
      "Epoch: 126/1000 Train loss: 0.182875 Valid loss: 0.208308 Train acc: 0.949456 Valid acc: 0.938803\n",
      "Epoch: 127/1000 Train loss: 0.182825 Valid loss: 0.211570 Train acc: 0.949229 Valid acc: 0.938350\n",
      "Epoch: 128/1000 Train loss: 0.185045 Valid loss: 0.220657 Train acc: 0.946056 Valid acc: 0.934270\n",
      "Epoch: 129/1000 Train loss: 0.191256 Valid loss: 0.229412 Train acc: 0.944016 Valid acc: 0.924751\n",
      "Epoch: 130/1000 Train loss: 0.193983 Valid loss: 0.223211 Train acc: 0.941750 Valid acc: 0.932910\n",
      "Epoch: 131/1000 Train loss: 0.189241 Valid loss: 0.209534 Train acc: 0.945376 Valid acc: 0.937443\n",
      "Epoch: 132/1000 Train loss: 0.185748 Valid loss: 0.204024 Train acc: 0.944923 Valid acc: 0.939710\n",
      "Epoch: 133/1000 Train loss: 0.185499 Valid loss: 0.206564 Train acc: 0.945150 Valid acc: 0.936990\n",
      "Epoch: 134/1000 Train loss: 0.191620 Valid loss: 0.208154 Train acc: 0.941976 Valid acc: 0.936990\n",
      "Epoch: 135/1000 Train loss: 0.188854 Valid loss: 0.199677 Train acc: 0.942430 Valid acc: 0.939257\n",
      "Epoch: 136/1000 Train loss: 0.183099 Valid loss: 0.204057 Train acc: 0.945603 Valid acc: 0.937443\n",
      "Epoch: 137/1000 Train loss: 0.180279 Valid loss: 0.203885 Train acc: 0.947189 Valid acc: 0.935630\n",
      "Epoch: 138/1000 Train loss: 0.179900 Valid loss: 0.198441 Train acc: 0.946509 Valid acc: 0.937443\n",
      "Epoch: 139/1000 Train loss: 0.177576 Valid loss: 0.196687 Train acc: 0.946963 Valid acc: 0.936990\n",
      "Epoch: 140/1000 Train loss: 0.177986 Valid loss: 0.190690 Train acc: 0.948096 Valid acc: 0.939710\n",
      "Epoch: 141/1000 Train loss: 0.177272 Valid loss: 0.190172 Train acc: 0.948549 Valid acc: 0.938350\n",
      "Epoch: 142/1000 Train loss: 0.176618 Valid loss: 0.188969 Train acc: 0.948323 Valid acc: 0.940616\n",
      "Epoch: 143/1000 Train loss: 0.175481 Valid loss: 0.189400 Train acc: 0.949229 Valid acc: 0.941976\n",
      "Epoch: 144/1000 Train loss: 0.173491 Valid loss: 0.187850 Train acc: 0.949456 Valid acc: 0.942883\n",
      "Epoch: 145/1000 Train loss: 0.170568 Valid loss: 0.186223 Train acc: 0.950589 Valid acc: 0.943336\n",
      "Epoch: 146/1000 Train loss: 0.167238 Valid loss: 0.183327 Train acc: 0.951949 Valid acc: 0.944243\n",
      "Epoch: 147/1000 Train loss: 0.164521 Valid loss: 0.180245 Train acc: 0.953083 Valid acc: 0.944243\n",
      "Epoch: 148/1000 Train loss: 0.161000 Valid loss: 0.177328 Train acc: 0.954669 Valid acc: 0.946510\n",
      "Epoch: 149/1000 Train loss: 0.158406 Valid loss: 0.174684 Train acc: 0.954669 Valid acc: 0.947416\n",
      "Epoch: 150/1000 Train loss: 0.156331 Valid loss: 0.173619 Train acc: 0.955122 Valid acc: 0.947869\n",
      "Epoch: 151/1000 Train loss: 0.154372 Valid loss: 0.172919 Train acc: 0.955802 Valid acc: 0.948776\n",
      "Epoch: 152/1000 Train loss: 0.152949 Valid loss: 0.170930 Train acc: 0.955802 Valid acc: 0.949229\n",
      "Epoch: 153/1000 Train loss: 0.151350 Valid loss: 0.170958 Train acc: 0.956256 Valid acc: 0.948776\n",
      "Epoch: 154/1000 Train loss: 0.148175 Valid loss: 0.169412 Train acc: 0.957616 Valid acc: 0.949683\n",
      "Epoch: 155/1000 Train loss: 0.147270 Valid loss: 0.167011 Train acc: 0.957842 Valid acc: 0.949683\n",
      "Epoch: 156/1000 Train loss: 0.146713 Valid loss: 0.166634 Train acc: 0.957389 Valid acc: 0.949683\n",
      "Epoch: 157/1000 Train loss: 0.146780 Valid loss: 0.166575 Train acc: 0.957389 Valid acc: 0.947416\n",
      "Epoch: 158/1000 Train loss: 0.146182 Valid loss: 0.164681 Train acc: 0.956936 Valid acc: 0.950136\n",
      "Epoch: 159/1000 Train loss: 0.145693 Valid loss: 0.163640 Train acc: 0.958069 Valid acc: 0.951043\n",
      "Epoch: 160/1000 Train loss: 0.144636 Valid loss: 0.164163 Train acc: 0.958296 Valid acc: 0.950589\n",
      "Epoch: 161/1000 Train loss: 0.144337 Valid loss: 0.162835 Train acc: 0.958522 Valid acc: 0.951496\n",
      "Epoch: 162/1000 Train loss: 0.143421 Valid loss: 0.161192 Train acc: 0.958296 Valid acc: 0.953309\n",
      "Epoch: 163/1000 Train loss: 0.142120 Valid loss: 0.161424 Train acc: 0.958296 Valid acc: 0.950589\n",
      "Epoch: 164/1000 Train loss: 0.141169 Valid loss: 0.161500 Train acc: 0.958976 Valid acc: 0.950589\n",
      "Epoch: 165/1000 Train loss: 0.140686 Valid loss: 0.160493 Train acc: 0.959202 Valid acc: 0.951496\n",
      "Epoch: 166/1000 Train loss: 0.139799 Valid loss: 0.160780 Train acc: 0.958522 Valid acc: 0.951496\n",
      "Epoch: 167/1000 Train loss: 0.139216 Valid loss: 0.161175 Train acc: 0.957842 Valid acc: 0.950136\n",
      "Epoch: 168/1000 Train loss: 0.138485 Valid loss: 0.160370 Train acc: 0.957616 Valid acc: 0.949683\n",
      "Epoch: 169/1000 Train loss: 0.137597 Valid loss: 0.159233 Train acc: 0.958069 Valid acc: 0.950589\n",
      "Epoch: 170/1000 Train loss: 0.137020 Valid loss: 0.159135 Train acc: 0.958296 Valid acc: 0.950136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 171/1000 Train loss: 0.136478 Valid loss: 0.159067 Train acc: 0.957842 Valid acc: 0.949229\n",
      "Epoch: 172/1000 Train loss: 0.135896 Valid loss: 0.157824 Train acc: 0.957842 Valid acc: 0.949683\n",
      "Epoch: 173/1000 Train loss: 0.135079 Valid loss: 0.155672 Train acc: 0.958522 Valid acc: 0.951043\n",
      "Epoch: 174/1000 Train loss: 0.134467 Valid loss: 0.156715 Train acc: 0.958296 Valid acc: 0.949683\n",
      "Epoch: 175/1000 Train loss: 0.134252 Valid loss: 0.155845 Train acc: 0.958296 Valid acc: 0.950136\n",
      "Epoch: 176/1000 Train loss: 0.133543 Valid loss: 0.159267 Train acc: 0.958296 Valid acc: 0.948323\n",
      "Epoch: 177/1000 Train loss: 0.134243 Valid loss: 0.156438 Train acc: 0.958069 Valid acc: 0.949683\n",
      "Epoch: 178/1000 Train loss: 0.133162 Valid loss: 0.155069 Train acc: 0.958522 Valid acc: 0.948776\n",
      "Epoch: 179/1000 Train loss: 0.132389 Valid loss: 0.154749 Train acc: 0.958749 Valid acc: 0.948323\n",
      "Epoch: 180/1000 Train loss: 0.131959 Valid loss: 0.154756 Train acc: 0.958522 Valid acc: 0.948323\n",
      "Epoch: 181/1000 Train loss: 0.131506 Valid loss: 0.154179 Train acc: 0.958296 Valid acc: 0.948323\n",
      "Epoch: 182/1000 Train loss: 0.131042 Valid loss: 0.153789 Train acc: 0.958069 Valid acc: 0.948323\n",
      "Epoch: 183/1000 Train loss: 0.130566 Valid loss: 0.153270 Train acc: 0.958069 Valid acc: 0.949229\n",
      "Epoch: 184/1000 Train loss: 0.130070 Valid loss: 0.152902 Train acc: 0.958522 Valid acc: 0.948776\n",
      "Epoch: 185/1000 Train loss: 0.129536 Valid loss: 0.152451 Train acc: 0.958522 Valid acc: 0.948323\n",
      "Epoch: 186/1000 Train loss: 0.129047 Valid loss: 0.151719 Train acc: 0.958296 Valid acc: 0.948323\n",
      "Epoch: 187/1000 Train loss: 0.128574 Valid loss: 0.151071 Train acc: 0.958749 Valid acc: 0.948323\n",
      "Epoch: 188/1000 Train loss: 0.128503 Valid loss: 0.152336 Train acc: 0.958296 Valid acc: 0.946963\n",
      "Epoch: 189/1000 Train loss: 0.127767 Valid loss: 0.153614 Train acc: 0.958522 Valid acc: 0.947416\n",
      "Epoch: 190/1000 Train loss: 0.128005 Valid loss: 0.145297 Train acc: 0.958749 Valid acc: 0.948776\n",
      "Epoch: 191/1000 Train loss: 0.135122 Valid loss: 0.151860 Train acc: 0.955122 Valid acc: 0.947416\n",
      "Epoch: 192/1000 Train loss: 0.153252 Valid loss: 0.164702 Train acc: 0.949683 Valid acc: 0.943336\n",
      "Epoch: 193/1000 Train loss: 0.155314 Valid loss: 0.169170 Train acc: 0.948549 Valid acc: 0.942883\n",
      "Epoch: 194/1000 Train loss: 0.156675 Valid loss: 0.173423 Train acc: 0.948549 Valid acc: 0.938803\n",
      "Epoch: 195/1000 Train loss: 0.156463 Valid loss: 0.170718 Train acc: 0.947416 Valid acc: 0.942430\n",
      "Epoch: 196/1000 Train loss: 0.148550 Valid loss: 0.158363 Train acc: 0.949909 Valid acc: 0.946510\n",
      "Epoch: 197/1000 Train loss: 0.139327 Valid loss: 0.155069 Train acc: 0.955122 Valid acc: 0.948776\n",
      "Epoch: 198/1000 Train loss: 0.136859 Valid loss: 0.155410 Train acc: 0.956256 Valid acc: 0.948776\n",
      "Epoch: 199/1000 Train loss: 0.140745 Valid loss: 0.154664 Train acc: 0.954216 Valid acc: 0.946510\n",
      "Epoch: 200/1000 Train loss: 0.138456 Valid loss: 0.154386 Train acc: 0.953309 Valid acc: 0.947416\n",
      "Epoch: 201/1000 Train loss: 0.133789 Valid loss: 0.153949 Train acc: 0.954669 Valid acc: 0.946510\n",
      "Epoch: 202/1000 Train loss: 0.131654 Valid loss: 0.152518 Train acc: 0.955122 Valid acc: 0.946056\n",
      "Epoch: 203/1000 Train loss: 0.130569 Valid loss: 0.152689 Train acc: 0.956029 Valid acc: 0.945150\n",
      "Epoch: 204/1000 Train loss: 0.129867 Valid loss: 0.151032 Train acc: 0.955122 Valid acc: 0.947416\n",
      "Epoch: 205/1000 Train loss: 0.128489 Valid loss: 0.149464 Train acc: 0.956482 Valid acc: 0.949683\n",
      "Epoch: 206/1000 Train loss: 0.127548 Valid loss: 0.148717 Train acc: 0.958296 Valid acc: 0.950136\n",
      "Epoch: 207/1000 Train loss: 0.126891 Valid loss: 0.147554 Train acc: 0.958522 Valid acc: 0.950136\n",
      "Epoch: 208/1000 Train loss: 0.126392 Valid loss: 0.147063 Train acc: 0.958069 Valid acc: 0.950136\n",
      "Epoch: 209/1000 Train loss: 0.125878 Valid loss: 0.147219 Train acc: 0.957842 Valid acc: 0.948776\n",
      "Epoch: 210/1000 Train loss: 0.125360 Valid loss: 0.146415 Train acc: 0.957842 Valid acc: 0.948323\n",
      "Epoch: 211/1000 Train loss: 0.124605 Valid loss: 0.145143 Train acc: 0.956936 Valid acc: 0.948323\n",
      "Epoch: 212/1000 Train loss: 0.123489 Valid loss: 0.143998 Train acc: 0.957162 Valid acc: 0.948323\n",
      "Epoch: 213/1000 Train loss: 0.123229 Valid loss: 0.143005 Train acc: 0.957616 Valid acc: 0.948323\n",
      "Epoch: 214/1000 Train loss: 0.122347 Valid loss: 0.143776 Train acc: 0.958749 Valid acc: 0.949229\n",
      "Epoch: 215/1000 Train loss: 0.122154 Valid loss: 0.143597 Train acc: 0.958749 Valid acc: 0.950136\n",
      "Epoch: 216/1000 Train loss: 0.122018 Valid loss: 0.143343 Train acc: 0.958749 Valid acc: 0.949683\n",
      "Epoch: 217/1000 Train loss: 0.121815 Valid loss: 0.143322 Train acc: 0.958296 Valid acc: 0.948776\n",
      "Epoch: 218/1000 Train loss: 0.121339 Valid loss: 0.143080 Train acc: 0.958749 Valid acc: 0.948323\n",
      "Epoch: 219/1000 Train loss: 0.120917 Valid loss: 0.141717 Train acc: 0.958749 Valid acc: 0.948323\n",
      "Epoch: 220/1000 Train loss: 0.120430 Valid loss: 0.141459 Train acc: 0.958069 Valid acc: 0.948323\n",
      "Epoch: 221/1000 Train loss: 0.119964 Valid loss: 0.140789 Train acc: 0.958976 Valid acc: 0.949229\n",
      "Epoch: 222/1000 Train loss: 0.119457 Valid loss: 0.140348 Train acc: 0.958749 Valid acc: 0.949229\n",
      "Epoch: 223/1000 Train loss: 0.119011 Valid loss: 0.140249 Train acc: 0.959429 Valid acc: 0.949229\n",
      "Epoch: 224/1000 Train loss: 0.118643 Valid loss: 0.139245 Train acc: 0.959655 Valid acc: 0.950136\n",
      "Epoch: 225/1000 Train loss: 0.118247 Valid loss: 0.139632 Train acc: 0.959882 Valid acc: 0.949229\n",
      "Epoch: 226/1000 Train loss: 0.117839 Valid loss: 0.139504 Train acc: 0.959656 Valid acc: 0.948776\n",
      "Epoch: 227/1000 Train loss: 0.117798 Valid loss: 0.140024 Train acc: 0.959656 Valid acc: 0.949683\n",
      "Epoch: 228/1000 Train loss: 0.117312 Valid loss: 0.142999 Train acc: 0.959656 Valid acc: 0.946510\n",
      "Epoch: 229/1000 Train loss: 0.117326 Valid loss: 0.145782 Train acc: 0.959882 Valid acc: 0.946056\n",
      "Epoch: 230/1000 Train loss: 0.118006 Valid loss: 0.147841 Train acc: 0.959202 Valid acc: 0.944696\n",
      "Epoch: 231/1000 Train loss: 0.117735 Valid loss: 0.149220 Train acc: 0.959656 Valid acc: 0.946056\n",
      "Epoch: 232/1000 Train loss: 0.117129 Valid loss: 0.148589 Train acc: 0.960109 Valid acc: 0.946963\n",
      "Epoch: 233/1000 Train loss: 0.116731 Valid loss: 0.145952 Train acc: 0.960335 Valid acc: 0.946056\n",
      "Epoch: 234/1000 Train loss: 0.116173 Valid loss: 0.145204 Train acc: 0.960109 Valid acc: 0.946963\n",
      "Epoch: 235/1000 Train loss: 0.115867 Valid loss: 0.145020 Train acc: 0.959882 Valid acc: 0.946963\n",
      "Epoch: 236/1000 Train loss: 0.115497 Valid loss: 0.143774 Train acc: 0.959882 Valid acc: 0.946510\n",
      "Epoch: 237/1000 Train loss: 0.115084 Valid loss: 0.142713 Train acc: 0.959656 Valid acc: 0.946963\n",
      "Epoch: 238/1000 Train loss: 0.114939 Valid loss: 0.142185 Train acc: 0.960109 Valid acc: 0.947416\n",
      "Epoch: 239/1000 Train loss: 0.114615 Valid loss: 0.141152 Train acc: 0.960109 Valid acc: 0.947869\n",
      "Epoch: 240/1000 Train loss: 0.114336 Valid loss: 0.140967 Train acc: 0.959656 Valid acc: 0.948323\n",
      "Epoch: 241/1000 Train loss: 0.114053 Valid loss: 0.140893 Train acc: 0.959656 Valid acc: 0.948323\n",
      "Epoch: 242/1000 Train loss: 0.113792 Valid loss: 0.140834 Train acc: 0.959882 Valid acc: 0.948323\n",
      "Epoch: 243/1000 Train loss: 0.113507 Valid loss: 0.140765 Train acc: 0.960109 Valid acc: 0.947869\n",
      "Epoch: 244/1000 Train loss: 0.113165 Valid loss: 0.140714 Train acc: 0.959882 Valid acc: 0.948323\n",
      "Epoch: 245/1000 Train loss: 0.112697 Valid loss: 0.140591 Train acc: 0.959882 Valid acc: 0.947869\n",
      "Epoch: 246/1000 Train loss: 0.112095 Valid loss: 0.140469 Train acc: 0.960562 Valid acc: 0.948323\n",
      "Epoch: 247/1000 Train loss: 0.111833 Valid loss: 0.140430 Train acc: 0.960335 Valid acc: 0.947416\n",
      "Epoch: 248/1000 Train loss: 0.111494 Valid loss: 0.140399 Train acc: 0.960335 Valid acc: 0.947416\n",
      "Epoch: 249/1000 Train loss: 0.111239 Valid loss: 0.140232 Train acc: 0.960335 Valid acc: 0.946963\n",
      "Epoch: 250/1000 Train loss: 0.110901 Valid loss: 0.140319 Train acc: 0.960335 Valid acc: 0.946963\n",
      "Epoch: 251/1000 Train loss: 0.110716 Valid loss: 0.139787 Train acc: 0.960789 Valid acc: 0.947416\n",
      "Epoch: 252/1000 Train loss: 0.110487 Valid loss: 0.139584 Train acc: 0.961015 Valid acc: 0.946963\n",
      "Epoch: 253/1000 Train loss: 0.110297 Valid loss: 0.139388 Train acc: 0.961015 Valid acc: 0.946963\n",
      "Epoch: 254/1000 Train loss: 0.110004 Valid loss: 0.139471 Train acc: 0.960789 Valid acc: 0.946510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 255/1000 Train loss: 0.109723 Valid loss: 0.139468 Train acc: 0.960789 Valid acc: 0.946510\n",
      "Epoch: 256/1000 Train loss: 0.109515 Valid loss: 0.139441 Train acc: 0.961015 Valid acc: 0.946510\n",
      "Epoch: 257/1000 Train loss: 0.109253 Valid loss: 0.139605 Train acc: 0.960562 Valid acc: 0.946056\n",
      "Epoch: 258/1000 Train loss: 0.108974 Valid loss: 0.139612 Train acc: 0.960789 Valid acc: 0.946056\n",
      "Epoch: 259/1000 Train loss: 0.108671 Valid loss: 0.139463 Train acc: 0.960562 Valid acc: 0.945150\n",
      "Epoch: 260/1000 Train loss: 0.108412 Valid loss: 0.139096 Train acc: 0.960562 Valid acc: 0.945150\n",
      "Epoch: 261/1000 Train loss: 0.108159 Valid loss: 0.138828 Train acc: 0.960562 Valid acc: 0.945603\n",
      "Epoch: 262/1000 Train loss: 0.107918 Valid loss: 0.140687 Train acc: 0.960562 Valid acc: 0.944696\n",
      "Epoch: 263/1000 Train loss: 0.107727 Valid loss: 0.140866 Train acc: 0.960562 Valid acc: 0.944696\n",
      "Epoch: 264/1000 Train loss: 0.107483 Valid loss: 0.141607 Train acc: 0.960562 Valid acc: 0.944243\n",
      "Epoch: 265/1000 Train loss: 0.107262 Valid loss: 0.141449 Train acc: 0.960789 Valid acc: 0.944696\n",
      "Epoch: 266/1000 Train loss: 0.107020 Valid loss: 0.141578 Train acc: 0.961015 Valid acc: 0.944243\n",
      "Epoch: 267/1000 Train loss: 0.106870 Valid loss: 0.141815 Train acc: 0.961242 Valid acc: 0.944243\n",
      "Epoch: 268/1000 Train loss: 0.106662 Valid loss: 0.142082 Train acc: 0.961015 Valid acc: 0.943790\n",
      "Epoch: 269/1000 Train loss: 0.106410 Valid loss: 0.142020 Train acc: 0.961015 Valid acc: 0.943790\n",
      "Epoch: 270/1000 Train loss: 0.106292 Valid loss: 0.141783 Train acc: 0.961015 Valid acc: 0.943790\n",
      "Epoch: 271/1000 Train loss: 0.106060 Valid loss: 0.142108 Train acc: 0.961015 Valid acc: 0.943336\n",
      "Epoch: 272/1000 Train loss: 0.106022 Valid loss: 0.142816 Train acc: 0.960789 Valid acc: 0.943336\n",
      "Epoch: 273/1000 Train loss: 0.105851 Valid loss: 0.143475 Train acc: 0.961242 Valid acc: 0.944696\n",
      "Epoch: 274/1000 Train loss: 0.105838 Valid loss: 0.143369 Train acc: 0.961015 Valid acc: 0.944243\n",
      "Epoch: 275/1000 Train loss: 0.105538 Valid loss: 0.143237 Train acc: 0.961015 Valid acc: 0.943790\n",
      "Epoch: 276/1000 Train loss: 0.105443 Valid loss: 0.142893 Train acc: 0.960789 Valid acc: 0.945150\n",
      "Epoch: 277/1000 Train loss: 0.105245 Valid loss: 0.143004 Train acc: 0.961015 Valid acc: 0.944243\n",
      "Epoch: 278/1000 Train loss: 0.105043 Valid loss: 0.143020 Train acc: 0.960789 Valid acc: 0.944696\n",
      "Epoch: 279/1000 Train loss: 0.104977 Valid loss: 0.142971 Train acc: 0.960789 Valid acc: 0.946056\n",
      "Epoch: 280/1000 Train loss: 0.104664 Valid loss: 0.142704 Train acc: 0.960562 Valid acc: 0.945150\n",
      "Epoch: 281/1000 Train loss: 0.104509 Valid loss: 0.143217 Train acc: 0.960789 Valid acc: 0.944696\n",
      "Epoch: 282/1000 Train loss: 0.104336 Valid loss: 0.143246 Train acc: 0.960562 Valid acc: 0.945150\n",
      "Epoch: 283/1000 Train loss: 0.104163 Valid loss: 0.144242 Train acc: 0.960789 Valid acc: 0.944243\n",
      "Epoch: 284/1000 Train loss: 0.104016 Valid loss: 0.144491 Train acc: 0.960109 Valid acc: 0.944243\n",
      "Epoch: 285/1000 Train loss: 0.103815 Valid loss: 0.142821 Train acc: 0.960335 Valid acc: 0.945603\n",
      "Epoch: 286/1000 Train loss: 0.104583 Valid loss: 0.143228 Train acc: 0.959429 Valid acc: 0.945150\n",
      "Epoch: 287/1000 Train loss: 0.103625 Valid loss: 0.143724 Train acc: 0.959882 Valid acc: 0.945150\n",
      "Epoch: 288/1000 Train loss: 0.104323 Valid loss: 0.143384 Train acc: 0.960335 Valid acc: 0.945150\n",
      "Epoch: 289/1000 Train loss: 0.104396 Valid loss: 0.141224 Train acc: 0.959656 Valid acc: 0.946510\n",
      "Epoch: 290/1000 Train loss: 0.113271 Valid loss: 0.148930 Train acc: 0.956029 Valid acc: 0.944243\n",
      "Epoch: 291/1000 Train loss: 0.132897 Valid loss: 0.183985 Train acc: 0.950816 Valid acc: 0.932910\n",
      "Epoch: 292/1000 Train loss: 0.156367 Valid loss: 0.185879 Train acc: 0.944923 Valid acc: 0.933817\n",
      "Epoch: 293/1000 Train loss: 0.161726 Valid loss: 0.173035 Train acc: 0.944696 Valid acc: 0.941070\n",
      "Epoch: 294/1000 Train loss: 0.150695 Valid loss: 0.166519 Train acc: 0.948549 Valid acc: 0.941070\n",
      "Epoch: 295/1000 Train loss: 0.140948 Valid loss: 0.149368 Train acc: 0.950363 Valid acc: 0.942430\n",
      "Epoch: 296/1000 Train loss: 0.127444 Valid loss: 0.146278 Train acc: 0.953536 Valid acc: 0.943790\n",
      "Epoch: 297/1000 Train loss: 0.124502 Valid loss: 0.143137 Train acc: 0.955576 Valid acc: 0.946963\n",
      "Epoch: 298/1000 Train loss: 0.123012 Valid loss: 0.142179 Train acc: 0.956256 Valid acc: 0.947416\n",
      "Epoch: 299/1000 Train loss: 0.119199 Valid loss: 0.146603 Train acc: 0.956256 Valid acc: 0.944696\n",
      "Epoch: 300/1000 Train loss: 0.117933 Valid loss: 0.138098 Train acc: 0.957162 Valid acc: 0.950589\n",
      "Epoch: 301/1000 Train loss: 0.115267 Valid loss: 0.153354 Train acc: 0.958296 Valid acc: 0.946510\n",
      "Epoch: 302/1000 Train loss: 0.120899 Valid loss: 0.159036 Train acc: 0.956936 Valid acc: 0.939710\n",
      "Epoch: 303/1000 Train loss: 0.121973 Valid loss: 0.170999 Train acc: 0.956936 Valid acc: 0.936990\n",
      "Epoch: 304/1000 Train loss: 0.133253 Valid loss: 0.174461 Train acc: 0.951949 Valid acc: 0.937897\n",
      "Epoch: 305/1000 Train loss: 0.134762 Valid loss: 0.174110 Train acc: 0.951043 Valid acc: 0.937443\n",
      "Epoch: 306/1000 Train loss: 0.130456 Valid loss: 0.167539 Train acc: 0.951949 Valid acc: 0.939257\n",
      "Epoch: 307/1000 Train loss: 0.128385 Valid loss: 0.152096 Train acc: 0.953762 Valid acc: 0.942883\n",
      "Epoch: 308/1000 Train loss: 0.119288 Valid loss: 0.150275 Train acc: 0.955802 Valid acc: 0.941070\n",
      "Epoch: 309/1000 Train loss: 0.119926 Valid loss: 0.136432 Train acc: 0.954216 Valid acc: 0.947869\n",
      "Epoch: 310/1000 Train loss: 0.116410 Valid loss: 0.135731 Train acc: 0.958522 Valid acc: 0.953309\n",
      "Epoch: 311/1000 Train loss: 0.121944 Valid loss: 0.138227 Train acc: 0.956482 Valid acc: 0.949683\n",
      "Epoch: 312/1000 Train loss: 0.135927 Valid loss: 0.138071 Train acc: 0.948549 Valid acc: 0.950136\n",
      "Epoch: 313/1000 Train loss: 0.141304 Valid loss: 0.139487 Train acc: 0.948549 Valid acc: 0.948323\n",
      "Epoch: 314/1000 Train loss: 0.148277 Valid loss: 0.138189 Train acc: 0.946056 Valid acc: 0.951043\n",
      "Epoch: 315/1000 Train loss: 0.150703 Valid loss: 0.143553 Train acc: 0.942883 Valid acc: 0.944243\n",
      "Epoch: 316/1000 Train loss: 0.156469 Valid loss: 0.141898 Train acc: 0.938803 Valid acc: 0.949683\n",
      "Epoch: 317/1000 Train loss: 0.155067 Valid loss: 0.140453 Train acc: 0.941976 Valid acc: 0.951949\n",
      "Epoch: 318/1000 Train loss: 0.147502 Valid loss: 0.138023 Train acc: 0.942883 Valid acc: 0.947869\n",
      "Epoch: 319/1000 Train loss: 0.138360 Valid loss: 0.134681 Train acc: 0.943110 Valid acc: 0.946510\n",
      "Epoch: 320/1000 Train loss: 0.130520 Valid loss: 0.136240 Train acc: 0.945150 Valid acc: 0.946963\n",
      "Epoch: 321/1000 Train loss: 0.127917 Valid loss: 0.133170 Train acc: 0.946963 Valid acc: 0.946510\n",
      "Epoch: 322/1000 Train loss: 0.116380 Valid loss: 0.130818 Train acc: 0.956029 Valid acc: 0.951043\n",
      "Epoch: 323/1000 Train loss: 0.115408 Valid loss: 0.129838 Train acc: 0.956256 Valid acc: 0.951949\n",
      "Epoch: 324/1000 Train loss: 0.112076 Valid loss: 0.129037 Train acc: 0.957616 Valid acc: 0.949683\n",
      "Epoch: 325/1000 Train loss: 0.109181 Valid loss: 0.132953 Train acc: 0.960335 Valid acc: 0.947416\n",
      "Epoch: 326/1000 Train loss: 0.109063 Valid loss: 0.133326 Train acc: 0.959882 Valid acc: 0.948776\n",
      "Epoch: 327/1000 Train loss: 0.108334 Valid loss: 0.130993 Train acc: 0.960335 Valid acc: 0.951496\n",
      "Epoch: 328/1000 Train loss: 0.107564 Valid loss: 0.131016 Train acc: 0.960562 Valid acc: 0.952403\n",
      "Epoch: 329/1000 Train loss: 0.107504 Valid loss: 0.133348 Train acc: 0.961695 Valid acc: 0.951949\n",
      "Epoch: 330/1000 Train loss: 0.106726 Valid loss: 0.135367 Train acc: 0.962149 Valid acc: 0.948323\n",
      "Epoch: 331/1000 Train loss: 0.105872 Valid loss: 0.138256 Train acc: 0.962149 Valid acc: 0.946056\n",
      "Epoch: 332/1000 Train loss: 0.106174 Valid loss: 0.137883 Train acc: 0.962149 Valid acc: 0.945603\n",
      "Epoch: 333/1000 Train loss: 0.105368 Valid loss: 0.136128 Train acc: 0.961015 Valid acc: 0.947869\n",
      "Epoch: 334/1000 Train loss: 0.104788 Valid loss: 0.136277 Train acc: 0.962149 Valid acc: 0.950589\n",
      "Epoch: 335/1000 Train loss: 0.104428 Valid loss: 0.136793 Train acc: 0.963282 Valid acc: 0.949229\n",
      "Epoch: 336/1000 Train loss: 0.103824 Valid loss: 0.138773 Train acc: 0.963282 Valid acc: 0.947416\n",
      "Epoch: 337/1000 Train loss: 0.103698 Valid loss: 0.136544 Train acc: 0.961469 Valid acc: 0.947416\n",
      "Epoch: 338/1000 Train loss: 0.103402 Valid loss: 0.135981 Train acc: 0.962829 Valid acc: 0.950589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 339/1000 Train loss: 0.102550 Valid loss: 0.138236 Train acc: 0.962375 Valid acc: 0.947869\n",
      "Epoch: 340/1000 Train loss: 0.102674 Valid loss: 0.135862 Train acc: 0.962149 Valid acc: 0.951043\n",
      "Epoch: 341/1000 Train loss: 0.102405 Valid loss: 0.135622 Train acc: 0.963509 Valid acc: 0.950589\n",
      "Epoch: 342/1000 Train loss: 0.102327 Valid loss: 0.135629 Train acc: 0.963282 Valid acc: 0.950136\n",
      "Epoch: 343/1000 Train loss: 0.101268 Valid loss: 0.136617 Train acc: 0.963282 Valid acc: 0.946963\n",
      "Epoch: 344/1000 Train loss: 0.101123 Valid loss: 0.134847 Train acc: 0.963055 Valid acc: 0.950136\n",
      "Epoch: 345/1000 Train loss: 0.101857 Valid loss: 0.134880 Train acc: 0.964189 Valid acc: 0.949683\n",
      "Epoch: 346/1000 Train loss: 0.100726 Valid loss: 0.138373 Train acc: 0.964189 Valid acc: 0.946510\n",
      "Epoch: 347/1000 Train loss: 0.100763 Valid loss: 0.135960 Train acc: 0.962829 Valid acc: 0.950136\n",
      "Epoch: 348/1000 Train loss: 0.101820 Valid loss: 0.135577 Train acc: 0.963055 Valid acc: 0.949683\n",
      "Epoch: 349/1000 Train loss: 0.100602 Valid loss: 0.137053 Train acc: 0.963735 Valid acc: 0.946963\n",
      "Epoch: 350/1000 Train loss: 0.100863 Valid loss: 0.137059 Train acc: 0.962149 Valid acc: 0.948323\n",
      "Epoch: 351/1000 Train loss: 0.100227 Valid loss: 0.135446 Train acc: 0.963055 Valid acc: 0.948776\n",
      "Epoch: 352/1000 Train loss: 0.100600 Valid loss: 0.135272 Train acc: 0.963735 Valid acc: 0.947416\n",
      "Epoch: 353/1000 Train loss: 0.099527 Valid loss: 0.136957 Train acc: 0.962829 Valid acc: 0.948323\n",
      "Epoch: 354/1000 Train loss: 0.099062 Valid loss: 0.135708 Train acc: 0.964415 Valid acc: 0.948323\n",
      "Epoch: 355/1000 Train loss: 0.099208 Valid loss: 0.136405 Train acc: 0.964869 Valid acc: 0.948323\n",
      "Epoch: 356/1000 Train loss: 0.099244 Valid loss: 0.136385 Train acc: 0.963735 Valid acc: 0.946963\n",
      "Epoch: 357/1000 Train loss: 0.098397 Valid loss: 0.134865 Train acc: 0.964189 Valid acc: 0.947416\n",
      "Epoch: 358/1000 Train loss: 0.098482 Valid loss: 0.135388 Train acc: 0.964189 Valid acc: 0.948323\n",
      "Epoch: 359/1000 Train loss: 0.098409 Valid loss: 0.135237 Train acc: 0.963282 Valid acc: 0.948776\n",
      "Epoch: 360/1000 Train loss: 0.098805 Valid loss: 0.135022 Train acc: 0.963962 Valid acc: 0.949229\n",
      "Epoch: 361/1000 Train loss: 0.099539 Valid loss: 0.135400 Train acc: 0.963735 Valid acc: 0.948776\n",
      "Epoch: 362/1000 Train loss: 0.099185 Valid loss: 0.135307 Train acc: 0.963055 Valid acc: 0.949229\n",
      "Epoch: 363/1000 Train loss: 0.098842 Valid loss: 0.134606 Train acc: 0.963962 Valid acc: 0.949229\n",
      "Epoch: 364/1000 Train loss: 0.098135 Valid loss: 0.136387 Train acc: 0.964415 Valid acc: 0.947869\n",
      "Epoch: 365/1000 Train loss: 0.098194 Valid loss: 0.135265 Train acc: 0.963735 Valid acc: 0.948323\n",
      "Epoch: 366/1000 Train loss: 0.098758 Valid loss: 0.135862 Train acc: 0.963509 Valid acc: 0.948323\n",
      "Epoch: 367/1000 Train loss: 0.097777 Valid loss: 0.135672 Train acc: 0.964415 Valid acc: 0.947416\n",
      "Epoch: 368/1000 Train loss: 0.098797 Valid loss: 0.130969 Train acc: 0.963735 Valid acc: 0.949229\n",
      "Epoch: 369/1000 Train loss: 0.100972 Valid loss: 0.133346 Train acc: 0.962602 Valid acc: 0.946963\n",
      "Epoch: 370/1000 Train loss: 0.100332 Valid loss: 0.133681 Train acc: 0.963735 Valid acc: 0.948776\n",
      "Epoch: 371/1000 Train loss: 0.098659 Valid loss: 0.135479 Train acc: 0.963735 Valid acc: 0.947416\n",
      "Epoch: 372/1000 Train loss: 0.099319 Valid loss: 0.137119 Train acc: 0.964642 Valid acc: 0.946510\n",
      "Epoch: 373/1000 Train loss: 0.098978 Valid loss: 0.136435 Train acc: 0.963735 Valid acc: 0.946056\n",
      "Epoch: 374/1000 Train loss: 0.099708 Valid loss: 0.136503 Train acc: 0.963735 Valid acc: 0.947416\n",
      "Epoch: 375/1000 Train loss: 0.107230 Valid loss: 0.153414 Train acc: 0.958296 Valid acc: 0.936537\n",
      "Epoch: 376/1000 Train loss: 0.116434 Valid loss: 0.140125 Train acc: 0.952856 Valid acc: 0.946056\n",
      "Epoch: 377/1000 Train loss: 0.115410 Valid loss: 0.137676 Train acc: 0.955576 Valid acc: 0.945150\n",
      "Epoch: 378/1000 Train loss: 0.106781 Valid loss: 0.139397 Train acc: 0.958976 Valid acc: 0.942430\n",
      "Epoch: 379/1000 Train loss: 0.106176 Valid loss: 0.141286 Train acc: 0.957616 Valid acc: 0.941523\n",
      "Epoch: 380/1000 Train loss: 0.109955 Valid loss: 0.140667 Train acc: 0.956482 Valid acc: 0.941976\n",
      "Epoch: 381/1000 Train loss: 0.107257 Valid loss: 0.138776 Train acc: 0.955576 Valid acc: 0.941976\n",
      "Epoch: 382/1000 Train loss: 0.104454 Valid loss: 0.136814 Train acc: 0.957162 Valid acc: 0.941976\n",
      "Epoch: 383/1000 Train loss: 0.104358 Valid loss: 0.133631 Train acc: 0.958296 Valid acc: 0.947869\n",
      "Epoch: 384/1000 Train loss: 0.106589 Valid loss: 0.135481 Train acc: 0.956256 Valid acc: 0.945150\n",
      "Epoch: 385/1000 Train loss: 0.104780 Valid loss: 0.136243 Train acc: 0.956936 Valid acc: 0.947416\n",
      "Epoch: 386/1000 Train loss: 0.102480 Valid loss: 0.136411 Train acc: 0.960562 Valid acc: 0.943790\n",
      "Epoch: 387/1000 Train loss: 0.101647 Valid loss: 0.134284 Train acc: 0.960109 Valid acc: 0.945150\n",
      "Epoch: 388/1000 Train loss: 0.102102 Valid loss: 0.133158 Train acc: 0.958069 Valid acc: 0.943336\n",
      "Epoch: 389/1000 Train loss: 0.102085 Valid loss: 0.133028 Train acc: 0.958749 Valid acc: 0.943790\n",
      "Epoch: 390/1000 Train loss: 0.101194 Valid loss: 0.133001 Train acc: 0.958749 Valid acc: 0.944696\n",
      "Epoch: 391/1000 Train loss: 0.099786 Valid loss: 0.133204 Train acc: 0.960335 Valid acc: 0.946056\n",
      "Epoch: 392/1000 Train loss: 0.099508 Valid loss: 0.132136 Train acc: 0.961922 Valid acc: 0.948323\n",
      "Epoch: 393/1000 Train loss: 0.099734 Valid loss: 0.131151 Train acc: 0.960789 Valid acc: 0.948323\n",
      "Epoch: 394/1000 Train loss: 0.099477 Valid loss: 0.130858 Train acc: 0.959655 Valid acc: 0.949229\n",
      "Epoch: 395/1000 Train loss: 0.098135 Valid loss: 0.131876 Train acc: 0.961922 Valid acc: 0.950589\n",
      "Epoch: 396/1000 Train loss: 0.097741 Valid loss: 0.130333 Train acc: 0.963509 Valid acc: 0.948776\n",
      "Epoch: 397/1000 Train loss: 0.097957 Valid loss: 0.128394 Train acc: 0.963509 Valid acc: 0.947416\n",
      "Epoch: 398/1000 Train loss: 0.097521 Valid loss: 0.127758 Train acc: 0.963735 Valid acc: 0.949683\n",
      "Epoch: 399/1000 Train loss: 0.096606 Valid loss: 0.131552 Train acc: 0.964415 Valid acc: 0.947869\n",
      "Epoch: 400/1000 Train loss: 0.096663 Valid loss: 0.130603 Train acc: 0.963509 Valid acc: 0.948323\n",
      "Epoch: 401/1000 Train loss: 0.096490 Valid loss: 0.128028 Train acc: 0.963735 Valid acc: 0.948776\n",
      "Epoch: 402/1000 Train loss: 0.098718 Valid loss: 0.133072 Train acc: 0.963055 Valid acc: 0.948323\n",
      "Epoch: 403/1000 Train loss: 0.103182 Valid loss: 0.128820 Train acc: 0.960335 Valid acc: 0.947416\n",
      "Epoch: 404/1000 Train loss: 0.097146 Valid loss: 0.134031 Train acc: 0.961922 Valid acc: 0.946510\n",
      "Epoch: 405/1000 Train loss: 0.100229 Valid loss: 0.127915 Train acc: 0.961469 Valid acc: 0.951949\n",
      "Epoch: 406/1000 Train loss: 0.098208 Valid loss: 0.132465 Train acc: 0.962375 Valid acc: 0.949683\n",
      "Epoch: 407/1000 Train loss: 0.102335 Valid loss: 0.130823 Train acc: 0.960109 Valid acc: 0.949683\n",
      "Epoch: 408/1000 Train loss: 0.097915 Valid loss: 0.128313 Train acc: 0.963735 Valid acc: 0.949229\n",
      "Epoch: 409/1000 Train loss: 0.097441 Valid loss: 0.127849 Train acc: 0.963509 Valid acc: 0.950136\n",
      "Epoch: 410/1000 Train loss: 0.097410 Valid loss: 0.128075 Train acc: 0.963282 Valid acc: 0.950589\n",
      "Epoch: 411/1000 Train loss: 0.096629 Valid loss: 0.128690 Train acc: 0.965775 Valid acc: 0.951043\n",
      "Epoch: 412/1000 Train loss: 0.095987 Valid loss: 0.128660 Train acc: 0.966002 Valid acc: 0.949683\n",
      "Epoch: 413/1000 Train loss: 0.095283 Valid loss: 0.129498 Train acc: 0.965095 Valid acc: 0.947416\n",
      "Epoch: 414/1000 Train loss: 0.095404 Valid loss: 0.128782 Train acc: 0.964189 Valid acc: 0.951043\n",
      "Epoch: 415/1000 Train loss: 0.095404 Valid loss: 0.128939 Train acc: 0.965322 Valid acc: 0.951949\n",
      "Epoch: 416/1000 Train loss: 0.095201 Valid loss: 0.129459 Train acc: 0.966908 Valid acc: 0.951949\n",
      "Epoch: 417/1000 Train loss: 0.094967 Valid loss: 0.128146 Train acc: 0.966682 Valid acc: 0.951043\n",
      "Epoch: 418/1000 Train loss: 0.094248 Valid loss: 0.128844 Train acc: 0.965095 Valid acc: 0.949683\n",
      "Epoch: 419/1000 Train loss: 0.094160 Valid loss: 0.128785 Train acc: 0.964869 Valid acc: 0.950589\n",
      "Epoch: 420/1000 Train loss: 0.093977 Valid loss: 0.127967 Train acc: 0.965322 Valid acc: 0.951949\n",
      "Epoch: 421/1000 Train loss: 0.093757 Valid loss: 0.127504 Train acc: 0.965549 Valid acc: 0.951043\n",
      "Epoch: 422/1000 Train loss: 0.093342 Valid loss: 0.127443 Train acc: 0.965775 Valid acc: 0.950589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 423/1000 Train loss: 0.093281 Valid loss: 0.127758 Train acc: 0.966002 Valid acc: 0.950589\n",
      "Epoch: 424/1000 Train loss: 0.093057 Valid loss: 0.128028 Train acc: 0.966228 Valid acc: 0.950589\n",
      "Epoch: 425/1000 Train loss: 0.093184 Valid loss: 0.127790 Train acc: 0.965549 Valid acc: 0.951949\n",
      "Epoch: 426/1000 Train loss: 0.092753 Valid loss: 0.127819 Train acc: 0.966455 Valid acc: 0.951496\n",
      "Epoch: 427/1000 Train loss: 0.092475 Valid loss: 0.127855 Train acc: 0.966228 Valid acc: 0.951949\n",
      "Epoch: 428/1000 Train loss: 0.092490 Valid loss: 0.128524 Train acc: 0.966228 Valid acc: 0.951949\n",
      "Epoch: 429/1000 Train loss: 0.092313 Valid loss: 0.127447 Train acc: 0.966002 Valid acc: 0.951496\n",
      "Epoch: 430/1000 Train loss: 0.091998 Valid loss: 0.127030 Train acc: 0.966228 Valid acc: 0.952856\n",
      "Epoch: 431/1000 Train loss: 0.091878 Valid loss: 0.126888 Train acc: 0.966455 Valid acc: 0.951949\n",
      "Epoch: 432/1000 Train loss: 0.091675 Valid loss: 0.126776 Train acc: 0.966455 Valid acc: 0.952403\n",
      "Epoch: 433/1000 Train loss: 0.091571 Valid loss: 0.127023 Train acc: 0.966682 Valid acc: 0.953309\n",
      "Epoch: 434/1000 Train loss: 0.091454 Valid loss: 0.126805 Train acc: 0.966228 Valid acc: 0.951949\n",
      "Epoch: 435/1000 Train loss: 0.091251 Valid loss: 0.126089 Train acc: 0.966228 Valid acc: 0.952403\n",
      "Epoch: 436/1000 Train loss: 0.091183 Valid loss: 0.125420 Train acc: 0.966455 Valid acc: 0.953762\n",
      "Epoch: 437/1000 Train loss: 0.091162 Valid loss: 0.125736 Train acc: 0.966002 Valid acc: 0.952403\n",
      "Epoch: 438/1000 Train loss: 0.090908 Valid loss: 0.125006 Train acc: 0.966908 Valid acc: 0.952403\n",
      "Epoch: 439/1000 Train loss: 0.090891 Valid loss: 0.124666 Train acc: 0.966682 Valid acc: 0.952856\n",
      "Epoch: 440/1000 Train loss: 0.090680 Valid loss: 0.124884 Train acc: 0.966682 Valid acc: 0.951949\n",
      "Epoch: 441/1000 Train loss: 0.090544 Valid loss: 0.123981 Train acc: 0.966908 Valid acc: 0.953309\n",
      "Epoch: 442/1000 Train loss: 0.090569 Valid loss: 0.124083 Train acc: 0.966908 Valid acc: 0.951949\n",
      "Epoch: 443/1000 Train loss: 0.090330 Valid loss: 0.123740 Train acc: 0.966455 Valid acc: 0.952856\n",
      "Epoch: 444/1000 Train loss: 0.090288 Valid loss: 0.123292 Train acc: 0.966908 Valid acc: 0.953309\n",
      "Epoch: 445/1000 Train loss: 0.090213 Valid loss: 0.123923 Train acc: 0.967135 Valid acc: 0.952403\n",
      "Epoch: 446/1000 Train loss: 0.089983 Valid loss: 0.123225 Train acc: 0.966455 Valid acc: 0.952856\n",
      "Epoch: 447/1000 Train loss: 0.090171 Valid loss: 0.123488 Train acc: 0.966908 Valid acc: 0.952856\n",
      "Epoch: 448/1000 Train loss: 0.089897 Valid loss: 0.123201 Train acc: 0.966228 Valid acc: 0.952856\n",
      "Epoch: 449/1000 Train loss: 0.089862 Valid loss: 0.122433 Train acc: 0.966682 Valid acc: 0.953309\n",
      "Epoch: 450/1000 Train loss: 0.089705 Valid loss: 0.123498 Train acc: 0.967362 Valid acc: 0.951949\n",
      "Epoch: 451/1000 Train loss: 0.089522 Valid loss: 0.123084 Train acc: 0.966455 Valid acc: 0.952856\n",
      "Epoch: 452/1000 Train loss: 0.089652 Valid loss: 0.122899 Train acc: 0.966682 Valid acc: 0.953309\n",
      "Epoch: 453/1000 Train loss: 0.089461 Valid loss: 0.123244 Train acc: 0.966455 Valid acc: 0.952403\n",
      "Epoch: 454/1000 Train loss: 0.090073 Valid loss: 0.122858 Train acc: 0.966455 Valid acc: 0.953762\n",
      "Epoch: 455/1000 Train loss: 0.089620 Valid loss: 0.126884 Train acc: 0.967588 Valid acc: 0.952403\n",
      "Epoch: 456/1000 Train loss: 0.089348 Valid loss: 0.126867 Train acc: 0.967135 Valid acc: 0.951496\n",
      "Epoch: 457/1000 Train loss: 0.089365 Valid loss: 0.128821 Train acc: 0.967135 Valid acc: 0.951496\n",
      "Epoch: 458/1000 Train loss: 0.089508 Valid loss: 0.126973 Train acc: 0.966908 Valid acc: 0.951496\n",
      "Epoch: 459/1000 Train loss: 0.089202 Valid loss: 0.125815 Train acc: 0.967135 Valid acc: 0.952403\n",
      "Epoch: 460/1000 Train loss: 0.089301 Valid loss: 0.124836 Train acc: 0.967135 Valid acc: 0.951949\n",
      "Epoch: 461/1000 Train loss: 0.089041 Valid loss: 0.125826 Train acc: 0.967362 Valid acc: 0.952403\n",
      "Epoch: 462/1000 Train loss: 0.088956 Valid loss: 0.124499 Train acc: 0.966682 Valid acc: 0.952403\n",
      "Epoch: 463/1000 Train loss: 0.089294 Valid loss: 0.125903 Train acc: 0.967362 Valid acc: 0.952403\n",
      "Epoch: 464/1000 Train loss: 0.088660 Valid loss: 0.125002 Train acc: 0.967135 Valid acc: 0.952856\n",
      "Epoch: 465/1000 Train loss: 0.088715 Valid loss: 0.123275 Train acc: 0.967588 Valid acc: 0.952856\n",
      "Epoch: 466/1000 Train loss: 0.088668 Valid loss: 0.123687 Train acc: 0.968042 Valid acc: 0.952856\n",
      "Epoch: 467/1000 Train loss: 0.088257 Valid loss: 0.124384 Train acc: 0.967588 Valid acc: 0.952856\n",
      "Epoch: 468/1000 Train loss: 0.088260 Valid loss: 0.123990 Train acc: 0.967815 Valid acc: 0.952856\n",
      "Epoch: 469/1000 Train loss: 0.088228 Valid loss: 0.123311 Train acc: 0.967588 Valid acc: 0.953762\n",
      "Epoch: 470/1000 Train loss: 0.088136 Valid loss: 0.123978 Train acc: 0.967362 Valid acc: 0.952856\n",
      "Epoch: 471/1000 Train loss: 0.087890 Valid loss: 0.123070 Train acc: 0.968042 Valid acc: 0.953309\n",
      "Epoch: 472/1000 Train loss: 0.087916 Valid loss: 0.123516 Train acc: 0.967815 Valid acc: 0.953762\n",
      "Epoch: 473/1000 Train loss: 0.087978 Valid loss: 0.121948 Train acc: 0.967815 Valid acc: 0.954216\n",
      "Epoch: 474/1000 Train loss: 0.087758 Valid loss: 0.121976 Train acc: 0.968042 Valid acc: 0.954216\n",
      "Epoch: 475/1000 Train loss: 0.087546 Valid loss: 0.122720 Train acc: 0.967588 Valid acc: 0.954669\n",
      "Epoch: 476/1000 Train loss: 0.087552 Valid loss: 0.121757 Train acc: 0.967588 Valid acc: 0.955122\n",
      "Epoch: 477/1000 Train loss: 0.087456 Valid loss: 0.121570 Train acc: 0.968042 Valid acc: 0.954669\n",
      "Epoch: 478/1000 Train loss: 0.087252 Valid loss: 0.121248 Train acc: 0.967815 Valid acc: 0.954669\n",
      "Epoch: 479/1000 Train loss: 0.087274 Valid loss: 0.121043 Train acc: 0.967588 Valid acc: 0.954669\n",
      "Epoch: 480/1000 Train loss: 0.087100 Valid loss: 0.121648 Train acc: 0.968042 Valid acc: 0.954216\n",
      "Epoch: 481/1000 Train loss: 0.087033 Valid loss: 0.120589 Train acc: 0.967588 Valid acc: 0.954669\n",
      "Epoch: 482/1000 Train loss: 0.087148 Valid loss: 0.120542 Train acc: 0.968042 Valid acc: 0.954669\n",
      "Epoch: 483/1000 Train loss: 0.086884 Valid loss: 0.121576 Train acc: 0.968042 Valid acc: 0.954216\n",
      "Epoch: 484/1000 Train loss: 0.086787 Valid loss: 0.121111 Train acc: 0.967815 Valid acc: 0.955122\n",
      "Epoch: 485/1000 Train loss: 0.086750 Valid loss: 0.121577 Train acc: 0.968042 Valid acc: 0.954669\n",
      "Epoch: 486/1000 Train loss: 0.086685 Valid loss: 0.120654 Train acc: 0.967588 Valid acc: 0.954669\n",
      "Epoch: 487/1000 Train loss: 0.086877 Valid loss: 0.121170 Train acc: 0.967815 Valid acc: 0.955122\n",
      "Epoch: 488/1000 Train loss: 0.086468 Valid loss: 0.121510 Train acc: 0.967815 Valid acc: 0.954669\n",
      "Epoch: 489/1000 Train loss: 0.086567 Valid loss: 0.120036 Train acc: 0.968042 Valid acc: 0.954216\n",
      "Epoch: 490/1000 Train loss: 0.086272 Valid loss: 0.120752 Train acc: 0.967588 Valid acc: 0.954669\n",
      "Epoch: 491/1000 Train loss: 0.086294 Valid loss: 0.119730 Train acc: 0.967362 Valid acc: 0.954669\n",
      "Epoch: 492/1000 Train loss: 0.086424 Valid loss: 0.120196 Train acc: 0.968042 Valid acc: 0.954669\n",
      "Epoch: 493/1000 Train loss: 0.086125 Valid loss: 0.120573 Train acc: 0.967362 Valid acc: 0.955122\n",
      "Epoch: 494/1000 Train loss: 0.086185 Valid loss: 0.119708 Train acc: 0.968042 Valid acc: 0.954669\n",
      "Epoch: 495/1000 Train loss: 0.087264 Valid loss: 0.133036 Train acc: 0.967815 Valid acc: 0.946963\n",
      "Epoch: 496/1000 Train loss: 0.092354 Valid loss: 0.125811 Train acc: 0.964415 Valid acc: 0.951496\n",
      "Epoch: 497/1000 Train loss: 0.093824 Valid loss: 0.131888 Train acc: 0.963509 Valid acc: 0.946963\n",
      "Epoch: 498/1000 Train loss: 0.100157 Valid loss: 0.128382 Train acc: 0.959429 Valid acc: 0.950589\n",
      "Epoch: 499/1000 Train loss: 0.095877 Valid loss: 0.140386 Train acc: 0.963735 Valid acc: 0.948323\n",
      "Epoch: 500/1000 Train loss: 0.116761 Valid loss: 0.142053 Train acc: 0.955802 Valid acc: 0.949229\n",
      "Epoch: 501/1000 Train loss: 0.142962 Valid loss: 0.162597 Train acc: 0.951269 Valid acc: 0.946510\n",
      "Epoch: 502/1000 Train loss: 0.160419 Valid loss: 0.171821 Train acc: 0.947869 Valid acc: 0.944696\n",
      "Epoch: 503/1000 Train loss: 0.173929 Valid loss: 0.175983 Train acc: 0.946283 Valid acc: 0.943790\n",
      "Epoch: 504/1000 Train loss: 0.172474 Valid loss: 0.179802 Train acc: 0.947869 Valid acc: 0.942430\n",
      "Epoch: 505/1000 Train loss: 0.166568 Valid loss: 0.186972 Train acc: 0.947869 Valid acc: 0.931097\n",
      "Epoch: 506/1000 Train loss: 0.169430 Valid loss: 0.177511 Train acc: 0.938803 Valid acc: 0.940616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 507/1000 Train loss: 0.153754 Valid loss: 0.184810 Train acc: 0.947643 Valid acc: 0.934270\n",
      "Epoch: 508/1000 Train loss: 0.153763 Valid loss: 0.165810 Train acc: 0.943790 Valid acc: 0.941070\n",
      "Epoch: 509/1000 Train loss: 0.133791 Valid loss: 0.159089 Train acc: 0.952629 Valid acc: 0.944243\n",
      "Epoch: 510/1000 Train loss: 0.120510 Valid loss: 0.159595 Train acc: 0.958976 Valid acc: 0.944243\n",
      "Epoch: 511/1000 Train loss: 0.121686 Valid loss: 0.158188 Train acc: 0.957162 Valid acc: 0.943790\n",
      "Epoch: 512/1000 Train loss: 0.113909 Valid loss: 0.154741 Train acc: 0.960335 Valid acc: 0.946056\n",
      "Epoch: 513/1000 Train loss: 0.110274 Valid loss: 0.150723 Train acc: 0.961469 Valid acc: 0.946963\n",
      "Epoch: 514/1000 Train loss: 0.110455 Valid loss: 0.145052 Train acc: 0.961469 Valid acc: 0.948323\n",
      "Epoch: 515/1000 Train loss: 0.108471 Valid loss: 0.140668 Train acc: 0.961469 Valid acc: 0.950136\n",
      "Epoch: 516/1000 Train loss: 0.104162 Valid loss: 0.136337 Train acc: 0.962375 Valid acc: 0.950589\n",
      "Epoch: 517/1000 Train loss: 0.102252 Valid loss: 0.135727 Train acc: 0.963282 Valid acc: 0.950589\n",
      "Epoch: 518/1000 Train loss: 0.099183 Valid loss: 0.134709 Train acc: 0.963735 Valid acc: 0.948323\n",
      "Epoch: 519/1000 Train loss: 0.098175 Valid loss: 0.136329 Train acc: 0.963735 Valid acc: 0.949683\n",
      "Epoch: 520/1000 Train loss: 0.097787 Valid loss: 0.141869 Train acc: 0.963282 Valid acc: 0.944696\n",
      "Epoch: 521/1000 Train loss: 0.108850 Valid loss: 0.143177 Train acc: 0.956256 Valid acc: 0.942430\n",
      "Epoch: 522/1000 Train loss: 0.108465 Valid loss: 0.141337 Train acc: 0.953536 Valid acc: 0.945603\n",
      "Epoch: 523/1000 Train loss: 0.110281 Valid loss: 0.141591 Train acc: 0.956029 Valid acc: 0.945603\n",
      "Epoch: 524/1000 Train loss: 0.109560 Valid loss: 0.136210 Train acc: 0.955802 Valid acc: 0.947416\n",
      "Epoch: 525/1000 Train loss: 0.106189 Valid loss: 0.138378 Train acc: 0.958976 Valid acc: 0.945603\n",
      "Epoch: 526/1000 Train loss: 0.109313 Valid loss: 0.136932 Train acc: 0.956936 Valid acc: 0.945603\n",
      "Epoch: 527/1000 Train loss: 0.105822 Valid loss: 0.134393 Train acc: 0.957842 Valid acc: 0.943336\n",
      "Epoch: 528/1000 Train loss: 0.103904 Valid loss: 0.130886 Train acc: 0.958296 Valid acc: 0.943336\n",
      "Epoch: 529/1000 Train loss: 0.100580 Valid loss: 0.129336 Train acc: 0.958749 Valid acc: 0.945603\n",
      "Epoch: 530/1000 Train loss: 0.101077 Valid loss: 0.128789 Train acc: 0.959429 Valid acc: 0.947869\n",
      "Epoch: 531/1000 Train loss: 0.099498 Valid loss: 0.128869 Train acc: 0.959655 Valid acc: 0.948776\n",
      "Epoch: 532/1000 Train loss: 0.098836 Valid loss: 0.127176 Train acc: 0.960562 Valid acc: 0.948323\n",
      "Epoch: 533/1000 Train loss: 0.096067 Valid loss: 0.128424 Train acc: 0.961922 Valid acc: 0.948323\n",
      "Epoch: 534/1000 Train loss: 0.097439 Valid loss: 0.128264 Train acc: 0.960562 Valid acc: 0.948776\n",
      "Epoch: 535/1000 Train loss: 0.095701 Valid loss: 0.127946 Train acc: 0.961695 Valid acc: 0.949229\n",
      "Epoch: 536/1000 Train loss: 0.094898 Valid loss: 0.127704 Train acc: 0.963055 Valid acc: 0.951043\n",
      "Epoch: 537/1000 Train loss: 0.094244 Valid loss: 0.126735 Train acc: 0.963735 Valid acc: 0.950589\n",
      "Epoch: 538/1000 Train loss: 0.092939 Valid loss: 0.127055 Train acc: 0.963509 Valid acc: 0.947869\n",
      "Epoch: 539/1000 Train loss: 0.093276 Valid loss: 0.124197 Train acc: 0.963962 Valid acc: 0.949229\n",
      "Epoch: 540/1000 Train loss: 0.091613 Valid loss: 0.123709 Train acc: 0.964415 Valid acc: 0.948776\n",
      "Epoch: 541/1000 Train loss: 0.092706 Valid loss: 0.124338 Train acc: 0.964415 Valid acc: 0.948323\n",
      "Epoch: 542/1000 Train loss: 0.091132 Valid loss: 0.125590 Train acc: 0.964642 Valid acc: 0.948323\n",
      "Epoch: 543/1000 Train loss: 0.090833 Valid loss: 0.125090 Train acc: 0.963962 Valid acc: 0.946510\n",
      "Epoch: 544/1000 Train loss: 0.090764 Valid loss: 0.124826 Train acc: 0.963962 Valid acc: 0.947416\n",
      "Epoch: 545/1000 Train loss: 0.090887 Valid loss: 0.124272 Train acc: 0.964642 Valid acc: 0.947869\n",
      "Epoch: 546/1000 Train loss: 0.090298 Valid loss: 0.124961 Train acc: 0.965322 Valid acc: 0.948323\n",
      "Epoch: 547/1000 Train loss: 0.090298 Valid loss: 0.122452 Train acc: 0.965095 Valid acc: 0.951496\n",
      "Epoch: 548/1000 Train loss: 0.090205 Valid loss: 0.122658 Train acc: 0.965549 Valid acc: 0.951949\n",
      "Epoch: 549/1000 Train loss: 0.089804 Valid loss: 0.123724 Train acc: 0.965549 Valid acc: 0.950589\n",
      "Epoch: 550/1000 Train loss: 0.089586 Valid loss: 0.124162 Train acc: 0.966455 Valid acc: 0.949683\n",
      "Epoch: 551/1000 Train loss: 0.089548 Valid loss: 0.123506 Train acc: 0.965775 Valid acc: 0.950136\n",
      "Epoch: 552/1000 Train loss: 0.089353 Valid loss: 0.122970 Train acc: 0.965549 Valid acc: 0.950589\n",
      "Epoch: 553/1000 Train loss: 0.089114 Valid loss: 0.122873 Train acc: 0.966228 Valid acc: 0.949683\n",
      "Epoch: 554/1000 Train loss: 0.089044 Valid loss: 0.121502 Train acc: 0.966228 Valid acc: 0.950136\n",
      "Epoch: 555/1000 Train loss: 0.088906 Valid loss: 0.120104 Train acc: 0.966455 Valid acc: 0.950136\n",
      "Epoch: 556/1000 Train loss: 0.088657 Valid loss: 0.120636 Train acc: 0.966228 Valid acc: 0.950589\n",
      "Epoch: 557/1000 Train loss: 0.088574 Valid loss: 0.120080 Train acc: 0.965549 Valid acc: 0.950589\n",
      "Epoch: 558/1000 Train loss: 0.088453 Valid loss: 0.120127 Train acc: 0.965322 Valid acc: 0.951496\n",
      "Epoch: 559/1000 Train loss: 0.088395 Valid loss: 0.120002 Train acc: 0.965322 Valid acc: 0.950589\n",
      "Epoch: 560/1000 Train loss: 0.088290 Valid loss: 0.120549 Train acc: 0.966002 Valid acc: 0.950589\n",
      "Epoch: 561/1000 Train loss: 0.088120 Valid loss: 0.120503 Train acc: 0.966002 Valid acc: 0.951496\n",
      "Epoch: 562/1000 Train loss: 0.088044 Valid loss: 0.120490 Train acc: 0.965549 Valid acc: 0.951496\n",
      "Epoch: 563/1000 Train loss: 0.087931 Valid loss: 0.120479 Train acc: 0.965322 Valid acc: 0.951043\n",
      "Epoch: 564/1000 Train loss: 0.089355 Valid loss: 0.122556 Train acc: 0.966228 Valid acc: 0.952403\n",
      "Epoch: 565/1000 Train loss: 0.090837 Valid loss: 0.131766 Train acc: 0.965095 Valid acc: 0.947869\n",
      "Epoch: 566/1000 Train loss: 0.093705 Valid loss: 0.125980 Train acc: 0.963282 Valid acc: 0.951043\n",
      "Epoch: 567/1000 Train loss: 0.092973 Valid loss: 0.125837 Train acc: 0.964642 Valid acc: 0.951949\n",
      "Epoch: 568/1000 Train loss: 0.092238 Valid loss: 0.124120 Train acc: 0.964415 Valid acc: 0.951043\n",
      "Epoch: 569/1000 Train loss: 0.091837 Valid loss: 0.120689 Train acc: 0.964869 Valid acc: 0.953309\n",
      "Epoch: 570/1000 Train loss: 0.090974 Valid loss: 0.128085 Train acc: 0.964642 Valid acc: 0.950136\n",
      "Epoch: 571/1000 Train loss: 0.089967 Valid loss: 0.129553 Train acc: 0.965322 Valid acc: 0.948776\n",
      "Epoch: 572/1000 Train loss: 0.089668 Valid loss: 0.129664 Train acc: 0.965549 Valid acc: 0.948776\n",
      "Epoch: 573/1000 Train loss: 0.089644 Valid loss: 0.128482 Train acc: 0.964869 Valid acc: 0.949683\n",
      "Epoch: 574/1000 Train loss: 0.089036 Valid loss: 0.127114 Train acc: 0.965322 Valid acc: 0.948776\n",
      "Epoch: 575/1000 Train loss: 0.088340 Valid loss: 0.125487 Train acc: 0.965775 Valid acc: 0.949683\n",
      "Epoch: 576/1000 Train loss: 0.088766 Valid loss: 0.124977 Train acc: 0.965549 Valid acc: 0.949229\n",
      "Epoch: 577/1000 Train loss: 0.088559 Valid loss: 0.125282 Train acc: 0.965775 Valid acc: 0.949683\n",
      "Epoch: 578/1000 Train loss: 0.088284 Valid loss: 0.125909 Train acc: 0.966002 Valid acc: 0.949229\n",
      "Epoch: 579/1000 Train loss: 0.088099 Valid loss: 0.125716 Train acc: 0.965775 Valid acc: 0.949683\n",
      "Epoch: 580/1000 Train loss: 0.087941 Valid loss: 0.124308 Train acc: 0.965775 Valid acc: 0.949229\n",
      "Epoch: 581/1000 Train loss: 0.087863 Valid loss: 0.123933 Train acc: 0.965549 Valid acc: 0.950136\n",
      "Epoch: 582/1000 Train loss: 0.087655 Valid loss: 0.124886 Train acc: 0.965549 Valid acc: 0.950136\n",
      "Epoch: 583/1000 Train loss: 0.087811 Valid loss: 0.123024 Train acc: 0.965322 Valid acc: 0.950589\n",
      "Epoch: 584/1000 Train loss: 0.087856 Valid loss: 0.123015 Train acc: 0.965322 Valid acc: 0.950136\n",
      "Epoch: 585/1000 Train loss: 0.087606 Valid loss: 0.124204 Train acc: 0.964869 Valid acc: 0.950136\n",
      "Epoch: 586/1000 Train loss: 0.087663 Valid loss: 0.125567 Train acc: 0.964869 Valid acc: 0.950136\n",
      "Epoch: 587/1000 Train loss: 0.087368 Valid loss: 0.125476 Train acc: 0.965095 Valid acc: 0.950589\n",
      "Epoch: 588/1000 Train loss: 0.087278 Valid loss: 0.125008 Train acc: 0.966455 Valid acc: 0.949683\n",
      "Epoch: 589/1000 Train loss: 0.087203 Valid loss: 0.125457 Train acc: 0.966002 Valid acc: 0.949683\n",
      "Epoch: 590/1000 Train loss: 0.087040 Valid loss: 0.125464 Train acc: 0.966002 Valid acc: 0.949229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 591/1000 Train loss: 0.086917 Valid loss: 0.124798 Train acc: 0.966002 Valid acc: 0.949683\n",
      "Epoch: 592/1000 Train loss: 0.086750 Valid loss: 0.122412 Train acc: 0.966228 Valid acc: 0.950136\n",
      "Epoch: 593/1000 Train loss: 0.086571 Valid loss: 0.122034 Train acc: 0.966228 Valid acc: 0.950136\n",
      "Epoch: 594/1000 Train loss: 0.086538 Valid loss: 0.121432 Train acc: 0.965775 Valid acc: 0.950136\n",
      "Epoch: 595/1000 Train loss: 0.086567 Valid loss: 0.121340 Train acc: 0.966682 Valid acc: 0.950136\n",
      "Epoch: 596/1000 Train loss: 0.086296 Valid loss: 0.121327 Train acc: 0.966455 Valid acc: 0.950136\n",
      "Epoch: 597/1000 Train loss: 0.086327 Valid loss: 0.120412 Train acc: 0.966228 Valid acc: 0.951043\n",
      "Epoch: 598/1000 Train loss: 0.086251 Valid loss: 0.120799 Train acc: 0.966002 Valid acc: 0.950589\n",
      "Epoch: 599/1000 Train loss: 0.086113 Valid loss: 0.121118 Train acc: 0.966228 Valid acc: 0.950589\n",
      "Epoch: 600/1000 Train loss: 0.086037 Valid loss: 0.120837 Train acc: 0.966455 Valid acc: 0.951496\n",
      "Epoch: 601/1000 Train loss: 0.086040 Valid loss: 0.121030 Train acc: 0.966455 Valid acc: 0.951043\n",
      "Epoch: 602/1000 Train loss: 0.085821 Valid loss: 0.121515 Train acc: 0.966002 Valid acc: 0.950589\n",
      "Epoch: 603/1000 Train loss: 0.085783 Valid loss: 0.121572 Train acc: 0.966002 Valid acc: 0.951043\n",
      "Epoch: 604/1000 Train loss: 0.085738 Valid loss: 0.122092 Train acc: 0.966228 Valid acc: 0.950589\n",
      "Epoch: 605/1000 Train loss: 0.085551 Valid loss: 0.122492 Train acc: 0.966002 Valid acc: 0.950589\n",
      "Epoch: 606/1000 Train loss: 0.085517 Valid loss: 0.122219 Train acc: 0.966455 Valid acc: 0.950589\n",
      "Epoch: 607/1000 Train loss: 0.085456 Valid loss: 0.121998 Train acc: 0.966908 Valid acc: 0.950589\n",
      "Epoch: 608/1000 Train loss: 0.085384 Valid loss: 0.121855 Train acc: 0.966908 Valid acc: 0.951043\n",
      "Epoch: 609/1000 Train loss: 0.085331 Valid loss: 0.121964 Train acc: 0.966455 Valid acc: 0.951496\n",
      "Epoch: 610/1000 Train loss: 0.085203 Valid loss: 0.122076 Train acc: 0.966455 Valid acc: 0.951496\n",
      "Epoch: 611/1000 Train loss: 0.085132 Valid loss: 0.122023 Train acc: 0.966455 Valid acc: 0.951496\n",
      "Epoch: 612/1000 Train loss: 0.085048 Valid loss: 0.122144 Train acc: 0.966908 Valid acc: 0.951043\n",
      "Epoch: 613/1000 Train loss: 0.084943 Valid loss: 0.122280 Train acc: 0.966455 Valid acc: 0.951496\n",
      "Epoch: 614/1000 Train loss: 0.084906 Valid loss: 0.122125 Train acc: 0.966682 Valid acc: 0.951949\n",
      "Epoch: 615/1000 Train loss: 0.084826 Valid loss: 0.121758 Train acc: 0.966455 Valid acc: 0.951949\n",
      "Epoch: 616/1000 Train loss: 0.084754 Valid loss: 0.122008 Train acc: 0.966682 Valid acc: 0.951949\n",
      "Epoch: 617/1000 Train loss: 0.084660 Valid loss: 0.122295 Train acc: 0.966228 Valid acc: 0.951949\n",
      "Epoch: 618/1000 Train loss: 0.084602 Valid loss: 0.122141 Train acc: 0.966455 Valid acc: 0.952856\n",
      "Epoch: 619/1000 Train loss: 0.084508 Valid loss: 0.121909 Train acc: 0.966908 Valid acc: 0.952403\n",
      "Epoch: 620/1000 Train loss: 0.084421 Valid loss: 0.122104 Train acc: 0.967135 Valid acc: 0.952403\n",
      "Epoch: 621/1000 Train loss: 0.084361 Valid loss: 0.122386 Train acc: 0.967135 Valid acc: 0.952856\n",
      "Epoch: 622/1000 Train loss: 0.084264 Valid loss: 0.122157 Train acc: 0.967135 Valid acc: 0.952403\n",
      "Epoch: 623/1000 Train loss: 0.084206 Valid loss: 0.121969 Train acc: 0.967588 Valid acc: 0.951949\n",
      "Epoch: 624/1000 Train loss: 0.084078 Valid loss: 0.122071 Train acc: 0.967815 Valid acc: 0.951496\n",
      "Epoch: 625/1000 Train loss: 0.084015 Valid loss: 0.121878 Train acc: 0.967815 Valid acc: 0.951949\n",
      "Epoch: 626/1000 Train loss: 0.083943 Valid loss: 0.121639 Train acc: 0.968042 Valid acc: 0.951496\n",
      "Epoch: 627/1000 Train loss: 0.083764 Valid loss: 0.121611 Train acc: 0.968268 Valid acc: 0.951496\n",
      "Epoch: 628/1000 Train loss: 0.083777 Valid loss: 0.122274 Train acc: 0.968042 Valid acc: 0.951496\n",
      "Epoch: 629/1000 Train loss: 0.084794 Valid loss: 0.122619 Train acc: 0.967588 Valid acc: 0.951043\n",
      "Epoch: 630/1000 Train loss: 0.091438 Valid loss: 0.142226 Train acc: 0.964869 Valid acc: 0.948323\n",
      "Epoch: 631/1000 Train loss: 0.114242 Valid loss: 0.138802 Train acc: 0.957616 Valid acc: 0.947416\n",
      "Epoch: 632/1000 Train loss: 0.105912 Valid loss: 0.133987 Train acc: 0.959882 Valid acc: 0.948776\n",
      "Epoch: 633/1000 Train loss: 0.106963 Valid loss: 0.131589 Train acc: 0.958296 Valid acc: 0.949683\n",
      "Epoch: 634/1000 Train loss: 0.106213 Valid loss: 0.136024 Train acc: 0.960562 Valid acc: 0.947416\n",
      "Epoch: 635/1000 Train loss: 0.104306 Valid loss: 0.143354 Train acc: 0.960109 Valid acc: 0.945603\n",
      "Epoch: 636/1000 Train loss: 0.103177 Valid loss: 0.140485 Train acc: 0.959202 Valid acc: 0.943790\n",
      "Epoch: 637/1000 Train loss: 0.103403 Valid loss: 0.135467 Train acc: 0.959429 Valid acc: 0.946056\n",
      "Epoch: 638/1000 Train loss: 0.103405 Valid loss: 0.136365 Train acc: 0.958522 Valid acc: 0.947869\n",
      "Epoch: 639/1000 Train loss: 0.100153 Valid loss: 0.135207 Train acc: 0.960109 Valid acc: 0.949683\n",
      "Epoch: 640/1000 Train loss: 0.100799 Valid loss: 0.133061 Train acc: 0.960335 Valid acc: 0.951496\n",
      "Epoch: 641/1000 Train loss: 0.099480 Valid loss: 0.127008 Train acc: 0.961015 Valid acc: 0.952856\n",
      "Epoch: 642/1000 Train loss: 0.096917 Valid loss: 0.127549 Train acc: 0.963962 Valid acc: 0.949683\n",
      "Epoch: 643/1000 Train loss: 0.096620 Valid loss: 0.127559 Train acc: 0.962149 Valid acc: 0.948776\n",
      "Epoch: 644/1000 Train loss: 0.095785 Valid loss: 0.127670 Train acc: 0.961015 Valid acc: 0.948776\n",
      "Epoch: 645/1000 Train loss: 0.094003 Valid loss: 0.128976 Train acc: 0.961922 Valid acc: 0.950589\n",
      "Epoch: 646/1000 Train loss: 0.098001 Valid loss: 0.131801 Train acc: 0.962149 Valid acc: 0.952856\n",
      "Epoch: 647/1000 Train loss: 0.101026 Valid loss: 0.132808 Train acc: 0.961922 Valid acc: 0.953762\n",
      "Epoch: 648/1000 Train loss: 0.103000 Valid loss: 0.132828 Train acc: 0.961469 Valid acc: 0.953309\n",
      "Epoch: 649/1000 Train loss: 0.102974 Valid loss: 0.134858 Train acc: 0.964642 Valid acc: 0.952403\n",
      "Epoch: 650/1000 Train loss: 0.105014 Valid loss: 0.134086 Train acc: 0.962602 Valid acc: 0.953309\n",
      "Epoch: 651/1000 Train loss: 0.101477 Valid loss: 0.134434 Train acc: 0.961695 Valid acc: 0.955122\n",
      "Epoch: 652/1000 Train loss: 0.101277 Valid loss: 0.133285 Train acc: 0.962149 Valid acc: 0.955576\n",
      "Epoch: 653/1000 Train loss: 0.099590 Valid loss: 0.131440 Train acc: 0.962149 Valid acc: 0.956029\n",
      "Epoch: 654/1000 Train loss: 0.098890 Valid loss: 0.131522 Train acc: 0.962375 Valid acc: 0.954669\n",
      "Epoch: 655/1000 Train loss: 0.098452 Valid loss: 0.128422 Train acc: 0.963962 Valid acc: 0.953309\n",
      "Epoch: 656/1000 Train loss: 0.097080 Valid loss: 0.128078 Train acc: 0.963962 Valid acc: 0.953309\n",
      "Epoch: 657/1000 Train loss: 0.097485 Valid loss: 0.126451 Train acc: 0.964415 Valid acc: 0.953309\n",
      "Epoch: 658/1000 Train loss: 0.095247 Valid loss: 0.125065 Train acc: 0.964869 Valid acc: 0.953762\n",
      "Epoch: 659/1000 Train loss: 0.095390 Valid loss: 0.124986 Train acc: 0.965095 Valid acc: 0.954216\n",
      "Epoch: 660/1000 Train loss: 0.095658 Valid loss: 0.124131 Train acc: 0.963509 Valid acc: 0.953762\n",
      "Epoch: 661/1000 Train loss: 0.095030 Valid loss: 0.123151 Train acc: 0.964642 Valid acc: 0.954669\n",
      "Epoch: 662/1000 Train loss: 0.093436 Valid loss: 0.126608 Train acc: 0.965095 Valid acc: 0.955576\n",
      "Epoch: 663/1000 Train loss: 0.093442 Valid loss: 0.125291 Train acc: 0.965095 Valid acc: 0.955122\n",
      "Epoch: 664/1000 Train loss: 0.092847 Valid loss: 0.129309 Train acc: 0.965095 Valid acc: 0.951043\n",
      "Epoch: 665/1000 Train loss: 0.103239 Valid loss: 0.134080 Train acc: 0.957389 Valid acc: 0.947869\n",
      "Epoch: 666/1000 Train loss: 0.111727 Valid loss: 0.130904 Train acc: 0.950589 Valid acc: 0.949683\n",
      "Epoch: 667/1000 Train loss: 0.108007 Valid loss: 0.131354 Train acc: 0.953989 Valid acc: 0.949683\n",
      "Epoch: 668/1000 Train loss: 0.105972 Valid loss: 0.131056 Train acc: 0.954896 Valid acc: 0.950136\n",
      "Epoch: 669/1000 Train loss: 0.103191 Valid loss: 0.128871 Train acc: 0.956709 Valid acc: 0.950589\n",
      "Epoch: 670/1000 Train loss: 0.101069 Valid loss: 0.129132 Train acc: 0.958069 Valid acc: 0.948323\n",
      "Epoch: 671/1000 Train loss: 0.100365 Valid loss: 0.126955 Train acc: 0.958749 Valid acc: 0.948323\n",
      "Epoch: 672/1000 Train loss: 0.100402 Valid loss: 0.125863 Train acc: 0.959202 Valid acc: 0.949683\n",
      "Epoch: 673/1000 Train loss: 0.099706 Valid loss: 0.125408 Train acc: 0.958976 Valid acc: 0.951496\n",
      "Epoch: 674/1000 Train loss: 0.098246 Valid loss: 0.127217 Train acc: 0.959429 Valid acc: 0.951949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 675/1000 Train loss: 0.096490 Valid loss: 0.127860 Train acc: 0.959882 Valid acc: 0.950589\n",
      "Epoch: 676/1000 Train loss: 0.096517 Valid loss: 0.126864 Train acc: 0.959656 Valid acc: 0.950589\n",
      "Epoch: 677/1000 Train loss: 0.096453 Valid loss: 0.126162 Train acc: 0.960335 Valid acc: 0.951949\n",
      "Epoch: 678/1000 Train loss: 0.096067 Valid loss: 0.126931 Train acc: 0.959882 Valid acc: 0.951496\n",
      "Epoch: 679/1000 Train loss: 0.095324 Valid loss: 0.125736 Train acc: 0.961015 Valid acc: 0.949683\n",
      "Epoch: 680/1000 Train loss: 0.094776 Valid loss: 0.125461 Train acc: 0.960789 Valid acc: 0.950136\n",
      "Epoch: 681/1000 Train loss: 0.094264 Valid loss: 0.125415 Train acc: 0.959882 Valid acc: 0.951496\n",
      "Epoch: 682/1000 Train loss: 0.093969 Valid loss: 0.122664 Train acc: 0.960335 Valid acc: 0.953309\n",
      "Epoch: 683/1000 Train loss: 0.093097 Valid loss: 0.123612 Train acc: 0.960335 Valid acc: 0.951949\n",
      "Epoch: 684/1000 Train loss: 0.094420 Valid loss: 0.123833 Train acc: 0.960335 Valid acc: 0.952403\n",
      "Epoch: 685/1000 Train loss: 0.094237 Valid loss: 0.122869 Train acc: 0.960789 Valid acc: 0.952856\n",
      "Epoch: 686/1000 Train loss: 0.092510 Valid loss: 0.122565 Train acc: 0.962375 Valid acc: 0.951949\n",
      "Epoch: 687/1000 Train loss: 0.092288 Valid loss: 0.122661 Train acc: 0.961469 Valid acc: 0.952403\n",
      "Epoch: 688/1000 Train loss: 0.091887 Valid loss: 0.123270 Train acc: 0.960335 Valid acc: 0.950136\n",
      "Epoch: 689/1000 Train loss: 0.093867 Valid loss: 0.124684 Train acc: 0.959429 Valid acc: 0.950136\n",
      "Epoch: 690/1000 Train loss: 0.093817 Valid loss: 0.124506 Train acc: 0.958976 Valid acc: 0.951496\n",
      "Epoch: 691/1000 Train loss: 0.093369 Valid loss: 0.127456 Train acc: 0.960109 Valid acc: 0.951496\n",
      "Epoch: 692/1000 Train loss: 0.100974 Valid loss: 0.126067 Train acc: 0.958976 Valid acc: 0.955122\n",
      "Epoch: 693/1000 Train loss: 0.098370 Valid loss: 0.124574 Train acc: 0.959655 Valid acc: 0.956029\n",
      "Epoch: 694/1000 Train loss: 0.095807 Valid loss: 0.129754 Train acc: 0.961695 Valid acc: 0.952856\n",
      "Epoch: 695/1000 Train loss: 0.100534 Valid loss: 0.130163 Train acc: 0.957842 Valid acc: 0.951043\n",
      "Epoch: 696/1000 Train loss: 0.098837 Valid loss: 0.127717 Train acc: 0.960109 Valid acc: 0.952856\n",
      "Epoch: 697/1000 Train loss: 0.095948 Valid loss: 0.124802 Train acc: 0.961469 Valid acc: 0.955576\n",
      "Epoch: 698/1000 Train loss: 0.094326 Valid loss: 0.124226 Train acc: 0.963735 Valid acc: 0.953309\n",
      "Epoch: 699/1000 Train loss: 0.092852 Valid loss: 0.125630 Train acc: 0.962375 Valid acc: 0.949683\n",
      "Epoch: 700/1000 Train loss: 0.093176 Valid loss: 0.127259 Train acc: 0.960335 Valid acc: 0.949229\n",
      "Epoch: 701/1000 Train loss: 0.091263 Valid loss: 0.128360 Train acc: 0.960562 Valid acc: 0.948776\n",
      "Epoch: 702/1000 Train loss: 0.092382 Valid loss: 0.128176 Train acc: 0.959656 Valid acc: 0.947416\n",
      "Epoch: 703/1000 Train loss: 0.092221 Valid loss: 0.129465 Train acc: 0.959882 Valid acc: 0.947869\n",
      "Epoch: 704/1000 Train loss: 0.091947 Valid loss: 0.128867 Train acc: 0.959656 Valid acc: 0.947416\n",
      "Epoch: 705/1000 Train loss: 0.091861 Valid loss: 0.127523 Train acc: 0.959656 Valid acc: 0.947869\n",
      "Epoch: 706/1000 Train loss: 0.090727 Valid loss: 0.126827 Train acc: 0.960789 Valid acc: 0.948776\n",
      "Epoch: 707/1000 Train loss: 0.090669 Valid loss: 0.125832 Train acc: 0.961922 Valid acc: 0.949229\n",
      "Epoch: 708/1000 Train loss: 0.089937 Valid loss: 0.124360 Train acc: 0.961695 Valid acc: 0.951043\n",
      "Epoch: 709/1000 Train loss: 0.089940 Valid loss: 0.124135 Train acc: 0.962149 Valid acc: 0.951949\n",
      "Epoch: 710/1000 Train loss: 0.089652 Valid loss: 0.124861 Train acc: 0.962602 Valid acc: 0.951949\n",
      "Epoch: 711/1000 Train loss: 0.089768 Valid loss: 0.125069 Train acc: 0.963509 Valid acc: 0.951496\n",
      "Epoch: 712/1000 Train loss: 0.089597 Valid loss: 0.125025 Train acc: 0.963962 Valid acc: 0.951043\n",
      "Epoch: 713/1000 Train loss: 0.089284 Valid loss: 0.124687 Train acc: 0.963055 Valid acc: 0.950136\n",
      "Epoch: 714/1000 Train loss: 0.089022 Valid loss: 0.126881 Train acc: 0.963282 Valid acc: 0.949229\n",
      "Epoch: 715/1000 Train loss: 0.087471 Valid loss: 0.128986 Train acc: 0.963055 Valid acc: 0.949229\n",
      "Epoch: 716/1000 Train loss: 0.087723 Valid loss: 0.128665 Train acc: 0.963962 Valid acc: 0.947416\n",
      "Epoch: 717/1000 Train loss: 0.088137 Valid loss: 0.127807 Train acc: 0.963282 Valid acc: 0.948323\n",
      "Epoch: 718/1000 Train loss: 0.088277 Valid loss: 0.126534 Train acc: 0.962602 Valid acc: 0.949683\n",
      "Epoch: 719/1000 Train loss: 0.087989 Valid loss: 0.125746 Train acc: 0.963509 Valid acc: 0.950136\n",
      "Epoch: 720/1000 Train loss: 0.087665 Valid loss: 0.125155 Train acc: 0.963282 Valid acc: 0.950589\n",
      "Epoch: 721/1000 Train loss: 0.087715 Valid loss: 0.125364 Train acc: 0.963735 Valid acc: 0.948776\n",
      "Epoch: 722/1000 Train loss: 0.087582 Valid loss: 0.124492 Train acc: 0.964415 Valid acc: 0.950136\n",
      "Epoch: 723/1000 Train loss: 0.087550 Valid loss: 0.124463 Train acc: 0.965549 Valid acc: 0.950589\n",
      "Epoch: 724/1000 Train loss: 0.088358 Valid loss: 0.124085 Train acc: 0.964642 Valid acc: 0.949683\n",
      "Epoch: 725/1000 Train loss: 0.087399 Valid loss: 0.125213 Train acc: 0.964869 Valid acc: 0.948776\n",
      "Epoch: 726/1000 Train loss: 0.088128 Valid loss: 0.125833 Train acc: 0.963962 Valid acc: 0.949683\n",
      "Epoch: 727/1000 Train loss: 0.087549 Valid loss: 0.145066 Train acc: 0.963282 Valid acc: 0.943336\n",
      "Epoch: 728/1000 Train loss: 0.096707 Valid loss: 0.136771 Train acc: 0.959655 Valid acc: 0.943336\n",
      "Epoch: 729/1000 Train loss: 0.090146 Valid loss: 0.123673 Train acc: 0.962149 Valid acc: 0.950136\n",
      "Epoch: 730/1000 Train loss: 0.087518 Valid loss: 0.116667 Train acc: 0.964415 Valid acc: 0.953309\n",
      "Epoch: 731/1000 Train loss: 0.098071 Valid loss: 0.117553 Train acc: 0.961242 Valid acc: 0.954669\n",
      "Epoch: 732/1000 Train loss: 0.099577 Valid loss: 0.119020 Train acc: 0.960109 Valid acc: 0.951949\n",
      "Epoch: 733/1000 Train loss: 0.096934 Valid loss: 0.120571 Train acc: 0.960562 Valid acc: 0.947869\n",
      "Epoch: 734/1000 Train loss: 0.093559 Valid loss: 0.128885 Train acc: 0.961695 Valid acc: 0.946510\n",
      "Epoch: 735/1000 Train loss: 0.090283 Valid loss: 0.130098 Train acc: 0.962375 Valid acc: 0.946510\n",
      "Epoch: 736/1000 Train loss: 0.093145 Valid loss: 0.137413 Train acc: 0.960335 Valid acc: 0.945150\n",
      "Epoch: 737/1000 Train loss: 0.096753 Valid loss: 0.137663 Train acc: 0.958976 Valid acc: 0.947869\n",
      "Epoch: 738/1000 Train loss: 0.093630 Valid loss: 0.126598 Train acc: 0.959656 Valid acc: 0.950136\n",
      "Epoch: 739/1000 Train loss: 0.089600 Valid loss: 0.122364 Train acc: 0.961922 Valid acc: 0.947869\n",
      "Epoch: 740/1000 Train loss: 0.087813 Valid loss: 0.121289 Train acc: 0.963962 Valid acc: 0.950136\n",
      "Epoch: 741/1000 Train loss: 0.090133 Valid loss: 0.127475 Train acc: 0.962829 Valid acc: 0.945150\n",
      "Epoch: 742/1000 Train loss: 0.099456 Valid loss: 0.119996 Train acc: 0.955576 Valid acc: 0.951949\n",
      "Epoch: 743/1000 Train loss: 0.096124 Valid loss: 0.122651 Train acc: 0.958296 Valid acc: 0.949683\n",
      "Epoch: 744/1000 Train loss: 0.096066 Valid loss: 0.121591 Train acc: 0.959655 Valid acc: 0.950136\n",
      "Epoch: 745/1000 Train loss: 0.094263 Valid loss: 0.113842 Train acc: 0.961922 Valid acc: 0.950589\n",
      "Epoch: 746/1000 Train loss: 0.092367 Valid loss: 0.116618 Train acc: 0.960789 Valid acc: 0.950589\n",
      "Epoch: 747/1000 Train loss: 0.092194 Valid loss: 0.119456 Train acc: 0.960335 Valid acc: 0.950589\n",
      "Epoch: 748/1000 Train loss: 0.090513 Valid loss: 0.126432 Train acc: 0.961242 Valid acc: 0.949683\n",
      "Epoch: 749/1000 Train loss: 0.090919 Valid loss: 0.130863 Train acc: 0.961469 Valid acc: 0.947416\n",
      "Epoch: 750/1000 Train loss: 0.090188 Valid loss: 0.133030 Train acc: 0.961469 Valid acc: 0.945150\n",
      "Epoch: 751/1000 Train loss: 0.090774 Valid loss: 0.133565 Train acc: 0.961015 Valid acc: 0.944696\n",
      "Epoch: 752/1000 Train loss: 0.090786 Valid loss: 0.131943 Train acc: 0.961242 Valid acc: 0.946963\n",
      "Epoch: 753/1000 Train loss: 0.089241 Valid loss: 0.127760 Train acc: 0.962829 Valid acc: 0.948776\n",
      "Epoch: 754/1000 Train loss: 0.088538 Valid loss: 0.126462 Train acc: 0.962829 Valid acc: 0.949229\n",
      "Epoch: 755/1000 Train loss: 0.088105 Valid loss: 0.125421 Train acc: 0.963282 Valid acc: 0.949683\n",
      "Epoch: 756/1000 Train loss: 0.088228 Valid loss: 0.123800 Train acc: 0.962375 Valid acc: 0.950589\n",
      "Epoch: 757/1000 Train loss: 0.087619 Valid loss: 0.122470 Train acc: 0.962149 Valid acc: 0.951496\n",
      "Epoch: 758/1000 Train loss: 0.087303 Valid loss: 0.121752 Train acc: 0.961695 Valid acc: 0.951949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 759/1000 Train loss: 0.087191 Valid loss: 0.121485 Train acc: 0.962149 Valid acc: 0.952403\n",
      "Epoch: 760/1000 Train loss: 0.087082 Valid loss: 0.121285 Train acc: 0.961469 Valid acc: 0.951949\n",
      "Epoch: 761/1000 Train loss: 0.086883 Valid loss: 0.120918 Train acc: 0.962149 Valid acc: 0.952403\n",
      "Epoch: 762/1000 Train loss: 0.086687 Valid loss: 0.120606 Train acc: 0.960789 Valid acc: 0.952856\n",
      "Epoch: 763/1000 Train loss: 0.086441 Valid loss: 0.121068 Train acc: 0.962149 Valid acc: 0.952856\n",
      "Epoch: 764/1000 Train loss: 0.086270 Valid loss: 0.120994 Train acc: 0.962149 Valid acc: 0.951496\n",
      "Epoch: 765/1000 Train loss: 0.086204 Valid loss: 0.120207 Train acc: 0.961922 Valid acc: 0.952403\n",
      "Epoch: 766/1000 Train loss: 0.085846 Valid loss: 0.119772 Train acc: 0.961922 Valid acc: 0.951496\n",
      "Epoch: 767/1000 Train loss: 0.085610 Valid loss: 0.119977 Train acc: 0.962375 Valid acc: 0.951043\n",
      "Epoch: 768/1000 Train loss: 0.085600 Valid loss: 0.120351 Train acc: 0.962829 Valid acc: 0.951043\n",
      "Epoch: 769/1000 Train loss: 0.085453 Valid loss: 0.120386 Train acc: 0.962602 Valid acc: 0.951043\n",
      "Epoch: 770/1000 Train loss: 0.085368 Valid loss: 0.120548 Train acc: 0.962375 Valid acc: 0.950136\n",
      "Epoch: 771/1000 Train loss: 0.085218 Valid loss: 0.120523 Train acc: 0.962375 Valid acc: 0.951043\n",
      "Epoch: 772/1000 Train loss: 0.085140 Valid loss: 0.120293 Train acc: 0.962375 Valid acc: 0.950589\n",
      "Epoch: 773/1000 Train loss: 0.085013 Valid loss: 0.120103 Train acc: 0.962375 Valid acc: 0.950589\n",
      "Epoch: 774/1000 Train loss: 0.084931 Valid loss: 0.120126 Train acc: 0.962829 Valid acc: 0.951043\n",
      "Epoch: 775/1000 Train loss: 0.084829 Valid loss: 0.120030 Train acc: 0.962829 Valid acc: 0.951496\n",
      "Epoch: 776/1000 Train loss: 0.084695 Valid loss: 0.119195 Train acc: 0.962829 Valid acc: 0.950589\n",
      "Epoch: 777/1000 Train loss: 0.084879 Valid loss: 0.119592 Train acc: 0.963509 Valid acc: 0.951043\n",
      "Epoch: 778/1000 Train loss: 0.084550 Valid loss: 0.120157 Train acc: 0.962829 Valid acc: 0.952856\n",
      "Epoch: 779/1000 Train loss: 0.084552 Valid loss: 0.119969 Train acc: 0.963735 Valid acc: 0.952403\n",
      "Epoch: 780/1000 Train loss: 0.084428 Valid loss: 0.119563 Train acc: 0.963509 Valid acc: 0.950589\n",
      "Epoch: 781/1000 Train loss: 0.084208 Valid loss: 0.120022 Train acc: 0.963735 Valid acc: 0.952403\n",
      "Epoch: 782/1000 Train loss: 0.084155 Valid loss: 0.119956 Train acc: 0.964189 Valid acc: 0.953309\n",
      "Epoch: 783/1000 Train loss: 0.084210 Valid loss: 0.120088 Train acc: 0.963735 Valid acc: 0.952856\n",
      "Epoch: 784/1000 Train loss: 0.084099 Valid loss: 0.119954 Train acc: 0.964189 Valid acc: 0.951496\n",
      "Epoch: 785/1000 Train loss: 0.084009 Valid loss: 0.119344 Train acc: 0.964189 Valid acc: 0.952856\n",
      "Epoch: 786/1000 Train loss: 0.083867 Valid loss: 0.118815 Train acc: 0.963962 Valid acc: 0.953762\n",
      "Epoch: 787/1000 Train loss: 0.083775 Valid loss: 0.116574 Train acc: 0.963509 Valid acc: 0.953762\n",
      "Epoch: 788/1000 Train loss: 0.083746 Valid loss: 0.116284 Train acc: 0.964415 Valid acc: 0.953762\n",
      "Epoch: 789/1000 Train loss: 0.083500 Valid loss: 0.116558 Train acc: 0.964189 Valid acc: 0.953309\n",
      "Epoch: 790/1000 Train loss: 0.083564 Valid loss: 0.115984 Train acc: 0.963962 Valid acc: 0.954216\n",
      "Epoch: 791/1000 Train loss: 0.083424 Valid loss: 0.116483 Train acc: 0.963962 Valid acc: 0.953762\n",
      "Epoch: 792/1000 Train loss: 0.083285 Valid loss: 0.115977 Train acc: 0.964189 Valid acc: 0.952856\n",
      "Epoch: 793/1000 Train loss: 0.083940 Valid loss: 0.115975 Train acc: 0.964642 Valid acc: 0.951949\n",
      "Epoch: 794/1000 Train loss: 0.083496 Valid loss: 0.116739 Train acc: 0.964642 Valid acc: 0.952856\n",
      "Epoch: 795/1000 Train loss: 0.083443 Valid loss: 0.116877 Train acc: 0.964642 Valid acc: 0.953309\n",
      "Epoch: 796/1000 Train loss: 0.083612 Valid loss: 0.115736 Train acc: 0.964415 Valid acc: 0.952856\n",
      "Epoch: 797/1000 Train loss: 0.083103 Valid loss: 0.116420 Train acc: 0.964415 Valid acc: 0.954216\n",
      "Epoch: 798/1000 Train loss: 0.083165 Valid loss: 0.116841 Train acc: 0.964189 Valid acc: 0.953309\n",
      "Epoch: 799/1000 Train loss: 0.083076 Valid loss: 0.116468 Train acc: 0.963282 Valid acc: 0.952403\n",
      "Epoch: 800/1000 Train loss: 0.083151 Valid loss: 0.117260 Train acc: 0.964869 Valid acc: 0.954669\n",
      "Epoch: 801/1000 Train loss: 0.084198 Valid loss: 0.117847 Train acc: 0.963282 Valid acc: 0.955122\n",
      "Epoch: 802/1000 Train loss: 0.087046 Valid loss: 0.118274 Train acc: 0.963509 Valid acc: 0.951496\n",
      "Epoch: 803/1000 Train loss: 0.086463 Valid loss: 0.118210 Train acc: 0.962829 Valid acc: 0.953762\n",
      "Epoch: 804/1000 Train loss: 0.085766 Valid loss: 0.123415 Train acc: 0.962602 Valid acc: 0.948323\n",
      "Epoch: 805/1000 Train loss: 0.090540 Valid loss: 0.118468 Train acc: 0.958069 Valid acc: 0.953762\n",
      "Epoch: 806/1000 Train loss: 0.084021 Valid loss: 0.119390 Train acc: 0.963735 Valid acc: 0.951949\n",
      "Epoch: 807/1000 Train loss: 0.085588 Valid loss: 0.117215 Train acc: 0.962602 Valid acc: 0.954669\n",
      "Epoch: 808/1000 Train loss: 0.084628 Valid loss: 0.118847 Train acc: 0.963509 Valid acc: 0.953309\n",
      "Epoch: 809/1000 Train loss: 0.084826 Valid loss: 0.118484 Train acc: 0.963509 Valid acc: 0.953762\n",
      "Epoch: 810/1000 Train loss: 0.083225 Valid loss: 0.119918 Train acc: 0.964189 Valid acc: 0.952403\n",
      "Epoch: 811/1000 Train loss: 0.084784 Valid loss: 0.118751 Train acc: 0.963509 Valid acc: 0.955576\n",
      "Epoch: 812/1000 Train loss: 0.082994 Valid loss: 0.118531 Train acc: 0.964642 Valid acc: 0.953309\n",
      "Epoch: 813/1000 Train loss: 0.083369 Valid loss: 0.117438 Train acc: 0.964642 Valid acc: 0.953762\n",
      "Epoch: 814/1000 Train loss: 0.083748 Valid loss: 0.118973 Train acc: 0.965322 Valid acc: 0.953309\n",
      "Epoch: 815/1000 Train loss: 0.083319 Valid loss: 0.118603 Train acc: 0.964869 Valid acc: 0.953762\n",
      "Epoch: 816/1000 Train loss: 0.082728 Valid loss: 0.118048 Train acc: 0.964869 Valid acc: 0.954669\n",
      "Epoch: 817/1000 Train loss: 0.083308 Valid loss: 0.118437 Train acc: 0.964415 Valid acc: 0.953762\n",
      "Epoch: 818/1000 Train loss: 0.083257 Valid loss: 0.120590 Train acc: 0.964869 Valid acc: 0.951043\n",
      "Epoch: 819/1000 Train loss: 0.084780 Valid loss: 0.117375 Train acc: 0.964415 Valid acc: 0.953309\n",
      "Epoch: 820/1000 Train loss: 0.088802 Valid loss: 0.119988 Train acc: 0.963509 Valid acc: 0.953309\n",
      "Epoch: 821/1000 Train loss: 0.089280 Valid loss: 0.122978 Train acc: 0.961922 Valid acc: 0.954216\n",
      "Epoch: 822/1000 Train loss: 0.089693 Valid loss: 0.120074 Train acc: 0.964189 Valid acc: 0.951496\n",
      "Epoch: 823/1000 Train loss: 0.086050 Valid loss: 0.120389 Train acc: 0.963962 Valid acc: 0.950136\n",
      "Epoch: 824/1000 Train loss: 0.086505 Valid loss: 0.121823 Train acc: 0.963509 Valid acc: 0.950589\n",
      "Epoch: 825/1000 Train loss: 0.084462 Valid loss: 0.118999 Train acc: 0.965549 Valid acc: 0.952403\n",
      "Epoch: 826/1000 Train loss: 0.085283 Valid loss: 0.123307 Train acc: 0.963735 Valid acc: 0.951949\n",
      "Epoch: 827/1000 Train loss: 0.086560 Valid loss: 0.121088 Train acc: 0.962602 Valid acc: 0.951949\n",
      "Epoch: 828/1000 Train loss: 0.083256 Valid loss: 0.122926 Train acc: 0.964869 Valid acc: 0.951496\n",
      "Epoch: 829/1000 Train loss: 0.083573 Valid loss: 0.126235 Train acc: 0.964642 Valid acc: 0.948776\n",
      "Epoch: 830/1000 Train loss: 0.083280 Valid loss: 0.126209 Train acc: 0.963962 Valid acc: 0.953309\n",
      "Epoch: 831/1000 Train loss: 0.084469 Valid loss: 0.122931 Train acc: 0.964415 Valid acc: 0.953309\n",
      "Epoch: 832/1000 Train loss: 0.084584 Valid loss: 0.120459 Train acc: 0.965549 Valid acc: 0.951496\n",
      "Epoch: 833/1000 Train loss: 0.083217 Valid loss: 0.120121 Train acc: 0.964869 Valid acc: 0.952856\n",
      "Epoch: 834/1000 Train loss: 0.083765 Valid loss: 0.119968 Train acc: 0.965322 Valid acc: 0.953309\n",
      "Epoch: 835/1000 Train loss: 0.083637 Valid loss: 0.119174 Train acc: 0.965549 Valid acc: 0.951496\n",
      "Epoch: 836/1000 Train loss: 0.082899 Valid loss: 0.119441 Train acc: 0.965549 Valid acc: 0.952403\n",
      "Epoch: 837/1000 Train loss: 0.082205 Valid loss: 0.122417 Train acc: 0.965322 Valid acc: 0.952856\n",
      "Epoch: 838/1000 Train loss: 0.081784 Valid loss: 0.121541 Train acc: 0.965322 Valid acc: 0.953762\n",
      "Epoch: 839/1000 Train loss: 0.082315 Valid loss: 0.122909 Train acc: 0.965549 Valid acc: 0.952403\n",
      "Epoch: 840/1000 Train loss: 0.083316 Valid loss: 0.179196 Train acc: 0.964642 Valid acc: 0.924297\n",
      "Epoch: 841/1000 Train loss: 0.177182 Valid loss: 0.231154 Train acc: 0.909565 Valid acc: 0.872167\n",
      "Epoch: 842/1000 Train loss: 0.216056 Valid loss: 0.183330 Train acc: 0.871260 Valid acc: 0.911605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 843/1000 Train loss: 0.163247 Valid loss: 0.149083 Train acc: 0.930190 Valid acc: 0.950136\n",
      "Epoch: 844/1000 Train loss: 0.141313 Valid loss: 0.149773 Train acc: 0.946283 Valid acc: 0.926564\n",
      "Epoch: 845/1000 Train loss: 0.148458 Valid loss: 0.165452 Train acc: 0.924297 Valid acc: 0.911605\n",
      "Epoch: 846/1000 Train loss: 0.165206 Valid loss: 0.176158 Train acc: 0.915911 Valid acc: 0.907978\n",
      "Epoch: 847/1000 Train loss: 0.171913 Valid loss: 0.174603 Train acc: 0.912738 Valid acc: 0.909338\n",
      "Epoch: 848/1000 Train loss: 0.168322 Valid loss: 0.168293 Train acc: 0.914551 Valid acc: 0.910698\n",
      "Epoch: 849/1000 Train loss: 0.160853 Valid loss: 0.161938 Train acc: 0.918178 Valid acc: 0.916138\n",
      "Epoch: 850/1000 Train loss: 0.152147 Valid loss: 0.155227 Train acc: 0.926564 Valid acc: 0.935177\n",
      "Epoch: 851/1000 Train loss: 0.148352 Valid loss: 0.153763 Train acc: 0.935403 Valid acc: 0.940616\n",
      "Epoch: 852/1000 Train loss: 0.148243 Valid loss: 0.155085 Train acc: 0.938577 Valid acc: 0.936990\n",
      "Epoch: 853/1000 Train loss: 0.148277 Valid loss: 0.152002 Train acc: 0.938803 Valid acc: 0.938803\n",
      "Epoch: 854/1000 Train loss: 0.144022 Valid loss: 0.147764 Train acc: 0.939483 Valid acc: 0.941976\n",
      "Epoch: 855/1000 Train loss: 0.137743 Valid loss: 0.145757 Train acc: 0.939257 Valid acc: 0.941976\n",
      "Epoch: 856/1000 Train loss: 0.134877 Valid loss: 0.145649 Train acc: 0.938577 Valid acc: 0.939257\n",
      "Epoch: 857/1000 Train loss: 0.134877 Valid loss: 0.143937 Train acc: 0.937670 Valid acc: 0.938350\n",
      "Epoch: 858/1000 Train loss: 0.134040 Valid loss: 0.141576 Train acc: 0.937443 Valid acc: 0.939710\n",
      "Epoch: 859/1000 Train loss: 0.130850 Valid loss: 0.137965 Train acc: 0.939937 Valid acc: 0.941976\n",
      "Epoch: 860/1000 Train loss: 0.128918 Valid loss: 0.137749 Train acc: 0.940163 Valid acc: 0.942883\n",
      "Epoch: 861/1000 Train loss: 0.127602 Valid loss: 0.133796 Train acc: 0.942430 Valid acc: 0.943790\n",
      "Epoch: 862/1000 Train loss: 0.127636 Valid loss: 0.138311 Train acc: 0.942430 Valid acc: 0.941976\n",
      "Epoch: 863/1000 Train loss: 0.124520 Valid loss: 0.145044 Train acc: 0.944016 Valid acc: 0.941070\n",
      "Epoch: 864/1000 Train loss: 0.124804 Valid loss: 0.159031 Train acc: 0.943336 Valid acc: 0.938350\n",
      "Epoch: 865/1000 Train loss: 0.130482 Valid loss: 0.153626 Train acc: 0.942883 Valid acc: 0.938803\n",
      "Epoch: 866/1000 Train loss: 0.126135 Valid loss: 0.146133 Train acc: 0.943110 Valid acc: 0.941976\n",
      "Epoch: 867/1000 Train loss: 0.121271 Valid loss: 0.144695 Train acc: 0.944243 Valid acc: 0.942430\n",
      "Epoch: 868/1000 Train loss: 0.119860 Valid loss: 0.143181 Train acc: 0.945150 Valid acc: 0.943790\n",
      "Epoch: 869/1000 Train loss: 0.118191 Valid loss: 0.140144 Train acc: 0.949229 Valid acc: 0.946963\n",
      "Epoch: 870/1000 Train loss: 0.116684 Valid loss: 0.138604 Train acc: 0.951949 Valid acc: 0.948323\n",
      "Epoch: 871/1000 Train loss: 0.118477 Valid loss: 0.135081 Train acc: 0.956029 Valid acc: 0.947869\n",
      "Epoch: 872/1000 Train loss: 0.120673 Valid loss: 0.133255 Train acc: 0.956256 Valid acc: 0.950589\n",
      "Epoch: 873/1000 Train loss: 0.120074 Valid loss: 0.131232 Train acc: 0.954896 Valid acc: 0.947869\n",
      "Epoch: 874/1000 Train loss: 0.118432 Valid loss: 0.131350 Train acc: 0.948549 Valid acc: 0.946510\n",
      "Epoch: 875/1000 Train loss: 0.118017 Valid loss: 0.132836 Train acc: 0.946963 Valid acc: 0.944696\n",
      "Epoch: 876/1000 Train loss: 0.117573 Valid loss: 0.131361 Train acc: 0.946736 Valid acc: 0.944696\n",
      "Epoch: 877/1000 Train loss: 0.117659 Valid loss: 0.133263 Train acc: 0.946736 Valid acc: 0.946510\n",
      "Epoch: 878/1000 Train loss: 0.115671 Valid loss: 0.134113 Train acc: 0.949229 Valid acc: 0.948323\n",
      "Epoch: 879/1000 Train loss: 0.115500 Valid loss: 0.134573 Train acc: 0.953989 Valid acc: 0.948776\n",
      "Epoch: 880/1000 Train loss: 0.116356 Valid loss: 0.133887 Train acc: 0.955122 Valid acc: 0.949683\n",
      "Epoch: 881/1000 Train loss: 0.114846 Valid loss: 0.131770 Train acc: 0.956029 Valid acc: 0.949229\n",
      "Epoch: 882/1000 Train loss: 0.113823 Valid loss: 0.130504 Train acc: 0.954896 Valid acc: 0.949229\n",
      "Epoch: 883/1000 Train loss: 0.112846 Valid loss: 0.127982 Train acc: 0.952403 Valid acc: 0.947416\n",
      "Epoch: 884/1000 Train loss: 0.112014 Valid loss: 0.126699 Train acc: 0.951043 Valid acc: 0.946510\n",
      "Epoch: 885/1000 Train loss: 0.111107 Valid loss: 0.127848 Train acc: 0.951496 Valid acc: 0.947416\n",
      "Epoch: 886/1000 Train loss: 0.110199 Valid loss: 0.126877 Train acc: 0.952856 Valid acc: 0.949683\n",
      "Epoch: 887/1000 Train loss: 0.109401 Valid loss: 0.126242 Train acc: 0.956029 Valid acc: 0.949229\n",
      "Epoch: 888/1000 Train loss: 0.108901 Valid loss: 0.125796 Train acc: 0.956936 Valid acc: 0.949683\n",
      "Epoch: 889/1000 Train loss: 0.108519 Valid loss: 0.125228 Train acc: 0.957389 Valid acc: 0.949683\n",
      "Epoch: 890/1000 Train loss: 0.108057 Valid loss: 0.123928 Train acc: 0.957162 Valid acc: 0.949683\n",
      "Epoch: 891/1000 Train loss: 0.107549 Valid loss: 0.121942 Train acc: 0.956482 Valid acc: 0.951043\n",
      "Epoch: 892/1000 Train loss: 0.107191 Valid loss: 0.121613 Train acc: 0.956936 Valid acc: 0.951496\n",
      "Epoch: 893/1000 Train loss: 0.106778 Valid loss: 0.121028 Train acc: 0.956709 Valid acc: 0.951949\n",
      "Epoch: 894/1000 Train loss: 0.106245 Valid loss: 0.120578 Train acc: 0.957389 Valid acc: 0.953762\n",
      "Epoch: 895/1000 Train loss: 0.106007 Valid loss: 0.120363 Train acc: 0.958296 Valid acc: 0.954216\n",
      "Epoch: 896/1000 Train loss: 0.105924 Valid loss: 0.120001 Train acc: 0.958296 Valid acc: 0.954669\n",
      "Epoch: 897/1000 Train loss: 0.105601 Valid loss: 0.119642 Train acc: 0.958069 Valid acc: 0.954216\n",
      "Epoch: 898/1000 Train loss: 0.105319 Valid loss: 0.119401 Train acc: 0.958749 Valid acc: 0.953762\n",
      "Epoch: 899/1000 Train loss: 0.105061 Valid loss: 0.119208 Train acc: 0.958522 Valid acc: 0.954669\n",
      "Epoch: 900/1000 Train loss: 0.104741 Valid loss: 0.119104 Train acc: 0.958976 Valid acc: 0.955122\n",
      "Epoch: 901/1000 Train loss: 0.104505 Valid loss: 0.119081 Train acc: 0.959202 Valid acc: 0.955122\n",
      "Epoch: 902/1000 Train loss: 0.104354 Valid loss: 0.118994 Train acc: 0.959429 Valid acc: 0.955576\n",
      "Epoch: 903/1000 Train loss: 0.104166 Valid loss: 0.118836 Train acc: 0.959429 Valid acc: 0.956029\n",
      "Epoch: 904/1000 Train loss: 0.103948 Valid loss: 0.118702 Train acc: 0.959202 Valid acc: 0.955576\n",
      "Epoch: 905/1000 Train loss: 0.103752 Valid loss: 0.118601 Train acc: 0.959656 Valid acc: 0.955122\n",
      "Epoch: 906/1000 Train loss: 0.103548 Valid loss: 0.118485 Train acc: 0.959882 Valid acc: 0.955122\n",
      "Epoch: 907/1000 Train loss: 0.103324 Valid loss: 0.118383 Train acc: 0.960109 Valid acc: 0.955122\n",
      "Epoch: 908/1000 Train loss: 0.103104 Valid loss: 0.118362 Train acc: 0.959882 Valid acc: 0.955122\n",
      "Epoch: 909/1000 Train loss: 0.102913 Valid loss: 0.118425 Train acc: 0.959656 Valid acc: 0.956482\n",
      "Epoch: 910/1000 Train loss: 0.102756 Valid loss: 0.118486 Train acc: 0.960335 Valid acc: 0.956482\n",
      "Epoch: 911/1000 Train loss: 0.102596 Valid loss: 0.118491 Train acc: 0.960335 Valid acc: 0.956029\n",
      "Epoch: 912/1000 Train loss: 0.102418 Valid loss: 0.118485 Train acc: 0.960335 Valid acc: 0.956029\n",
      "Epoch: 913/1000 Train loss: 0.102228 Valid loss: 0.118506 Train acc: 0.960335 Valid acc: 0.956029\n",
      "Epoch: 914/1000 Train loss: 0.102011 Valid loss: 0.118535 Train acc: 0.960335 Valid acc: 0.956482\n",
      "Epoch: 915/1000 Train loss: 0.101828 Valid loss: 0.118547 Train acc: 0.960335 Valid acc: 0.956482\n",
      "Epoch: 916/1000 Train loss: 0.101652 Valid loss: 0.118543 Train acc: 0.960109 Valid acc: 0.956482\n",
      "Epoch: 917/1000 Train loss: 0.101479 Valid loss: 0.118541 Train acc: 0.960109 Valid acc: 0.956482\n",
      "Epoch: 918/1000 Train loss: 0.101309 Valid loss: 0.118558 Train acc: 0.960109 Valid acc: 0.956936\n",
      "Epoch: 919/1000 Train loss: 0.101139 Valid loss: 0.118562 Train acc: 0.960335 Valid acc: 0.956936\n",
      "Epoch: 920/1000 Train loss: 0.100972 Valid loss: 0.118530 Train acc: 0.960335 Valid acc: 0.956936\n",
      "Epoch: 921/1000 Train loss: 0.100796 Valid loss: 0.118509 Train acc: 0.960562 Valid acc: 0.956936\n",
      "Epoch: 922/1000 Train loss: 0.100611 Valid loss: 0.119272 Train acc: 0.960789 Valid acc: 0.956482\n",
      "Epoch: 923/1000 Train loss: 0.100403 Valid loss: 0.119610 Train acc: 0.960789 Valid acc: 0.956482\n",
      "Epoch: 924/1000 Train loss: 0.100187 Valid loss: 0.119716 Train acc: 0.960789 Valid acc: 0.956029\n",
      "Epoch: 925/1000 Train loss: 0.099965 Valid loss: 0.120708 Train acc: 0.960562 Valid acc: 0.955122\n",
      "Epoch: 926/1000 Train loss: 0.099713 Valid loss: 0.121872 Train acc: 0.960789 Valid acc: 0.955122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 927/1000 Train loss: 0.100684 Valid loss: 0.121681 Train acc: 0.960562 Valid acc: 0.955576\n",
      "Epoch: 928/1000 Train loss: 0.099033 Valid loss: 0.119903 Train acc: 0.961695 Valid acc: 0.956029\n",
      "Epoch: 929/1000 Train loss: 0.098380 Valid loss: 0.122536 Train acc: 0.961695 Valid acc: 0.955122\n",
      "Epoch: 930/1000 Train loss: 0.098116 Valid loss: 0.122321 Train acc: 0.961469 Valid acc: 0.955576\n",
      "Epoch: 931/1000 Train loss: 0.098002 Valid loss: 0.121592 Train acc: 0.961469 Valid acc: 0.955576\n",
      "Epoch: 932/1000 Train loss: 0.097885 Valid loss: 0.120635 Train acc: 0.961469 Valid acc: 0.955576\n",
      "Epoch: 933/1000 Train loss: 0.097677 Valid loss: 0.119434 Train acc: 0.961242 Valid acc: 0.956029\n",
      "Epoch: 934/1000 Train loss: 0.097461 Valid loss: 0.119389 Train acc: 0.961242 Valid acc: 0.955576\n",
      "Epoch: 935/1000 Train loss: 0.097283 Valid loss: 0.119487 Train acc: 0.961242 Valid acc: 0.955576\n",
      "Epoch: 936/1000 Train loss: 0.097098 Valid loss: 0.119330 Train acc: 0.961242 Valid acc: 0.955576\n",
      "Epoch: 937/1000 Train loss: 0.096874 Valid loss: 0.119251 Train acc: 0.960562 Valid acc: 0.955576\n",
      "Epoch: 938/1000 Train loss: 0.096690 Valid loss: 0.119243 Train acc: 0.960562 Valid acc: 0.955576\n",
      "Epoch: 939/1000 Train loss: 0.096516 Valid loss: 0.119297 Train acc: 0.960789 Valid acc: 0.955576\n",
      "Epoch: 940/1000 Train loss: 0.096350 Valid loss: 0.119475 Train acc: 0.961015 Valid acc: 0.955122\n",
      "Epoch: 941/1000 Train loss: 0.096188 Valid loss: 0.119547 Train acc: 0.961242 Valid acc: 0.955576\n",
      "Epoch: 942/1000 Train loss: 0.096027 Valid loss: 0.118188 Train acc: 0.961015 Valid acc: 0.955122\n",
      "Epoch: 943/1000 Train loss: 0.095857 Valid loss: 0.118103 Train acc: 0.961242 Valid acc: 0.955122\n",
      "Epoch: 944/1000 Train loss: 0.095683 Valid loss: 0.117849 Train acc: 0.961015 Valid acc: 0.955576\n",
      "Epoch: 945/1000 Train loss: 0.095525 Valid loss: 0.117766 Train acc: 0.961015 Valid acc: 0.955576\n",
      "Epoch: 946/1000 Train loss: 0.095377 Valid loss: 0.117910 Train acc: 0.961015 Valid acc: 0.955122\n",
      "Epoch: 947/1000 Train loss: 0.095233 Valid loss: 0.118259 Train acc: 0.961242 Valid acc: 0.954669\n",
      "Epoch: 948/1000 Train loss: 0.095070 Valid loss: 0.118588 Train acc: 0.961015 Valid acc: 0.953762\n",
      "Epoch: 949/1000 Train loss: 0.094912 Valid loss: 0.119924 Train acc: 0.961015 Valid acc: 0.954216\n",
      "Epoch: 950/1000 Train loss: 0.094763 Valid loss: 0.120669 Train acc: 0.961242 Valid acc: 0.953762\n",
      "Epoch: 951/1000 Train loss: 0.094623 Valid loss: 0.120739 Train acc: 0.961242 Valid acc: 0.953762\n",
      "Epoch: 952/1000 Train loss: 0.094485 Valid loss: 0.120763 Train acc: 0.961242 Valid acc: 0.953762\n",
      "Epoch: 953/1000 Train loss: 0.094339 Valid loss: 0.120708 Train acc: 0.961242 Valid acc: 0.953762\n",
      "Epoch: 954/1000 Train loss: 0.094189 Valid loss: 0.120593 Train acc: 0.961015 Valid acc: 0.953309\n",
      "Epoch: 955/1000 Train loss: 0.094045 Valid loss: 0.120430 Train acc: 0.961242 Valid acc: 0.953309\n",
      "Epoch: 956/1000 Train loss: 0.093924 Valid loss: 0.120220 Train acc: 0.961015 Valid acc: 0.953309\n",
      "Epoch: 957/1000 Train loss: 0.093777 Valid loss: 0.119983 Train acc: 0.961015 Valid acc: 0.953309\n",
      "Epoch: 958/1000 Train loss: 0.093631 Valid loss: 0.119788 Train acc: 0.961242 Valid acc: 0.953309\n",
      "Epoch: 959/1000 Train loss: 0.093489 Valid loss: 0.119648 Train acc: 0.961242 Valid acc: 0.953762\n",
      "Epoch: 960/1000 Train loss: 0.093342 Valid loss: 0.119535 Train acc: 0.961015 Valid acc: 0.953762\n",
      "Epoch: 961/1000 Train loss: 0.093186 Valid loss: 0.119420 Train acc: 0.961469 Valid acc: 0.953309\n",
      "Epoch: 962/1000 Train loss: 0.093036 Valid loss: 0.119351 Train acc: 0.961922 Valid acc: 0.953762\n",
      "Epoch: 963/1000 Train loss: 0.092895 Valid loss: 0.119227 Train acc: 0.961695 Valid acc: 0.954216\n",
      "Epoch: 964/1000 Train loss: 0.092761 Valid loss: 0.118942 Train acc: 0.961469 Valid acc: 0.953762\n",
      "Epoch: 965/1000 Train loss: 0.092630 Valid loss: 0.118373 Train acc: 0.961469 Valid acc: 0.953309\n",
      "Epoch: 966/1000 Train loss: 0.092481 Valid loss: 0.117997 Train acc: 0.961695 Valid acc: 0.953762\n",
      "Epoch: 967/1000 Train loss: 0.092329 Valid loss: 0.117796 Train acc: 0.961922 Valid acc: 0.953762\n",
      "Epoch: 968/1000 Train loss: 0.092181 Valid loss: 0.117620 Train acc: 0.961922 Valid acc: 0.954669\n",
      "Epoch: 969/1000 Train loss: 0.092029 Valid loss: 0.117433 Train acc: 0.961922 Valid acc: 0.954669\n",
      "Epoch: 970/1000 Train loss: 0.091839 Valid loss: 0.117276 Train acc: 0.961922 Valid acc: 0.955576\n",
      "Epoch: 971/1000 Train loss: 0.091684 Valid loss: 0.117094 Train acc: 0.961922 Valid acc: 0.955122\n",
      "Epoch: 972/1000 Train loss: 0.091522 Valid loss: 0.116913 Train acc: 0.961922 Valid acc: 0.955576\n",
      "Epoch: 973/1000 Train loss: 0.091375 Valid loss: 0.116825 Train acc: 0.961695 Valid acc: 0.956029\n",
      "Epoch: 974/1000 Train loss: 0.091271 Valid loss: 0.116881 Train acc: 0.961922 Valid acc: 0.955122\n",
      "Epoch: 975/1000 Train loss: 0.091175 Valid loss: 0.117989 Train acc: 0.963055 Valid acc: 0.955122\n",
      "Epoch: 976/1000 Train loss: 0.091039 Valid loss: 0.118504 Train acc: 0.961922 Valid acc: 0.954216\n",
      "Epoch: 977/1000 Train loss: 0.090947 Valid loss: 0.118502 Train acc: 0.962602 Valid acc: 0.955576\n",
      "Epoch: 978/1000 Train loss: 0.090871 Valid loss: 0.118611 Train acc: 0.962829 Valid acc: 0.953762\n",
      "Epoch: 979/1000 Train loss: 0.092310 Valid loss: 0.118868 Train acc: 0.962375 Valid acc: 0.954216\n",
      "Epoch: 980/1000 Train loss: 0.090515 Valid loss: 0.117163 Train acc: 0.962602 Valid acc: 0.956029\n",
      "Epoch: 981/1000 Train loss: 0.090313 Valid loss: 0.117078 Train acc: 0.963509 Valid acc: 0.955122\n",
      "Epoch: 982/1000 Train loss: 0.090217 Valid loss: 0.118025 Train acc: 0.962602 Valid acc: 0.955122\n",
      "Epoch: 983/1000 Train loss: 0.090295 Valid loss: 0.117189 Train acc: 0.962829 Valid acc: 0.955122\n",
      "Epoch: 984/1000 Train loss: 0.090007 Valid loss: 0.116353 Train acc: 0.963509 Valid acc: 0.955122\n",
      "Epoch: 985/1000 Train loss: 0.090748 Valid loss: 0.116667 Train acc: 0.962829 Valid acc: 0.955576\n",
      "Epoch: 986/1000 Train loss: 0.090128 Valid loss: 0.117632 Train acc: 0.963282 Valid acc: 0.955576\n",
      "Epoch: 987/1000 Train loss: 0.089918 Valid loss: 0.114501 Train acc: 0.963735 Valid acc: 0.956936\n",
      "Epoch: 988/1000 Train loss: 0.089667 Valid loss: 0.113583 Train acc: 0.963735 Valid acc: 0.957842\n",
      "Epoch: 989/1000 Train loss: 0.089489 Valid loss: 0.113902 Train acc: 0.963735 Valid acc: 0.955576\n",
      "Epoch: 990/1000 Train loss: 0.089412 Valid loss: 0.114383 Train acc: 0.963282 Valid acc: 0.956029\n",
      "Epoch: 991/1000 Train loss: 0.089300 Valid loss: 0.113695 Train acc: 0.963509 Valid acc: 0.956482\n",
      "Epoch: 992/1000 Train loss: 0.089010 Valid loss: 0.113891 Train acc: 0.963055 Valid acc: 0.955122\n",
      "Epoch: 993/1000 Train loss: 0.088840 Valid loss: 0.114702 Train acc: 0.963735 Valid acc: 0.956936\n",
      "Epoch: 994/1000 Train loss: 0.089064 Valid loss: 0.114495 Train acc: 0.963735 Valid acc: 0.956029\n",
      "Epoch: 995/1000 Train loss: 0.089123 Valid loss: 0.114982 Train acc: 0.963282 Valid acc: 0.956482\n",
      "Epoch: 996/1000 Train loss: 0.088836 Valid loss: 0.114481 Train acc: 0.963735 Valid acc: 0.955122\n",
      "Epoch: 997/1000 Train loss: 0.088400 Valid loss: 0.113982 Train acc: 0.963962 Valid acc: 0.955576\n",
      "Epoch: 998/1000 Train loss: 0.088322 Valid loss: 0.114126 Train acc: 0.963735 Valid acc: 0.955122\n",
      "Epoch: 999/1000 Train loss: 0.088337 Valid loss: 0.114757 Train acc: 0.963735 Valid acc: 0.955576\n",
      "Epoch: 1000/1000 Train loss: 0.088342 Valid loss: 0.114735 Train acc: 0.963735 Valid acc: 0.954669\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "\n",
    "# Save the training result or trained and validated model params\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "   \n",
    "    # Loop over epochs\n",
    "    epochs = 1000\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Loop over batches of training\n",
    "        state = sess.run(initial_state)\n",
    "        loss_batch, acc_batch = [], []\n",
    "        for Xarr, Yarr in get_batches(X=Xtrain, y=Ytrain, batch_size=batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed_dict = {Xinput:Xarr, Ylabels:Yarr, initial_state:state}\n",
    "            lossarr, _ , state, accarr = sess.run([loss, optimizer, final_state, accuracy], feed_dict=feed_dict)\n",
    "            loss_batch.append(lossarr)\n",
    "            acc_batch.append(accarr)\n",
    "            \n",
    "        # acc and loss for plotting\n",
    "        train_acc.append(np.mean(acc_batch))\n",
    "        train_loss.append(np.mean(loss_batch))\n",
    "\n",
    "        # Loop over batches of validation\n",
    "        state = sess.run(initial_state)\n",
    "        loss_batch, acc_batch = [], []\n",
    "        for Xarr, Yarr in get_batches(X=Xvalid, y=Yvalid, batch_size=batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed_dict = {Xinput:Xarr, Ylabels:Yarr, initial_state:state}\n",
    "            lossarr, state, accarr = sess.run([loss, final_state, accuracy], feed_dict=feed_dict)\n",
    "            loss_batch.append(lossarr)\n",
    "            acc_batch.append(accarr)\n",
    "            \n",
    "        # acc and loss for plotting\n",
    "        valid_acc.append(np.mean(acc_batch))\n",
    "        valid_loss.append(np.mean(loss_batch))\n",
    "            \n",
    "        # Print info for every iter/epoch\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs),\n",
    "              \"Train loss: {:6f}\".format(train_loss[epoch]),\n",
    "              \"Valid loss: {:.6f}\".format(valid_loss[epoch]),\n",
    "              \"Train acc: {:6f}\".format(train_acc[epoch]),\n",
    "              \"Valid acc: {:.6f}\".format(valid_acc[epoch]))\n",
    "                \n",
    "    saver.save(sess, 'checkpoints/lstm-imu-har.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "%matplotlib inline\n",
    "\n",
    "mplot.plot(train_loss, label='train_loss')\n",
    "mplot.plot(valid_loss, label='valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as mplot\n",
    "mplot.plot(train_acc, label='train_acc')\n",
    "mplot.plot(valid_acc, label='valid_acc')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/lstm-imu-har.ckpt\n",
      "Test loss: 0.453735 Test acc: 0.875340\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Restore the validated model\n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    saver.restore(sess=sess, save_path='checkpoints/lstm-imu-har.ckpt')\n",
    "    \n",
    "    # Loop over batches of Test\n",
    "    state = sess.run(initial_state)\n",
    "    loss_batch, acc_batch = [], []\n",
    "    for Xarr, Yarr in get_batches(X=Xtest, y=Ytest, batch_size=batch_size):\n",
    "\n",
    "        # Feed dictionary\n",
    "        feed_dict = {Xinput:Xarr, Ylabels:Yarr, initial_state:state}\n",
    "        lossarr, state, accarr = sess.run([loss, final_state, accuracy], feed_dict=feed_dict)\n",
    "        loss_batch.append(lossarr)\n",
    "        acc_batch.append(accarr)\n",
    "\n",
    "    # Print info for every iter/epoch\n",
    "    print(\"Test loss: {:6f}\".format(np.mean(loss_batch)),\n",
    "          \"Test acc: {:.6f}\".format(np.mean(acc_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
