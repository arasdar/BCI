{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16675734494015235 0.1459466811751904 0.13411316648531013 0.1749183895538629 0.1868879216539717 0.1913764961915125\n",
      "(7352, 128, 9) float64 (2947, 128, 9) float64\n",
      "(7352,) int64 (2947,) int64\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "import numpy as np\n",
    "from utilities import *\n",
    "\n",
    "# test and train read\n",
    "Xtrain, Ytrain, _ = read_data(data_path='/home/arasdar/datasets/har/har-data/', split='train')\n",
    "Xtest, Ytest, _ = read_data(data_path='/home/arasdar/datasets/har/har-data/', split='test')\n",
    "\n",
    "# assert list_ch_train_valid == list_ch_test, \"Mistmatch in channels!\"\n",
    "assert Ytrain.max(axis=0) == Ytest.max(axis=0), 'Mismatch in channels of Ytrain and Ytest'\n",
    "\n",
    "# balanced data or not\n",
    "print(np.mean(Ytrain==1), np.mean(Ytrain==2), np.mean(Ytrain==3), \n",
    "      np.mean(Ytrain==4), np.mean(Ytrain==5), np.mean(Ytrain==6))\n",
    "\n",
    "print(Xtrain.shape, Xtrain.dtype, Xtest.shape, Xtest.dtype)\n",
    "print(Ytrain.shape, Ytrain.dtype, Ytest.shape, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) float64 (2947, 128, 9) float64\n",
      "(7352, 6) float64 (2947, 6) float64\n"
     ]
    }
   ],
   "source": [
    "# Normalizing/standardizing the input data features\n",
    "Xtrain, Xtest = standardize(train=Xtrain, test=Xtest)\n",
    "\n",
    "Ytrain = one_hot(labels=Ytrain.reshape(-1), n_class=Ytrain.max(axis=0)) \n",
    "Ytest = one_hot(labels=Ytest.reshape(-1), n_class=Ytest.max(axis=0)) \n",
    "\n",
    "print(Xtrain.shape, Xtrain.dtype, Xtest.shape, Xtest.dtype)\n",
    "print(Ytrain.shape, Ytrain.dtype, Ytest.shape, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5146, 128, 9) float64 (2947, 128, 9) float64 (2206, 128, 9) float64\n",
      "(5146, 6) float64 (2947, 6) float64 (2206, 6) float64\n"
     ]
    }
   ],
   "source": [
    "# Train and valid split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtrain, Ytrain, test_size=0.30)\n",
    "\n",
    "print(Xtrain.shape, Xtrain.dtype, Xtest.shape, Xtest.dtype, Xvalid.shape, Xvalid.dtype)\n",
    "print(Ytrain.shape, Ytrain.dtype, Ytest.shape, Ytest.dtype, Yvalid.shape, Yvalid.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size, seq_len, n_channels 2206 128 9\n",
      "bach_size, n_classes 2206 6\n"
     ]
    }
   ],
   "source": [
    "assert Xvalid.shape[0]==Yvalid.shape[0], 'batch_size or N for Xvalid and Yvalid are not equal.'\n",
    "\n",
    "# Input data: NxWxCin\n",
    "batch_size = Xvalid.shape[0]\n",
    "seq_len = Xvalid.shape[1]\n",
    "n_channels = Xvalid.shape[2]\n",
    "print('batch_size, seq_len, n_channels', batch_size, seq_len, n_channels)\n",
    "\n",
    "# Output labels: NxCout\n",
    "batch_size = Yvalid.shape[0]\n",
    "n_classes = Yvalid.shape[1]\n",
    "print('bach_size, n_classes', batch_size, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Feed the data from python/numpy to tensorflow framework\n",
    "Xinput = tf.placeholder(dtype=tf.float32, shape=[batch_size, seq_len, n_channels], name=None)\n",
    "Ylabels = tf.placeholder(dtype=tf.float32, shape=[batch_size, n_classes], name=None)\n",
    "print(Xinput.shape, Xinput.dtype)\n",
    "print(Ylabels.shape, Ylabels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(128, 2206, 9) <dtype: 'float32'>\n",
      "(282368, 9) <dtype: 'float32'>\n",
      "128 (2206, 9) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# # Xinput NxWxCin => WxNxCin == (seq_len, N, n_channels)\n",
    "print(Xinput.shape, Xinput.dtype)\n",
    "\n",
    "lstm_in = tf.transpose(Xinput, [1,0,2]) # reshape into (seq_len, N, channels)\n",
    "print(lstm_in.shape, lstm_in.dtype)\n",
    "\n",
    "lstm_in = tf.reshape(lstm_in, [-1, n_channels]) # Now (seq_len*N, n_channels)\n",
    "print(lstm_in.shape, lstm_in.dtype)\n",
    "\n",
    "# Open up the tensor into a list of seq_len pieces\n",
    "lstm_in = tf.split(value=lstm_in, num_or_size_splits=seq_len, axis=0)\n",
    "print(len(lstm_in), lstm_in[0].shape, lstm_in[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "# RNN-LSTM parameters\n",
    "lstm_size = 3 * n_channels # 3 times the amount of channels\n",
    "print(lstm_size)\n",
    "\n",
    "# Add LSTM layers\n",
    "# lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "lstm = tf.nn.rnn_cell.BasicLSTMCell(num_units=lstm_size)\n",
    "\n",
    "# drop = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "lstm_layers = 1 # Number of layers\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell(cells=[lstm] * lstm_layers)\n",
    "\n",
    "initial_state = cell.zero_state(batch_size=batch_size, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, final_state = tf.nn.static_rnn(cell=cell, inputs=lstm_in, dtype=tf.float32, initial_state=initial_state)\n",
    "# print(outputs, final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 6) <dtype: 'float32'>\n",
      "128 (2206, 27) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# We only need the last output tensor to pass into a classifier\n",
    "Ylogits = tf.layers.dense(inputs=outputs[-1], units=n_classes, name=None)\n",
    "print(Ylogits.shape, Ylogits.dtype)\n",
    "print(len(outputs), outputs[-1].shape, outputs[-1].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"softmax_cross_entropy_with_logits/Reshape_2:0\", shape=(2206,), dtype=float32)\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "optimizer name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_dense/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dense/bias/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n",
      "Tensor(\"ArgMax:0\", shape=(2206,), dtype=int64) Tensor(\"ArgMax_1:0\", shape=(2206,), dtype=int64)\n",
      "Tensor(\"Equal:0\", shape=(2206,), dtype=bool)\n",
      "Tensor(\"Cast:0\", shape=(2206,), dtype=float32)\n",
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits, labels=Ylabels)\n",
    "print(loss)\n",
    "loss = tf.reduce_mean(input_tensor=loss)\n",
    "print(loss)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss=loss)\n",
    "print('optimizer', optimizer)\n",
    "\n",
    "# Accuracy\n",
    "Ylogits_argmax = tf.argmax(input=Ylogits, axis=1)\n",
    "Ylabels_argmax = tf.argmax(input=Ylabels, axis=1)\n",
    "print(Ylogits_argmax, Ylabels_argmax)\n",
    "accuracy = tf.equal(x=Ylogits_argmax, y=Ylabels_argmax)\n",
    "print(accuracy)\n",
    "accuracy = tf.cast(x=accuracy, dtype=tf.float32)\n",
    "print(accuracy)\n",
    "accuracy = tf.reduce_mean(input_tensor=accuracy, name=None)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confusion matrix\n",
    "# confusion_matrix = tf.confusion_matrix(predictions=tf.argmax(logits, 1),\n",
    "#                                        labels=tf.argmax(labels_, 1))\n",
    "# print('confusion_matrix', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000 Train loss: 1.778386 Valid loss: 1.764080 Train acc: 0.334542 Valid acc: 0.340889\n",
      "Epoch: 2/1000 Train loss: 1.743969 Valid loss: 1.729560 Train acc: 0.357208 Valid acc: 0.354941\n",
      "Epoch: 3/1000 Train loss: 1.711249 Valid loss: 1.696650 Train acc: 0.371487 Valid acc: 0.374887\n",
      "Epoch: 4/1000 Train loss: 1.679941 Valid loss: 1.665096 Train acc: 0.394379 Valid acc: 0.417951\n",
      "Epoch: 5/1000 Train loss: 1.649791 Valid loss: 1.634589 Train acc: 0.434950 Valid acc: 0.464189\n",
      "Epoch: 6/1000 Train loss: 1.620479 Valid loss: 1.604738 Train acc: 0.475521 Valid acc: 0.503173\n",
      "Epoch: 7/1000 Train loss: 1.591622 Valid loss: 1.575143 Train acc: 0.510879 Valid acc: 0.543971\n",
      "Epoch: 8/1000 Train loss: 1.562842 Valid loss: 1.545457 Train acc: 0.547824 Valid acc: 0.576156\n",
      "Epoch: 9/1000 Train loss: 1.533816 Valid loss: 1.515411 Train acc: 0.570943 Valid acc: 0.593382\n",
      "Epoch: 10/1000 Train loss: 1.504290 Valid loss: 1.484810 Train acc: 0.582276 Valid acc: 0.600635\n",
      "Epoch: 11/1000 Train loss: 1.474077 Valid loss: 1.453519 Train acc: 0.589075 Valid acc: 0.603355\n",
      "Epoch: 12/1000 Train loss: 1.443041 Valid loss: 1.421451 Train acc: 0.598368 Valid acc: 0.608794\n",
      "Epoch: 13/1000 Train loss: 1.411082 Valid loss: 1.388570 Train acc: 0.604941 Valid acc: 0.611061\n",
      "Epoch: 14/1000 Train loss: 1.378152 Valid loss: 1.354929 Train acc: 0.614234 Valid acc: 0.616500\n",
      "Epoch: 15/1000 Train loss: 1.344298 Valid loss: 1.320721 Train acc: 0.616274 Valid acc: 0.621487\n",
      "Epoch: 16/1000 Train loss: 1.309741 Valid loss: 1.286350 Train acc: 0.621034 Valid acc: 0.621034\n",
      "Epoch: 17/1000 Train loss: 1.274946 Valid loss: 1.252495 Train acc: 0.615367 Valid acc: 0.609248\n",
      "Epoch: 18/1000 Train loss: 1.240703 Valid loss: 1.220069 Train acc: 0.613327 Valid acc: 0.607434\n",
      "Epoch: 19/1000 Train loss: 1.207986 Valid loss: 1.189751 Train acc: 0.613781 Valid acc: 0.601088\n",
      "Epoch: 20/1000 Train loss: 1.177238 Valid loss: 1.161488 Train acc: 0.613327 Valid acc: 0.600635\n",
      "Epoch: 21/1000 Train loss: 1.147987 Valid loss: 1.134542 Train acc: 0.614687 Valid acc: 0.608341\n",
      "Epoch: 22/1000 Train loss: 1.120577 Valid loss: 1.108102 Train acc: 0.616500 Valid acc: 0.613327\n",
      "Epoch: 23/1000 Train loss: 1.094275 Valid loss: 1.081746 Train acc: 0.621714 Valid acc: 0.615140\n",
      "Epoch: 24/1000 Train loss: 1.069116 Valid loss: 1.055796 Train acc: 0.622167 Valid acc: 0.619674\n",
      "Epoch: 25/1000 Train loss: 1.043456 Valid loss: 1.030171 Train acc: 0.623980 Valid acc: 0.628740\n",
      "Epoch: 26/1000 Train loss: 1.017695 Valid loss: 1.005507 Train acc: 0.631686 Valid acc: 0.635539\n",
      "Epoch: 27/1000 Train loss: 0.993263 Valid loss: 0.981912 Train acc: 0.641659 Valid acc: 0.650499\n",
      "Epoch: 28/1000 Train loss: 0.969908 Valid loss: 0.959496 Train acc: 0.653445 Valid acc: 0.671804\n",
      "Epoch: 29/1000 Train loss: 0.948228 Valid loss: 0.937765 Train acc: 0.666591 Valid acc: 0.678150\n",
      "Epoch: 30/1000 Train loss: 0.928386 Valid loss: 0.916410 Train acc: 0.674977 Valid acc: 0.681777\n",
      "Epoch: 31/1000 Train loss: 0.909120 Valid loss: 0.899040 Train acc: 0.677471 Valid acc: 0.679964\n",
      "Epoch: 32/1000 Train loss: 0.890002 Valid loss: 0.882611 Train acc: 0.684723 Valid acc: 0.681324\n",
      "Epoch: 33/1000 Train loss: 0.873408 Valid loss: 0.865718 Train acc: 0.686990 Valid acc: 0.689030\n",
      "Epoch: 34/1000 Train loss: 0.855870 Valid loss: 0.848029 Train acc: 0.689937 Valid acc: 0.694923\n",
      "Epoch: 35/1000 Train loss: 0.839824 Valid loss: 0.831866 Train acc: 0.696283 Valid acc: 0.700363\n",
      "Epoch: 36/1000 Train loss: 0.824634 Valid loss: 0.816855 Train acc: 0.699229 Valid acc: 0.714869\n",
      "Epoch: 37/1000 Train loss: 0.809295 Valid loss: 0.802352 Train acc: 0.714415 Valid acc: 0.725295\n",
      "Epoch: 38/1000 Train loss: 0.793821 Valid loss: 0.789202 Train acc: 0.729148 Valid acc: 0.733908\n",
      "Epoch: 39/1000 Train loss: 0.779752 Valid loss: 0.776465 Train acc: 0.737081 Valid acc: 0.741160\n",
      "Epoch: 40/1000 Train loss: 0.765801 Valid loss: 0.763134 Train acc: 0.747733 Valid acc: 0.753400\n",
      "Epoch: 41/1000 Train loss: 0.751194 Valid loss: 0.751362 Train acc: 0.754306 Valid acc: 0.762013\n",
      "Epoch: 42/1000 Train loss: 0.740052 Valid loss: 0.740451 Train acc: 0.763146 Valid acc: 0.767906\n",
      "Epoch: 43/1000 Train loss: 0.729518 Valid loss: 0.731083 Train acc: 0.768812 Valid acc: 0.771985\n",
      "Epoch: 44/1000 Train loss: 0.719378 Valid loss: 0.722985 Train acc: 0.772892 Valid acc: 0.772892\n",
      "Epoch: 45/1000 Train loss: 0.710554 Valid loss: 0.713052 Train acc: 0.778332 Valid acc: 0.776972\n",
      "Epoch: 46/1000 Train loss: 0.699250 Valid loss: 0.702882 Train acc: 0.784678 Valid acc: 0.787398\n",
      "Epoch: 47/1000 Train loss: 0.689548 Valid loss: 0.693292 Train acc: 0.789665 Valid acc: 0.789665\n",
      "Epoch: 48/1000 Train loss: 0.680212 Valid loss: 0.683199 Train acc: 0.793744 Valid acc: 0.795558\n",
      "Epoch: 49/1000 Train loss: 0.670727 Valid loss: 0.673884 Train acc: 0.796011 Valid acc: 0.797824\n",
      "Epoch: 50/1000 Train loss: 0.660991 Valid loss: 0.663528 Train acc: 0.801451 Valid acc: 0.802810\n",
      "Epoch: 51/1000 Train loss: 0.651564 Valid loss: 0.653714 Train acc: 0.802357 Valid acc: 0.807344\n",
      "Epoch: 52/1000 Train loss: 0.642588 Valid loss: 0.644419 Train acc: 0.805984 Valid acc: 0.815050\n",
      "Epoch: 53/1000 Train loss: 0.633276 Valid loss: 0.635333 Train acc: 0.808704 Valid acc: 0.815503\n",
      "Epoch: 54/1000 Train loss: 0.623669 Valid loss: 0.625858 Train acc: 0.813690 Valid acc: 0.818223\n",
      "Epoch: 55/1000 Train loss: 0.613819 Valid loss: 0.615658 Train acc: 0.817090 Valid acc: 0.822303\n",
      "Epoch: 56/1000 Train loss: 0.604254 Valid loss: 0.605133 Train acc: 0.819130 Valid acc: 0.830009\n",
      "Epoch: 57/1000 Train loss: 0.593688 Valid loss: 0.594437 Train acc: 0.821623 Valid acc: 0.829556\n",
      "Epoch: 58/1000 Train loss: 0.583593 Valid loss: 0.582973 Train acc: 0.826156 Valid acc: 0.836809\n",
      "Epoch: 59/1000 Train loss: 0.573219 Valid loss: 0.571553 Train acc: 0.827516 Valid acc: 0.840435\n",
      "Epoch: 60/1000 Train loss: 0.562418 Valid loss: 0.560648 Train acc: 0.830689 Valid acc: 0.844062\n",
      "Epoch: 61/1000 Train loss: 0.552177 Valid loss: 0.549643 Train acc: 0.834769 Valid acc: 0.846328\n",
      "Epoch: 62/1000 Train loss: 0.541979 Valid loss: 0.538494 Train acc: 0.837715 Valid acc: 0.849955\n",
      "Epoch: 63/1000 Train loss: 0.532442 Valid loss: 0.527894 Train acc: 0.838622 Valid acc: 0.853128\n",
      "Epoch: 64/1000 Train loss: 0.522561 Valid loss: 0.517427 Train acc: 0.841342 Valid acc: 0.853581\n",
      "Epoch: 65/1000 Train loss: 0.512910 Valid loss: 0.508603 Train acc: 0.845195 Valid acc: 0.859927\n",
      "Epoch: 66/1000 Train loss: 0.507078 Valid loss: 0.508604 Train acc: 0.844742 Valid acc: 0.860381\n",
      "Epoch: 67/1000 Train loss: 0.505879 Valid loss: 0.506707 Train acc: 0.843382 Valid acc: 0.856301\n",
      "Epoch: 68/1000 Train loss: 0.503686 Valid loss: 0.498189 Train acc: 0.844288 Valid acc: 0.859474\n",
      "Epoch: 69/1000 Train loss: 0.494951 Valid loss: 0.489295 Train acc: 0.844062 Valid acc: 0.860834\n",
      "Epoch: 70/1000 Train loss: 0.486178 Valid loss: 0.481966 Train acc: 0.846781 Valid acc: 0.864914\n",
      "Epoch: 71/1000 Train loss: 0.478896 Valid loss: 0.475333 Train acc: 0.845195 Valid acc: 0.865367\n",
      "Epoch: 72/1000 Train loss: 0.472877 Valid loss: 0.467518 Train acc: 0.845875 Valid acc: 0.862647\n",
      "Epoch: 73/1000 Train loss: 0.466706 Valid loss: 0.462486 Train acc: 0.848595 Valid acc: 0.863101\n",
      "Epoch: 74/1000 Train loss: 0.459920 Valid loss: 0.456402 Train acc: 0.849728 Valid acc: 0.866727\n",
      "Epoch: 75/1000 Train loss: 0.454561 Valid loss: 0.450342 Train acc: 0.852901 Valid acc: 0.869900\n",
      "Epoch: 76/1000 Train loss: 0.448874 Valid loss: 0.444897 Train acc: 0.856981 Valid acc: 0.873980\n",
      "Epoch: 77/1000 Train loss: 0.442297 Valid loss: 0.438874 Train acc: 0.861061 Valid acc: 0.874887\n",
      "Epoch: 78/1000 Train loss: 0.436072 Valid loss: 0.433057 Train acc: 0.865141 Valid acc: 0.876247\n",
      "Epoch: 79/1000 Train loss: 0.430059 Valid loss: 0.426698 Train acc: 0.869220 Valid acc: 0.878966\n",
      "Epoch: 80/1000 Train loss: 0.424557 Valid loss: 0.421222 Train acc: 0.873980 Valid acc: 0.881233\n",
      "Epoch: 81/1000 Train loss: 0.418796 Valid loss: 0.416447 Train acc: 0.877153 Valid acc: 0.881233\n",
      "Epoch: 82/1000 Train loss: 0.415037 Valid loss: 0.410446 Train acc: 0.876927 Valid acc: 0.886219\n",
      "Epoch: 83/1000 Train loss: 0.409680 Valid loss: 0.407470 Train acc: 0.881233 Valid acc: 0.888486\n",
      "Epoch: 84/1000 Train loss: 0.405091 Valid loss: 0.401793 Train acc: 0.882593 Valid acc: 0.889393\n",
      "Epoch: 85/1000 Train loss: 0.400668 Valid loss: 0.398299 Train acc: 0.882140 Valid acc: 0.889846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/1000 Train loss: 0.394824 Valid loss: 0.393208 Train acc: 0.886899 Valid acc: 0.890299\n",
      "Epoch: 87/1000 Train loss: 0.389918 Valid loss: 0.387659 Train acc: 0.891206 Valid acc: 0.890299\n",
      "Epoch: 88/1000 Train loss: 0.384560 Valid loss: 0.382772 Train acc: 0.892566 Valid acc: 0.892112\n",
      "Epoch: 89/1000 Train loss: 0.379530 Valid loss: 0.379096 Train acc: 0.895286 Valid acc: 0.891659\n",
      "Epoch: 90/1000 Train loss: 0.375687 Valid loss: 0.376132 Train acc: 0.898232 Valid acc: 0.890752\n",
      "Epoch: 91/1000 Train loss: 0.371146 Valid loss: 0.372179 Train acc: 0.899365 Valid acc: 0.892112\n",
      "Epoch: 92/1000 Train loss: 0.367079 Valid loss: 0.368162 Train acc: 0.899819 Valid acc: 0.892112\n",
      "Epoch: 93/1000 Train loss: 0.362283 Valid loss: 0.363094 Train acc: 0.902539 Valid acc: 0.894832\n",
      "Epoch: 94/1000 Train loss: 0.357599 Valid loss: 0.357023 Train acc: 0.903672 Valid acc: 0.898005\n",
      "Epoch: 95/1000 Train loss: 0.352463 Valid loss: 0.353839 Train acc: 0.904578 Valid acc: 0.896645\n",
      "Epoch: 96/1000 Train loss: 0.348183 Valid loss: 0.348148 Train acc: 0.905712 Valid acc: 0.896645\n",
      "Epoch: 97/1000 Train loss: 0.343355 Valid loss: 0.345151 Train acc: 0.908205 Valid acc: 0.897552\n",
      "Epoch: 98/1000 Train loss: 0.339962 Valid loss: 0.342893 Train acc: 0.908885 Valid acc: 0.899819\n",
      "Epoch: 99/1000 Train loss: 0.335853 Valid loss: 0.338053 Train acc: 0.910698 Valid acc: 0.903898\n",
      "Epoch: 100/1000 Train loss: 0.331932 Valid loss: 0.334427 Train acc: 0.910925 Valid acc: 0.901632\n",
      "Epoch: 101/1000 Train loss: 0.328016 Valid loss: 0.328619 Train acc: 0.911151 Valid acc: 0.903445\n",
      "Epoch: 102/1000 Train loss: 0.324160 Valid loss: 0.324664 Train acc: 0.910925 Valid acc: 0.903445\n",
      "Epoch: 103/1000 Train loss: 0.325822 Valid loss: 0.329259 Train acc: 0.911378 Valid acc: 0.905712\n",
      "Epoch: 104/1000 Train loss: 0.330051 Valid loss: 0.320830 Train acc: 0.910018 Valid acc: 0.916591\n",
      "Epoch: 105/1000 Train loss: 0.322805 Valid loss: 0.320404 Train acc: 0.912965 Valid acc: 0.916138\n",
      "Epoch: 106/1000 Train loss: 0.318548 Valid loss: 0.311872 Train acc: 0.915684 Valid acc: 0.924297\n",
      "Epoch: 107/1000 Train loss: 0.312144 Valid loss: 0.314004 Train acc: 0.920898 Valid acc: 0.922484\n",
      "Epoch: 108/1000 Train loss: 0.312493 Valid loss: 0.305487 Train acc: 0.921578 Valid acc: 0.925204\n",
      "Epoch: 109/1000 Train loss: 0.306544 Valid loss: 0.302885 Train acc: 0.922257 Valid acc: 0.925657\n",
      "Epoch: 110/1000 Train loss: 0.303898 Valid loss: 0.296756 Train acc: 0.922711 Valid acc: 0.926564\n",
      "Epoch: 111/1000 Train loss: 0.296337 Valid loss: 0.294052 Train acc: 0.925657 Valid acc: 0.925204\n",
      "Epoch: 112/1000 Train loss: 0.292239 Valid loss: 0.287911 Train acc: 0.929057 Valid acc: 0.926564\n",
      "Epoch: 113/1000 Train loss: 0.285366 Valid loss: 0.280350 Train acc: 0.929510 Valid acc: 0.928830\n",
      "Epoch: 114/1000 Train loss: 0.279125 Valid loss: 0.277076 Train acc: 0.931097 Valid acc: 0.928377\n",
      "Epoch: 115/1000 Train loss: 0.274918 Valid loss: 0.272251 Train acc: 0.933364 Valid acc: 0.931550\n",
      "Epoch: 116/1000 Train loss: 0.272242 Valid loss: 0.267073 Train acc: 0.933137 Valid acc: 0.935177\n",
      "Epoch: 117/1000 Train loss: 0.268630 Valid loss: 0.260604 Train acc: 0.934044 Valid acc: 0.937897\n",
      "Epoch: 118/1000 Train loss: 0.263634 Valid loss: 0.258005 Train acc: 0.935630 Valid acc: 0.938350\n",
      "Epoch: 119/1000 Train loss: 0.260126 Valid loss: 0.252288 Train acc: 0.935403 Valid acc: 0.939710\n",
      "Epoch: 120/1000 Train loss: 0.255134 Valid loss: 0.246468 Train acc: 0.935857 Valid acc: 0.941976\n",
      "Epoch: 121/1000 Train loss: 0.251738 Valid loss: 0.242156 Train acc: 0.935857 Valid acc: 0.941070\n",
      "Epoch: 122/1000 Train loss: 0.246901 Valid loss: 0.239605 Train acc: 0.937443 Valid acc: 0.938803\n",
      "Epoch: 123/1000 Train loss: 0.243605 Valid loss: 0.234387 Train acc: 0.939257 Valid acc: 0.941523\n",
      "Epoch: 124/1000 Train loss: 0.239939 Valid loss: 0.230217 Train acc: 0.938123 Valid acc: 0.941070\n",
      "Epoch: 125/1000 Train loss: 0.235791 Valid loss: 0.227840 Train acc: 0.938803 Valid acc: 0.940616\n",
      "Epoch: 126/1000 Train loss: 0.230892 Valid loss: 0.225511 Train acc: 0.941070 Valid acc: 0.939710\n",
      "Epoch: 127/1000 Train loss: 0.227921 Valid loss: 0.221877 Train acc: 0.942656 Valid acc: 0.941976\n",
      "Epoch: 128/1000 Train loss: 0.225167 Valid loss: 0.218881 Train acc: 0.942656 Valid acc: 0.943336\n",
      "Epoch: 129/1000 Train loss: 0.222432 Valid loss: 0.215807 Train acc: 0.943563 Valid acc: 0.941523\n",
      "Epoch: 130/1000 Train loss: 0.219052 Valid loss: 0.213893 Train acc: 0.944016 Valid acc: 0.940163\n",
      "Epoch: 131/1000 Train loss: 0.217316 Valid loss: 0.215026 Train acc: 0.942883 Valid acc: 0.941976\n",
      "Epoch: 132/1000 Train loss: 0.215588 Valid loss: 0.213696 Train acc: 0.942883 Valid acc: 0.940616\n",
      "Epoch: 133/1000 Train loss: 0.213860 Valid loss: 0.211880 Train acc: 0.943336 Valid acc: 0.941070\n",
      "Epoch: 134/1000 Train loss: 0.212221 Valid loss: 0.209254 Train acc: 0.943110 Valid acc: 0.941070\n",
      "Epoch: 135/1000 Train loss: 0.209756 Valid loss: 0.207724 Train acc: 0.944243 Valid acc: 0.940163\n",
      "Epoch: 136/1000 Train loss: 0.206399 Valid loss: 0.200116 Train acc: 0.945150 Valid acc: 0.943336\n",
      "Epoch: 137/1000 Train loss: 0.204468 Valid loss: 0.196872 Train acc: 0.945150 Valid acc: 0.944696\n",
      "Epoch: 138/1000 Train loss: 0.204058 Valid loss: 0.194725 Train acc: 0.945150 Valid acc: 0.942430\n",
      "Epoch: 139/1000 Train loss: 0.204171 Valid loss: 0.191764 Train acc: 0.943790 Valid acc: 0.944696\n",
      "Epoch: 140/1000 Train loss: 0.202746 Valid loss: 0.189797 Train acc: 0.944923 Valid acc: 0.945603\n",
      "Epoch: 141/1000 Train loss: 0.201690 Valid loss: 0.191866 Train acc: 0.943110 Valid acc: 0.945603\n",
      "Epoch: 142/1000 Train loss: 0.197397 Valid loss: 0.194443 Train acc: 0.946283 Valid acc: 0.941976\n",
      "Epoch: 143/1000 Train loss: 0.197152 Valid loss: 0.200978 Train acc: 0.945376 Valid acc: 0.940163\n",
      "Epoch: 144/1000 Train loss: 0.199371 Valid loss: 0.196420 Train acc: 0.943110 Valid acc: 0.943336\n",
      "Epoch: 145/1000 Train loss: 0.193751 Valid loss: 0.189545 Train acc: 0.946283 Valid acc: 0.946963\n",
      "Epoch: 146/1000 Train loss: 0.189964 Valid loss: 0.186648 Train acc: 0.947416 Valid acc: 0.946963\n",
      "Epoch: 147/1000 Train loss: 0.187790 Valid loss: 0.183419 Train acc: 0.947416 Valid acc: 0.946510\n",
      "Epoch: 148/1000 Train loss: 0.184937 Valid loss: 0.177802 Train acc: 0.949683 Valid acc: 0.949683\n",
      "Epoch: 149/1000 Train loss: 0.184184 Valid loss: 0.174825 Train acc: 0.949229 Valid acc: 0.949683\n",
      "Epoch: 150/1000 Train loss: 0.184796 Valid loss: 0.177406 Train acc: 0.948549 Valid acc: 0.947869\n",
      "Epoch: 151/1000 Train loss: 0.184317 Valid loss: 0.191520 Train acc: 0.949229 Valid acc: 0.946510\n",
      "Epoch: 152/1000 Train loss: 0.204678 Valid loss: 0.195784 Train acc: 0.937217 Valid acc: 0.947869\n",
      "Epoch: 153/1000 Train loss: 0.199832 Valid loss: 0.191952 Train acc: 0.943790 Valid acc: 0.950589\n",
      "Epoch: 154/1000 Train loss: 0.198860 Valid loss: 0.186299 Train acc: 0.945603 Valid acc: 0.946963\n",
      "Epoch: 155/1000 Train loss: 0.197444 Valid loss: 0.184997 Train acc: 0.942203 Valid acc: 0.942883\n",
      "Epoch: 156/1000 Train loss: 0.192294 Valid loss: 0.187477 Train acc: 0.944923 Valid acc: 0.942430\n",
      "Epoch: 157/1000 Train loss: 0.197309 Valid loss: 0.190709 Train acc: 0.935630 Valid acc: 0.939710\n",
      "Epoch: 158/1000 Train loss: 0.194287 Valid loss: 0.189291 Train acc: 0.944243 Valid acc: 0.947416\n",
      "Epoch: 159/1000 Train loss: 0.198515 Valid loss: 0.198579 Train acc: 0.943563 Valid acc: 0.944696\n",
      "Epoch: 160/1000 Train loss: 0.195876 Valid loss: 0.178456 Train acc: 0.944696 Valid acc: 0.949229\n",
      "Epoch: 161/1000 Train loss: 0.182867 Valid loss: 0.182615 Train acc: 0.946736 Valid acc: 0.945603\n",
      "Epoch: 162/1000 Train loss: 0.187977 Valid loss: 0.185033 Train acc: 0.939710 Valid acc: 0.945150\n",
      "Epoch: 163/1000 Train loss: 0.187418 Valid loss: 0.175491 Train acc: 0.939030 Valid acc: 0.946510\n",
      "Epoch: 164/1000 Train loss: 0.178320 Valid loss: 0.171887 Train acc: 0.947416 Valid acc: 0.949229\n",
      "Epoch: 165/1000 Train loss: 0.181642 Valid loss: 0.175291 Train acc: 0.945376 Valid acc: 0.947869\n",
      "Epoch: 166/1000 Train loss: 0.180294 Valid loss: 0.165403 Train acc: 0.947416 Valid acc: 0.955122\n",
      "Epoch: 167/1000 Train loss: 0.172041 Valid loss: 0.165534 Train acc: 0.951043 Valid acc: 0.951496\n",
      "Epoch: 168/1000 Train loss: 0.173488 Valid loss: 0.165254 Train acc: 0.949909 Valid acc: 0.952856\n",
      "Epoch: 169/1000 Train loss: 0.171081 Valid loss: 0.164719 Train acc: 0.951269 Valid acc: 0.951949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170/1000 Train loss: 0.167467 Valid loss: 0.165238 Train acc: 0.951723 Valid acc: 0.952403\n",
      "Epoch: 171/1000 Train loss: 0.167729 Valid loss: 0.164977 Train acc: 0.951269 Valid acc: 0.953762\n",
      "Epoch: 172/1000 Train loss: 0.166128 Valid loss: 0.162357 Train acc: 0.951723 Valid acc: 0.953309\n",
      "Epoch: 173/1000 Train loss: 0.162409 Valid loss: 0.160518 Train acc: 0.953989 Valid acc: 0.951949\n",
      "Epoch: 174/1000 Train loss: 0.163364 Valid loss: 0.157323 Train acc: 0.952856 Valid acc: 0.953309\n",
      "Epoch: 175/1000 Train loss: 0.160940 Valid loss: 0.156731 Train acc: 0.953762 Valid acc: 0.955122\n",
      "Epoch: 176/1000 Train loss: 0.160257 Valid loss: 0.155939 Train acc: 0.952856 Valid acc: 0.954669\n",
      "Epoch: 177/1000 Train loss: 0.157637 Valid loss: 0.158506 Train acc: 0.955122 Valid acc: 0.951496\n",
      "Epoch: 178/1000 Train loss: 0.159860 Valid loss: 0.164881 Train acc: 0.953083 Valid acc: 0.946510\n",
      "Epoch: 179/1000 Train loss: 0.161585 Valid loss: 0.160308 Train acc: 0.951949 Valid acc: 0.950589\n",
      "Epoch: 180/1000 Train loss: 0.156428 Valid loss: 0.154437 Train acc: 0.953989 Valid acc: 0.956029\n",
      "Epoch: 181/1000 Train loss: 0.155299 Valid loss: 0.153730 Train acc: 0.954896 Valid acc: 0.955576\n",
      "Epoch: 182/1000 Train loss: 0.156389 Valid loss: 0.154376 Train acc: 0.955576 Valid acc: 0.956029\n",
      "Epoch: 183/1000 Train loss: 0.155563 Valid loss: 0.154225 Train acc: 0.954669 Valid acc: 0.955576\n",
      "Epoch: 184/1000 Train loss: 0.153543 Valid loss: 0.154613 Train acc: 0.955802 Valid acc: 0.955122\n",
      "Epoch: 185/1000 Train loss: 0.152403 Valid loss: 0.153132 Train acc: 0.957162 Valid acc: 0.954669\n",
      "Epoch: 186/1000 Train loss: 0.152193 Valid loss: 0.152079 Train acc: 0.955576 Valid acc: 0.953762\n",
      "Epoch: 187/1000 Train loss: 0.150998 Valid loss: 0.150462 Train acc: 0.956482 Valid acc: 0.956029\n",
      "Epoch: 188/1000 Train loss: 0.151101 Valid loss: 0.148481 Train acc: 0.957842 Valid acc: 0.956029\n",
      "Epoch: 189/1000 Train loss: 0.150127 Valid loss: 0.147580 Train acc: 0.956936 Valid acc: 0.955122\n",
      "Epoch: 190/1000 Train loss: 0.151839 Valid loss: 0.147499 Train acc: 0.956709 Valid acc: 0.955576\n",
      "Epoch: 191/1000 Train loss: 0.151090 Valid loss: 0.148788 Train acc: 0.958069 Valid acc: 0.953309\n",
      "Epoch: 192/1000 Train loss: 0.150502 Valid loss: 0.150493 Train acc: 0.957616 Valid acc: 0.954216\n",
      "Epoch: 193/1000 Train loss: 0.150714 Valid loss: 0.148506 Train acc: 0.956482 Valid acc: 0.954216\n",
      "Epoch: 194/1000 Train loss: 0.150145 Valid loss: 0.149016 Train acc: 0.956256 Valid acc: 0.953309\n",
      "Epoch: 195/1000 Train loss: 0.149962 Valid loss: 0.147911 Train acc: 0.956029 Valid acc: 0.953309\n",
      "Epoch: 196/1000 Train loss: 0.149359 Valid loss: 0.150920 Train acc: 0.955802 Valid acc: 0.951043\n",
      "Epoch: 197/1000 Train loss: 0.149786 Valid loss: 0.147492 Train acc: 0.956256 Valid acc: 0.950589\n",
      "Epoch: 198/1000 Train loss: 0.146673 Valid loss: 0.148274 Train acc: 0.955802 Valid acc: 0.950136\n",
      "Epoch: 199/1000 Train loss: 0.145636 Valid loss: 0.147278 Train acc: 0.957389 Valid acc: 0.951496\n",
      "Epoch: 200/1000 Train loss: 0.145881 Valid loss: 0.144554 Train acc: 0.956482 Valid acc: 0.953309\n",
      "Epoch: 201/1000 Train loss: 0.143446 Valid loss: 0.141808 Train acc: 0.956709 Valid acc: 0.953762\n",
      "Epoch: 202/1000 Train loss: 0.143219 Valid loss: 0.140705 Train acc: 0.957842 Valid acc: 0.956029\n",
      "Epoch: 203/1000 Train loss: 0.142276 Valid loss: 0.139527 Train acc: 0.958296 Valid acc: 0.956029\n",
      "Epoch: 204/1000 Train loss: 0.141478 Valid loss: 0.138908 Train acc: 0.958296 Valid acc: 0.955576\n",
      "Epoch: 205/1000 Train loss: 0.141333 Valid loss: 0.139357 Train acc: 0.957389 Valid acc: 0.955122\n",
      "Epoch: 206/1000 Train loss: 0.139917 Valid loss: 0.139279 Train acc: 0.958296 Valid acc: 0.956482\n",
      "Epoch: 207/1000 Train loss: 0.139602 Valid loss: 0.140050 Train acc: 0.958976 Valid acc: 0.956936\n",
      "Epoch: 208/1000 Train loss: 0.139308 Valid loss: 0.140321 Train acc: 0.958069 Valid acc: 0.955576\n",
      "Epoch: 209/1000 Train loss: 0.137846 Valid loss: 0.141685 Train acc: 0.958522 Valid acc: 0.955576\n",
      "Epoch: 210/1000 Train loss: 0.139561 Valid loss: 0.141779 Train acc: 0.958296 Valid acc: 0.955576\n",
      "Epoch: 211/1000 Train loss: 0.138494 Valid loss: 0.138973 Train acc: 0.957162 Valid acc: 0.954216\n",
      "Epoch: 212/1000 Train loss: 0.136958 Valid loss: 0.138909 Train acc: 0.957842 Valid acc: 0.954669\n",
      "Epoch: 213/1000 Train loss: 0.137406 Valid loss: 0.138020 Train acc: 0.958522 Valid acc: 0.955576\n",
      "Epoch: 214/1000 Train loss: 0.136838 Valid loss: 0.138293 Train acc: 0.957389 Valid acc: 0.954216\n",
      "Epoch: 215/1000 Train loss: 0.135843 Valid loss: 0.138974 Train acc: 0.957389 Valid acc: 0.955576\n",
      "Epoch: 216/1000 Train loss: 0.135676 Valid loss: 0.136252 Train acc: 0.959202 Valid acc: 0.956482\n",
      "Epoch: 217/1000 Train loss: 0.135291 Valid loss: 0.137382 Train acc: 0.958522 Valid acc: 0.956936\n",
      "Epoch: 218/1000 Train loss: 0.135262 Valid loss: 0.137237 Train acc: 0.959202 Valid acc: 0.955576\n",
      "Epoch: 219/1000 Train loss: 0.134395 Valid loss: 0.136056 Train acc: 0.959429 Valid acc: 0.955576\n",
      "Epoch: 220/1000 Train loss: 0.134444 Valid loss: 0.135509 Train acc: 0.958522 Valid acc: 0.956029\n",
      "Epoch: 221/1000 Train loss: 0.133978 Valid loss: 0.135465 Train acc: 0.958522 Valid acc: 0.955122\n",
      "Epoch: 222/1000 Train loss: 0.133149 Valid loss: 0.134150 Train acc: 0.959202 Valid acc: 0.954216\n",
      "Epoch: 223/1000 Train loss: 0.132872 Valid loss: 0.135616 Train acc: 0.958749 Valid acc: 0.954669\n",
      "Epoch: 224/1000 Train loss: 0.133418 Valid loss: 0.142150 Train acc: 0.958976 Valid acc: 0.951496\n",
      "Epoch: 225/1000 Train loss: 0.134670 Valid loss: 0.138634 Train acc: 0.958976 Valid acc: 0.953762\n",
      "Epoch: 226/1000 Train loss: 0.133358 Valid loss: 0.135482 Train acc: 0.958976 Valid acc: 0.954669\n",
      "Epoch: 227/1000 Train loss: 0.133537 Valid loss: 0.135620 Train acc: 0.958976 Valid acc: 0.953762\n",
      "Epoch: 228/1000 Train loss: 0.133431 Valid loss: 0.135023 Train acc: 0.958749 Valid acc: 0.954216\n",
      "Epoch: 229/1000 Train loss: 0.132585 Valid loss: 0.134785 Train acc: 0.958522 Valid acc: 0.953762\n",
      "Epoch: 230/1000 Train loss: 0.132220 Valid loss: 0.134890 Train acc: 0.958749 Valid acc: 0.954669\n",
      "Epoch: 231/1000 Train loss: 0.131855 Valid loss: 0.135167 Train acc: 0.958522 Valid acc: 0.954216\n",
      "Epoch: 232/1000 Train loss: 0.131580 Valid loss: 0.135740 Train acc: 0.958522 Valid acc: 0.954216\n",
      "Epoch: 233/1000 Train loss: 0.130935 Valid loss: 0.133848 Train acc: 0.959429 Valid acc: 0.953762\n",
      "Epoch: 234/1000 Train loss: 0.130710 Valid loss: 0.133424 Train acc: 0.958069 Valid acc: 0.954669\n",
      "Epoch: 235/1000 Train loss: 0.130125 Valid loss: 0.133382 Train acc: 0.958296 Valid acc: 0.955122\n",
      "Epoch: 236/1000 Train loss: 0.130338 Valid loss: 0.133167 Train acc: 0.957842 Valid acc: 0.954669\n",
      "Epoch: 237/1000 Train loss: 0.130017 Valid loss: 0.132594 Train acc: 0.957842 Valid acc: 0.955122\n",
      "Epoch: 238/1000 Train loss: 0.129420 Valid loss: 0.132239 Train acc: 0.958522 Valid acc: 0.954669\n",
      "Epoch: 239/1000 Train loss: 0.128488 Valid loss: 0.132800 Train acc: 0.958522 Valid acc: 0.953762\n",
      "Epoch: 240/1000 Train loss: 0.128291 Valid loss: 0.133803 Train acc: 0.958522 Valid acc: 0.953309\n",
      "Epoch: 241/1000 Train loss: 0.127709 Valid loss: 0.134380 Train acc: 0.958749 Valid acc: 0.953309\n",
      "Epoch: 242/1000 Train loss: 0.127397 Valid loss: 0.134691 Train acc: 0.958749 Valid acc: 0.954216\n",
      "Epoch: 243/1000 Train loss: 0.127026 Valid loss: 0.134862 Train acc: 0.958749 Valid acc: 0.954216\n",
      "Epoch: 244/1000 Train loss: 0.126770 Valid loss: 0.134426 Train acc: 0.959202 Valid acc: 0.954216\n",
      "Epoch: 245/1000 Train loss: 0.126480 Valid loss: 0.135443 Train acc: 0.959202 Valid acc: 0.952856\n",
      "Epoch: 246/1000 Train loss: 0.126552 Valid loss: 0.134401 Train acc: 0.958522 Valid acc: 0.953762\n",
      "Epoch: 247/1000 Train loss: 0.126214 Valid loss: 0.131966 Train acc: 0.959202 Valid acc: 0.954216\n",
      "Epoch: 248/1000 Train loss: 0.125626 Valid loss: 0.130166 Train acc: 0.959429 Valid acc: 0.954216\n",
      "Epoch: 249/1000 Train loss: 0.125789 Valid loss: 0.129032 Train acc: 0.958749 Valid acc: 0.955122\n",
      "Epoch: 250/1000 Train loss: 0.125363 Valid loss: 0.128556 Train acc: 0.959202 Valid acc: 0.956029\n",
      "Epoch: 251/1000 Train loss: 0.124928 Valid loss: 0.128253 Train acc: 0.959656 Valid acc: 0.954216\n",
      "Epoch: 252/1000 Train loss: 0.124796 Valid loss: 0.128302 Train acc: 0.958976 Valid acc: 0.955122\n",
      "Epoch: 253/1000 Train loss: 0.124328 Valid loss: 0.128886 Train acc: 0.959429 Valid acc: 0.955576\n",
      "Epoch: 254/1000 Train loss: 0.124172 Valid loss: 0.129425 Train acc: 0.959202 Valid acc: 0.955576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 255/1000 Train loss: 0.123666 Valid loss: 0.129978 Train acc: 0.959429 Valid acc: 0.954669\n",
      "Epoch: 256/1000 Train loss: 0.123663 Valid loss: 0.128545 Train acc: 0.958976 Valid acc: 0.954669\n",
      "Epoch: 257/1000 Train loss: 0.123455 Valid loss: 0.128414 Train acc: 0.958976 Valid acc: 0.955122\n",
      "Epoch: 258/1000 Train loss: 0.123341 Valid loss: 0.128201 Train acc: 0.959656 Valid acc: 0.955122\n",
      "Epoch: 259/1000 Train loss: 0.122611 Valid loss: 0.128140 Train acc: 0.959202 Valid acc: 0.955122\n",
      "Epoch: 260/1000 Train loss: 0.122232 Valid loss: 0.129301 Train acc: 0.958976 Valid acc: 0.954669\n",
      "Epoch: 261/1000 Train loss: 0.121921 Valid loss: 0.127806 Train acc: 0.959882 Valid acc: 0.955576\n",
      "Epoch: 262/1000 Train loss: 0.121134 Valid loss: 0.125344 Train acc: 0.960109 Valid acc: 0.956936\n",
      "Epoch: 263/1000 Train loss: 0.120924 Valid loss: 0.124062 Train acc: 0.960109 Valid acc: 0.957389\n",
      "Epoch: 264/1000 Train loss: 0.120603 Valid loss: 0.123768 Train acc: 0.959429 Valid acc: 0.956936\n",
      "Epoch: 265/1000 Train loss: 0.120294 Valid loss: 0.124233 Train acc: 0.959882 Valid acc: 0.956482\n",
      "Epoch: 266/1000 Train loss: 0.119883 Valid loss: 0.125322 Train acc: 0.959429 Valid acc: 0.956029\n",
      "Epoch: 267/1000 Train loss: 0.119509 Valid loss: 0.126737 Train acc: 0.960109 Valid acc: 0.955576\n",
      "Epoch: 268/1000 Train loss: 0.119246 Valid loss: 0.127397 Train acc: 0.960109 Valid acc: 0.955576\n",
      "Epoch: 269/1000 Train loss: 0.118789 Valid loss: 0.127333 Train acc: 0.960109 Valid acc: 0.955576\n",
      "Epoch: 270/1000 Train loss: 0.118665 Valid loss: 0.126295 Train acc: 0.959656 Valid acc: 0.955122\n",
      "Epoch: 271/1000 Train loss: 0.117927 Valid loss: 0.125427 Train acc: 0.960335 Valid acc: 0.955122\n",
      "Epoch: 272/1000 Train loss: 0.118350 Valid loss: 0.124245 Train acc: 0.959882 Valid acc: 0.956029\n",
      "Epoch: 273/1000 Train loss: 0.117141 Valid loss: 0.124630 Train acc: 0.960789 Valid acc: 0.955122\n",
      "Epoch: 274/1000 Train loss: 0.117584 Valid loss: 0.128032 Train acc: 0.959429 Valid acc: 0.955576\n",
      "Epoch: 275/1000 Train loss: 0.116921 Valid loss: 0.130273 Train acc: 0.961015 Valid acc: 0.955122\n",
      "Epoch: 276/1000 Train loss: 0.117177 Valid loss: 0.127575 Train acc: 0.961242 Valid acc: 0.955122\n",
      "Epoch: 277/1000 Train loss: 0.117010 Valid loss: 0.129356 Train acc: 0.961242 Valid acc: 0.952403\n",
      "Epoch: 278/1000 Train loss: 0.117806 Valid loss: 0.128941 Train acc: 0.959882 Valid acc: 0.955122\n",
      "Epoch: 279/1000 Train loss: 0.117675 Valid loss: 0.127062 Train acc: 0.959882 Valid acc: 0.952856\n",
      "Epoch: 280/1000 Train loss: 0.116632 Valid loss: 0.132778 Train acc: 0.961015 Valid acc: 0.952403\n",
      "Epoch: 281/1000 Train loss: 0.120253 Valid loss: 0.126353 Train acc: 0.959429 Valid acc: 0.956029\n",
      "Epoch: 282/1000 Train loss: 0.117529 Valid loss: 0.129434 Train acc: 0.959429 Valid acc: 0.955576\n",
      "Epoch: 283/1000 Train loss: 0.119840 Valid loss: 0.127670 Train acc: 0.957616 Valid acc: 0.956936\n",
      "Epoch: 284/1000 Train loss: 0.119583 Valid loss: 0.131409 Train acc: 0.960109 Valid acc: 0.952403\n",
      "Epoch: 285/1000 Train loss: 0.120446 Valid loss: 0.132010 Train acc: 0.957162 Valid acc: 0.951949\n",
      "Epoch: 286/1000 Train loss: 0.119765 Valid loss: 0.131540 Train acc: 0.957389 Valid acc: 0.952403\n",
      "Epoch: 287/1000 Train loss: 0.119180 Valid loss: 0.131750 Train acc: 0.956029 Valid acc: 0.952856\n",
      "Epoch: 288/1000 Train loss: 0.119438 Valid loss: 0.129461 Train acc: 0.956256 Valid acc: 0.952856\n",
      "Epoch: 289/1000 Train loss: 0.117736 Valid loss: 0.127511 Train acc: 0.956936 Valid acc: 0.956482\n",
      "Epoch: 290/1000 Train loss: 0.116850 Valid loss: 0.129159 Train acc: 0.959655 Valid acc: 0.955576\n",
      "Epoch: 291/1000 Train loss: 0.117390 Valid loss: 0.130655 Train acc: 0.960335 Valid acc: 0.954669\n",
      "Epoch: 292/1000 Train loss: 0.116680 Valid loss: 0.130025 Train acc: 0.960562 Valid acc: 0.954669\n",
      "Epoch: 293/1000 Train loss: 0.116012 Valid loss: 0.128679 Train acc: 0.961242 Valid acc: 0.955122\n",
      "Epoch: 294/1000 Train loss: 0.114956 Valid loss: 0.128886 Train acc: 0.960109 Valid acc: 0.958296\n",
      "Epoch: 295/1000 Train loss: 0.123747 Valid loss: 0.144074 Train acc: 0.956936 Valid acc: 0.952856\n",
      "Epoch: 296/1000 Train loss: 0.186473 Valid loss: 0.189102 Train acc: 0.936763 Valid acc: 0.939257\n",
      "Epoch: 297/1000 Train loss: 0.238517 Valid loss: 0.244274 Train acc: 0.917951 Valid acc: 0.919764\n",
      "Epoch: 298/1000 Train loss: 0.275428 Valid loss: 0.254813 Train acc: 0.900045 Valid acc: 0.907525\n",
      "Epoch: 299/1000 Train loss: 0.262834 Valid loss: 0.223619 Train acc: 0.896872 Valid acc: 0.906618\n",
      "Epoch: 300/1000 Train loss: 0.223206 Valid loss: 0.182136 Train acc: 0.897779 Valid acc: 0.910245\n",
      "Epoch: 301/1000 Train loss: 0.176045 Valid loss: 0.155885 Train acc: 0.910018 Valid acc: 0.933817\n",
      "Epoch: 302/1000 Train loss: 0.145584 Valid loss: 0.134439 Train acc: 0.947190 Valid acc: 0.956482\n",
      "Epoch: 303/1000 Train loss: 0.124513 Valid loss: 0.124613 Train acc: 0.961015 Valid acc: 0.958296\n",
      "Epoch: 304/1000 Train loss: 0.120700 Valid loss: 0.125798 Train acc: 0.961695 Valid acc: 0.954669\n",
      "Epoch: 305/1000 Train loss: 0.128370 Valid loss: 0.131594 Train acc: 0.955802 Valid acc: 0.954216\n",
      "Epoch: 306/1000 Train loss: 0.137744 Valid loss: 0.125425 Train acc: 0.951043 Valid acc: 0.954669\n",
      "Epoch: 307/1000 Train loss: 0.130607 Valid loss: 0.133543 Train acc: 0.954896 Valid acc: 0.951949\n",
      "Epoch: 308/1000 Train loss: 0.136425 Valid loss: 0.124629 Train acc: 0.951949 Valid acc: 0.959655\n",
      "Epoch: 309/1000 Train loss: 0.122985 Valid loss: 0.127797 Train acc: 0.958749 Valid acc: 0.957389\n",
      "Epoch: 310/1000 Train loss: 0.126627 Valid loss: 0.123543 Train acc: 0.955349 Valid acc: 0.959655\n",
      "Epoch: 311/1000 Train loss: 0.121178 Valid loss: 0.129009 Train acc: 0.959429 Valid acc: 0.953309\n",
      "Epoch: 312/1000 Train loss: 0.126977 Valid loss: 0.127356 Train acc: 0.951949 Valid acc: 0.952856\n",
      "Epoch: 313/1000 Train loss: 0.123902 Valid loss: 0.121981 Train acc: 0.954896 Valid acc: 0.956936\n",
      "Epoch: 314/1000 Train loss: 0.123232 Valid loss: 0.124359 Train acc: 0.955349 Valid acc: 0.957389\n",
      "Epoch: 315/1000 Train loss: 0.124481 Valid loss: 0.122228 Train acc: 0.956256 Valid acc: 0.955122\n",
      "Epoch: 316/1000 Train loss: 0.120938 Valid loss: 0.122907 Train acc: 0.957162 Valid acc: 0.955122\n",
      "Epoch: 317/1000 Train loss: 0.122258 Valid loss: 0.121901 Train acc: 0.953989 Valid acc: 0.954669\n",
      "Epoch: 318/1000 Train loss: 0.118650 Valid loss: 0.122763 Train acc: 0.957162 Valid acc: 0.958749\n",
      "Epoch: 319/1000 Train loss: 0.118388 Valid loss: 0.125222 Train acc: 0.959429 Valid acc: 0.958296\n",
      "Epoch: 320/1000 Train loss: 0.118087 Valid loss: 0.121689 Train acc: 0.959882 Valid acc: 0.957842\n",
      "Epoch: 321/1000 Train loss: 0.116691 Valid loss: 0.119841 Train acc: 0.959202 Valid acc: 0.959655\n",
      "Epoch: 322/1000 Train loss: 0.116559 Valid loss: 0.118638 Train acc: 0.959655 Valid acc: 0.960109\n",
      "Epoch: 323/1000 Train loss: 0.116672 Valid loss: 0.123435 Train acc: 0.958522 Valid acc: 0.953309\n",
      "Epoch: 324/1000 Train loss: 0.119168 Valid loss: 0.123565 Train acc: 0.954442 Valid acc: 0.955576\n",
      "Epoch: 325/1000 Train loss: 0.121375 Valid loss: 0.130443 Train acc: 0.954442 Valid acc: 0.952403\n",
      "Epoch: 326/1000 Train loss: 0.132299 Valid loss: 0.121769 Train acc: 0.949229 Valid acc: 0.951949\n",
      "Epoch: 327/1000 Train loss: 0.126404 Valid loss: 0.121180 Train acc: 0.950136 Valid acc: 0.954216\n",
      "Epoch: 328/1000 Train loss: 0.128824 Valid loss: 0.122474 Train acc: 0.951496 Valid acc: 0.955122\n",
      "Epoch: 329/1000 Train loss: 0.128718 Valid loss: 0.122561 Train acc: 0.950816 Valid acc: 0.952403\n",
      "Epoch: 330/1000 Train loss: 0.125855 Valid loss: 0.118566 Train acc: 0.951043 Valid acc: 0.952856\n",
      "Epoch: 331/1000 Train loss: 0.125067 Valid loss: 0.117591 Train acc: 0.951949 Valid acc: 0.951949\n",
      "Epoch: 332/1000 Train loss: 0.124771 Valid loss: 0.117250 Train acc: 0.951496 Valid acc: 0.953762\n",
      "Epoch: 333/1000 Train loss: 0.123863 Valid loss: 0.115829 Train acc: 0.952856 Valid acc: 0.956029\n",
      "Epoch: 334/1000 Train loss: 0.121760 Valid loss: 0.113751 Train acc: 0.955122 Valid acc: 0.960109\n",
      "Epoch: 335/1000 Train loss: 0.120655 Valid loss: 0.113639 Train acc: 0.956256 Valid acc: 0.960109\n",
      "Epoch: 336/1000 Train loss: 0.119177 Valid loss: 0.113409 Train acc: 0.956936 Valid acc: 0.960562\n",
      "Epoch: 337/1000 Train loss: 0.117607 Valid loss: 0.115603 Train acc: 0.959429 Valid acc: 0.958749\n",
      "Epoch: 338/1000 Train loss: 0.117923 Valid loss: 0.114908 Train acc: 0.958749 Valid acc: 0.959202\n",
      "Epoch: 339/1000 Train loss: 0.116460 Valid loss: 0.113502 Train acc: 0.959882 Valid acc: 0.960109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340/1000 Train loss: 0.115046 Valid loss: 0.113832 Train acc: 0.958296 Valid acc: 0.960562\n",
      "Epoch: 341/1000 Train loss: 0.114346 Valid loss: 0.112411 Train acc: 0.957389 Valid acc: 0.960109\n",
      "Epoch: 342/1000 Train loss: 0.112988 Valid loss: 0.112540 Train acc: 0.959882 Valid acc: 0.961922\n",
      "Epoch: 343/1000 Train loss: 0.112302 Valid loss: 0.112204 Train acc: 0.961695 Valid acc: 0.961922\n",
      "Epoch: 344/1000 Train loss: 0.111154 Valid loss: 0.113638 Train acc: 0.960562 Valid acc: 0.960562\n",
      "Epoch: 345/1000 Train loss: 0.111237 Valid loss: 0.111703 Train acc: 0.960335 Valid acc: 0.962375\n",
      "Epoch: 346/1000 Train loss: 0.110602 Valid loss: 0.112148 Train acc: 0.962149 Valid acc: 0.961922\n",
      "Epoch: 347/1000 Train loss: 0.110762 Valid loss: 0.111406 Train acc: 0.962375 Valid acc: 0.962829\n",
      "Epoch: 348/1000 Train loss: 0.108694 Valid loss: 0.113810 Train acc: 0.963962 Valid acc: 0.959202\n",
      "Epoch: 349/1000 Train loss: 0.109956 Valid loss: 0.112211 Train acc: 0.961015 Valid acc: 0.959655\n",
      "Epoch: 350/1000 Train loss: 0.109178 Valid loss: 0.113584 Train acc: 0.962149 Valid acc: 0.960109\n",
      "Epoch: 351/1000 Train loss: 0.109590 Valid loss: 0.112431 Train acc: 0.961015 Valid acc: 0.961469\n",
      "Epoch: 352/1000 Train loss: 0.107432 Valid loss: 0.114380 Train acc: 0.962375 Valid acc: 0.957842\n",
      "Epoch: 353/1000 Train loss: 0.108094 Valid loss: 0.112200 Train acc: 0.963055 Valid acc: 0.960109\n",
      "Epoch: 354/1000 Train loss: 0.107437 Valid loss: 0.112822 Train acc: 0.962375 Valid acc: 0.961015\n",
      "Epoch: 355/1000 Train loss: 0.107198 Valid loss: 0.112281 Train acc: 0.962375 Valid acc: 0.961469\n",
      "Epoch: 356/1000 Train loss: 0.106395 Valid loss: 0.111903 Train acc: 0.963509 Valid acc: 0.960109\n",
      "Epoch: 357/1000 Train loss: 0.106695 Valid loss: 0.110758 Train acc: 0.963282 Valid acc: 0.961469\n",
      "Epoch: 358/1000 Train loss: 0.105988 Valid loss: 0.111351 Train acc: 0.963962 Valid acc: 0.960109\n",
      "Epoch: 359/1000 Train loss: 0.105926 Valid loss: 0.110675 Train acc: 0.963282 Valid acc: 0.961469\n",
      "Epoch: 360/1000 Train loss: 0.105720 Valid loss: 0.110609 Train acc: 0.963509 Valid acc: 0.960562\n",
      "Epoch: 361/1000 Train loss: 0.104910 Valid loss: 0.110947 Train acc: 0.964189 Valid acc: 0.960562\n",
      "Epoch: 362/1000 Train loss: 0.105259 Valid loss: 0.110659 Train acc: 0.963055 Valid acc: 0.960562\n",
      "Epoch: 363/1000 Train loss: 0.104622 Valid loss: 0.110640 Train acc: 0.964189 Valid acc: 0.960562\n",
      "Epoch: 364/1000 Train loss: 0.104430 Valid loss: 0.110791 Train acc: 0.963735 Valid acc: 0.960109\n",
      "Epoch: 365/1000 Train loss: 0.104402 Valid loss: 0.111364 Train acc: 0.963282 Valid acc: 0.960562\n",
      "Epoch: 366/1000 Train loss: 0.104476 Valid loss: 0.108793 Train acc: 0.963962 Valid acc: 0.961015\n",
      "Epoch: 367/1000 Train loss: 0.105777 Valid loss: 0.126085 Train acc: 0.963282 Valid acc: 0.958296\n",
      "Epoch: 368/1000 Train loss: 0.117032 Valid loss: 0.143509 Train acc: 0.960335 Valid acc: 0.954216\n",
      "Epoch: 369/1000 Train loss: 0.133109 Valid loss: 0.152655 Train acc: 0.956256 Valid acc: 0.950589\n",
      "Epoch: 370/1000 Train loss: 0.134400 Valid loss: 0.142028 Train acc: 0.955802 Valid acc: 0.952856\n",
      "Epoch: 371/1000 Train loss: 0.131756 Valid loss: 0.132671 Train acc: 0.956256 Valid acc: 0.955122\n",
      "Epoch: 372/1000 Train loss: 0.127893 Valid loss: 0.124628 Train acc: 0.956029 Valid acc: 0.957389\n",
      "Epoch: 373/1000 Train loss: 0.118556 Valid loss: 0.119251 Train acc: 0.958749 Valid acc: 0.957842\n",
      "Epoch: 374/1000 Train loss: 0.111637 Valid loss: 0.115279 Train acc: 0.961469 Valid acc: 0.958749\n",
      "Epoch: 375/1000 Train loss: 0.111565 Valid loss: 0.110684 Train acc: 0.961469 Valid acc: 0.959655\n",
      "Epoch: 376/1000 Train loss: 0.111650 Valid loss: 0.110076 Train acc: 0.961015 Valid acc: 0.960562\n",
      "Epoch: 377/1000 Train loss: 0.111138 Valid loss: 0.109175 Train acc: 0.961015 Valid acc: 0.961469\n",
      "Epoch: 378/1000 Train loss: 0.108449 Valid loss: 0.108763 Train acc: 0.961469 Valid acc: 0.960562\n",
      "Epoch: 379/1000 Train loss: 0.108022 Valid loss: 0.110412 Train acc: 0.962375 Valid acc: 0.960109\n",
      "Epoch: 380/1000 Train loss: 0.106584 Valid loss: 0.109150 Train acc: 0.962829 Valid acc: 0.960562\n",
      "Epoch: 381/1000 Train loss: 0.106042 Valid loss: 0.105276 Train acc: 0.963055 Valid acc: 0.961015\n",
      "Epoch: 382/1000 Train loss: 0.104563 Valid loss: 0.105781 Train acc: 0.963509 Valid acc: 0.961469\n",
      "Epoch: 383/1000 Train loss: 0.104331 Valid loss: 0.104670 Train acc: 0.963509 Valid acc: 0.962375\n",
      "Epoch: 384/1000 Train loss: 0.103746 Valid loss: 0.105357 Train acc: 0.963962 Valid acc: 0.961922\n",
      "Epoch: 385/1000 Train loss: 0.103494 Valid loss: 0.105133 Train acc: 0.964869 Valid acc: 0.961469\n",
      "Epoch: 386/1000 Train loss: 0.103028 Valid loss: 0.105888 Train acc: 0.964642 Valid acc: 0.961469\n",
      "Epoch: 387/1000 Train loss: 0.102807 Valid loss: 0.105976 Train acc: 0.964189 Valid acc: 0.961469\n",
      "Epoch: 388/1000 Train loss: 0.102615 Valid loss: 0.105845 Train acc: 0.964189 Valid acc: 0.962375\n",
      "Epoch: 389/1000 Train loss: 0.102320 Valid loss: 0.105808 Train acc: 0.964415 Valid acc: 0.962375\n",
      "Epoch: 390/1000 Train loss: 0.102163 Valid loss: 0.105583 Train acc: 0.963962 Valid acc: 0.962829\n",
      "Epoch: 391/1000 Train loss: 0.101779 Valid loss: 0.105763 Train acc: 0.964415 Valid acc: 0.961469\n",
      "Epoch: 392/1000 Train loss: 0.101557 Valid loss: 0.105831 Train acc: 0.963962 Valid acc: 0.961015\n",
      "Epoch: 393/1000 Train loss: 0.101346 Valid loss: 0.105990 Train acc: 0.964189 Valid acc: 0.961015\n",
      "Epoch: 394/1000 Train loss: 0.101082 Valid loss: 0.106097 Train acc: 0.964189 Valid acc: 0.961469\n",
      "Epoch: 395/1000 Train loss: 0.100823 Valid loss: 0.106178 Train acc: 0.964415 Valid acc: 0.961015\n",
      "Epoch: 396/1000 Train loss: 0.100522 Valid loss: 0.106087 Train acc: 0.964642 Valid acc: 0.960109\n",
      "Epoch: 397/1000 Train loss: 0.100307 Valid loss: 0.105629 Train acc: 0.964642 Valid acc: 0.961015\n",
      "Epoch: 398/1000 Train loss: 0.100103 Valid loss: 0.105473 Train acc: 0.964642 Valid acc: 0.961469\n",
      "Epoch: 399/1000 Train loss: 0.099908 Valid loss: 0.105281 Train acc: 0.964189 Valid acc: 0.961469\n",
      "Epoch: 400/1000 Train loss: 0.099702 Valid loss: 0.105140 Train acc: 0.964189 Valid acc: 0.961015\n",
      "Epoch: 401/1000 Train loss: 0.099477 Valid loss: 0.105066 Train acc: 0.964189 Valid acc: 0.961015\n",
      "Epoch: 402/1000 Train loss: 0.098793 Valid loss: 0.105110 Train acc: 0.964415 Valid acc: 0.959655\n",
      "Epoch: 403/1000 Train loss: 0.098680 Valid loss: 0.105156 Train acc: 0.964642 Valid acc: 0.959655\n",
      "Epoch: 404/1000 Train loss: 0.098539 Valid loss: 0.105211 Train acc: 0.964642 Valid acc: 0.960109\n",
      "Epoch: 405/1000 Train loss: 0.098382 Valid loss: 0.105231 Train acc: 0.964642 Valid acc: 0.960562\n",
      "Epoch: 406/1000 Train loss: 0.098231 Valid loss: 0.105217 Train acc: 0.964415 Valid acc: 0.960562\n",
      "Epoch: 407/1000 Train loss: 0.098090 Valid loss: 0.105047 Train acc: 0.964642 Valid acc: 0.960562\n",
      "Epoch: 408/1000 Train loss: 0.097945 Valid loss: 0.104852 Train acc: 0.964415 Valid acc: 0.961015\n",
      "Epoch: 409/1000 Train loss: 0.097814 Valid loss: 0.104648 Train acc: 0.964189 Valid acc: 0.961469\n",
      "Epoch: 410/1000 Train loss: 0.097681 Valid loss: 0.104615 Train acc: 0.964415 Valid acc: 0.961469\n",
      "Epoch: 411/1000 Train loss: 0.097577 Valid loss: 0.104560 Train acc: 0.964189 Valid acc: 0.961922\n",
      "Epoch: 412/1000 Train loss: 0.097435 Valid loss: 0.104602 Train acc: 0.964415 Valid acc: 0.961469\n",
      "Epoch: 413/1000 Train loss: 0.097286 Valid loss: 0.104667 Train acc: 0.964415 Valid acc: 0.961469\n",
      "Epoch: 414/1000 Train loss: 0.097190 Valid loss: 0.104718 Train acc: 0.963962 Valid acc: 0.961469\n",
      "Epoch: 415/1000 Train loss: 0.097060 Valid loss: 0.104769 Train acc: 0.964189 Valid acc: 0.961015\n",
      "Epoch: 416/1000 Train loss: 0.096941 Valid loss: 0.104791 Train acc: 0.963962 Valid acc: 0.961469\n",
      "Epoch: 417/1000 Train loss: 0.096785 Valid loss: 0.104896 Train acc: 0.963962 Valid acc: 0.960562\n",
      "Epoch: 418/1000 Train loss: 0.096680 Valid loss: 0.104995 Train acc: 0.963962 Valid acc: 0.961015\n",
      "Epoch: 419/1000 Train loss: 0.096571 Valid loss: 0.105114 Train acc: 0.964189 Valid acc: 0.960562\n",
      "Epoch: 420/1000 Train loss: 0.096492 Valid loss: 0.105170 Train acc: 0.964415 Valid acc: 0.961015\n",
      "Epoch: 421/1000 Train loss: 0.096301 Valid loss: 0.105264 Train acc: 0.964189 Valid acc: 0.961469\n",
      "Epoch: 422/1000 Train loss: 0.096174 Valid loss: 0.105266 Train acc: 0.963735 Valid acc: 0.961469\n",
      "Epoch: 423/1000 Train loss: 0.096014 Valid loss: 0.105275 Train acc: 0.963962 Valid acc: 0.961469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 424/1000 Train loss: 0.095853 Valid loss: 0.105304 Train acc: 0.963962 Valid acc: 0.961469\n",
      "Epoch: 425/1000 Train loss: 0.095719 Valid loss: 0.105450 Train acc: 0.963962 Valid acc: 0.960562\n",
      "Epoch: 426/1000 Train loss: 0.095656 Valid loss: 0.105428 Train acc: 0.963735 Valid acc: 0.961015\n",
      "Epoch: 427/1000 Train loss: 0.095503 Valid loss: 0.105478 Train acc: 0.963962 Valid acc: 0.961015\n",
      "Epoch: 428/1000 Train loss: 0.095391 Valid loss: 0.105468 Train acc: 0.963962 Valid acc: 0.961469\n",
      "Epoch: 429/1000 Train loss: 0.095273 Valid loss: 0.105511 Train acc: 0.963962 Valid acc: 0.960562\n",
      "Epoch: 430/1000 Train loss: 0.095199 Valid loss: 0.105497 Train acc: 0.963962 Valid acc: 0.961015\n",
      "Epoch: 431/1000 Train loss: 0.095089 Valid loss: 0.105515 Train acc: 0.963962 Valid acc: 0.961015\n",
      "Epoch: 432/1000 Train loss: 0.094981 Valid loss: 0.105529 Train acc: 0.963962 Valid acc: 0.960562\n",
      "Epoch: 433/1000 Train loss: 0.094877 Valid loss: 0.105558 Train acc: 0.963962 Valid acc: 0.960562\n",
      "Epoch: 434/1000 Train loss: 0.094810 Valid loss: 0.105534 Train acc: 0.963962 Valid acc: 0.960109\n",
      "Epoch: 435/1000 Train loss: 0.094696 Valid loss: 0.105544 Train acc: 0.963962 Valid acc: 0.960109\n",
      "Epoch: 436/1000 Train loss: 0.094595 Valid loss: 0.105555 Train acc: 0.963962 Valid acc: 0.960562\n",
      "Epoch: 437/1000 Train loss: 0.094482 Valid loss: 0.105608 Train acc: 0.964189 Valid acc: 0.960109\n",
      "Epoch: 438/1000 Train loss: 0.094405 Valid loss: 0.105680 Train acc: 0.964189 Valid acc: 0.960109\n",
      "Epoch: 439/1000 Train loss: 0.094297 Valid loss: 0.105770 Train acc: 0.964189 Valid acc: 0.960562\n",
      "Epoch: 440/1000 Train loss: 0.094193 Valid loss: 0.105861 Train acc: 0.964189 Valid acc: 0.960562\n",
      "Epoch: 441/1000 Train loss: 0.094104 Valid loss: 0.105944 Train acc: 0.964189 Valid acc: 0.960562\n",
      "Epoch: 442/1000 Train loss: 0.094022 Valid loss: 0.106017 Train acc: 0.964189 Valid acc: 0.960562\n",
      "Epoch: 443/1000 Train loss: 0.093942 Valid loss: 0.106077 Train acc: 0.963962 Valid acc: 0.961015\n",
      "Epoch: 444/1000 Train loss: 0.093842 Valid loss: 0.106133 Train acc: 0.963962 Valid acc: 0.960562\n",
      "Epoch: 445/1000 Train loss: 0.093756 Valid loss: 0.106170 Train acc: 0.963962 Valid acc: 0.960562\n",
      "Epoch: 446/1000 Train loss: 0.093676 Valid loss: 0.106177 Train acc: 0.963735 Valid acc: 0.960562\n",
      "Epoch: 447/1000 Train loss: 0.093597 Valid loss: 0.107389 Train acc: 0.963962 Valid acc: 0.960562\n",
      "Epoch: 448/1000 Train loss: 0.093532 Valid loss: 0.108293 Train acc: 0.964189 Valid acc: 0.960562\n",
      "Epoch: 449/1000 Train loss: 0.094441 Valid loss: 0.108616 Train acc: 0.964415 Valid acc: 0.960562\n",
      "Epoch: 450/1000 Train loss: 0.094397 Valid loss: 0.108713 Train acc: 0.964189 Valid acc: 0.960562\n",
      "Epoch: 451/1000 Train loss: 0.094311 Valid loss: 0.108693 Train acc: 0.963962 Valid acc: 0.961015\n",
      "Epoch: 452/1000 Train loss: 0.094218 Valid loss: 0.108642 Train acc: 0.963962 Valid acc: 0.960109\n",
      "Epoch: 453/1000 Train loss: 0.094183 Valid loss: 0.108513 Train acc: 0.963735 Valid acc: 0.959655\n",
      "Epoch: 454/1000 Train loss: 0.094062 Valid loss: 0.108360 Train acc: 0.963962 Valid acc: 0.960562\n",
      "Epoch: 455/1000 Train loss: 0.093965 Valid loss: 0.108282 Train acc: 0.963735 Valid acc: 0.959655\n",
      "Epoch: 456/1000 Train loss: 0.093947 Valid loss: 0.108129 Train acc: 0.963509 Valid acc: 0.959655\n",
      "Epoch: 457/1000 Train loss: 0.093782 Valid loss: 0.108052 Train acc: 0.964415 Valid acc: 0.959655\n",
      "Epoch: 458/1000 Train loss: 0.093677 Valid loss: 0.108106 Train acc: 0.963735 Valid acc: 0.960562\n",
      "Epoch: 459/1000 Train loss: 0.094111 Valid loss: 0.109186 Train acc: 0.963962 Valid acc: 0.959655\n",
      "Epoch: 460/1000 Train loss: 0.095304 Valid loss: 0.111151 Train acc: 0.963962 Valid acc: 0.957842\n",
      "Epoch: 461/1000 Train loss: 0.094844 Valid loss: 0.114623 Train acc: 0.963735 Valid acc: 0.957389\n",
      "Epoch: 462/1000 Train loss: 0.095978 Valid loss: 0.117815 Train acc: 0.963735 Valid acc: 0.956482\n",
      "Epoch: 463/1000 Train loss: 0.097825 Valid loss: 0.113818 Train acc: 0.962602 Valid acc: 0.958296\n",
      "Epoch: 464/1000 Train loss: 0.096664 Valid loss: 0.114571 Train acc: 0.961695 Valid acc: 0.956482\n",
      "Epoch: 465/1000 Train loss: 0.097435 Valid loss: 0.112493 Train acc: 0.962829 Valid acc: 0.957842\n",
      "Epoch: 466/1000 Train loss: 0.095641 Valid loss: 0.113629 Train acc: 0.961922 Valid acc: 0.956482\n",
      "Epoch: 467/1000 Train loss: 0.097374 Valid loss: 0.110658 Train acc: 0.962149 Valid acc: 0.959202\n",
      "Epoch: 468/1000 Train loss: 0.097189 Valid loss: 0.113743 Train acc: 0.961469 Valid acc: 0.956482\n",
      "Epoch: 469/1000 Train loss: 0.096572 Valid loss: 0.109529 Train acc: 0.962375 Valid acc: 0.957389\n",
      "Epoch: 470/1000 Train loss: 0.095967 Valid loss: 0.108170 Train acc: 0.962602 Valid acc: 0.961469\n",
      "Epoch: 471/1000 Train loss: 0.094398 Valid loss: 0.110784 Train acc: 0.962829 Valid acc: 0.957389\n",
      "Epoch: 472/1000 Train loss: 0.094431 Valid loss: 0.107436 Train acc: 0.963282 Valid acc: 0.959202\n",
      "Epoch: 473/1000 Train loss: 0.093945 Valid loss: 0.108349 Train acc: 0.963509 Valid acc: 0.958296\n",
      "Epoch: 474/1000 Train loss: 0.093195 Valid loss: 0.106729 Train acc: 0.963735 Valid acc: 0.959202\n",
      "Epoch: 475/1000 Train loss: 0.093145 Valid loss: 0.105452 Train acc: 0.963055 Valid acc: 0.961015\n",
      "Epoch: 476/1000 Train loss: 0.093172 Valid loss: 0.105314 Train acc: 0.964642 Valid acc: 0.960562\n",
      "Epoch: 477/1000 Train loss: 0.092352 Valid loss: 0.105167 Train acc: 0.963962 Valid acc: 0.959655\n",
      "Epoch: 478/1000 Train loss: 0.092390 Valid loss: 0.103596 Train acc: 0.963509 Valid acc: 0.960109\n",
      "Epoch: 479/1000 Train loss: 0.092322 Valid loss: 0.103424 Train acc: 0.965095 Valid acc: 0.959655\n",
      "Epoch: 480/1000 Train loss: 0.092040 Valid loss: 0.104060 Train acc: 0.964869 Valid acc: 0.959655\n",
      "Epoch: 481/1000 Train loss: 0.091594 Valid loss: 0.104894 Train acc: 0.964189 Valid acc: 0.959655\n",
      "Epoch: 482/1000 Train loss: 0.091685 Valid loss: 0.103677 Train acc: 0.964189 Valid acc: 0.961015\n",
      "Epoch: 483/1000 Train loss: 0.091307 Valid loss: 0.104670 Train acc: 0.964415 Valid acc: 0.960562\n",
      "Epoch: 484/1000 Train loss: 0.091804 Valid loss: 0.103537 Train acc: 0.964189 Valid acc: 0.960562\n",
      "Epoch: 485/1000 Train loss: 0.091448 Valid loss: 0.105585 Train acc: 0.963735 Valid acc: 0.961469\n",
      "Epoch: 486/1000 Train loss: 0.092203 Valid loss: 0.103666 Train acc: 0.964415 Valid acc: 0.961015\n",
      "Epoch: 487/1000 Train loss: 0.092340 Valid loss: 0.104782 Train acc: 0.963735 Valid acc: 0.961469\n",
      "Epoch: 488/1000 Train loss: 0.091718 Valid loss: 0.103549 Train acc: 0.963735 Valid acc: 0.961922\n",
      "Epoch: 489/1000 Train loss: 0.091868 Valid loss: 0.104339 Train acc: 0.964415 Valid acc: 0.962375\n",
      "Epoch: 490/1000 Train loss: 0.091768 Valid loss: 0.105489 Train acc: 0.965095 Valid acc: 0.960562\n",
      "Epoch: 491/1000 Train loss: 0.091554 Valid loss: 0.106010 Train acc: 0.964415 Valid acc: 0.959655\n",
      "Epoch: 492/1000 Train loss: 0.090870 Valid loss: 0.107087 Train acc: 0.964642 Valid acc: 0.961015\n",
      "Epoch: 493/1000 Train loss: 0.091410 Valid loss: 0.105814 Train acc: 0.964415 Valid acc: 0.960562\n",
      "Epoch: 494/1000 Train loss: 0.091380 Valid loss: 0.135202 Train acc: 0.964642 Valid acc: 0.955576\n",
      "Epoch: 495/1000 Train loss: 0.123436 Valid loss: 0.139500 Train acc: 0.958069 Valid acc: 0.952856\n",
      "Epoch: 496/1000 Train loss: 0.110713 Valid loss: 0.121725 Train acc: 0.960109 Valid acc: 0.957389\n",
      "Epoch: 497/1000 Train loss: 0.103898 Valid loss: 0.111016 Train acc: 0.960562 Valid acc: 0.957842\n",
      "Epoch: 498/1000 Train loss: 0.108340 Valid loss: 0.119333 Train acc: 0.957842 Valid acc: 0.955122\n",
      "Epoch: 499/1000 Train loss: 0.111561 Valid loss: 0.119190 Train acc: 0.958749 Valid acc: 0.955576\n",
      "Epoch: 500/1000 Train loss: 0.108623 Valid loss: 0.116388 Train acc: 0.959202 Valid acc: 0.958749\n",
      "Epoch: 501/1000 Train loss: 0.106570 Valid loss: 0.118684 Train acc: 0.959429 Valid acc: 0.956482\n",
      "Epoch: 502/1000 Train loss: 0.107981 Valid loss: 0.115106 Train acc: 0.958069 Valid acc: 0.956936\n",
      "Epoch: 503/1000 Train loss: 0.104825 Valid loss: 0.113712 Train acc: 0.960109 Valid acc: 0.959202\n",
      "Epoch: 504/1000 Train loss: 0.103464 Valid loss: 0.110550 Train acc: 0.961242 Valid acc: 0.958296\n",
      "Epoch: 505/1000 Train loss: 0.098372 Valid loss: 0.110490 Train acc: 0.962375 Valid acc: 0.958749\n",
      "Epoch: 506/1000 Train loss: 0.098278 Valid loss: 0.109843 Train acc: 0.962149 Valid acc: 0.957842\n",
      "Epoch: 507/1000 Train loss: 0.097288 Valid loss: 0.110338 Train acc: 0.962829 Valid acc: 0.957842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 508/1000 Train loss: 0.096784 Valid loss: 0.110028 Train acc: 0.962375 Valid acc: 0.957389\n",
      "Epoch: 509/1000 Train loss: 0.095945 Valid loss: 0.110561 Train acc: 0.963055 Valid acc: 0.959655\n",
      "Epoch: 510/1000 Train loss: 0.095978 Valid loss: 0.108727 Train acc: 0.963055 Valid acc: 0.958296\n",
      "Epoch: 511/1000 Train loss: 0.095106 Valid loss: 0.109951 Train acc: 0.963735 Valid acc: 0.959202\n",
      "Epoch: 512/1000 Train loss: 0.095695 Valid loss: 0.107259 Train acc: 0.963509 Valid acc: 0.958749\n",
      "Epoch: 513/1000 Train loss: 0.094481 Valid loss: 0.109424 Train acc: 0.963962 Valid acc: 0.960109\n",
      "Epoch: 514/1000 Train loss: 0.094989 Valid loss: 0.106433 Train acc: 0.963735 Valid acc: 0.959655\n",
      "Epoch: 515/1000 Train loss: 0.094073 Valid loss: 0.107898 Train acc: 0.964415 Valid acc: 0.960109\n",
      "Epoch: 516/1000 Train loss: 0.094203 Valid loss: 0.105589 Train acc: 0.963735 Valid acc: 0.959202\n",
      "Epoch: 517/1000 Train loss: 0.091931 Valid loss: 0.107374 Train acc: 0.964642 Valid acc: 0.960562\n",
      "Epoch: 518/1000 Train loss: 0.092304 Valid loss: 0.106198 Train acc: 0.964415 Valid acc: 0.959655\n",
      "Epoch: 519/1000 Train loss: 0.091569 Valid loss: 0.107502 Train acc: 0.964415 Valid acc: 0.960109\n",
      "Epoch: 520/1000 Train loss: 0.092012 Valid loss: 0.106044 Train acc: 0.964415 Valid acc: 0.958749\n",
      "Epoch: 521/1000 Train loss: 0.091177 Valid loss: 0.107707 Train acc: 0.964642 Valid acc: 0.960562\n",
      "Epoch: 522/1000 Train loss: 0.091407 Valid loss: 0.107234 Train acc: 0.963735 Valid acc: 0.959655\n",
      "Epoch: 523/1000 Train loss: 0.090814 Valid loss: 0.109409 Train acc: 0.964642 Valid acc: 0.960109\n",
      "Epoch: 524/1000 Train loss: 0.091326 Valid loss: 0.108306 Train acc: 0.964642 Valid acc: 0.960562\n",
      "Epoch: 525/1000 Train loss: 0.090601 Valid loss: 0.108914 Train acc: 0.964642 Valid acc: 0.960562\n",
      "Epoch: 526/1000 Train loss: 0.090618 Valid loss: 0.109135 Train acc: 0.964415 Valid acc: 0.960562\n",
      "Epoch: 527/1000 Train loss: 0.090303 Valid loss: 0.109750 Train acc: 0.964415 Valid acc: 0.961015\n",
      "Epoch: 528/1000 Train loss: 0.090357 Valid loss: 0.110336 Train acc: 0.964869 Valid acc: 0.960562\n",
      "Epoch: 529/1000 Train loss: 0.090210 Valid loss: 0.110381 Train acc: 0.964415 Valid acc: 0.960109\n",
      "Epoch: 530/1000 Train loss: 0.089977 Valid loss: 0.110972 Train acc: 0.964869 Valid acc: 0.960562\n",
      "Epoch: 531/1000 Train loss: 0.090002 Valid loss: 0.111005 Train acc: 0.964642 Valid acc: 0.960562\n",
      "Epoch: 532/1000 Train loss: 0.089804 Valid loss: 0.111098 Train acc: 0.965095 Valid acc: 0.960109\n",
      "Epoch: 533/1000 Train loss: 0.089729 Valid loss: 0.111218 Train acc: 0.964642 Valid acc: 0.960562\n",
      "Epoch: 534/1000 Train loss: 0.089620 Valid loss: 0.111145 Train acc: 0.964642 Valid acc: 0.960562\n",
      "Epoch: 535/1000 Train loss: 0.089469 Valid loss: 0.111885 Train acc: 0.964869 Valid acc: 0.960109\n",
      "Epoch: 536/1000 Train loss: 0.089426 Valid loss: 0.111785 Train acc: 0.965322 Valid acc: 0.959655\n",
      "Epoch: 537/1000 Train loss: 0.089281 Valid loss: 0.111744 Train acc: 0.966002 Valid acc: 0.960109\n",
      "Epoch: 538/1000 Train loss: 0.089193 Valid loss: 0.111928 Train acc: 0.966228 Valid acc: 0.960109\n",
      "Epoch: 539/1000 Train loss: 0.089167 Valid loss: 0.111804 Train acc: 0.966455 Valid acc: 0.959655\n",
      "Epoch: 540/1000 Train loss: 0.089022 Valid loss: 0.111887 Train acc: 0.966228 Valid acc: 0.960109\n",
      "Epoch: 541/1000 Train loss: 0.088998 Valid loss: 0.111658 Train acc: 0.966455 Valid acc: 0.959655\n",
      "Epoch: 542/1000 Train loss: 0.088892 Valid loss: 0.111024 Train acc: 0.966908 Valid acc: 0.959655\n",
      "Epoch: 543/1000 Train loss: 0.088824 Valid loss: 0.110543 Train acc: 0.966682 Valid acc: 0.960109\n",
      "Epoch: 544/1000 Train loss: 0.088754 Valid loss: 0.109927 Train acc: 0.966455 Valid acc: 0.959655\n",
      "Epoch: 545/1000 Train loss: 0.088628 Valid loss: 0.109274 Train acc: 0.967135 Valid acc: 0.959655\n",
      "Epoch: 546/1000 Train loss: 0.088561 Valid loss: 0.108599 Train acc: 0.966682 Valid acc: 0.960109\n",
      "Epoch: 547/1000 Train loss: 0.088466 Valid loss: 0.108399 Train acc: 0.966682 Valid acc: 0.959655\n",
      "Epoch: 548/1000 Train loss: 0.088371 Valid loss: 0.109778 Train acc: 0.966682 Valid acc: 0.959655\n",
      "Epoch: 549/1000 Train loss: 0.088295 Valid loss: 0.110267 Train acc: 0.966455 Valid acc: 0.959202\n",
      "Epoch: 550/1000 Train loss: 0.088210 Valid loss: 0.110483 Train acc: 0.966228 Valid acc: 0.959202\n",
      "Epoch: 551/1000 Train loss: 0.088124 Valid loss: 0.110631 Train acc: 0.966455 Valid acc: 0.959202\n",
      "Epoch: 552/1000 Train loss: 0.088045 Valid loss: 0.110705 Train acc: 0.966455 Valid acc: 0.959202\n",
      "Epoch: 553/1000 Train loss: 0.087961 Valid loss: 0.110759 Train acc: 0.966228 Valid acc: 0.959202\n",
      "Epoch: 554/1000 Train loss: 0.087884 Valid loss: 0.110825 Train acc: 0.966682 Valid acc: 0.960109\n",
      "Epoch: 555/1000 Train loss: 0.087814 Valid loss: 0.110864 Train acc: 0.966682 Valid acc: 0.960109\n",
      "Epoch: 556/1000 Train loss: 0.087750 Valid loss: 0.110893 Train acc: 0.966682 Valid acc: 0.960109\n",
      "Epoch: 557/1000 Train loss: 0.087678 Valid loss: 0.110917 Train acc: 0.966908 Valid acc: 0.960109\n",
      "Epoch: 558/1000 Train loss: 0.087612 Valid loss: 0.110914 Train acc: 0.966908 Valid acc: 0.959655\n",
      "Epoch: 559/1000 Train loss: 0.087542 Valid loss: 0.110901 Train acc: 0.966682 Valid acc: 0.959655\n",
      "Epoch: 560/1000 Train loss: 0.087475 Valid loss: 0.110887 Train acc: 0.966682 Valid acc: 0.959655\n",
      "Epoch: 561/1000 Train loss: 0.087408 Valid loss: 0.110872 Train acc: 0.966682 Valid acc: 0.959655\n",
      "Epoch: 562/1000 Train loss: 0.087333 Valid loss: 0.110873 Train acc: 0.966682 Valid acc: 0.959655\n",
      "Epoch: 563/1000 Train loss: 0.087259 Valid loss: 0.110912 Train acc: 0.966682 Valid acc: 0.959202\n",
      "Epoch: 564/1000 Train loss: 0.087167 Valid loss: 0.116292 Train acc: 0.966455 Valid acc: 0.959202\n",
      "Epoch: 565/1000 Train loss: 0.091221 Valid loss: 0.121067 Train acc: 0.965095 Valid acc: 0.957389\n",
      "Epoch: 566/1000 Train loss: 0.099926 Valid loss: 0.123844 Train acc: 0.963055 Valid acc: 0.956482\n",
      "Epoch: 567/1000 Train loss: 0.098938 Valid loss: 0.121448 Train acc: 0.963509 Valid acc: 0.957389\n",
      "Epoch: 568/1000 Train loss: 0.096149 Valid loss: 0.116117 Train acc: 0.964189 Valid acc: 0.960109\n",
      "Epoch: 569/1000 Train loss: 0.094048 Valid loss: 0.113853 Train acc: 0.964869 Valid acc: 0.959655\n",
      "Epoch: 570/1000 Train loss: 0.090702 Valid loss: 0.111909 Train acc: 0.965322 Valid acc: 0.961015\n",
      "Epoch: 571/1000 Train loss: 0.090637 Valid loss: 0.108459 Train acc: 0.965549 Valid acc: 0.960562\n",
      "Epoch: 572/1000 Train loss: 0.089456 Valid loss: 0.104351 Train acc: 0.965549 Valid acc: 0.960109\n",
      "Epoch: 573/1000 Train loss: 0.089434 Valid loss: 0.103911 Train acc: 0.966002 Valid acc: 0.961015\n",
      "Epoch: 574/1000 Train loss: 0.088750 Valid loss: 0.103810 Train acc: 0.966002 Valid acc: 0.962375\n",
      "Epoch: 575/1000 Train loss: 0.088148 Valid loss: 0.103287 Train acc: 0.965549 Valid acc: 0.961015\n",
      "Epoch: 576/1000 Train loss: 0.087642 Valid loss: 0.104431 Train acc: 0.966908 Valid acc: 0.963282\n",
      "Epoch: 577/1000 Train loss: 0.087484 Valid loss: 0.105897 Train acc: 0.966455 Valid acc: 0.963282\n",
      "Epoch: 578/1000 Train loss: 0.087324 Valid loss: 0.105672 Train acc: 0.966002 Valid acc: 0.961922\n",
      "Epoch: 579/1000 Train loss: 0.086830 Valid loss: 0.106294 Train acc: 0.966002 Valid acc: 0.963735\n",
      "Epoch: 580/1000 Train loss: 0.087103 Valid loss: 0.106197 Train acc: 0.966228 Valid acc: 0.963282\n",
      "Epoch: 581/1000 Train loss: 0.086767 Valid loss: 0.105064 Train acc: 0.965549 Valid acc: 0.961922\n",
      "Epoch: 582/1000 Train loss: 0.086713 Valid loss: 0.105540 Train acc: 0.966002 Valid acc: 0.964189\n",
      "Epoch: 583/1000 Train loss: 0.086824 Valid loss: 0.105218 Train acc: 0.966682 Valid acc: 0.964189\n",
      "Epoch: 584/1000 Train loss: 0.086374 Valid loss: 0.105395 Train acc: 0.966908 Valid acc: 0.963735\n",
      "Epoch: 585/1000 Train loss: 0.086997 Valid loss: 0.105960 Train acc: 0.967362 Valid acc: 0.963735\n",
      "Epoch: 586/1000 Train loss: 0.086519 Valid loss: 0.108177 Train acc: 0.967362 Valid acc: 0.964642\n",
      "Epoch: 587/1000 Train loss: 0.086343 Valid loss: 0.107889 Train acc: 0.966908 Valid acc: 0.962829\n",
      "Epoch: 588/1000 Train loss: 0.086043 Valid loss: 0.109451 Train acc: 0.966682 Valid acc: 0.963735\n",
      "Epoch: 589/1000 Train loss: 0.086354 Valid loss: 0.108464 Train acc: 0.968042 Valid acc: 0.963735\n",
      "Epoch: 590/1000 Train loss: 0.085827 Valid loss: 0.108602 Train acc: 0.967588 Valid acc: 0.963735\n",
      "Epoch: 591/1000 Train loss: 0.085631 Valid loss: 0.109386 Train acc: 0.968495 Valid acc: 0.963735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 592/1000 Train loss: 0.085640 Valid loss: 0.108863 Train acc: 0.968948 Valid acc: 0.962829\n",
      "Epoch: 593/1000 Train loss: 0.085718 Valid loss: 0.108739 Train acc: 0.968722 Valid acc: 0.963282\n",
      "Epoch: 594/1000 Train loss: 0.085461 Valid loss: 0.109231 Train acc: 0.968268 Valid acc: 0.963282\n",
      "Epoch: 595/1000 Train loss: 0.085315 Valid loss: 0.108630 Train acc: 0.968042 Valid acc: 0.962829\n",
      "Epoch: 596/1000 Train loss: 0.085224 Valid loss: 0.109429 Train acc: 0.968722 Valid acc: 0.963282\n",
      "Epoch: 597/1000 Train loss: 0.085403 Valid loss: 0.108929 Train acc: 0.968042 Valid acc: 0.963282\n",
      "Epoch: 598/1000 Train loss: 0.085119 Valid loss: 0.108529 Train acc: 0.968042 Valid acc: 0.963282\n",
      "Epoch: 599/1000 Train loss: 0.084982 Valid loss: 0.109490 Train acc: 0.967815 Valid acc: 0.964189\n",
      "Epoch: 600/1000 Train loss: 0.085053 Valid loss: 0.109534 Train acc: 0.968268 Valid acc: 0.962829\n",
      "Epoch: 601/1000 Train loss: 0.085019 Valid loss: 0.109287 Train acc: 0.968495 Valid acc: 0.962829\n",
      "Epoch: 602/1000 Train loss: 0.085096 Valid loss: 0.109443 Train acc: 0.968722 Valid acc: 0.963735\n",
      "Epoch: 603/1000 Train loss: 0.084830 Valid loss: 0.110380 Train acc: 0.967815 Valid acc: 0.962375\n",
      "Epoch: 604/1000 Train loss: 0.084807 Valid loss: 0.109471 Train acc: 0.967362 Valid acc: 0.961922\n",
      "Epoch: 605/1000 Train loss: 0.084893 Valid loss: 0.109681 Train acc: 0.968268 Valid acc: 0.963282\n",
      "Epoch: 606/1000 Train loss: 0.084946 Valid loss: 0.110582 Train acc: 0.968042 Valid acc: 0.961922\n",
      "Epoch: 607/1000 Train loss: 0.084896 Valid loss: 0.109430 Train acc: 0.967815 Valid acc: 0.961922\n",
      "Epoch: 608/1000 Train loss: 0.086981 Valid loss: 0.109846 Train acc: 0.967135 Valid acc: 0.959655\n",
      "Epoch: 609/1000 Train loss: 0.087228 Valid loss: 0.110832 Train acc: 0.967815 Valid acc: 0.960562\n",
      "Epoch: 610/1000 Train loss: 0.087590 Valid loss: 0.111027 Train acc: 0.965775 Valid acc: 0.961015\n",
      "Epoch: 611/1000 Train loss: 0.086055 Valid loss: 0.111493 Train acc: 0.968948 Valid acc: 0.961922\n",
      "Epoch: 612/1000 Train loss: 0.086911 Valid loss: 0.109677 Train acc: 0.967135 Valid acc: 0.961922\n",
      "Epoch: 613/1000 Train loss: 0.085190 Valid loss: 0.109444 Train acc: 0.967815 Valid acc: 0.962375\n",
      "Epoch: 614/1000 Train loss: 0.085929 Valid loss: 0.109340 Train acc: 0.967815 Valid acc: 0.962375\n",
      "Epoch: 615/1000 Train loss: 0.084883 Valid loss: 0.108758 Train acc: 0.968495 Valid acc: 0.962375\n",
      "Epoch: 616/1000 Train loss: 0.085637 Valid loss: 0.108830 Train acc: 0.969175 Valid acc: 0.963735\n",
      "Epoch: 617/1000 Train loss: 0.085627 Valid loss: 0.108133 Train acc: 0.967815 Valid acc: 0.964642\n",
      "Epoch: 618/1000 Train loss: 0.084927 Valid loss: 0.107109 Train acc: 0.968042 Valid acc: 0.962375\n",
      "Epoch: 619/1000 Train loss: 0.084800 Valid loss: 0.109047 Train acc: 0.967815 Valid acc: 0.961922\n",
      "Epoch: 620/1000 Train loss: 0.085225 Valid loss: 0.107352 Train acc: 0.967815 Valid acc: 0.962829\n",
      "Epoch: 621/1000 Train loss: 0.084177 Valid loss: 0.108925 Train acc: 0.968042 Valid acc: 0.962375\n",
      "Epoch: 622/1000 Train loss: 0.084602 Valid loss: 0.107704 Train acc: 0.968495 Valid acc: 0.961015\n",
      "Epoch: 623/1000 Train loss: 0.084403 Valid loss: 0.109056 Train acc: 0.968722 Valid acc: 0.962829\n",
      "Epoch: 624/1000 Train loss: 0.084620 Valid loss: 0.107782 Train acc: 0.968495 Valid acc: 0.962829\n",
      "Epoch: 625/1000 Train loss: 0.084191 Valid loss: 0.107344 Train acc: 0.968948 Valid acc: 0.963282\n",
      "Epoch: 626/1000 Train loss: 0.083911 Valid loss: 0.108602 Train acc: 0.968722 Valid acc: 0.962829\n",
      "Epoch: 627/1000 Train loss: 0.083972 Valid loss: 0.107292 Train acc: 0.968495 Valid acc: 0.961922\n",
      "Epoch: 628/1000 Train loss: 0.083945 Valid loss: 0.108586 Train acc: 0.968722 Valid acc: 0.963282\n",
      "Epoch: 629/1000 Train loss: 0.083947 Valid loss: 0.107410 Train acc: 0.968495 Valid acc: 0.963735\n",
      "Epoch: 630/1000 Train loss: 0.084893 Valid loss: 0.109367 Train acc: 0.969402 Valid acc: 0.961922\n",
      "Epoch: 631/1000 Train loss: 0.084775 Valid loss: 0.113381 Train acc: 0.969402 Valid acc: 0.961469\n",
      "Epoch: 632/1000 Train loss: 0.085896 Valid loss: 0.111639 Train acc: 0.968042 Valid acc: 0.961922\n",
      "Epoch: 633/1000 Train loss: 0.086934 Valid loss: 0.109826 Train acc: 0.967135 Valid acc: 0.961922\n",
      "Epoch: 634/1000 Train loss: 0.085174 Valid loss: 0.108764 Train acc: 0.969175 Valid acc: 0.963282\n",
      "Epoch: 635/1000 Train loss: 0.085682 Valid loss: 0.105152 Train acc: 0.967815 Valid acc: 0.962375\n",
      "Epoch: 636/1000 Train loss: 0.084841 Valid loss: 0.106733 Train acc: 0.968268 Valid acc: 0.963735\n",
      "Epoch: 637/1000 Train loss: 0.084900 Valid loss: 0.106846 Train acc: 0.968495 Valid acc: 0.962375\n",
      "Epoch: 638/1000 Train loss: 0.086817 Valid loss: 0.105526 Train acc: 0.968042 Valid acc: 0.963282\n",
      "Epoch: 639/1000 Train loss: 0.085223 Valid loss: 0.105199 Train acc: 0.968495 Valid acc: 0.964189\n",
      "Epoch: 640/1000 Train loss: 0.084864 Valid loss: 0.104682 Train acc: 0.968722 Valid acc: 0.960562\n",
      "Epoch: 641/1000 Train loss: 0.085525 Valid loss: 0.104454 Train acc: 0.968268 Valid acc: 0.964642\n",
      "Epoch: 642/1000 Train loss: 0.085131 Valid loss: 0.104399 Train acc: 0.969628 Valid acc: 0.964642\n",
      "Epoch: 643/1000 Train loss: 0.084126 Valid loss: 0.104293 Train acc: 0.970535 Valid acc: 0.964189\n",
      "Epoch: 644/1000 Train loss: 0.084295 Valid loss: 0.104318 Train acc: 0.970082 Valid acc: 0.964642\n",
      "Epoch: 645/1000 Train loss: 0.083898 Valid loss: 0.104021 Train acc: 0.970535 Valid acc: 0.964189\n",
      "Epoch: 646/1000 Train loss: 0.083679 Valid loss: 0.104780 Train acc: 0.970082 Valid acc: 0.963735\n",
      "Epoch: 647/1000 Train loss: 0.083525 Valid loss: 0.104352 Train acc: 0.970308 Valid acc: 0.963282\n",
      "Epoch: 648/1000 Train loss: 0.083504 Valid loss: 0.104567 Train acc: 0.970762 Valid acc: 0.963282\n",
      "Epoch: 649/1000 Train loss: 0.083459 Valid loss: 0.104253 Train acc: 0.970762 Valid acc: 0.963735\n",
      "Epoch: 650/1000 Train loss: 0.082992 Valid loss: 0.105070 Train acc: 0.970535 Valid acc: 0.962829\n",
      "Epoch: 651/1000 Train loss: 0.083140 Valid loss: 0.104991 Train acc: 0.970988 Valid acc: 0.963735\n",
      "Epoch: 652/1000 Train loss: 0.083358 Valid loss: 0.104881 Train acc: 0.971215 Valid acc: 0.964189\n",
      "Epoch: 653/1000 Train loss: 0.083197 Valid loss: 0.105145 Train acc: 0.970535 Valid acc: 0.963735\n",
      "Epoch: 654/1000 Train loss: 0.082792 Valid loss: 0.105151 Train acc: 0.969628 Valid acc: 0.962829\n",
      "Epoch: 655/1000 Train loss: 0.082709 Valid loss: 0.106184 Train acc: 0.970762 Valid acc: 0.963735\n",
      "Epoch: 656/1000 Train loss: 0.082773 Valid loss: 0.105620 Train acc: 0.970535 Valid acc: 0.962829\n",
      "Epoch: 657/1000 Train loss: 0.087180 Valid loss: 0.108293 Train acc: 0.968722 Valid acc: 0.961015\n",
      "Epoch: 658/1000 Train loss: 0.090421 Valid loss: 0.107753 Train acc: 0.966002 Valid acc: 0.961015\n",
      "Epoch: 659/1000 Train loss: 0.090166 Valid loss: 0.109189 Train acc: 0.968268 Valid acc: 0.961922\n",
      "Epoch: 660/1000 Train loss: 0.090731 Valid loss: 0.113354 Train acc: 0.966682 Valid acc: 0.958749\n",
      "Epoch: 661/1000 Train loss: 0.091593 Valid loss: 0.108324 Train acc: 0.965775 Valid acc: 0.961469\n",
      "Epoch: 662/1000 Train loss: 0.088135 Valid loss: 0.106427 Train acc: 0.967588 Valid acc: 0.960562\n",
      "Epoch: 663/1000 Train loss: 0.086143 Valid loss: 0.107204 Train acc: 0.968722 Valid acc: 0.962829\n",
      "Epoch: 664/1000 Train loss: 0.086300 Valid loss: 0.106114 Train acc: 0.968268 Valid acc: 0.961469\n",
      "Epoch: 665/1000 Train loss: 0.085979 Valid loss: 0.107671 Train acc: 0.968495 Valid acc: 0.960562\n",
      "Epoch: 666/1000 Train loss: 0.085310 Valid loss: 0.105060 Train acc: 0.967362 Valid acc: 0.961922\n",
      "Epoch: 667/1000 Train loss: 0.085471 Valid loss: 0.105054 Train acc: 0.969402 Valid acc: 0.961922\n",
      "Epoch: 668/1000 Train loss: 0.084369 Valid loss: 0.107117 Train acc: 0.970535 Valid acc: 0.962375\n",
      "Epoch: 669/1000 Train loss: 0.083476 Valid loss: 0.109432 Train acc: 0.970082 Valid acc: 0.961469\n",
      "Epoch: 670/1000 Train loss: 0.086056 Valid loss: 0.107377 Train acc: 0.969175 Valid acc: 0.962375\n",
      "Epoch: 671/1000 Train loss: 0.083825 Valid loss: 0.106284 Train acc: 0.970988 Valid acc: 0.961469\n",
      "Epoch: 672/1000 Train loss: 0.084876 Valid loss: 0.106422 Train acc: 0.968722 Valid acc: 0.963282\n",
      "Epoch: 673/1000 Train loss: 0.083601 Valid loss: 0.106679 Train acc: 0.970535 Valid acc: 0.962829\n",
      "Epoch: 674/1000 Train loss: 0.082973 Valid loss: 0.107427 Train acc: 0.969628 Valid acc: 0.960562\n",
      "Epoch: 675/1000 Train loss: 0.082853 Valid loss: 0.106808 Train acc: 0.971215 Valid acc: 0.962375\n",
      "Epoch: 676/1000 Train loss: 0.082621 Valid loss: 0.108222 Train acc: 0.970988 Valid acc: 0.961469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 677/1000 Train loss: 0.082492 Valid loss: 0.107664 Train acc: 0.971668 Valid acc: 0.963282\n",
      "Epoch: 678/1000 Train loss: 0.082978 Valid loss: 0.107840 Train acc: 0.970082 Valid acc: 0.962829\n",
      "Epoch: 679/1000 Train loss: 0.082336 Valid loss: 0.107269 Train acc: 0.971895 Valid acc: 0.962375\n",
      "Epoch: 680/1000 Train loss: 0.082388 Valid loss: 0.108054 Train acc: 0.971895 Valid acc: 0.962829\n",
      "Epoch: 681/1000 Train loss: 0.082090 Valid loss: 0.107685 Train acc: 0.972121 Valid acc: 0.963282\n",
      "Epoch: 682/1000 Train loss: 0.082580 Valid loss: 0.108164 Train acc: 0.970308 Valid acc: 0.962829\n",
      "Epoch: 683/1000 Train loss: 0.082181 Valid loss: 0.108128 Train acc: 0.971215 Valid acc: 0.961469\n",
      "Epoch: 684/1000 Train loss: 0.082196 Valid loss: 0.108432 Train acc: 0.970762 Valid acc: 0.961922\n",
      "Epoch: 685/1000 Train loss: 0.082078 Valid loss: 0.107997 Train acc: 0.971668 Valid acc: 0.962375\n",
      "Epoch: 686/1000 Train loss: 0.082114 Valid loss: 0.108348 Train acc: 0.969628 Valid acc: 0.962375\n",
      "Epoch: 687/1000 Train loss: 0.081822 Valid loss: 0.108261 Train acc: 0.971215 Valid acc: 0.962375\n",
      "Epoch: 688/1000 Train loss: 0.081969 Valid loss: 0.108635 Train acc: 0.970762 Valid acc: 0.962375\n",
      "Epoch: 689/1000 Train loss: 0.081810 Valid loss: 0.108530 Train acc: 0.971215 Valid acc: 0.962829\n",
      "Epoch: 690/1000 Train loss: 0.082282 Valid loss: 0.108599 Train acc: 0.971442 Valid acc: 0.961922\n",
      "Epoch: 691/1000 Train loss: 0.081734 Valid loss: 0.108490 Train acc: 0.971442 Valid acc: 0.963282\n",
      "Epoch: 692/1000 Train loss: 0.082043 Valid loss: 0.108493 Train acc: 0.970988 Valid acc: 0.962375\n",
      "Epoch: 693/1000 Train loss: 0.081933 Valid loss: 0.108523 Train acc: 0.970988 Valid acc: 0.961469\n",
      "Epoch: 694/1000 Train loss: 0.081701 Valid loss: 0.108698 Train acc: 0.971215 Valid acc: 0.962375\n",
      "Epoch: 695/1000 Train loss: 0.081537 Valid loss: 0.108868 Train acc: 0.970762 Valid acc: 0.962829\n",
      "Epoch: 696/1000 Train loss: 0.083743 Valid loss: 0.109027 Train acc: 0.969628 Valid acc: 0.962375\n",
      "Epoch: 697/1000 Train loss: 0.082956 Valid loss: 0.108296 Train acc: 0.970308 Valid acc: 0.962375\n",
      "Epoch: 698/1000 Train loss: 0.082160 Valid loss: 0.108067 Train acc: 0.970535 Valid acc: 0.962375\n",
      "Epoch: 699/1000 Train loss: 0.082145 Valid loss: 0.108493 Train acc: 0.970762 Valid acc: 0.962829\n",
      "Epoch: 700/1000 Train loss: 0.094423 Valid loss: 0.124186 Train acc: 0.965549 Valid acc: 0.956482\n",
      "Epoch: 701/1000 Train loss: 0.100049 Valid loss: 0.129429 Train acc: 0.961695 Valid acc: 0.953309\n",
      "Epoch: 702/1000 Train loss: 0.096576 Valid loss: 0.111390 Train acc: 0.963055 Valid acc: 0.960562\n",
      "Epoch: 703/1000 Train loss: 0.091583 Valid loss: 0.113597 Train acc: 0.964642 Valid acc: 0.958749\n",
      "Epoch: 704/1000 Train loss: 0.090375 Valid loss: 0.107956 Train acc: 0.965322 Valid acc: 0.960109\n",
      "Epoch: 705/1000 Train loss: 0.087037 Valid loss: 0.110375 Train acc: 0.967362 Valid acc: 0.959655\n",
      "Epoch: 706/1000 Train loss: 0.086218 Valid loss: 0.110306 Train acc: 0.967588 Valid acc: 0.960562\n",
      "Epoch: 707/1000 Train loss: 0.085117 Valid loss: 0.114158 Train acc: 0.967588 Valid acc: 0.959655\n",
      "Epoch: 708/1000 Train loss: 0.087005 Valid loss: 0.109783 Train acc: 0.966228 Valid acc: 0.961469\n",
      "Epoch: 709/1000 Train loss: 0.087010 Valid loss: 0.110311 Train acc: 0.966228 Valid acc: 0.959655\n",
      "Epoch: 710/1000 Train loss: 0.084940 Valid loss: 0.110801 Train acc: 0.967588 Valid acc: 0.959655\n",
      "Epoch: 711/1000 Train loss: 0.086813 Valid loss: 0.108185 Train acc: 0.966455 Valid acc: 0.960562\n",
      "Epoch: 712/1000 Train loss: 0.085840 Valid loss: 0.108268 Train acc: 0.967135 Valid acc: 0.963735\n",
      "Epoch: 713/1000 Train loss: 0.084035 Valid loss: 0.109588 Train acc: 0.970988 Valid acc: 0.963282\n",
      "Epoch: 714/1000 Train loss: 0.084010 Valid loss: 0.107534 Train acc: 0.970308 Valid acc: 0.962375\n",
      "Epoch: 715/1000 Train loss: 0.084005 Valid loss: 0.108929 Train acc: 0.969855 Valid acc: 0.961922\n",
      "Epoch: 716/1000 Train loss: 0.083064 Valid loss: 0.108565 Train acc: 0.969855 Valid acc: 0.962829\n",
      "Epoch: 717/1000 Train loss: 0.082896 Valid loss: 0.108053 Train acc: 0.971442 Valid acc: 0.961469\n",
      "Epoch: 718/1000 Train loss: 0.082253 Valid loss: 0.110559 Train acc: 0.969855 Valid acc: 0.961469\n",
      "Epoch: 719/1000 Train loss: 0.082787 Valid loss: 0.108162 Train acc: 0.969855 Valid acc: 0.961469\n",
      "Epoch: 720/1000 Train loss: 0.082213 Valid loss: 0.109591 Train acc: 0.971668 Valid acc: 0.962375\n",
      "Epoch: 721/1000 Train loss: 0.082170 Valid loss: 0.107972 Train acc: 0.971215 Valid acc: 0.962829\n",
      "Epoch: 722/1000 Train loss: 0.081977 Valid loss: 0.107844 Train acc: 0.971895 Valid acc: 0.962829\n",
      "Epoch: 723/1000 Train loss: 0.081339 Valid loss: 0.108397 Train acc: 0.972348 Valid acc: 0.963282\n",
      "Epoch: 724/1000 Train loss: 0.081481 Valid loss: 0.108618 Train acc: 0.971215 Valid acc: 0.961922\n",
      "Epoch: 725/1000 Train loss: 0.081122 Valid loss: 0.110386 Train acc: 0.971668 Valid acc: 0.961469\n",
      "Epoch: 726/1000 Train loss: 0.081443 Valid loss: 0.109308 Train acc: 0.971442 Valid acc: 0.961469\n",
      "Epoch: 727/1000 Train loss: 0.081638 Valid loss: 0.110536 Train acc: 0.971668 Valid acc: 0.962375\n",
      "Epoch: 728/1000 Train loss: 0.082087 Valid loss: 0.108924 Train acc: 0.971215 Valid acc: 0.961922\n",
      "Epoch: 729/1000 Train loss: 0.081342 Valid loss: 0.110090 Train acc: 0.971668 Valid acc: 0.962375\n",
      "Epoch: 730/1000 Train loss: 0.081553 Valid loss: 0.109366 Train acc: 0.970988 Valid acc: 0.962375\n",
      "Epoch: 731/1000 Train loss: 0.081533 Valid loss: 0.110404 Train acc: 0.972348 Valid acc: 0.962829\n",
      "Epoch: 732/1000 Train loss: 0.080891 Valid loss: 0.110595 Train acc: 0.971442 Valid acc: 0.963282\n",
      "Epoch: 733/1000 Train loss: 0.081140 Valid loss: 0.110198 Train acc: 0.972121 Valid acc: 0.962829\n",
      "Epoch: 734/1000 Train loss: 0.081112 Valid loss: 0.110644 Train acc: 0.971442 Valid acc: 0.962829\n",
      "Epoch: 735/1000 Train loss: 0.080804 Valid loss: 0.111052 Train acc: 0.972348 Valid acc: 0.961922\n",
      "Epoch: 736/1000 Train loss: 0.080623 Valid loss: 0.111537 Train acc: 0.971895 Valid acc: 0.962375\n",
      "Epoch: 737/1000 Train loss: 0.081094 Valid loss: 0.111140 Train acc: 0.971895 Valid acc: 0.962375\n",
      "Epoch: 738/1000 Train loss: 0.080635 Valid loss: 0.110844 Train acc: 0.972575 Valid acc: 0.962829\n",
      "Epoch: 739/1000 Train loss: 0.080768 Valid loss: 0.110706 Train acc: 0.973028 Valid acc: 0.961922\n",
      "Epoch: 740/1000 Train loss: 0.080948 Valid loss: 0.110501 Train acc: 0.972575 Valid acc: 0.962375\n",
      "Epoch: 741/1000 Train loss: 0.081189 Valid loss: 0.110157 Train acc: 0.972121 Valid acc: 0.961469\n",
      "Epoch: 742/1000 Train loss: 0.080799 Valid loss: 0.110058 Train acc: 0.972348 Valid acc: 0.962829\n",
      "Epoch: 743/1000 Train loss: 0.081127 Valid loss: 0.109977 Train acc: 0.972348 Valid acc: 0.961922\n",
      "Epoch: 744/1000 Train loss: 0.080738 Valid loss: 0.110451 Train acc: 0.972575 Valid acc: 0.961922\n",
      "Epoch: 745/1000 Train loss: 0.080911 Valid loss: 0.110533 Train acc: 0.971668 Valid acc: 0.960109\n",
      "Epoch: 746/1000 Train loss: 0.081151 Valid loss: 0.110461 Train acc: 0.971215 Valid acc: 0.960109\n",
      "Epoch: 747/1000 Train loss: 0.080279 Valid loss: 0.110286 Train acc: 0.972121 Valid acc: 0.961015\n",
      "Epoch: 748/1000 Train loss: 0.080507 Valid loss: 0.110549 Train acc: 0.971895 Valid acc: 0.961015\n",
      "Epoch: 749/1000 Train loss: 0.080020 Valid loss: 0.110775 Train acc: 0.972575 Valid acc: 0.961922\n",
      "Epoch: 750/1000 Train loss: 0.080340 Valid loss: 0.110823 Train acc: 0.971895 Valid acc: 0.960562\n",
      "Epoch: 751/1000 Train loss: 0.080114 Valid loss: 0.110654 Train acc: 0.973255 Valid acc: 0.961922\n",
      "Epoch: 752/1000 Train loss: 0.080212 Valid loss: 0.110865 Train acc: 0.972121 Valid acc: 0.961015\n",
      "Epoch: 753/1000 Train loss: 0.079976 Valid loss: 0.110856 Train acc: 0.972348 Valid acc: 0.961469\n",
      "Epoch: 754/1000 Train loss: 0.080115 Valid loss: 0.110720 Train acc: 0.972575 Valid acc: 0.961015\n",
      "Epoch: 755/1000 Train loss: 0.079986 Valid loss: 0.110975 Train acc: 0.972121 Valid acc: 0.961469\n",
      "Epoch: 756/1000 Train loss: 0.079905 Valid loss: 0.111137 Train acc: 0.973028 Valid acc: 0.962375\n",
      "Epoch: 757/1000 Train loss: 0.079939 Valid loss: 0.111335 Train acc: 0.972801 Valid acc: 0.962375\n",
      "Epoch: 758/1000 Train loss: 0.079552 Valid loss: 0.111978 Train acc: 0.973255 Valid acc: 0.962375\n",
      "Epoch: 759/1000 Train loss: 0.079739 Valid loss: 0.112327 Train acc: 0.972801 Valid acc: 0.960562\n",
      "Epoch: 760/1000 Train loss: 0.079702 Valid loss: 0.112618 Train acc: 0.973028 Valid acc: 0.961469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 761/1000 Train loss: 0.079691 Valid loss: 0.112573 Train acc: 0.972801 Valid acc: 0.961015\n",
      "Epoch: 762/1000 Train loss: 0.079592 Valid loss: 0.112247 Train acc: 0.973708 Valid acc: 0.961922\n",
      "Epoch: 763/1000 Train loss: 0.079477 Valid loss: 0.112062 Train acc: 0.974161 Valid acc: 0.961469\n",
      "Epoch: 764/1000 Train loss: 0.079253 Valid loss: 0.112144 Train acc: 0.973028 Valid acc: 0.961015\n",
      "Epoch: 765/1000 Train loss: 0.079232 Valid loss: 0.114083 Train acc: 0.974161 Valid acc: 0.961015\n",
      "Epoch: 766/1000 Train loss: 0.079001 Valid loss: 0.114523 Train acc: 0.973935 Valid acc: 0.961922\n",
      "Epoch: 767/1000 Train loss: 0.079048 Valid loss: 0.114288 Train acc: 0.973935 Valid acc: 0.961015\n",
      "Epoch: 768/1000 Train loss: 0.078709 Valid loss: 0.114404 Train acc: 0.973481 Valid acc: 0.960562\n",
      "Epoch: 769/1000 Train loss: 0.078774 Valid loss: 0.114346 Train acc: 0.974161 Valid acc: 0.960562\n",
      "Epoch: 770/1000 Train loss: 0.078727 Valid loss: 0.113523 Train acc: 0.974161 Valid acc: 0.960562\n",
      "Epoch: 771/1000 Train loss: 0.078714 Valid loss: 0.113675 Train acc: 0.974615 Valid acc: 0.960562\n",
      "Epoch: 772/1000 Train loss: 0.078583 Valid loss: 0.113274 Train acc: 0.973708 Valid acc: 0.960562\n",
      "Epoch: 773/1000 Train loss: 0.078593 Valid loss: 0.113439 Train acc: 0.973935 Valid acc: 0.960562\n",
      "Epoch: 774/1000 Train loss: 0.078406 Valid loss: 0.113374 Train acc: 0.973481 Valid acc: 0.961469\n",
      "Epoch: 775/1000 Train loss: 0.078543 Valid loss: 0.113921 Train acc: 0.974161 Valid acc: 0.960109\n",
      "Epoch: 776/1000 Train loss: 0.078423 Valid loss: 0.113914 Train acc: 0.974388 Valid acc: 0.960562\n",
      "Epoch: 777/1000 Train loss: 0.078307 Valid loss: 0.113625 Train acc: 0.974161 Valid acc: 0.960562\n",
      "Epoch: 778/1000 Train loss: 0.078351 Valid loss: 0.113263 Train acc: 0.974388 Valid acc: 0.960109\n",
      "Epoch: 779/1000 Train loss: 0.078377 Valid loss: 0.113315 Train acc: 0.974841 Valid acc: 0.961469\n",
      "Epoch: 780/1000 Train loss: 0.078526 Valid loss: 0.113601 Train acc: 0.974161 Valid acc: 0.961469\n",
      "Epoch: 781/1000 Train loss: 0.078140 Valid loss: 0.113681 Train acc: 0.974388 Valid acc: 0.960562\n",
      "Epoch: 782/1000 Train loss: 0.078807 Valid loss: 0.112644 Train acc: 0.973481 Valid acc: 0.961469\n",
      "Epoch: 783/1000 Train loss: 0.078510 Valid loss: 0.112691 Train acc: 0.974841 Valid acc: 0.962375\n",
      "Epoch: 784/1000 Train loss: 0.078366 Valid loss: 0.113231 Train acc: 0.974161 Valid acc: 0.961922\n",
      "Epoch: 785/1000 Train loss: 0.078079 Valid loss: 0.113892 Train acc: 0.974388 Valid acc: 0.959202\n",
      "Epoch: 786/1000 Train loss: 0.080082 Valid loss: 0.112656 Train acc: 0.972348 Valid acc: 0.960562\n",
      "Epoch: 787/1000 Train loss: 0.079508 Valid loss: 0.115746 Train acc: 0.973028 Valid acc: 0.961469\n",
      "Epoch: 788/1000 Train loss: 0.080456 Valid loss: 0.113358 Train acc: 0.972575 Valid acc: 0.960562\n",
      "Epoch: 789/1000 Train loss: 0.079620 Valid loss: 0.113556 Train acc: 0.973255 Valid acc: 0.958296\n",
      "Epoch: 790/1000 Train loss: 0.083348 Valid loss: 0.108922 Train acc: 0.970988 Valid acc: 0.961922\n",
      "Epoch: 791/1000 Train loss: 0.081977 Valid loss: 0.110443 Train acc: 0.971895 Valid acc: 0.959655\n",
      "Epoch: 792/1000 Train loss: 0.082090 Valid loss: 0.110839 Train acc: 0.971895 Valid acc: 0.961922\n",
      "Epoch: 793/1000 Train loss: 0.085595 Valid loss: 0.119771 Train acc: 0.968495 Valid acc: 0.951496\n",
      "Epoch: 794/1000 Train loss: 0.089705 Valid loss: 0.111400 Train acc: 0.965549 Valid acc: 0.962829\n",
      "Epoch: 795/1000 Train loss: 0.086562 Valid loss: 0.109077 Train acc: 0.967588 Valid acc: 0.963735\n",
      "Epoch: 796/1000 Train loss: 0.080917 Valid loss: 0.109364 Train acc: 0.973028 Valid acc: 0.959655\n",
      "Epoch: 797/1000 Train loss: 0.083230 Valid loss: 0.109796 Train acc: 0.971668 Valid acc: 0.961922\n",
      "Epoch: 798/1000 Train loss: 0.083542 Valid loss: 0.116435 Train acc: 0.968495 Valid acc: 0.953762\n",
      "Epoch: 799/1000 Train loss: 0.087112 Valid loss: 0.112275 Train acc: 0.966455 Valid acc: 0.961015\n",
      "Epoch: 800/1000 Train loss: 0.089013 Valid loss: 0.109098 Train acc: 0.967362 Valid acc: 0.961922\n",
      "Epoch: 801/1000 Train loss: 0.084369 Valid loss: 0.114257 Train acc: 0.970082 Valid acc: 0.958296\n",
      "Epoch: 802/1000 Train loss: 0.085914 Valid loss: 0.112826 Train acc: 0.968948 Valid acc: 0.961015\n",
      "Epoch: 803/1000 Train loss: 0.087511 Valid loss: 0.110206 Train acc: 0.969628 Valid acc: 0.961015\n",
      "Epoch: 804/1000 Train loss: 0.088429 Valid loss: 0.107948 Train acc: 0.964642 Valid acc: 0.961015\n",
      "Epoch: 805/1000 Train loss: 0.084028 Valid loss: 0.117484 Train acc: 0.969628 Valid acc: 0.958749\n",
      "Epoch: 806/1000 Train loss: 0.090131 Valid loss: 0.111503 Train acc: 0.966228 Valid acc: 0.958749\n",
      "Epoch: 807/1000 Train loss: 0.087374 Valid loss: 0.113062 Train acc: 0.969175 Valid acc: 0.961015\n",
      "Epoch: 808/1000 Train loss: 0.083735 Valid loss: 0.112066 Train acc: 0.970082 Valid acc: 0.963282\n",
      "Epoch: 809/1000 Train loss: 0.084814 Valid loss: 0.107708 Train acc: 0.969175 Valid acc: 0.961922\n",
      "Epoch: 810/1000 Train loss: 0.082637 Valid loss: 0.110072 Train acc: 0.970988 Valid acc: 0.962375\n",
      "Epoch: 811/1000 Train loss: 0.081734 Valid loss: 0.110299 Train acc: 0.971442 Valid acc: 0.961922\n",
      "Epoch: 812/1000 Train loss: 0.081412 Valid loss: 0.108431 Train acc: 0.971895 Valid acc: 0.961469\n",
      "Epoch: 813/1000 Train loss: 0.081429 Valid loss: 0.110834 Train acc: 0.970082 Valid acc: 0.961922\n",
      "Epoch: 814/1000 Train loss: 0.080736 Valid loss: 0.110246 Train acc: 0.971215 Valid acc: 0.963282\n",
      "Epoch: 815/1000 Train loss: 0.078645 Valid loss: 0.111552 Train acc: 0.973708 Valid acc: 0.961015\n",
      "Epoch: 816/1000 Train loss: 0.080704 Valid loss: 0.109963 Train acc: 0.971668 Valid acc: 0.963282\n",
      "Epoch: 817/1000 Train loss: 0.079234 Valid loss: 0.109256 Train acc: 0.972801 Valid acc: 0.962829\n",
      "Epoch: 818/1000 Train loss: 0.078380 Valid loss: 0.109416 Train acc: 0.973708 Valid acc: 0.964189\n",
      "Epoch: 819/1000 Train loss: 0.078226 Valid loss: 0.110125 Train acc: 0.973481 Valid acc: 0.963735\n",
      "Epoch: 820/1000 Train loss: 0.078065 Valid loss: 0.109917 Train acc: 0.973708 Valid acc: 0.962829\n",
      "Epoch: 821/1000 Train loss: 0.078372 Valid loss: 0.110743 Train acc: 0.973028 Valid acc: 0.962829\n",
      "Epoch: 822/1000 Train loss: 0.078184 Valid loss: 0.110474 Train acc: 0.972348 Valid acc: 0.961469\n",
      "Epoch: 823/1000 Train loss: 0.077955 Valid loss: 0.109912 Train acc: 0.973708 Valid acc: 0.962829\n",
      "Epoch: 824/1000 Train loss: 0.077688 Valid loss: 0.107607 Train acc: 0.974388 Valid acc: 0.962829\n",
      "Epoch: 825/1000 Train loss: 0.077515 Valid loss: 0.106755 Train acc: 0.974161 Valid acc: 0.962375\n",
      "Epoch: 826/1000 Train loss: 0.077463 Valid loss: 0.108232 Train acc: 0.973935 Valid acc: 0.963282\n",
      "Epoch: 827/1000 Train loss: 0.077499 Valid loss: 0.107132 Train acc: 0.973935 Valid acc: 0.964189\n",
      "Epoch: 828/1000 Train loss: 0.077453 Valid loss: 0.107323 Train acc: 0.973708 Valid acc: 0.963735\n",
      "Epoch: 829/1000 Train loss: 0.077323 Valid loss: 0.107541 Train acc: 0.973935 Valid acc: 0.963735\n",
      "Epoch: 830/1000 Train loss: 0.077157 Valid loss: 0.109012 Train acc: 0.974388 Valid acc: 0.962829\n",
      "Epoch: 831/1000 Train loss: 0.077031 Valid loss: 0.109336 Train acc: 0.973935 Valid acc: 0.962829\n",
      "Epoch: 832/1000 Train loss: 0.077099 Valid loss: 0.109719 Train acc: 0.974161 Valid acc: 0.962829\n",
      "Epoch: 833/1000 Train loss: 0.077092 Valid loss: 0.110976 Train acc: 0.974388 Valid acc: 0.963282\n",
      "Epoch: 834/1000 Train loss: 0.077084 Valid loss: 0.111054 Train acc: 0.974388 Valid acc: 0.962829\n",
      "Epoch: 835/1000 Train loss: 0.077001 Valid loss: 0.110997 Train acc: 0.974615 Valid acc: 0.964189\n",
      "Epoch: 836/1000 Train loss: 0.076620 Valid loss: 0.111157 Train acc: 0.974161 Valid acc: 0.963282\n",
      "Epoch: 837/1000 Train loss: 0.076649 Valid loss: 0.111376 Train acc: 0.975295 Valid acc: 0.962375\n",
      "Epoch: 838/1000 Train loss: 0.076880 Valid loss: 0.111414 Train acc: 0.973935 Valid acc: 0.962829\n",
      "Epoch: 839/1000 Train loss: 0.076666 Valid loss: 0.111548 Train acc: 0.974388 Valid acc: 0.962375\n",
      "Epoch: 840/1000 Train loss: 0.076923 Valid loss: 0.111084 Train acc: 0.974161 Valid acc: 0.963735\n",
      "Epoch: 841/1000 Train loss: 0.076643 Valid loss: 0.112041 Train acc: 0.975295 Valid acc: 0.961469\n",
      "Epoch: 842/1000 Train loss: 0.076757 Valid loss: 0.113465 Train acc: 0.975068 Valid acc: 0.962829\n",
      "Epoch: 843/1000 Train loss: 0.077776 Valid loss: 0.119387 Train acc: 0.975068 Valid acc: 0.960562\n",
      "Epoch: 844/1000 Train loss: 0.083446 Valid loss: 0.118915 Train acc: 0.970988 Valid acc: 0.961922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 845/1000 Train loss: 0.084053 Valid loss: 0.122514 Train acc: 0.972121 Valid acc: 0.959655\n",
      "Epoch: 846/1000 Train loss: 0.087002 Valid loss: 0.129981 Train acc: 0.970762 Valid acc: 0.959655\n",
      "Epoch: 847/1000 Train loss: 0.089539 Valid loss: 0.130766 Train acc: 0.969628 Valid acc: 0.957842\n",
      "Epoch: 848/1000 Train loss: 0.089413 Valid loss: 0.120904 Train acc: 0.969175 Valid acc: 0.959202\n",
      "Epoch: 849/1000 Train loss: 0.089956 Valid loss: 0.119093 Train acc: 0.969175 Valid acc: 0.959655\n",
      "Epoch: 850/1000 Train loss: 0.101321 Valid loss: 0.118743 Train acc: 0.967815 Valid acc: 0.961469\n",
      "Epoch: 851/1000 Train loss: 0.099551 Valid loss: 0.112905 Train acc: 0.968495 Valid acc: 0.959655\n",
      "Epoch: 852/1000 Train loss: 0.094229 Valid loss: 0.112838 Train acc: 0.967362 Valid acc: 0.961922\n",
      "Epoch: 853/1000 Train loss: 0.088729 Valid loss: 0.116822 Train acc: 0.969402 Valid acc: 0.957842\n",
      "Epoch: 854/1000 Train loss: 0.091411 Valid loss: 0.117775 Train acc: 0.967362 Valid acc: 0.957842\n",
      "Epoch: 855/1000 Train loss: 0.091017 Valid loss: 0.115125 Train acc: 0.968042 Valid acc: 0.959202\n",
      "Epoch: 856/1000 Train loss: 0.090321 Valid loss: 0.113791 Train acc: 0.968268 Valid acc: 0.959655\n",
      "Epoch: 857/1000 Train loss: 0.090547 Valid loss: 0.116476 Train acc: 0.969175 Valid acc: 0.959655\n",
      "Epoch: 858/1000 Train loss: 0.090486 Valid loss: 0.125424 Train acc: 0.968722 Valid acc: 0.951949\n",
      "Epoch: 859/1000 Train loss: 0.095451 Valid loss: 0.114959 Train acc: 0.964869 Valid acc: 0.959655\n",
      "Epoch: 860/1000 Train loss: 0.092442 Valid loss: 0.112500 Train acc: 0.967362 Valid acc: 0.960109\n",
      "Epoch: 861/1000 Train loss: 0.090529 Valid loss: 0.109820 Train acc: 0.966682 Valid acc: 0.962829\n",
      "Epoch: 862/1000 Train loss: 0.090488 Valid loss: 0.110153 Train acc: 0.968722 Valid acc: 0.962829\n",
      "Epoch: 863/1000 Train loss: 0.086114 Valid loss: 0.110124 Train acc: 0.970535 Valid acc: 0.963282\n",
      "Epoch: 864/1000 Train loss: 0.086236 Valid loss: 0.107977 Train acc: 0.970762 Valid acc: 0.962829\n",
      "Epoch: 865/1000 Train loss: 0.085451 Valid loss: 0.109577 Train acc: 0.971442 Valid acc: 0.960562\n",
      "Epoch: 866/1000 Train loss: 0.085526 Valid loss: 0.109271 Train acc: 0.972121 Valid acc: 0.961922\n",
      "Epoch: 867/1000 Train loss: 0.085511 Valid loss: 0.108608 Train acc: 0.970308 Valid acc: 0.961922\n",
      "Epoch: 868/1000 Train loss: 0.084622 Valid loss: 0.107581 Train acc: 0.972121 Valid acc: 0.963735\n",
      "Epoch: 869/1000 Train loss: 0.084051 Valid loss: 0.107170 Train acc: 0.971442 Valid acc: 0.963282\n",
      "Epoch: 870/1000 Train loss: 0.084134 Valid loss: 0.107092 Train acc: 0.971442 Valid acc: 0.963282\n",
      "Epoch: 871/1000 Train loss: 0.083658 Valid loss: 0.107257 Train acc: 0.973481 Valid acc: 0.962829\n",
      "Epoch: 872/1000 Train loss: 0.083375 Valid loss: 0.107042 Train acc: 0.973028 Valid acc: 0.962829\n",
      "Epoch: 873/1000 Train loss: 0.083001 Valid loss: 0.107400 Train acc: 0.972121 Valid acc: 0.962375\n",
      "Epoch: 874/1000 Train loss: 0.082915 Valid loss: 0.107398 Train acc: 0.971668 Valid acc: 0.961015\n",
      "Epoch: 875/1000 Train loss: 0.082762 Valid loss: 0.107604 Train acc: 0.973028 Valid acc: 0.961922\n",
      "Epoch: 876/1000 Train loss: 0.082550 Valid loss: 0.107693 Train acc: 0.972575 Valid acc: 0.961922\n",
      "Epoch: 877/1000 Train loss: 0.082344 Valid loss: 0.107685 Train acc: 0.971668 Valid acc: 0.963282\n",
      "Epoch: 878/1000 Train loss: 0.082147 Valid loss: 0.107733 Train acc: 0.973028 Valid acc: 0.962829\n",
      "Epoch: 879/1000 Train loss: 0.081927 Valid loss: 0.107783 Train acc: 0.973481 Valid acc: 0.963282\n",
      "Epoch: 880/1000 Train loss: 0.081672 Valid loss: 0.107974 Train acc: 0.972575 Valid acc: 0.962829\n",
      "Epoch: 881/1000 Train loss: 0.081032 Valid loss: 0.107984 Train acc: 0.973255 Valid acc: 0.963735\n",
      "Epoch: 882/1000 Train loss: 0.080256 Valid loss: 0.108838 Train acc: 0.973255 Valid acc: 0.962829\n",
      "Epoch: 883/1000 Train loss: 0.080207 Valid loss: 0.109388 Train acc: 0.972575 Valid acc: 0.962375\n",
      "Epoch: 884/1000 Train loss: 0.079826 Valid loss: 0.109708 Train acc: 0.973255 Valid acc: 0.961922\n",
      "Epoch: 885/1000 Train loss: 0.079657 Valid loss: 0.109677 Train acc: 0.973481 Valid acc: 0.961469\n",
      "Epoch: 886/1000 Train loss: 0.079964 Valid loss: 0.109435 Train acc: 0.973255 Valid acc: 0.961469\n",
      "Epoch: 887/1000 Train loss: 0.079622 Valid loss: 0.109563 Train acc: 0.973481 Valid acc: 0.960562\n",
      "Epoch: 888/1000 Train loss: 0.079553 Valid loss: 0.109228 Train acc: 0.973708 Valid acc: 0.961015\n",
      "Epoch: 889/1000 Train loss: 0.079321 Valid loss: 0.109696 Train acc: 0.973255 Valid acc: 0.961015\n",
      "Epoch: 890/1000 Train loss: 0.079351 Valid loss: 0.109211 Train acc: 0.973255 Valid acc: 0.961922\n",
      "Epoch: 891/1000 Train loss: 0.079029 Valid loss: 0.109262 Train acc: 0.973708 Valid acc: 0.962375\n",
      "Epoch: 892/1000 Train loss: 0.078971 Valid loss: 0.109472 Train acc: 0.973708 Valid acc: 0.961922\n",
      "Epoch: 893/1000 Train loss: 0.078923 Valid loss: 0.108566 Train acc: 0.973935 Valid acc: 0.962829\n",
      "Epoch: 894/1000 Train loss: 0.078862 Valid loss: 0.109569 Train acc: 0.974615 Valid acc: 0.961015\n",
      "Epoch: 895/1000 Train loss: 0.078829 Valid loss: 0.108289 Train acc: 0.974388 Valid acc: 0.963282\n",
      "Epoch: 896/1000 Train loss: 0.078836 Valid loss: 0.109508 Train acc: 0.974388 Valid acc: 0.960109\n",
      "Epoch: 897/1000 Train loss: 0.077203 Valid loss: 0.108167 Train acc: 0.975068 Valid acc: 0.962829\n",
      "Epoch: 898/1000 Train loss: 0.078650 Valid loss: 0.109431 Train acc: 0.974161 Valid acc: 0.961469\n",
      "Epoch: 899/1000 Train loss: 0.078604 Valid loss: 0.109208 Train acc: 0.974388 Valid acc: 0.962829\n",
      "Epoch: 900/1000 Train loss: 0.078265 Valid loss: 0.109015 Train acc: 0.975068 Valid acc: 0.962829\n",
      "Epoch: 901/1000 Train loss: 0.078359 Valid loss: 0.109981 Train acc: 0.974615 Valid acc: 0.960562\n",
      "Epoch: 902/1000 Train loss: 0.078653 Valid loss: 0.108423 Train acc: 0.974615 Valid acc: 0.962829\n",
      "Epoch: 903/1000 Train loss: 0.078720 Valid loss: 0.110169 Train acc: 0.974388 Valid acc: 0.960109\n",
      "Epoch: 904/1000 Train loss: 0.077057 Valid loss: 0.107708 Train acc: 0.975068 Valid acc: 0.963282\n",
      "Epoch: 905/1000 Train loss: 0.078728 Valid loss: 0.110157 Train acc: 0.974388 Valid acc: 0.959202\n",
      "Epoch: 906/1000 Train loss: 0.077263 Valid loss: 0.107553 Train acc: 0.974841 Valid acc: 0.962375\n",
      "Epoch: 907/1000 Train loss: 0.078855 Valid loss: 0.109706 Train acc: 0.974388 Valid acc: 0.960109\n",
      "Epoch: 908/1000 Train loss: 0.077453 Valid loss: 0.106674 Train acc: 0.974841 Valid acc: 0.962829\n",
      "Epoch: 909/1000 Train loss: 0.078934 Valid loss: 0.108255 Train acc: 0.974161 Valid acc: 0.961015\n",
      "Epoch: 910/1000 Train loss: 0.077602 Valid loss: 0.107070 Train acc: 0.974161 Valid acc: 0.963282\n",
      "Epoch: 911/1000 Train loss: 0.078350 Valid loss: 0.107339 Train acc: 0.975068 Valid acc: 0.963282\n",
      "Epoch: 912/1000 Train loss: 0.078252 Valid loss: 0.108037 Train acc: 0.974161 Valid acc: 0.961922\n",
      "Epoch: 913/1000 Train loss: 0.078149 Valid loss: 0.107214 Train acc: 0.975521 Valid acc: 0.962829\n",
      "Epoch: 914/1000 Train loss: 0.077852 Valid loss: 0.109505 Train acc: 0.975521 Valid acc: 0.960109\n",
      "Epoch: 915/1000 Train loss: 0.076590 Valid loss: 0.107266 Train acc: 0.975521 Valid acc: 0.962829\n",
      "Epoch: 916/1000 Train loss: 0.078273 Valid loss: 0.110172 Train acc: 0.974841 Valid acc: 0.960109\n",
      "Epoch: 917/1000 Train loss: 0.079143 Valid loss: 0.108356 Train acc: 0.974388 Valid acc: 0.962829\n",
      "Epoch: 918/1000 Train loss: 0.080029 Valid loss: 0.110876 Train acc: 0.972801 Valid acc: 0.960109\n",
      "Epoch: 919/1000 Train loss: 0.079149 Valid loss: 0.108000 Train acc: 0.974161 Valid acc: 0.962375\n",
      "Epoch: 920/1000 Train loss: 0.078740 Valid loss: 0.111138 Train acc: 0.973935 Valid acc: 0.961015\n",
      "Epoch: 921/1000 Train loss: 0.077339 Valid loss: 0.107693 Train acc: 0.974161 Valid acc: 0.962375\n",
      "Epoch: 922/1000 Train loss: 0.078902 Valid loss: 0.110941 Train acc: 0.974388 Valid acc: 0.960109\n",
      "Epoch: 923/1000 Train loss: 0.076873 Valid loss: 0.107996 Train acc: 0.975295 Valid acc: 0.961469\n",
      "Epoch: 924/1000 Train loss: 0.078491 Valid loss: 0.111795 Train acc: 0.974615 Valid acc: 0.960562\n",
      "Epoch: 925/1000 Train loss: 0.078015 Valid loss: 0.110902 Train acc: 0.975295 Valid acc: 0.961922\n",
      "Epoch: 926/1000 Train loss: 0.077722 Valid loss: 0.111759 Train acc: 0.974841 Valid acc: 0.962375\n",
      "Epoch: 927/1000 Train loss: 0.078950 Valid loss: 0.113301 Train acc: 0.974615 Valid acc: 0.961922\n",
      "Epoch: 928/1000 Train loss: 0.078582 Valid loss: 0.114266 Train acc: 0.975295 Valid acc: 0.961922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 929/1000 Train loss: 0.077817 Valid loss: 0.113780 Train acc: 0.974161 Valid acc: 0.961015\n",
      "Epoch: 930/1000 Train loss: 0.078217 Valid loss: 0.111510 Train acc: 0.975295 Valid acc: 0.962375\n",
      "Epoch: 931/1000 Train loss: 0.078616 Valid loss: 0.113047 Train acc: 0.974161 Valid acc: 0.960109\n",
      "Epoch: 932/1000 Train loss: 0.077331 Valid loss: 0.110330 Train acc: 0.975521 Valid acc: 0.963282\n",
      "Epoch: 933/1000 Train loss: 0.078894 Valid loss: 0.112570 Train acc: 0.974161 Valid acc: 0.960562\n",
      "Epoch: 934/1000 Train loss: 0.077407 Valid loss: 0.109660 Train acc: 0.975068 Valid acc: 0.963282\n",
      "Epoch: 935/1000 Train loss: 0.077906 Valid loss: 0.112705 Train acc: 0.974388 Valid acc: 0.960562\n",
      "Epoch: 936/1000 Train loss: 0.077539 Valid loss: 0.110562 Train acc: 0.975068 Valid acc: 0.961922\n",
      "Epoch: 937/1000 Train loss: 0.077487 Valid loss: 0.111284 Train acc: 0.973708 Valid acc: 0.962375\n",
      "Epoch: 938/1000 Train loss: 0.077136 Valid loss: 0.110831 Train acc: 0.974388 Valid acc: 0.962829\n",
      "Epoch: 939/1000 Train loss: 0.076720 Valid loss: 0.110451 Train acc: 0.975521 Valid acc: 0.962829\n",
      "Epoch: 940/1000 Train loss: 0.079851 Valid loss: 0.111838 Train acc: 0.974161 Valid acc: 0.961015\n",
      "Epoch: 941/1000 Train loss: 0.076617 Valid loss: 0.107747 Train acc: 0.975521 Valid acc: 0.962829\n",
      "Epoch: 942/1000 Train loss: 0.075745 Valid loss: 0.109210 Train acc: 0.974841 Valid acc: 0.962375\n",
      "Epoch: 943/1000 Train loss: 0.075622 Valid loss: 0.108552 Train acc: 0.975521 Valid acc: 0.962375\n",
      "Epoch: 944/1000 Train loss: 0.075561 Valid loss: 0.112039 Train acc: 0.975068 Valid acc: 0.962829\n",
      "Epoch: 945/1000 Train loss: 0.075536 Valid loss: 0.112330 Train acc: 0.975521 Valid acc: 0.962375\n",
      "Epoch: 946/1000 Train loss: 0.075098 Valid loss: 0.111954 Train acc: 0.975748 Valid acc: 0.962375\n",
      "Epoch: 947/1000 Train loss: 0.075625 Valid loss: 0.113648 Train acc: 0.974615 Valid acc: 0.961469\n",
      "Epoch: 948/1000 Train loss: 0.075225 Valid loss: 0.112023 Train acc: 0.975295 Valid acc: 0.963282\n",
      "Epoch: 949/1000 Train loss: 0.075248 Valid loss: 0.113443 Train acc: 0.975748 Valid acc: 0.961015\n",
      "Epoch: 950/1000 Train loss: 0.075209 Valid loss: 0.111655 Train acc: 0.975975 Valid acc: 0.962375\n",
      "Epoch: 951/1000 Train loss: 0.075280 Valid loss: 0.111995 Train acc: 0.975521 Valid acc: 0.961015\n",
      "Epoch: 952/1000 Train loss: 0.075160 Valid loss: 0.111203 Train acc: 0.975975 Valid acc: 0.963282\n",
      "Epoch: 953/1000 Train loss: 0.074762 Valid loss: 0.111068 Train acc: 0.975748 Valid acc: 0.962829\n",
      "Epoch: 954/1000 Train loss: 0.074921 Valid loss: 0.111903 Train acc: 0.975295 Valid acc: 0.961469\n",
      "Epoch: 955/1000 Train loss: 0.075120 Valid loss: 0.110212 Train acc: 0.976428 Valid acc: 0.962375\n",
      "Epoch: 956/1000 Train loss: 0.074633 Valid loss: 0.111253 Train acc: 0.975295 Valid acc: 0.961469\n",
      "Epoch: 957/1000 Train loss: 0.075352 Valid loss: 0.109870 Train acc: 0.975295 Valid acc: 0.963282\n",
      "Epoch: 958/1000 Train loss: 0.075137 Valid loss: 0.110900 Train acc: 0.974841 Valid acc: 0.963282\n",
      "Epoch: 959/1000 Train loss: 0.074844 Valid loss: 0.108963 Train acc: 0.974841 Valid acc: 0.962375\n",
      "Epoch: 960/1000 Train loss: 0.074919 Valid loss: 0.109399 Train acc: 0.975068 Valid acc: 0.961015\n",
      "Epoch: 961/1000 Train loss: 0.074872 Valid loss: 0.108076 Train acc: 0.975295 Valid acc: 0.963282\n",
      "Epoch: 962/1000 Train loss: 0.074923 Valid loss: 0.109492 Train acc: 0.975295 Valid acc: 0.962829\n",
      "Epoch: 963/1000 Train loss: 0.075745 Valid loss: 0.108121 Train acc: 0.975975 Valid acc: 0.963735\n",
      "Epoch: 964/1000 Train loss: 0.074931 Valid loss: 0.108795 Train acc: 0.975521 Valid acc: 0.961922\n",
      "Epoch: 965/1000 Train loss: 0.075457 Valid loss: 0.108562 Train acc: 0.975521 Valid acc: 0.964189\n",
      "Epoch: 966/1000 Train loss: 0.074971 Valid loss: 0.108421 Train acc: 0.975295 Valid acc: 0.963735\n",
      "Epoch: 967/1000 Train loss: 0.074466 Valid loss: 0.108810 Train acc: 0.975748 Valid acc: 0.962829\n",
      "Epoch: 968/1000 Train loss: 0.075136 Valid loss: 0.107549 Train acc: 0.976428 Valid acc: 0.963735\n",
      "Epoch: 969/1000 Train loss: 0.075089 Valid loss: 0.109485 Train acc: 0.975068 Valid acc: 0.962375\n",
      "Epoch: 970/1000 Train loss: 0.075481 Valid loss: 0.106806 Train acc: 0.975975 Valid acc: 0.964642\n",
      "Epoch: 971/1000 Train loss: 0.074860 Valid loss: 0.109030 Train acc: 0.975975 Valid acc: 0.961469\n",
      "Epoch: 972/1000 Train loss: 0.074420 Valid loss: 0.106543 Train acc: 0.976428 Valid acc: 0.964189\n",
      "Epoch: 973/1000 Train loss: 0.074976 Valid loss: 0.109770 Train acc: 0.974841 Valid acc: 0.960562\n",
      "Epoch: 974/1000 Train loss: 0.075193 Valid loss: 0.106615 Train acc: 0.975521 Valid acc: 0.964189\n",
      "Epoch: 975/1000 Train loss: 0.075271 Valid loss: 0.110420 Train acc: 0.974615 Valid acc: 0.961469\n",
      "Epoch: 976/1000 Train loss: 0.075212 Valid loss: 0.107026 Train acc: 0.975295 Valid acc: 0.963282\n",
      "Epoch: 977/1000 Train loss: 0.074592 Valid loss: 0.109824 Train acc: 0.975521 Valid acc: 0.961015\n",
      "Epoch: 978/1000 Train loss: 0.074813 Valid loss: 0.107437 Train acc: 0.975295 Valid acc: 0.962375\n",
      "Epoch: 979/1000 Train loss: 0.075459 Valid loss: 0.110238 Train acc: 0.974615 Valid acc: 0.960562\n",
      "Epoch: 980/1000 Train loss: 0.075118 Valid loss: 0.108348 Train acc: 0.975748 Valid acc: 0.962829\n",
      "Epoch: 981/1000 Train loss: 0.075905 Valid loss: 0.109682 Train acc: 0.974841 Valid acc: 0.961922\n",
      "Epoch: 982/1000 Train loss: 0.075109 Valid loss: 0.109034 Train acc: 0.975521 Valid acc: 0.962829\n",
      "Epoch: 983/1000 Train loss: 0.074822 Valid loss: 0.108288 Train acc: 0.975068 Valid acc: 0.963735\n",
      "Epoch: 984/1000 Train loss: 0.074859 Valid loss: 0.109810 Train acc: 0.975748 Valid acc: 0.961015\n",
      "Epoch: 985/1000 Train loss: 0.074650 Valid loss: 0.107580 Train acc: 0.976655 Valid acc: 0.962375\n",
      "Epoch: 986/1000 Train loss: 0.075282 Valid loss: 0.111629 Train acc: 0.974161 Valid acc: 0.958296\n",
      "Epoch: 987/1000 Train loss: 0.075955 Valid loss: 0.106839 Train acc: 0.974615 Valid acc: 0.962829\n",
      "Epoch: 988/1000 Train loss: 0.075147 Valid loss: 0.110680 Train acc: 0.975068 Valid acc: 0.959655\n",
      "Epoch: 989/1000 Train loss: 0.075533 Valid loss: 0.107215 Train acc: 0.975068 Valid acc: 0.961469\n",
      "Epoch: 990/1000 Train loss: 0.074524 Valid loss: 0.107926 Train acc: 0.975068 Valid acc: 0.961922\n",
      "Epoch: 991/1000 Train loss: 0.074077 Valid loss: 0.108862 Train acc: 0.975521 Valid acc: 0.961469\n",
      "Epoch: 992/1000 Train loss: 0.074244 Valid loss: 0.107620 Train acc: 0.975521 Valid acc: 0.962375\n",
      "Epoch: 993/1000 Train loss: 0.073797 Valid loss: 0.109338 Train acc: 0.975975 Valid acc: 0.961015\n",
      "Epoch: 994/1000 Train loss: 0.074770 Valid loss: 0.108321 Train acc: 0.975068 Valid acc: 0.963735\n",
      "Epoch: 995/1000 Train loss: 0.074157 Valid loss: 0.109691 Train acc: 0.975748 Valid acc: 0.962375\n",
      "Epoch: 996/1000 Train loss: 0.074171 Valid loss: 0.108444 Train acc: 0.975521 Valid acc: 0.963735\n",
      "Epoch: 997/1000 Train loss: 0.074127 Valid loss: 0.110150 Train acc: 0.975068 Valid acc: 0.961015\n",
      "Epoch: 998/1000 Train loss: 0.074036 Valid loss: 0.108834 Train acc: 0.976428 Valid acc: 0.961922\n",
      "Epoch: 999/1000 Train loss: 0.073595 Valid loss: 0.108963 Train acc: 0.976201 Valid acc: 0.961922\n",
      "Epoch: 1000/1000 Train loss: 0.073522 Valid loss: 0.108654 Train acc: 0.975975 Valid acc: 0.962829\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "\n",
    "# Save the training result or trained and validated model params\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "   \n",
    "    # Loop over epochs\n",
    "    epochs = 1000\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Loop over batches of training\n",
    "        state = sess.run(fetches=initial_state)\n",
    "        loss_batch, acc_batch = [], []\n",
    "        for Xarr, Yarr in get_batches(X=Xtrain, y=Ytrain, batch_size=batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed_dict = {Xinput:Xarr, Ylabels:Yarr, initial_state:state}\n",
    "            lossarr, _ , state, accarr = sess.run(fetches=[loss, optimizer, final_state, accuracy], \n",
    "                                                  feed_dict=feed_dict)\n",
    "            loss_batch.append(lossarr)\n",
    "            acc_batch.append(accarr)\n",
    "            \n",
    "        # acc and loss for plotting\n",
    "        train_acc.append(np.mean(acc_batch))\n",
    "        train_loss.append(np.mean(loss_batch))\n",
    "\n",
    "        # Loop over batches of validation\n",
    "        state = sess.run(initial_state)\n",
    "        loss_batch, acc_batch = [], []\n",
    "        for Xarr, Yarr in get_batches(X=Xvalid, y=Yvalid, batch_size=batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed_dict = {Xinput:Xarr, Ylabels:Yarr, initial_state:state}\n",
    "            lossarr, state, accarr = sess.run(fetches=[loss, final_state, accuracy], feed_dict=feed_dict)\n",
    "            loss_batch.append(lossarr)\n",
    "            acc_batch.append(accarr)\n",
    "            \n",
    "        # acc and loss for plotting\n",
    "        valid_acc.append(np.mean(acc_batch))\n",
    "        valid_loss.append(np.mean(loss_batch))\n",
    "            \n",
    "        # Print info for every iter/epoch\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs),\n",
    "              \"Train loss: {:6f}\".format(train_loss[epoch]),\n",
    "              \"Valid loss: {:.6f}\".format(valid_loss[epoch]),\n",
    "              \"Train acc: {:6f}\".format(train_acc[epoch]),\n",
    "              \"Valid acc: {:.6f}\".format(valid_acc[epoch]))\n",
    "                \n",
    "    saver.save(sess, 'checkpoints/lstm-imu-har.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "%matplotlib inline\n",
    "\n",
    "mplot.plot(train_loss, label='train_loss')\n",
    "mplot.plot(valid_loss, label='valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as mplot\n",
    "mplot.plot(train_acc, label='train_acc')\n",
    "mplot.plot(valid_acc, label='valid_acc')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/lstm-imu-har.ckpt\n",
      "Test loss: 0.535821 Test acc: 0.881233\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Restore the validated model\n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    saver.restore(sess=sess, save_path='checkpoints/lstm-imu-har.ckpt')\n",
    "    \n",
    "    # Loop over batches of Test\n",
    "    state = sess.run(fetches=initial_state)\n",
    "    loss_batch, acc_batch = [], []\n",
    "    for Xarr, Yarr in get_batches(X=Xtest, y=Ytest, batch_size=batch_size):\n",
    "\n",
    "        # Feed dictionary\n",
    "        feed_dict = {Xinput:Xarr, Ylabels:Yarr, initial_state:state}\n",
    "        lossarr, state, accarr = sess.run(fetches=[loss, final_state, accuracy], feed_dict=feed_dict)\n",
    "        loss_batch.append(lossarr)\n",
    "        acc_batch.append(accarr)\n",
    "\n",
    "    # Print info for every iter/epoch\n",
    "    print(\"Test loss: {:6f}\".format(np.mean(loss_batch)),\n",
    "          \"Test acc: {:.6f}\".format(np.mean(acc_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
