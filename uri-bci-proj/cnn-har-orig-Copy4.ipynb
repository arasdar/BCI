{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "import numpy as np\n",
    "from utilities import *\n",
    "\n",
    "# test and train read\n",
    "Xtrain, Ytrain, list_ch_train = read_data(data_path=\"../../../datasets/har/har-data/\", split=\"train\")\n",
    "Xtest, Ytest, list_ch_test = read_data(data_path=\"../../../datasets/har/har-data/\", split=\"test\")\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\"\n",
    "assert Ytrain.max(axis=0) == Ytest.max(axis=0)\n",
    "\n",
    "# print(np.mean(Y_train_valid==0), np.mean(Y_train_valid==1), np.mean(Y_train_valid==2), \n",
    "#       np.mean(Y_train_valid==3), np.mean(Y_train_valid==4), np.mean(Y_train_valid==5),\n",
    "#       np.mean(Y_train_valid==6), np.mean(Y_train_valid==7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing input and output data\n",
    "# from utilities import *\n",
    "\n",
    "# Normalizing/standardizing the input data features\n",
    "Xtrain, Xtest = standardize(test=Xtest, train=Xtrain)\n",
    "\n",
    "# # Onehot encoding/vectorizing the output data labels\n",
    "# print(np.mean((Y_train_valid).reshape(-1)==0), np.mean((Y_train_valid).reshape(-1)==1),\n",
    "#      np.mean((Y_train_valid).reshape(-1)==2), np.mean((Y_train_valid).reshape(-1)==3),\n",
    "#      np.mean((Y_train_valid).reshape(-1)==4), np.mean((Y_train_valid).reshape(-1)==5),\n",
    "#      np.mean((Y_train_valid).reshape(-1)==6), np.mean((Y_train_valid).reshape(-1)==7))\n",
    "\n",
    "Ytrain_onehot = one_hot(labels=Ytrain.reshape(-1), n_class=6) \n",
    "Ytest_onehot = one_hot(labels=Ytest.reshape(-1), n_class=6) \n",
    "\n",
    "# print(Y_train_valid_onehot.shape, Y_train_valid_onehot.dtype, \n",
    "#       Y_test_onehot.shape, Y_test_onehot.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and valid split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 30% of the training data/ entire training data is assigned to validation.\n",
    "Xtrain, Xvalid, Ytrain_onehot, Yvalid_onehot = train_test_split(Xtrain, Ytrain_onehot, test_size=0.30)\n",
    "\n",
    "# print(X_train_norm.shape, X_valid_norm.shape, Y_train_onehot.shape, Y_valid_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Input data which is divided into train, valid, and testing.\n",
    "N, W, Cin = Xvalid.shape[0], Xtrain.shape[1], Xtrain.shape[2]\n",
    "X = tf.placeholder(dtype=tf.float32, name=None, shape=[N, W, Cin])\n",
    "print(X.shape, X.dtype)\n",
    "\n",
    "# Output data/labels\n",
    "assert Ytrain.max(axis=0)==Ytest.max(axis=0)\n",
    "Cout = Ytrain.max(axis=0)\n",
    "Y = tf.placeholder(dtype=tf.float32, name=None, shape=[N, Cout])\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(64, 9, 18) <dtype: 'float32_ref'>\n",
      "(2206, 64, 18) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# One convolution layer\n",
    "print(X.shape, X.dtype)\n",
    "# NWC: N is not important for weights/filters/kernels since it is not being convolved.\n",
    "Wwidth, Wchannels, Wnumber = X.shape[1].value//2, X.shape[2].value, X.shape[2].value*2\n",
    "shape = [Wwidth, Wchannels, Wnumber]\n",
    "initial_value = tf.random_normal(dtype=X.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "Wconv = tf.Variable(dtype=X.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(Wconv.shape, Wconv.dtype)\n",
    "Xconv = tf.nn.conv1d(data_format='NWC', filters=Wconv, name=None, padding='SAME', stride=2, use_cudnn_on_gpu=True, \n",
    "                     value=X)\n",
    "# Relu or nonlinearity/activation should also be implemnted\n",
    "# leaky relu is what I am interested in which is the simplest possible non-linearity and gets the job easily done.\n",
    "Xconv = tf.maximum(name=None, x=0.1*Xconv, y=1.0*Xconv)\n",
    "print(Xconv.shape, Xconv.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 1152) <dtype: 'float32'>\n",
      "(1152, 6) <dtype: 'float32_ref'>\n",
      "(2206, 6) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# This is a multiplication layer/ dense/fully-connected/gobal\n",
    "# shape = [-1, Xconv.shape[1].value*Xconv.shape[2].value] # N is None which is a value or creating an extra index\n",
    "shape = [Xconv.shape[0].value, Xconv.shape[1].value*Xconv.shape[2].value]\n",
    "Xconv_reshaped = tf.reshape(name=None, shape=shape, tensor=Xconv)\n",
    "print(Xconv_reshaped.shape, Xconv_reshaped.dtype)\n",
    "# print(Y.shape, Y.dtype)\n",
    "# In this layer there is not very much \n",
    "# Wwidth, Wchannels, Wnumber which is for a normal conv layer\n",
    "# NWC or WCN but for a dense layer, there is no W or H it is just CN or NC\n",
    "Wchannels, Wnumber = Xconv_reshaped.shape[1].value, Y.shape[1].value\n",
    "shape = [Wchannels, Wnumber]\n",
    "# print(shape)\n",
    "initial_value = tf.random_normal(dtype=Xconv_reshaped.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "W = tf.Variable(dtype=Xconv_reshaped.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(W.shape, W.dtype)\n",
    "logits = tf.matmul(a=Xconv_reshaped, b=W, name=None)\n",
    "print(logits.shape, logits.dtype)\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"softmax_cross_entropy_with_logits_1/Reshape_2:0\", shape=(2206,), dtype=float32)\n",
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "loss_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y, name=None)\n",
    "print(loss_tensor)\n",
    "loss = tf.reduce_mean(axis=0, input_tensor=loss_tensor)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer name: \"Adam_1\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam_1/update_Variable_2/ApplyAdam\"\n",
      "input: \"^Adam_1/update_Variable_3/ApplyAdam\"\n",
      "input: \"^Adam_1/Assign\"\n",
      "input: \"^Adam_1/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "# __init__(\n",
    "#     learning_rate=0.001,\n",
    "#     beta1=0.9,\n",
    "#     beta2=0.999,\n",
    "#     epsilon=1e-08,\n",
    "#     use_locking=False,\n",
    "#     name='Adam'\n",
    "# )\n",
    "# minimize(\n",
    "#     loss,\n",
    "#     global_step=None,\n",
    "#     var_list=None,\n",
    "#     gate_gradients=GATE_OP,\n",
    "#     aggregation_method=None,\n",
    "#     colocate_gradients_with_ops=False,\n",
    "#     name=None,\n",
    "#     grad_loss=None\n",
    "# )\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss=loss)\n",
    "print('optimizer', optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Accuracy\n",
    "# correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "# print('correct_pred, accuracy', correct_pred, accuracy)\n",
    "\n",
    "# # Confusion matrix\n",
    "# confusion_matrix = tf.confusion_matrix(predictions=tf.argmax(logits, 1),\n",
    "#                                        labels=tf.argmax(labels_, 1))\n",
    "# print('confusion_matrix', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minibatching techniques for online learning and offline learning of big dataset\n",
    "# for X, Y in get_batches(X=X_train_norm, batch_size=N, y=Y_train_onehot):\n",
    "#     print(X.shape, X.dtype, Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 training loss: 548.7199 validation loss: 533.09534\n",
      "epoch: 1 training loss: 519.1821 validation loss: 505.7445\n",
      "epoch: 2 training loss: 490.48273 validation loss: 479.13632\n",
      "epoch: 3 training loss: 462.57947 validation loss: 453.22202\n",
      "epoch: 4 training loss: 435.6148 validation loss: 428.18658\n",
      "epoch: 5 training loss: 409.6103 validation loss: 404.17227\n",
      "epoch: 6 training loss: 384.64896 validation loss: 381.7933\n",
      "epoch: 7 training loss: 361.4378 validation loss: 361.6289\n",
      "epoch: 8 training loss: 340.83673 validation loss: 343.85468\n",
      "epoch: 9 training loss: 322.81372 validation loss: 328.18625\n",
      "epoch: 10 training loss: 307.07025 validation loss: 314.47614\n",
      "epoch: 11 training loss: 293.21045 validation loss: 302.436\n",
      "epoch: 12 training loss: 281.1966 validation loss: 292.10205\n",
      "epoch: 13 training loss: 270.98764 validation loss: 283.42203\n",
      "epoch: 14 training loss: 262.2124 validation loss: 276.12018\n",
      "epoch: 15 training loss: 254.64851 validation loss: 269.7119\n",
      "epoch: 16 training loss: 247.92738 validation loss: 264.02255\n",
      "epoch: 17 training loss: 241.85045 validation loss: 258.88074\n",
      "epoch: 18 training loss: 236.36559 validation loss: 254.13399\n",
      "epoch: 19 training loss: 231.26074 validation loss: 249.51256\n",
      "epoch: 20 training loss: 226.28128 validation loss: 244.9243\n",
      "epoch: 21 training loss: 221.37473 validation loss: 240.3666\n",
      "epoch: 22 training loss: 216.52054 validation loss: 235.8852\n",
      "epoch: 23 training loss: 211.76775 validation loss: 231.52344\n",
      "epoch: 24 training loss: 207.18977 validation loss: 227.38889\n",
      "epoch: 25 training loss: 202.75958 validation loss: 223.44041\n",
      "epoch: 26 training loss: 198.48648 validation loss: 219.70837\n",
      "epoch: 27 training loss: 194.40817 validation loss: 216.25612\n",
      "epoch: 28 training loss: 190.51549 validation loss: 212.98555\n",
      "epoch: 29 training loss: 186.77899 validation loss: 209.83641\n",
      "epoch: 30 training loss: 183.15485 validation loss: 206.78088\n",
      "epoch: 31 training loss: 179.62863 validation loss: 203.79997\n",
      "epoch: 32 training loss: 176.1951 validation loss: 200.91168\n",
      "epoch: 33 training loss: 172.86418 validation loss: 198.09686\n",
      "epoch: 34 training loss: 169.63629 validation loss: 195.3645\n",
      "epoch: 35 training loss: 166.52504 validation loss: 192.72354\n",
      "epoch: 36 training loss: 163.50699 validation loss: 190.1453\n",
      "epoch: 37 training loss: 160.58836 validation loss: 187.62262\n",
      "epoch: 38 training loss: 157.74388 validation loss: 185.16515\n",
      "epoch: 39 training loss: 154.97537 validation loss: 182.75586\n",
      "epoch: 40 training loss: 152.28702 validation loss: 180.38786\n",
      "epoch: 41 training loss: 149.6735 validation loss: 178.06503\n",
      "epoch: 42 training loss: 147.12071 validation loss: 175.80649\n",
      "epoch: 43 training loss: 144.64005 validation loss: 173.6048\n",
      "epoch: 44 training loss: 142.23145 validation loss: 171.45084\n",
      "epoch: 45 training loss: 139.86685 validation loss: 169.33928\n",
      "epoch: 46 training loss: 137.54169 validation loss: 167.26547\n",
      "epoch: 47 training loss: 135.2577 validation loss: 165.22896\n",
      "epoch: 48 training loss: 133.02502 validation loss: 163.2205\n",
      "epoch: 49 training loss: 130.82764 validation loss: 161.26604\n",
      "epoch: 50 training loss: 128.68657 validation loss: 159.35849\n",
      "epoch: 51 training loss: 126.58719 validation loss: 157.49176\n",
      "epoch: 52 training loss: 124.53911 validation loss: 155.66426\n",
      "epoch: 53 training loss: 122.55322 validation loss: 153.86269\n",
      "epoch: 54 training loss: 120.62124 validation loss: 152.08511\n",
      "epoch: 55 training loss: 118.72554 validation loss: 150.34697\n",
      "epoch: 56 training loss: 116.87011 validation loss: 148.64212\n",
      "epoch: 57 training loss: 115.05226 validation loss: 146.97575\n",
      "epoch: 58 training loss: 113.27964 validation loss: 145.35669\n",
      "epoch: 59 training loss: 111.548256 validation loss: 143.77863\n",
      "epoch: 60 training loss: 109.857185 validation loss: 142.24825\n",
      "epoch: 61 training loss: 108.202866 validation loss: 140.74976\n",
      "epoch: 62 training loss: 106.57643 validation loss: 139.26651\n",
      "epoch: 63 training loss: 104.973434 validation loss: 137.80353\n",
      "epoch: 64 training loss: 103.388 validation loss: 136.3583\n",
      "epoch: 65 training loss: 101.82831 validation loss: 134.92964\n",
      "epoch: 66 training loss: 100.293724 validation loss: 133.52061\n",
      "epoch: 67 training loss: 98.77846 validation loss: 132.12715\n",
      "epoch: 68 training loss: 97.286804 validation loss: 130.75172\n",
      "epoch: 69 training loss: 95.821 validation loss: 129.38689\n",
      "epoch: 70 training loss: 94.379074 validation loss: 128.02742\n",
      "epoch: 71 training loss: 92.95427 validation loss: 126.67093\n",
      "epoch: 72 training loss: 91.54695 validation loss: 125.325165\n",
      "epoch: 73 training loss: 90.15639 validation loss: 123.97915\n",
      "epoch: 74 training loss: 88.78517 validation loss: 122.63929\n",
      "epoch: 75 training loss: 87.44081 validation loss: 121.32103\n",
      "epoch: 76 training loss: 86.118484 validation loss: 120.01663\n",
      "epoch: 77 training loss: 84.81536 validation loss: 118.730194\n",
      "epoch: 78 training loss: 83.53874 validation loss: 117.46801\n",
      "epoch: 79 training loss: 82.28351 validation loss: 116.22794\n",
      "epoch: 80 training loss: 81.05504 validation loss: 115.01493\n",
      "epoch: 81 training loss: 79.85185 validation loss: 113.81911\n",
      "epoch: 82 training loss: 78.67456 validation loss: 112.64047\n",
      "epoch: 83 training loss: 77.52138 validation loss: 111.4819\n",
      "epoch: 84 training loss: 76.38341 validation loss: 110.34205\n",
      "epoch: 85 training loss: 75.257195 validation loss: 109.21939\n",
      "epoch: 86 training loss: 74.14667 validation loss: 108.10161\n",
      "epoch: 87 training loss: 73.05546 validation loss: 106.984406\n",
      "epoch: 88 training loss: 71.9785 validation loss: 105.86754\n",
      "epoch: 89 training loss: 70.91946 validation loss: 104.7582\n",
      "epoch: 90 training loss: 69.87728 validation loss: 103.66644\n",
      "epoch: 91 training loss: 68.855705 validation loss: 102.589615\n",
      "epoch: 92 training loss: 67.84964 validation loss: 101.534065\n",
      "epoch: 93 training loss: 66.860504 validation loss: 100.49409\n",
      "epoch: 94 training loss: 65.88757 validation loss: 99.465996\n",
      "epoch: 95 training loss: 64.93013 validation loss: 98.45835\n",
      "epoch: 96 training loss: 63.988647 validation loss: 97.46395\n",
      "epoch: 97 training loss: 63.0647 validation loss: 96.48562\n",
      "epoch: 98 training loss: 62.154633 validation loss: 95.526505\n",
      "epoch: 99 training loss: 61.25669 validation loss: 94.582375\n"
     ]
    }
   ],
   "source": [
    "# Plotting the learning/loss curve\n",
    "train_loss, valid_loss = [], []\n",
    "\n",
    "# Save the training result or trained and validated model params\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "   \n",
    "    # Loop over epochs\n",
    "    epochs=100\n",
    "    for epoch in range(0, epochs, 1): # start=0, stop=epochs, step=1\n",
    "        \n",
    "        # Training\n",
    "        loss_batch = []\n",
    "        for Xarr, Yarr in get_batches(X=Xtrain, batch_size=N, y=Ytrain_onehot):\n",
    "\n",
    "            # feeding the input array into TF framework and fetche the output\n",
    "            feed_dict = {X:Xarr, Y:Yarr}\n",
    "            lossarr, _ = sess.run(feed_dict=feed_dict, fetches=[loss, optimizer])\n",
    "            loss_batch.append(np.mean(lossarr))\n",
    "        \n",
    "        # Averaging the loss of the batch/minibatch\n",
    "        train_loss.append(np.mean(loss_batch))\n",
    "        \n",
    "        # validation\n",
    "        feed_dict = {X:Xvalid, Y:Yvalid_onehot}\n",
    "        lossarr = sess.run(feed_dict=feed_dict, fetches=[loss])\n",
    "        valid_loss.append(np.mean(lossarr))\n",
    "\n",
    "        # Printing out the training and validating loss\n",
    "        print('epoch:', epoch, 'training loss:', train_loss[epoch], 'validation loss:', valid_loss[epoch])\n",
    "            \n",
    "    saver.save(save_path='checkpoints/model.ckpt', sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "# % %matplotlib inline\n",
    "# this is keeping the mpl inline or outline\n",
    "# inline would inside this block and outline/out of block would be out of this block.\n",
    "# %matplotlib inline\n",
    "# %matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "mplot.plot(train_loss, label='har train_loss')\n",
    "mplot.plot(valid_loss, label='har valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing and playing around with checkpoints and trained model saved or saved trained model\n",
    "# loaded_ckpt = tf.train.load_checkpoint(ckpt_dir_or_file='checkpoints/cnn-har.ckpt')\n",
    "# loaded_ckpt.debug_string, \n",
    "# loaded_ckpt.get_variable_to_dtype_map()\n",
    "# loaded_ckpt.get_variable_to_shape_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "test_loss: 115.5474\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Restore the validated model\n",
    "#     save_path = tf.train.latest_checkpoint(checkpoint_dir='checkpoints')\n",
    "    save_path = tf.train.latest_checkpoint(checkpoint_dir='checkpoints/')\n",
    "    saver.restore(save_path=save_path, sess=sess)\n",
    "    \n",
    "    loss_batch = []\n",
    "    for Xarr, Yarr in get_batches(X=Xtest, batch_size=N, y=Ytest_onehot):\n",
    "#         print(Xarr.shape, Yarr.shape)\n",
    "        feed_dict = {X:Xarr, Y:Yarr}\n",
    "        lossarr = sess.run(feed_dict=feed_dict, fetches=[loss])\n",
    "        loss_batch.append(np.mean(lossarr))\n",
    "\n",
    "    # Print info for every iter/epoch\n",
    "    print('test_loss:', np.mean(loss_batch))\n",
    "#     print(\"Test loss: {:6f}\".format(np.mean(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
