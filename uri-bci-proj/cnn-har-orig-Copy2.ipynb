{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.16675734494015235 0.1459466811751904 0.13411316648531013 0.1749183895538629 0.1868879216539717 0.1913764961915125 0.0\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "import numpy as np\n",
    "from utilities import *\n",
    "\n",
    "# test and train read\n",
    "X_train_valid, Y_train_valid, list_ch_train_valid = read_data(data_path=\"../../../datasets/har/har-data/\", \n",
    "                                                              split=\"train\")\n",
    "X_test, Y_test, list_ch_test = read_data(data_path=\"../../../datasets/har/har-data/\", split=\"test\")\n",
    "\n",
    "assert list_ch_train_valid == list_ch_test, \"Mistmatch in channels!\"\n",
    "assert Y_train_valid.max(axis=0) == Y_test.max(axis=0)\n",
    "\n",
    "print(np.mean(Y_train_valid==0), np.mean(Y_train_valid==1), np.mean(Y_train_valid==2), \n",
    "      np.mean(Y_train_valid==3), np.mean(Y_train_valid==4), np.mean(Y_train_valid==5),\n",
    "      np.mean(Y_train_valid==6), np.mean(Y_train_valid==7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.16675734494015235 0.1459466811751904 0.13411316648531013 0.1749183895538629 0.1868879216539717 0.1913764961915125 0.0\n",
      "(7352, 6) float64 (2947, 6) float64\n"
     ]
    }
   ],
   "source": [
    "# Preparing input and output data\n",
    "# from utilities import *\n",
    "\n",
    "# Normalizing/standardizing the input data features\n",
    "X_train_valid_norm, X_test_norm = standardize(test=X_test, train=X_train_valid)\n",
    "\n",
    "# Onehot encoding/vectorizing the output data labels\n",
    "print(np.mean((Y_train_valid).reshape(-1)==0), np.mean((Y_train_valid).reshape(-1)==1),\n",
    "     np.mean((Y_train_valid).reshape(-1)==2), np.mean((Y_train_valid).reshape(-1)==3),\n",
    "     np.mean((Y_train_valid).reshape(-1)==4), np.mean((Y_train_valid).reshape(-1)==5),\n",
    "     np.mean((Y_train_valid).reshape(-1)==6), np.mean((Y_train_valid).reshape(-1)==7))\n",
    "\n",
    "Y_train_valid_onehot = one_hot(labels=Y_train_valid.reshape(-1), n_class=6) \n",
    "Y_test_onehot = one_hot(labels=Y_test.reshape(-1), n_class=6) \n",
    "\n",
    "print(Y_train_valid_onehot.shape, Y_train_valid_onehot.dtype, \n",
    "      Y_test_onehot.shape, Y_test_onehot.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5146, 128, 9) (2206, 128, 9) (5146, 6) (2206, 6)\n"
     ]
    }
   ],
   "source": [
    "# Train and valid split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_norm, X_valid_norm, Y_train_onehot, Y_valid_onehot = train_test_split(X_train_valid_norm, \n",
    "                                                                              Y_train_valid_onehot,\n",
    "                                                                              test_size=0.30)\n",
    "\n",
    "print(X_train_norm.shape, X_valid_norm.shape, Y_train_onehot.shape, Y_valid_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Hyperparameters\n",
    "# # Input data\n",
    "# batch_size = X_train_norm.shape[0]// 100 # minibatch size & number of minibatches\n",
    "# seq_len = X_train_norm.shape[1] # Number of steps: each trial length\n",
    "# n_channels = X_train_norm.shape[2] # number of channels in each trial\n",
    "# print('batch_size, seq_len, n_channels', batch_size, seq_len, n_channels)\n",
    "\n",
    "# # Output labels\n",
    "# n_classes = Y_train_valid.max(axis=0)\n",
    "# assert Y_train_valid.max(axis=0) == Y_test.max(axis=0)\n",
    "# print('n_classes', n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Feed the data from python/numpy to tensorflow framework\n",
    "# NWC or NHWC: Number, Height/Width, Channels\n",
    "# print(X_train_norm.shape, X_train_norm.dtype)\n",
    "# The common mistake the N or number of batches or number of input should be minimum of train, valid, or test\n",
    "# obviously should be validation set since it is the smallest one then.\n",
    "# The rest of other dimensions/axes/axises are all the same\n",
    "# print(X_train_norm.shape, X_valid_norm.shape, X_test_norm.shape)\n",
    "# print(X_train_norm.dtype, X_valid_norm.dtype, X_test_norm.dtype)\n",
    "# The N should be the minimum of these three bacthes so that we can train, validate and test.\n",
    "# W, Cin are the same for all training, validation, testing\n",
    "N, W, Cin = X_valid_norm.shape[0], X_train_norm.shape[1], X_train_norm.shape[2]\n",
    "# print(N, W, Cin)\n",
    "# inputs_ = tf.placeholder(tf.float32, [N, W, Cin], name =None)\n",
    "X = tf.placeholder(dtype=tf.float32, name=None, shape=[N, W, Cin])\n",
    "print(X.shape, X.dtype)\n",
    "\n",
    "# Channels for output or classes or dimensions for output\n",
    "# print(Y_train_valid.shape, Y_train_valid.dtype)\n",
    "# print(Y_train_valid.max(axis=0), Y_test.max(axis=0))\n",
    "assert Y_train_valid.max(axis=0)==Y_test.max(axis=0)\n",
    "# This is the class label or number from 1, ..., 6\n",
    "Cout = Y_train_valid.max(axis=0)\n",
    "# labels_ = tf.placeholder(tf.float32, [N, Cout], name =None)\n",
    "Y = tf.placeholder(dtype=tf.float32, name=None, shape=[N, Cout])\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 128, 9) <dtype: 'float32'>\n",
      "(64, 9, 18) <dtype: 'float32_ref'>\n",
      "(2206, 64, 18) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# This is one convolution channel for example\n",
    "print(X.shape, X.dtype)\n",
    "# variable/weight shape should be based on NWC but the other way around WCN\n",
    "# Width, Channels, Number of weights\n",
    "Wwidth, Wchannels, Wnumber = X.shape[1].value//2, X.shape[2].value, X.shape[2].value*2 # double up the input channels\n",
    "shape = [Wwidth, Wchannels, Wnumber]\n",
    "# print(shape)\n",
    "# initializing the weight using normal\n",
    "initial_value = tf.random_normal(dtype=X.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "# Weight, variable and itsshape\n",
    "Wconv = tf.Variable(dtype=X.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(Wconv.shape, Wconv.dtype)\n",
    "# input shape and type as the input tensor\n",
    "# convolution operation as well\n",
    "Xconv = tf.nn.conv1d(data_format='NWC', filters=Wconv, name=None, padding='SAME', stride=2, use_cudnn_on_gpu=True, \n",
    "                     value=X)\n",
    "print(Xconv.shape, Xconv.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 1152) <dtype: 'float32'>\n",
      "(1152, 6) <dtype: 'float32_ref'>\n",
      "(2206, 6) <dtype: 'float32'>\n",
      "(2206, 6) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# This is one multiplication channel for example\n",
    "# Flatten and add dropout + predicted output\n",
    "# WHY!!!!!!!! this is not working!!\n",
    "shape = [Xconv.shape[0].value, Xconv.shape[1].value*Xconv.shape[2].value]\n",
    "# shape = [-1, Xconv.shape[1].value*Xconv.shape[2].value]\n",
    "# print(shape, 64*18) # as a double check\n",
    "Xconv_reshaped = tf.reshape(name=None, shape=shape, tensor=Xconv)\n",
    "print(Xconv_reshaped.shape, Xconv_reshaped.dtype)\n",
    "# The weight for fully connected/dense layer and for multiplication not convolution though.\n",
    "# multiplication is so much easier than convolution in terms of implementation.\n",
    "# shape = this shape should be the same NWC as well but the other way around or maybe transposed\n",
    "# X is NWC which is describing the tensor shape0, 1, 2\n",
    "# labels which are the output labels are supposed to be NC, \n",
    "# N:batch size, C: output channels or output classes or dimensions \n",
    "Wchannels, Wnumber = Xconv_reshaped.shape[1].value, Y.shape[1].value\n",
    "shape = [Wchannels, Wnumber]\n",
    "# print(shape)\n",
    "initial_value = tf.random_normal(dtype=Xconv_reshaped.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "W = tf.Variable(dtype=Xconv_reshaped.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(W.shape, W.dtype)\n",
    "logits = tf.matmul(a=Xconv_reshaped, b=W, name=None)\n",
    "print(logits.shape, logits.dtype)\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost_tensor, cost Tensor(\"softmax_cross_entropy_with_logits_3/Reshape_2:0\", shape=(2206,), dtype=float32) Tensor(\"Mean_3:0\", shape=(), dtype=float32)\n",
      "optimizer name: \"Adam_3\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam_3/update_Variable_5/ApplyAdam\"\n",
      "input: \"^Adam_3/update_Variable_6/ApplyAdam\"\n",
      "input: \"^Adam_3/Assign\"\n",
      "input: \"^Adam_3/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "cost_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y)\n",
    "cost = tf.reduce_mean(input_tensor=cost_tensor)\n",
    "print('cost_tensor, cost', cost_tensor, cost)\n",
    "\n",
    "# Optimizer\n",
    "# __init__(\n",
    "#     learning_rate=0.001,\n",
    "#     beta1=0.9,\n",
    "#     beta2=0.999,\n",
    "#     epsilon=1e-08,\n",
    "#     use_locking=False,\n",
    "#     name='Adam'\n",
    "# )\n",
    "# minimize(\n",
    "#     loss,\n",
    "#     global_step=None,\n",
    "#     var_list=None,\n",
    "#     gate_gradients=GATE_OP,\n",
    "#     aggregation_method=None,\n",
    "#     colocate_gradients_with_ops=False,\n",
    "#     name=None,\n",
    "#     grad_loss=None\n",
    "# )\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss=cost)\n",
    "print('optimizer', optimizer)\n",
    "\n",
    "# # Accuracy\n",
    "# correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "# print('correct_pred, accuracy', correct_pred, accuracy)\n",
    "\n",
    "# # Confusion matrix\n",
    "# confusion_matrix = tf.confusion_matrix(predictions=tf.argmax(logits, 1),\n",
    "#                                        labels=tf.argmax(labels_, 1))\n",
    "# print('confusion_matrix', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X, Y in get_batches(X=X_train_norm, batch_size=N, y=Y_train_onehot):\n",
    "#     print(X.shape, X.dtype, Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 training loss: 622.09863 validation loss: 552.83795\n"
     ]
    }
   ],
   "source": [
    "# Plotting the learning/loss curve\n",
    "train_loss, valid_loss = [], []\n",
    "\n",
    "# Save the training result or trained and validated model params\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "   \n",
    "    # Loop over epochs\n",
    "    epochs=1\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Training\n",
    "        loss_batch, acc_batch = [], []\n",
    "        for Xarr, Yarr in get_batches(X=X_train_norm, batch_size=N, y=Y_train_onehot):\n",
    "            \n",
    "            # feeding the training data and fetching the output loss and accuracy and gradients as well;\n",
    "            feed_dict = {X:Xarr, Y:Yarr}\n",
    "            loss, _ = sess.run(feed_dict=feed_dict, fetches=[cost, optimizer])\n",
    "            loss_batch.append(loss)\n",
    "        \n",
    "        # Averaging the loss of the batch/minibatch\n",
    "        train_loss.append(np.mean(loss_batch))\n",
    "        \n",
    "        # validation\n",
    "        feed_dict = {X:X_valid_norm, Y:Y_valid_onehot}\n",
    "        loss = sess.run(feed_dict=feed_dict, fetches=[cost])\n",
    "        valid_loss.append(np.mean(loss))\n",
    "        \n",
    "        print('epoch:', epoch, 'training loss:', np.mean(loss_batch), 'validation loss:', np.mean(loss))\n",
    "            \n",
    "    saver.save(save_path='checkpoints/model.ckpt', sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "# % %matplotlib inline\n",
    "# this is keeping the mpl inline or outline\n",
    "# inline would inside this block and outline/out of block would be out of this block.\n",
    "# %matplotlib inline\n",
    "%matplotlib inline\n",
    "\n",
    "mplot.plot(train_loss, label='har train_loss')\n",
    "mplot.plot(valid_loss, label='har valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing and playing around with checkpoints and trained model saved or saved trained model\n",
    "# loaded_ckpt = tf.train.load_checkpoint(ckpt_dir_or_file='checkpoints/cnn-har.ckpt')\n",
    "# loaded_ckpt.debug_string, \n",
    "# loaded_ckpt.get_variable_to_dtype_map()\n",
    "# loaded_ckpt.get_variable_to_shape_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "(2206, 128, 9) (2206, 6)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Restore the validated model\n",
    "    save_path = tf.train.latest_checkpoint(checkpoint_dir='checkpoints')\n",
    "    saver.restore(save_path=save_path, sess=sess)\n",
    "    \n",
    "    loss_batch = []\n",
    "    for Xarr, Yarr in get_batches(X=X_test_norm, batch_size=N, y=Y_test_onehot):\n",
    "        print(Xarr.shape, Yarr.shape)\n",
    "        feed_dict = {X:Xarr, Y:Yarr}\n",
    "#         loss = sess.run(feed_dict=feed_dict, fetches=[cost])\n",
    "#         loss_batch.append(loss)\n",
    "\n",
    "\n",
    "#     # Print info for every iter/epoch\n",
    "#     print('test_loss:', np.mean(loss_batch))\n",
    "# #     print(\"Test loss: {:6f}\".format(np.mean(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
