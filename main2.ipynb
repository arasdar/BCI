{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL Brain project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O2test1.txt   O2valid2.txt  O3train.txt   O4test2.txt   O8test3.txt\r\n",
      "O2test2.txt   O2valid3.txt  O3valid1.txt  O4test3.txt\r\n",
      "O2test3.txt   O3test1.txt   O3valid2.txt  O4train.txt\r\n",
      "O2train.txt   O3test2.txt   O3valid3.txt  O4valid1.txt\r\n",
      "O2valid1.txt  O3test3.txt   O4test1.txt   O6valid1.txt\r\n"
     ]
    }
   ],
   "source": [
    "% ls /home/arasdar/datasets/DL-BrainBody/Control/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P10test1.txt   P10valid2.txt  P11valid1.txt  P8valid1.txt  P9valid1.txt\r\n",
      "P10test2.txt   P10valid3.txt  P11valid3.txt  P8valid3.txt  P9valid2.txt\r\n",
      "P10train.txt   P11test2.txt   P1test3.txt    P9test1.txt   P9valid3.txt\r\n",
      "P10valid1.txt  P11train.txt   P5valid2.txt   P9test2.txt\r\n"
     ]
    }
   ],
   "source": [
    "% ls /home/arasdar/datasets/DL-BrainBody/PD/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_02train = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "X_03train = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O3train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "X_04train = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O4train.txt', header=None, \n",
    "                        delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_02test1 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2test1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "X_02test2 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2test2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "X_02test3 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2test3.txt', header=None, \n",
    "                        delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_02val1 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2valid1.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "X_02val2 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2valid2.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "X_02val3 = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/Control/O2valid3.txt', header=None, \n",
    "                        delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10train = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P10train.txt', header=None, \n",
    "                        delim_whitespace=True)\n",
    "X_11train = pd.read_csv(filepath_or_buffer='/home/arasdar/datasets/DL-BrainBody/PD/P11train.txt', header=None, \n",
    "                        delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.209726</td>\n",
       "      <td>12.769014</td>\n",
       "      <td>20.533919</td>\n",
       "      <td>23.334040</td>\n",
       "      <td>20.961187</td>\n",
       "      <td>13.078469</td>\n",
       "      <td>11.735945</td>\n",
       "      <td>16.111497</td>\n",
       "      <td>18.142478</td>\n",
       "      <td>13.539838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.004046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.021142</td>\n",
       "      <td>12.643165</td>\n",
       "      <td>20.218837</td>\n",
       "      <td>22.950314</td>\n",
       "      <td>20.679862</td>\n",
       "      <td>12.888323</td>\n",
       "      <td>11.614003</td>\n",
       "      <td>15.879573</td>\n",
       "      <td>17.881589</td>\n",
       "      <td>13.330785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.003933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.824358</td>\n",
       "      <td>12.517779</td>\n",
       "      <td>19.902334</td>\n",
       "      <td>22.569245</td>\n",
       "      <td>20.398636</td>\n",
       "      <td>12.678654</td>\n",
       "      <td>11.491152</td>\n",
       "      <td>15.648011</td>\n",
       "      <td>17.635582</td>\n",
       "      <td>13.118641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.003783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.615051</td>\n",
       "      <td>12.400658</td>\n",
       "      <td>19.586463</td>\n",
       "      <td>22.195706</td>\n",
       "      <td>20.124669</td>\n",
       "      <td>12.453331</td>\n",
       "      <td>11.369833</td>\n",
       "      <td>15.418428</td>\n",
       "      <td>17.407024</td>\n",
       "      <td>12.900863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.003597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.406888</td>\n",
       "      <td>12.275768</td>\n",
       "      <td>19.271061</td>\n",
       "      <td>21.819514</td>\n",
       "      <td>19.842709</td>\n",
       "      <td>12.253250</td>\n",
       "      <td>11.244309</td>\n",
       "      <td>15.187043</td>\n",
       "      <td>17.158334</td>\n",
       "      <td>12.683974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.003378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2          3          4          5   \\\n",
       "0  12.209726  12.769014  20.533919  23.334040  20.961187  13.078469   \n",
       "1  12.021142  12.643165  20.218837  22.950314  20.679862  12.888323   \n",
       "2  11.824358  12.517779  19.902334  22.569245  20.398636  12.678654   \n",
       "3  11.615051  12.400658  19.586463  22.195706  20.124669  12.453331   \n",
       "4  11.406888  12.275768  19.271061  21.819514  19.842709  12.253250   \n",
       "\n",
       "          6          7          8          9     ...           46        47  \\\n",
       "0  11.735945  16.111497  18.142478  13.539838    ...    -0.000233 -0.000153   \n",
       "1  11.614003  15.879573  17.881589  13.330785    ...    -0.000233 -0.000153   \n",
       "2  11.491152  15.648011  17.635582  13.118641    ...    -0.000233 -0.000153   \n",
       "3  11.369833  15.418428  17.407024  12.900863    ...    -0.000232 -0.000152   \n",
       "4  11.244309  15.187043  17.158334  12.683974    ...    -0.000232 -0.000152   \n",
       "\n",
       "         48        49        50        51        52        53        54  \\\n",
       "0 -0.000154 -0.000156 -0.000248 -0.000156 -0.000007 -0.000153 -0.000093   \n",
       "1 -0.000153 -0.000156 -0.000248 -0.000156 -0.000007 -0.000153 -0.000093   \n",
       "2 -0.000153 -0.000156 -0.000248 -0.000156 -0.000006 -0.000152 -0.000093   \n",
       "3 -0.000153 -0.000156 -0.000248 -0.000155 -0.000006 -0.000152 -0.000093   \n",
       "4 -0.000153 -0.000156 -0.000248 -0.000155 -0.000006 -0.000152 -0.000093   \n",
       "\n",
       "         55  \n",
       "0  0.004046  \n",
       "1  0.003933  \n",
       "2  0.003783  \n",
       "3  0.003597  \n",
       "4  0.003378  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_02train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.457454</td>\n",
       "      <td>12.445384</td>\n",
       "      <td>18.119576</td>\n",
       "      <td>19.370328</td>\n",
       "      <td>12.656703</td>\n",
       "      <td>13.892439</td>\n",
       "      <td>8.936810</td>\n",
       "      <td>20.811161</td>\n",
       "      <td>10.925257</td>\n",
       "      <td>6.555349</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-0.279654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.231003</td>\n",
       "      <td>12.254238</td>\n",
       "      <td>17.858055</td>\n",
       "      <td>19.202569</td>\n",
       "      <td>12.442125</td>\n",
       "      <td>13.667595</td>\n",
       "      <td>8.822499</td>\n",
       "      <td>20.617468</td>\n",
       "      <td>10.785753</td>\n",
       "      <td>6.574644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-0.281396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.007766</td>\n",
       "      <td>12.057109</td>\n",
       "      <td>17.595238</td>\n",
       "      <td>19.038346</td>\n",
       "      <td>12.230002</td>\n",
       "      <td>13.442645</td>\n",
       "      <td>8.719482</td>\n",
       "      <td>20.424830</td>\n",
       "      <td>10.642517</td>\n",
       "      <td>6.597178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-0.283095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.806366</td>\n",
       "      <td>11.861607</td>\n",
       "      <td>17.348878</td>\n",
       "      <td>18.880562</td>\n",
       "      <td>12.029017</td>\n",
       "      <td>13.237053</td>\n",
       "      <td>8.622327</td>\n",
       "      <td>20.241193</td>\n",
       "      <td>10.503883</td>\n",
       "      <td>6.622125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-0.000310</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-0.284728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.608479</td>\n",
       "      <td>11.667124</td>\n",
       "      <td>17.103489</td>\n",
       "      <td>18.720062</td>\n",
       "      <td>11.832847</td>\n",
       "      <td>13.036611</td>\n",
       "      <td>8.533794</td>\n",
       "      <td>20.058779</td>\n",
       "      <td>10.366837</td>\n",
       "      <td>6.650151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-0.286286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2          3          4          5         6   \\\n",
       "0  11.457454  12.445384  18.119576  19.370328  12.656703  13.892439  8.936810   \n",
       "1  11.231003  12.254238  17.858055  19.202569  12.442125  13.667595  8.822499   \n",
       "2  11.007766  12.057109  17.595238  19.038346  12.230002  13.442645  8.719482   \n",
       "3  10.806366  11.861607  17.348878  18.880562  12.029017  13.237053  8.622327   \n",
       "4  10.608479  11.667124  17.103489  18.720062  11.832847  13.036611  8.533794   \n",
       "\n",
       "          7          8         9     ...           46        47        48  \\\n",
       "0  20.811161  10.925257  6.555349    ...    -0.000073 -0.000312 -0.000002   \n",
       "1  20.617468  10.785753  6.574644    ...    -0.000071 -0.000311 -0.000002   \n",
       "2  20.424830  10.642517  6.597178    ...    -0.000070 -0.000311 -0.000002   \n",
       "3  20.241193  10.503883  6.622125    ...    -0.000069 -0.000310 -0.000002   \n",
       "4  20.058779  10.366837  6.650151    ...    -0.000067 -0.000309 -0.000002   \n",
       "\n",
       "         49        50        51        52        53       54        55  \n",
       "0  0.000016  0.000423  0.003046  0.000250 -0.000093  0.00002 -0.279654  \n",
       "1  0.000016  0.000423  0.003054  0.000249 -0.000093  0.00002 -0.281396  \n",
       "2  0.000016  0.000423  0.003067  0.000249 -0.000093  0.00002 -0.283095  \n",
       "3  0.000016  0.000422  0.003075  0.000249 -0.000094  0.00002 -0.284728  \n",
       "4  0.000016  0.000423  0.003088  0.000249 -0.000094  0.00002 -0.286286  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_03train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81920, 56),\n",
       " (81920, 56),\n",
       " (81920, 56),\n",
       " (81920, 56),\n",
       " (81920, 56),\n",
       " (79872, 56),\n",
       " (79872, 56),\n",
       " (81920, 56),\n",
       " (40960, 56),\n",
       " (40960, 56),\n",
       " (38912, 56))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_02train.shape, X_03train.shape, X_04train.shape, X_10train.shape, X_11train.shape, \\\n",
    "X_02test1.shape, X_02test2.shape, X_02test3.shape, X_02val1.shape, X_02val2.shape, X_02val3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_02train.values.dtype, X_03train.values.dtype, X_04train.values.dtype, X_10train.values.dtype, X_11train.values.dtype, \\\n",
    "X_02test1.values.dtype, X_02test2.values.dtype, X_02test3.values.dtype, X_02val1.values.dtype, \\\n",
    "X_02val2.values.dtype, X_02val3.values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a373f857718f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# In this one we should define and detect GPUs for tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# GPUs or CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Check TensorFlow Version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(input_size, output_size):\n",
    "    #     N, W, Cin = Xvalid.shape[0], Xvalid.shape[1], Xvalid.shape[2]\n",
    "    Xinputs = tf.placeholder(dtype=tf.float32, shape=[None, *input_size], name='Xinputs')\n",
    "    \n",
    "    #     N, Cout = Yvalid.shape[0], Yvalid.shape[1]\n",
    "    Yindices = tf.placeholder(dtype=tf.int32, shape=[None], name='Yindices')\n",
    "    \n",
    "    # # Batchnorm mode: training and inference/testing/validation\n",
    "    # #is_bn_training = tf.placeholder(dtype=tf.bool, shape=[], name='is_bn_training')\n",
    "    # training = tf.placeholder(dtype=tf.bool, shape=[], name='training')\n",
    "\n",
    "    # returning input data/sequences, output labels/classes\n",
    "    return Xinputs, Yindices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator/ classifier/ recognizer\n",
    "def discriminator(Xinputs, input_size, output_size, hidden_size, reuse=False, alpha=0.1, training=True):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        \n",
    "        # Flatten/Vectorize the input data tensor for FC/fully connected layer/Dense Layer\n",
    "        Xinputs_vec = tf.reshape(tensor=Xinputs, shape=[-1, input_size[0]*input_size[1]])\n",
    "        \n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=Xinputs_vec, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)\n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)\n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=output_size)   \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "        # return output logits for loss and accuracy\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the forward propagation of the model to calculate the loss.\n",
    "def model_loss(Xinputs, Yindices, input_size, output_size, hidden_size):\n",
    "    \n",
    "    # Creating logits and labels\n",
    "    Ylogits = discriminator(Xinputs=Xinputs, input_size=input_size, output_size=output_size, \n",
    "                            hidden_size=hidden_size)\n",
    "    Ylabels = tf.one_hot(indices=Yindices, depth=output_size, dtype=Ylogits.dtype)\n",
    "    \n",
    "    # Loss using logits and labels\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits, labels=Ylabels))\n",
    "    \n",
    "    # Accuracy using logits and labels\n",
    "    acc_tensor = tf.equal(x=tf.argmax(axis=1, input=Ylogits), y=tf.argmax(axis=1, input=Ylabels))\n",
    "    acc = tf.reduce_mean(axis=0, input_tensor=tf.cast(dtype=tf.float32, x=acc_tensor))\n",
    "\n",
    "    # returning loss and accuracy\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, input_size, output_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.Xinputs, self.Yindices = model_input(input_size=input_size, output_size=output_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.loss, self.acc = model_loss(Xinputs=self.Xinputs, Yindices=self.Yindices,\n",
    "                                         input_size=input_size, output_size=output_size, hidden_size=hidden_size)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        #self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)\n",
    "        self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(X, Y, batch_size):\n",
    "    \"\"\" Return a generator for batches \"\"\"\n",
    "    n_batches = len(X) // batch_size\n",
    "    X, Y = X[:n_batches*batch_size], Y[:n_batches*batch_size]\n",
    "\n",
    "    # Loop over batches and yield\n",
    "    for b in range(0, len(X), batch_size):\n",
    "        yield X[b:b+batch_size], Y[b:b+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Hyper-parameters\n",
    "\n",
    "# Number of classes Output layer or target labels\n",
    "assert Ytrain.max()==Ytest.max()==Yvalid.max(), 'Number of output classes is the same in training, validation and testing data.'\n",
    "\n",
    "# Hidden layer\n",
    "input_size = [Xvalid.shape[1], Xvalid.shape[2]]\n",
    "hidden_size = Xvalid.shape[1]* Xvalid.shape[2]\n",
    "output_size = Yvalid.max()\n",
    "\n",
    "# learning parameters\n",
    "batch_size = Xvalid.shape[0]//1  # experience mini-batch size\n",
    "train_epochs = 1000              # max number of training episodes/epochs\n",
    "learning_rate = 0.001            # learning rate for training/optimization/adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yvalid.max(), Yvalid.min(): 5 1\n",
      "Yvalid.shape: (14619,)\n",
      "Xvalid.shape: (14619, 250, 40)\n"
     ]
    }
   ],
   "source": [
    "print('Yvalid.max(), Yvalid.min():', Yvalid.max(), Yvalid.min())\n",
    "print('Yvalid.shape:', Yvalid.shape)\n",
    "print('Xvalid.shape:', Xvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = MLP(input_size=input_size, hidden_size=hidden_size, output_size=output_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss: 7.688725 train_acc: 0.2269991\n",
      "epoch: 1 valid_loss: 16.188286 valid_acc: 0.23715712\n",
      "epoch: 2 train_loss: 12.676353 train_acc: 0.2563445\n",
      "epoch: 2 valid_loss: 8.694114 valid_acc: 0.31411177\n",
      "epoch: 3 train_loss: 7.5286446 train_acc: 0.33651412\n",
      "epoch: 3 valid_loss: 5.4588995 valid_acc: 0.28032014\n",
      "epoch: 4 train_loss: 4.7111692 train_acc: 0.29109377\n",
      "epoch: 4 valid_loss: 3.5290227 valid_acc: 0.3791641\n",
      "epoch: 5 train_loss: 3.034183 train_acc: 0.4003352\n",
      "epoch: 5 valid_loss: 1.8962796 valid_acc: 0.3557699\n",
      "epoch: 6 train_loss: 1.6121278 train_acc: 0.3659621\n",
      "epoch: 6 valid_loss: 1.8903593 valid_acc: 0.3955811\n",
      "epoch: 7 train_loss: 2.0607088 train_acc: 0.35854027\n",
      "epoch: 7 valid_loss: 2.168816 valid_acc: 0.30234626\n",
      "epoch: 8 train_loss: 2.0824676 train_acc: 0.30692935\n",
      "epoch: 8 valid_loss: 1.5942453 valid_acc: 0.4086463\n",
      "epoch: 9 train_loss: 1.4510515 train_acc: 0.40820166\n",
      "epoch: 9 valid_loss: 1.1627387 valid_acc: 0.4486627\n",
      "epoch: 10 train_loss: 1.1163874 train_acc: 0.45037282\n",
      "epoch: 10 valid_loss: 1.0688372 valid_acc: 0.46131745\n",
      "epoch: 11 train_loss: 1.0201076 train_acc: 0.45427185\n",
      "epoch: 11 valid_loss: 1.0420313 valid_acc: 0.44264314\n",
      "epoch: 12 train_loss: 1.0575744 train_acc: 0.4153841\n",
      "epoch: 12 valid_loss: 1.0225041 valid_acc: 0.4733566\n",
      "epoch: 13 train_loss: 0.9590154 train_acc: 0.46901292\n",
      "epoch: 13 valid_loss: 0.8311536 valid_acc: 0.47622958\n",
      "epoch: 14 train_loss: 0.83075374 train_acc: 0.5042069\n",
      "epoch: 14 valid_loss: 0.89025265 valid_acc: 0.5053013\n",
      "epoch: 15 train_loss: 0.8962368 train_acc: 0.5021889\n",
      "epoch: 15 valid_loss: 0.84114915 valid_acc: 0.5518161\n",
      "epoch: 16 train_loss: 0.8030379 train_acc: 0.54412067\n",
      "epoch: 16 valid_loss: 0.70492876 valid_acc: 0.5685067\n",
      "epoch: 17 train_loss: 0.6958271 train_acc: 0.5689856\n",
      "epoch: 17 valid_loss: 0.67141235 valid_acc: 0.6041453\n",
      "epoch: 18 train_loss: 0.6632615 train_acc: 0.58020383\n",
      "epoch: 18 valid_loss: 0.6625925 valid_acc: 0.56570214\n",
      "epoch: 19 train_loss: 0.6566901 train_acc: 0.577023\n",
      "epoch: 19 valid_loss: 0.6607353 valid_acc: 0.6011355\n",
      "epoch: 20 train_loss: 0.64443314 train_acc: 0.60691565\n",
      "epoch: 20 valid_loss: 0.622964 valid_acc: 0.62822354\n",
      "epoch: 21 train_loss: 0.6194409 train_acc: 0.6219988\n",
      "epoch: 21 valid_loss: 0.6292451 valid_acc: 0.6014775\n",
      "epoch: 22 train_loss: 0.6200876 train_acc: 0.6134825\n",
      "epoch: 22 valid_loss: 0.5902853 valid_acc: 0.6343115\n",
      "epoch: 23 train_loss: 0.57934356 train_acc: 0.63376427\n",
      "epoch: 23 valid_loss: 0.5613397 valid_acc: 0.6790478\n",
      "epoch: 24 train_loss: 0.55400455 train_acc: 0.68544364\n",
      "epoch: 24 valid_loss: 0.5401608 valid_acc: 0.66338325\n",
      "epoch: 25 train_loss: 0.53340435 train_acc: 0.6760038\n",
      "epoch: 25 valid_loss: 0.53681517 valid_acc: 0.668924\n",
      "epoch: 26 train_loss: 0.53443193 train_acc: 0.66820574\n",
      "epoch: 26 valid_loss: 0.5381879 valid_acc: 0.64190435\n",
      "epoch: 27 train_loss: 0.53353465 train_acc: 0.6514809\n",
      "epoch: 27 valid_loss: 0.53699327 valid_acc: 0.66181\n",
      "epoch: 28 train_loss: 0.53209436 train_acc: 0.66009986\n",
      "epoch: 28 valid_loss: 0.53236794 valid_acc: 0.6672139\n",
      "epoch: 29 train_loss: 0.520653 train_acc: 0.6748409\n",
      "epoch: 29 valid_loss: 0.50723666 valid_acc: 0.675012\n",
      "epoch: 30 train_loss: 0.5009097 train_acc: 0.672139\n",
      "epoch: 30 valid_loss: 0.49115047 valid_acc: 0.66974485\n",
      "epoch: 31 train_loss: 0.48464411 train_acc: 0.6725152\n",
      "epoch: 31 valid_loss: 0.47944036 valid_acc: 0.6823312\n",
      "epoch: 32 train_loss: 0.47188488 train_acc: 0.6905397\n",
      "epoch: 32 valid_loss: 0.47367615 valid_acc: 0.69922704\n",
      "epoch: 33 train_loss: 0.46923625 train_acc: 0.7001505\n",
      "epoch: 33 valid_loss: 0.48176047 valid_acc: 0.6926602\n",
      "epoch: 34 train_loss: 0.47660026 train_acc: 0.688727\n",
      "epoch: 34 valid_loss: 0.48618898 valid_acc: 0.6798003\n",
      "epoch: 35 train_loss: 0.47679138 train_acc: 0.68174976\n",
      "epoch: 35 valid_loss: 0.4740586 valid_acc: 0.6868459\n",
      "epoch: 36 train_loss: 0.46056628 train_acc: 0.697688\n",
      "epoch: 36 valid_loss: 0.44871327 valid_acc: 0.71940625\n",
      "epoch: 37 train_loss: 0.43657553 train_acc: 0.72395515\n",
      "epoch: 37 valid_loss: 0.43228927 valid_acc: 0.728846\n",
      "epoch: 38 train_loss: 0.42354798 train_acc: 0.73373693\n",
      "epoch: 38 valid_loss: 0.4317119 valid_acc: 0.7265203\n",
      "epoch: 39 train_loss: 0.4252742 train_acc: 0.72723854\n",
      "epoch: 39 valid_loss: 0.4414016 valid_acc: 0.718859\n",
      "epoch: 40 train_loss: 0.43346572 train_acc: 0.7193036\n",
      "epoch: 40 valid_loss: 0.44154835 valid_acc: 0.71489155\n",
      "epoch: 41 train_loss: 0.4314239 train_acc: 0.71937203\n",
      "epoch: 41 valid_loss: 0.43163866 valid_acc: 0.7230317\n",
      "epoch: 42 train_loss: 0.41959894 train_acc: 0.72306585\n",
      "epoch: 42 valid_loss: 0.42002374 valid_acc: 0.7251522\n",
      "epoch: 43 train_loss: 0.412022 train_acc: 0.72142416\n",
      "epoch: 43 valid_loss: 0.42108193 valid_acc: 0.7168753\n",
      "epoch: 44 train_loss: 0.41329128 train_acc: 0.71930367\n",
      "epoch: 44 valid_loss: 0.41249672 valid_acc: 0.7215268\n",
      "epoch: 45 train_loss: 0.40055972 train_acc: 0.7280594\n",
      "epoch: 45 valid_loss: 0.39604953 valid_acc: 0.73308706\n",
      "epoch: 46 train_loss: 0.3869254 train_acc: 0.7337027\n",
      "epoch: 46 valid_loss: 0.39230663 valid_acc: 0.73390794\n",
      "epoch: 47 train_loss: 0.39042166 train_acc: 0.74030375\n",
      "epoch: 47 valid_loss: 0.39161763 valid_acc: 0.7330187\n",
      "epoch: 48 train_loss: 0.37612432 train_acc: 0.7380464\n",
      "epoch: 48 valid_loss: 0.37538576 valid_acc: 0.74293727\n",
      "epoch: 49 train_loss: 0.37618703 train_acc: 0.73028255\n",
      "epoch: 49 valid_loss: 0.35700652 valid_acc: 0.74307406\n",
      "epoch: 50 train_loss: 0.34382278 train_acc: 0.73777276\n",
      "epoch: 50 valid_loss: 0.36418486 valid_acc: 0.74594706\n",
      "epoch: 51 train_loss: 0.3670373 train_acc: 0.75094056\n",
      "epoch: 51 valid_loss: 0.3849352 valid_acc: 0.7268623\n",
      "epoch: 52 train_loss: 0.3543143 train_acc: 0.7348656\n",
      "epoch: 52 valid_loss: 0.34507903 valid_acc: 0.7618852\n",
      "epoch: 53 train_loss: 0.34170777 train_acc: 0.7586702\n",
      "epoch: 53 valid_loss: 0.36802986 valid_acc: 0.7321294\n",
      "epoch: 54 train_loss: 0.37140667 train_acc: 0.74362135\n",
      "epoch: 54 valid_loss: 0.40649456 valid_acc: 0.7252206\n",
      "epoch: 55 train_loss: 0.37997845 train_acc: 0.73106915\n",
      "epoch: 55 valid_loss: 0.37861434 valid_acc: 0.7280252\n",
      "epoch: 56 train_loss: 0.3447299 train_acc: 0.75849926\n",
      "epoch: 56 valid_loss: 0.35444483 valid_acc: 0.7833641\n",
      "epoch: 57 train_loss: 0.38244545 train_acc: 0.7396197\n",
      "epoch: 57 valid_loss: 0.32412225 valid_acc: 0.7601067\n",
      "epoch: 58 train_loss: 0.33131754 train_acc: 0.74389493\n",
      "epoch: 58 valid_loss: 0.41095886 valid_acc: 0.7399275\n",
      "epoch: 59 train_loss: 0.41294372 train_acc: 0.7408167\n",
      "epoch: 59 valid_loss: 0.38144723 valid_acc: 0.7343184\n",
      "epoch: 60 train_loss: 0.43813533 train_acc: 0.695157\n",
      "epoch: 60 valid_loss: 0.46880195 valid_acc: 0.6636569\n",
      "epoch: 61 train_loss: 0.42805934 train_acc: 0.7084616\n",
      "epoch: 61 valid_loss: 0.43943968 valid_acc: 0.705315\n",
      "epoch: 62 train_loss: 0.40416747 train_acc: 0.71157396\n",
      "epoch: 62 valid_loss: 0.40585718 valid_acc: 0.7575073\n",
      "epoch: 63 train_loss: 0.4538589 train_acc: 0.7474861\n",
      "epoch: 63 valid_loss: 0.51839036 valid_acc: 0.6391682\n",
      "epoch: 64 train_loss: 0.4353636 train_acc: 0.68188655\n",
      "epoch: 64 valid_loss: 0.6893609 valid_acc: 0.73089814\n",
      "epoch: 65 train_loss: 0.5837959 train_acc: 0.72310007\n",
      "epoch: 65 valid_loss: 0.6395315 valid_acc: 0.7430057\n",
      "epoch: 66 train_loss: 0.56158847 train_acc: 0.72816193\n",
      "epoch: 66 valid_loss: 0.6433017 valid_acc: 0.6655722\n",
      "epoch: 67 train_loss: 0.53720176 train_acc: 0.68373346\n",
      "epoch: 67 valid_loss: 0.4488582 valid_acc: 0.6991586\n",
      "epoch: 68 train_loss: 0.38719058 train_acc: 0.72785413\n",
      "epoch: 68 valid_loss: 0.62563086 valid_acc: 0.64942884\n",
      "epoch: 69 train_loss: 0.64559555 train_acc: 0.68520415\n",
      "epoch: 69 valid_loss: 0.52407974 valid_acc: 0.704631\n",
      "epoch: 70 train_loss: 0.49323493 train_acc: 0.70442575\n",
      "epoch: 70 valid_loss: 0.7409573 valid_acc: 0.71769613\n",
      "epoch: 71 train_loss: 0.72974956 train_acc: 0.668924\n",
      "epoch: 71 valid_loss: 0.64512366 valid_acc: 0.66988164\n",
      "epoch: 72 train_loss: 0.5333598 train_acc: 0.708359\n",
      "epoch: 72 valid_loss: 0.7585966 valid_acc: 0.65955263\n",
      "epoch: 73 train_loss: 0.78364 train_acc: 0.64282787\n",
      "epoch: 73 valid_loss: 1.0358253 valid_acc: 0.58574456\n",
      "epoch: 74 train_loss: 0.79849136 train_acc: 0.63140434\n",
      "epoch: 74 valid_loss: 0.83343184 valid_acc: 0.5951843\n",
      "epoch: 75 train_loss: 0.70712006 train_acc: 0.61888635\n",
      "epoch: 75 valid_loss: 0.55538124 valid_acc: 0.6555168\n",
      "epoch: 76 train_loss: 0.547967 train_acc: 0.65828717\n",
      "epoch: 76 valid_loss: 0.6199413 valid_acc: 0.69307065\n",
      "epoch: 77 train_loss: 0.6321912 train_acc: 0.6946782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 77 valid_loss: 0.55148774 valid_acc: 0.6766537\n",
      "epoch: 78 train_loss: 0.6849936 train_acc: 0.66988164\n",
      "epoch: 78 valid_loss: 1.2358253 valid_acc: 0.6388262\n",
      "epoch: 79 train_loss: 0.9872297 train_acc: 0.6188179\n",
      "epoch: 79 valid_loss: 0.959475 valid_acc: 0.6060606\n",
      "epoch: 80 train_loss: 1.2790678 train_acc: 0.5893016\n",
      "epoch: 80 valid_loss: 2.057887 valid_acc: 0.5746631\n",
      "epoch: 81 train_loss: 1.5577369 train_acc: 0.58222175\n",
      "epoch: 81 valid_loss: 1.1898404 valid_acc: 0.5579041\n",
      "epoch: 82 train_loss: 1.0625516 train_acc: 0.5848553\n",
      "epoch: 82 valid_loss: 0.87314427 valid_acc: 0.5312265\n",
      "epoch: 83 train_loss: 0.86881626 train_acc: 0.5790752\n",
      "epoch: 83 valid_loss: 0.6721019 valid_acc: 0.6366373\n",
      "epoch: 84 train_loss: 0.76674527 train_acc: 0.64508516\n",
      "epoch: 84 valid_loss: 0.51257014 valid_acc: 0.67740613\n",
      "epoch: 85 train_loss: 0.5729754 train_acc: 0.67289144\n",
      "epoch: 85 valid_loss: 0.70896477 valid_acc: 0.6455298\n",
      "epoch: 86 train_loss: 0.5685186 train_acc: 0.7157124\n",
      "epoch: 86 valid_loss: 0.8813826 valid_acc: 0.72104794\n",
      "epoch: 87 train_loss: 0.8690635 train_acc: 0.6950886\n",
      "epoch: 87 valid_loss: 0.62666035 valid_acc: 0.6840413\n",
      "epoch: 88 train_loss: 0.57105136 train_acc: 0.6784664\n",
      "epoch: 88 valid_loss: 0.9612241 valid_acc: 0.6456666\n",
      "epoch: 89 train_loss: 0.82121384 train_acc: 0.645735\n",
      "epoch: 89 valid_loss: 0.5283289 valid_acc: 0.6401943\n",
      "epoch: 90 train_loss: 0.58989596 train_acc: 0.6371161\n",
      "epoch: 90 valid_loss: 0.47052985 valid_acc: 0.7319926\n",
      "epoch: 91 train_loss: 0.51272774 train_acc: 0.70476776\n",
      "epoch: 91 valid_loss: 0.90056777 valid_acc: 0.6462138\n",
      "epoch: 92 train_loss: 0.87999415 train_acc: 0.6520966\n",
      "epoch: 92 valid_loss: 0.57646364 valid_acc: 0.7891785\n",
      "epoch: 93 train_loss: 0.63544846 train_acc: 0.7825775\n",
      "epoch: 93 valid_loss: 1.114109 valid_acc: 0.6558588\n",
      "epoch: 94 train_loss: 1.0724711 train_acc: 0.625932\n",
      "epoch: 94 valid_loss: 0.6040471 valid_acc: 0.68623024\n",
      "epoch: 95 train_loss: 0.78052294 train_acc: 0.6725836\n",
      "epoch: 95 valid_loss: 1.415177 valid_acc: 0.6303441\n",
      "epoch: 96 train_loss: 1.1037561 train_acc: 0.63738966\n",
      "epoch: 96 valid_loss: 0.611894 valid_acc: 0.69190776\n",
      "epoch: 97 train_loss: 0.53224343 train_acc: 0.7131815\n",
      "epoch: 97 valid_loss: 0.53344595 valid_acc: 0.7483412\n",
      "epoch: 98 train_loss: 0.67987186 train_acc: 0.71277106\n",
      "epoch: 98 valid_loss: 0.8117752 valid_acc: 0.6937547\n",
      "epoch: 99 train_loss: 0.81653625 train_acc: 0.7267939\n",
      "epoch: 99 valid_loss: 0.6840636 valid_acc: 0.7129763\n",
      "epoch: 100 train_loss: 1.0151424 train_acc: 0.6590054\n",
      "epoch: 100 valid_loss: 0.7960923 valid_acc: 0.66659826\n",
      "epoch: 101 train_loss: 0.6368003 train_acc: 0.69693553\n",
      "epoch: 101 valid_loss: 0.8427948 valid_acc: 0.7222108\n",
      "epoch: 102 train_loss: 0.9691807 train_acc: 0.71725154\n",
      "epoch: 102 valid_loss: 1.1389225 valid_acc: 0.622546\n",
      "epoch: 103 train_loss: 1.0557246 train_acc: 0.6395444\n",
      "epoch: 103 valid_loss: 0.91921496 valid_acc: 0.71858543\n",
      "epoch: 104 train_loss: 0.85607845 train_acc: 0.70271564\n",
      "epoch: 104 valid_loss: 0.9248829 valid_acc: 0.715302\n",
      "epoch: 105 train_loss: 0.67471087 train_acc: 0.70842737\n",
      "epoch: 105 valid_loss: 1.0591375 valid_acc: 0.68171555\n"
     ]
    }
   ],
   "source": [
    "# We should save the after training and validation\n",
    "saver = tf.train.Saver() \n",
    "\n",
    "# Loss and accuracy of the model for training and validation\n",
    "train_loss_mean, valid_loss_mean = [], []\n",
    "train_acc_mean, valid_acc_mean = [], []\n",
    "\n",
    "# now that we can calculate loss and optimize, we can start a session for calculating the error.\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize all the model parameters/variables\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "    \n",
    "    #     # Restoring/loading/uploading the trained and validated model\n",
    "    #     saver.restore(sess,'checkpoints/mlp-fnirs-har.ckpt')\n",
    "    \n",
    "    # for every epoch start feeding the arrays into the tensors in the model\n",
    "    for epoch in range(train_epochs):\n",
    "        train_loss, valid_loss = [], []\n",
    "        train_acc, valid_acc = [], []\n",
    "        \n",
    "        # Training\n",
    "        for Xinputs, Yindices in get_batches(X=Xtrain, Y=Ytrain, batch_size=batch_size):\n",
    "            feed_dict = {model.Xinputs: Xinputs, model.Yindices: Yindices}\n",
    "            loss, acc, _ = sess.run(fetches=[model.loss, model.acc, model.opt], feed_dict=feed_dict)\n",
    "            train_loss.append(loss)\n",
    "            train_acc.append(acc)\n",
    "            \n",
    "        # printing out train and validation loss\n",
    "        print('epoch:', epoch+1, 'train_loss:', np.mean(train_loss), 'train_acc:', np.mean(train_acc))\n",
    "        \n",
    "        # Saving the losses for plotting\n",
    "        train_loss_mean.append(np.mean(train_loss))\n",
    "        train_acc_mean.append(np.mean(train_acc))\n",
    "        \n",
    "        # Validation\n",
    "        for Xinputs, Yindices in get_batches(X=Xvalid, Y=Yvalid, batch_size=batch_size):\n",
    "            feed_dict = {model.Xinputs: Xinputs, model.Yindices: Yindices}\n",
    "            loss, acc = sess.run(fetches=[model.loss, model.acc], feed_dict=feed_dict)\n",
    "            valid_loss.append(loss)\n",
    "            valid_acc.append(acc)\n",
    "        \n",
    "        # printing out train and validation loss\n",
    "        print('epoch:', epoch+1, 'valid_loss:', np.mean(valid_loss), 'valid_acc:', np.mean(valid_acc))\n",
    "\n",
    "        # Saving the losses for plotting\n",
    "        valid_loss_mean.append(np.mean(valid_loss))\n",
    "        valid_acc_mean.append(np.mean(valid_acc))        \n",
    "    \n",
    "    # Saving the trained and validated model\n",
    "    saver.save(sess,'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "%matplotlib inline\n",
    "\n",
    "mplot.plot(train_loss_mean, label='train_loss_mean')\n",
    "mplot.plot(valid_loss_mean, label='valid_loss_mean')\n",
    "mplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mplot.plot(train_acc_mean, label='train_acc_mean')\n",
    "mplot.plot(valid_acc_mean, label='valid_acc_mean')\n",
    "mplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    #sess.run(fetches=tf.global_variables_initializer())\n",
    "    \n",
    "    # Restoring/loading/uploading the trained and validated model\n",
    "    saver.restore(sess,'checkpoints/model.ckpt')\n",
    "    \n",
    "    # Saving the test loss for every batch/minibtch\n",
    "    test_loss, test_acc = [], []\n",
    "    \n",
    "    # Testing\n",
    "    for Xinputs, Yindices in get_batches(X=Xtest, Y=Ytest, batch_size=batch_size):\n",
    "        feed_dict = {model.Xinputs: Xinputs, model.Yindices: Yindices}\n",
    "        loss, acc = sess.run(fetches=[model.loss, model.acc], feed_dict=feed_dict)\n",
    "        test_loss.append(loss)\n",
    "        test_acc.append(acc)\n",
    "        \n",
    "    # Printing the test loss\n",
    "    print('test_loss:', np.mean(test_loss), 'test acc', np.mean(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO:tensorflow:Restoring parameters from checkpoints/mlp-fnirs-har.ckpt\n",
    "# test_loss: 0.16514638 test acc 0.807716"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
