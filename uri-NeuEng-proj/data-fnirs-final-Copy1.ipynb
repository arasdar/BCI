{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fNIRS data for Human Activity Recognition (HAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mP12-4-17-2018\u001b[0m/  \u001b[01;34mP14-4-18-2018\u001b[0m/  \u001b[01;34mP16-4-18-2018\u001b[0m/\r\n",
      "\u001b[01;34mP13-4-17-2018\u001b[0m/  \u001b[01;34mP15-4-18-2018\u001b[0m/  \u001b[01;34mP17-4-18-2018\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "% ls ../../../datasets/fNIRs_data/\n",
    "# % find ../../datasets/fNIRs_data/ | grep fNIR_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m1. Right Hand\u001b[0m/  \u001b[01;34m2. Both Hands\u001b[0m/  \u001b[01;34m3. Left Hand\u001b[0m/  \u001b[01;34m4. Right Leg\u001b[0m/  \u001b[01;34m5. Left Leg\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "% ls ../../../datasets/fNIRs_data/P12-4-17-2018/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m2018-04-17_006\u001b[0m/\r\n",
      "fNIR_data.txt\r\n",
      "head20180417-145130.txt\r\n",
      "NIRS-2018-04-17_006_deoxyhb_T141to2511_C1to20.txt\r\n",
      "NIRS-2018-04-17_006_oxyhb_T141to2511_C1to20.txt\r\n",
      "\u001b[01;34mProcessed\u001b[0m/\r\n",
      "r_hand20180417-145128.txt\r\n",
      "r_lower_arm20180417-145129.txt\r\n",
      "r_upper_arm20180417-145129.txt\r\n"
     ]
    }
   ],
   "source": [
    "% ls ../../../datasets/fNIRs_data/P12-4-17-2018/1.\\ Right\\ Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/home/arasdar/datasets/fNIRs_data/P12-4-17-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P12-4-17-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P12-4-17-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P12-4-17-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P12-4-17-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P13-4-17-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P13-4-17-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P13-4-17-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P13-4-17-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P13-4-17-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P14-4-18-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P14-4-18-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P14-4-18-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P14-4-18-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P14-4-18-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P15-4-18-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P15-4-18-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P15-4-18-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P15-4-18-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P15-4-18-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P16-4-18-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P16-4-18-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P16-4-18-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P16-4-18-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P16-4-18-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P17-4-18-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P17-4-18-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P17-4-18-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P17-4-18-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P17-4-18-2018/5. Left Leg/fNIR_data.txt'],\n",
       " 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def find_all(name, path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            result.append(os.path.join(root, name))\n",
    "    return result\n",
    "\n",
    "allpaths = find_all(name='fNIR_data.txt', path='/home/arasdar/datasets/fNIRs_data/')\n",
    "((sorted(allpaths, reverse=False)), len(allpaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/arasdar-DL-env/lib/python3.6/site-packages/pandas/io/parsers.py:709: UserWarning: Duplicate names specified. This will raise an error in the future.\n",
      "  return _read(filepath_or_buffer, kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1196, 42)\n",
      "(2384, 42)\n",
      "(1230, 42)\n",
      "(2375, 42)\n",
      "(1197, 42)\n",
      "(1203, 42)\n",
      "(2405, 42)\n",
      "(1196, 42)\n",
      "(2380, 42)\n",
      "(1242, 42)\n",
      "(1230, 42)\n",
      "(2387, 42)\n",
      "(1224, 42)\n",
      "(2379, 42)\n",
      "(1227, 42)\n",
      "(1202, 42)\n",
      "(2372, 42)\n",
      "(1210, 42)\n",
      "(2378, 42)\n",
      "(1222, 42)\n",
      "(1196, 42)\n",
      "(2373, 42)\n",
      "(1202, 42)\n",
      "(2386, 42)\n",
      "(1229, 42)\n",
      "(1223, 42)\n",
      "(2373, 42)\n",
      "(1220, 42)\n",
      "(2372, 42)\n",
      "(1222, 42)\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# df: data frame object\n",
    "df = []\n",
    "for each_idx in range(len(allpaths)):\n",
    "    file = pd.read_csv(filepath_or_buffer=allpaths[each_idx], names=['time', 'sample', \n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel'],\n",
    "                         header=None)\n",
    "    df.append(file)\n",
    "    \n",
    "for each in range(len(df)):\n",
    "    print(df[each].shape)\n",
    "    df[each]=df[each].drop(axis=1, columns=None, index=None, labels=['time', 'sample'])\n",
    "    df[each] = df[each].dropna()\n",
    "    df[each]['channel.39'] = df[each]['channel.39'].astype(str).str[1:-1].astype(float)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64 (1195, 40) 1\n",
      "float64 (2383, 40) 2\n",
      "float64 (1229, 40) 3\n",
      "float64 (2374, 40) 4\n",
      "float64 (1196, 40) 5\n",
      "float64 (1202, 40) 1\n",
      "float64 (2404, 40) 2\n",
      "float64 (1195, 40) 3\n",
      "float64 (2379, 40) 4\n",
      "float64 (1241, 40) 5\n",
      "float64 (1229, 40) 1\n",
      "float64 (2386, 40) 2\n",
      "float64 (1223, 40) 3\n",
      "float64 (2378, 40) 4\n",
      "float64 (1226, 40) 5\n",
      "float64 (1201, 40) 1\n",
      "float64 (2371, 40) 2\n",
      "float64 (1209, 40) 3\n",
      "float64 (2377, 40) 4\n",
      "float64 (1221, 40) 5\n",
      "float64 (1195, 40) 1\n",
      "float64 (2372, 40) 2\n",
      "float64 (1201, 40) 3\n",
      "float64 (2385, 40) 4\n",
      "float64 (1228, 40) 5\n",
      "float64 (1222, 40) 1\n",
      "float64 (2372, 40) 2\n",
      "float64 (1219, 40) 3\n",
      "float64 (2371, 40) 4\n",
      "float64 (1221, 40) 5\n"
     ]
    }
   ],
   "source": [
    "# Why not working? can not convert obj to arr???\n",
    "data, labels = [], []\n",
    "for each in range(0, len(df), 1):\n",
    "    dfmat = df[each].as_matrix()\n",
    "    label=(each%5)+1\n",
    "    print(dfmat.dtype, dfmat.shape, label)\n",
    "    data.append(dfmat)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is very much like a convolution for extracting the windows\n",
    "# size/width, stride/overlap, padding, dilation, num filters/out channel\n",
    "def minibatching(X, Y, stride, width):\n",
    "    Xmb, Ymb = [], []\n",
    "    print(len(X), len(Y))\n",
    "    # 1st and 1st\n",
    "    for eachX in range(len(X)):\n",
    "        num_mb = ((X[eachX].shape[0]-width)//stride)+1\n",
    "        for each in range(num_mb):\n",
    "            # The max is (num_mb-1)*stride+width==X[idx].shape[0]\n",
    "            # The last each is (num_mb-1)\n",
    "            # each = ((each-1)*stride)+width\n",
    "            each *= stride\n",
    "            Xmb.append(X[eachX][each:each+width])\n",
    "            # There is only one label for one image signal or signal window or temporal window\n",
    "            #Ymb.append(Y[eachX][each:each+1])\n",
    "            Ymb.append(Y[eachX])\n",
    "    return Xmb, Ymb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n",
      "4307 4307\n",
      "(250, 40) float64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "width = 250\n",
    "Xmb, Ymb = minibatching(X=data, Y=labels, stride=10, width=width)\n",
    "# for eachX, eachY in zip(Xmb, Ymb):\n",
    "#     print(eachX.shape, eachY)\n",
    "print(len(Xmb), len(Ymb))\n",
    "print(Xmb[0].shape, Xmb[0].dtype)\n",
    "print(Ymb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4307, 250, 40) float64 (4307,) int64\n"
     ]
    }
   ],
   "source": [
    "# Conversion from python list to numpy array\n",
    "X, Y=np.array(object=Xmb, dtype=float), np.array(object=Ymb, dtype=int)\n",
    "print(X.shape, X.dtype, Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3014, 250, 40) (1293, 250, 40) (3014,) (1293,)\n",
      "float64 float64 int64 int64\n"
     ]
    }
   ],
   "source": [
    "# Now I should devide the data into train and test\n",
    "# Train and valid split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 30% of the training data/ entire training data is assigned to validation.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.30)\n",
    "print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)\n",
    "print(Xtrain.dtype, Xtest.dtype, Ytrain.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3014, 250, 40) float64\n",
      "(1293, 250, 40) float64\n"
     ]
    }
   ],
   "source": [
    "# # standardizing/normalizing the train and test data\n",
    "# def standardize(train, test):\n",
    "# \t\"\"\" Standardize data \"\"\"\n",
    "\n",
    "# \t# Standardize train and test\n",
    "# \tX_train = (train - np.mean(train, axis=0)[None,:,:]) / np.std(train, axis=0)[None,:,:]\n",
    "# \tX_test = (test - np.mean(test, axis=0)[None,:,:]) / np.std(test, axis=0)[None,:,:]\n",
    "\n",
    "# \treturn X_train, X_test\n",
    "\n",
    "Xtrain = (Xtrain-Xtrain.mean(axis=0))/Xtrain.std(axis=0)\n",
    "Xtest = (Xtest-Xtest.mean(axis=0))/Xtest.std(axis=0)\n",
    "print(Xtrain.shape, Xtrain.dtype)\n",
    "print(Xtest.shape, Xtest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3014, 5) float64 (1293, 5) float64\n"
     ]
    }
   ],
   "source": [
    "# Onehotencoding of the output labels\n",
    "def onehot(labels, n_class = 6):\n",
    "\t\"\"\" One-hot encoding \"\"\"\n",
    "\texpansion = np.eye(n_class)\n",
    "\ty = expansion[:, labels-1].T\n",
    "\tassert y.shape[1] == n_class, \"Wrong number of labels!\"\n",
    "\n",
    "\treturn y\n",
    "\n",
    "# print(Y.shape, Y.dtype, Y.max(axis=0), Ytrain.max(axis=0), Ytest.max(axis=0))\n",
    "# # assert Y.max(axis=0) == Ytrain.max(axis=0) == Ytest.max(axis=0), 'wrong labels'\n",
    "\n",
    "Ytrain=onehot(labels=Ytrain, n_class=Ytrain.max(axis=0))\n",
    "Ytest=onehot(labels=Ytest, n_class=Ytest.max(axis=0))\n",
    "print(Ytrain.shape, Ytrain.dtype, Ytest.shape, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 250, 40) (443, 250, 40) (1293, 250, 40) float64 float64 float64\n",
      "(1033, 5) (443, 5) (1293, 5) float64 float64 float64\n"
     ]
    }
   ],
   "source": [
    "# Now separating train and validation set\n",
    "# 30% of the training data/ entire training data is assigned to validation.\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtrain, Ytrain, test_size=0.30)\n",
    "print(Xtrain.shape, Xvalid.shape, Xtest.shape, Xtrain.dtype, Xvalid.dtype, Xtest.dtype)\n",
    "print(Ytrain.shape, Yvalid.shape, Ytest.shape, Ytrain.dtype, Yvalid.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443, 250, 40) <dtype: 'float32'> (1033, 250, 40) float64 (443, 250, 40) float64 (1293, 250, 40) float64\n"
     ]
    }
   ],
   "source": [
    "# now I can design the actual input and output tensors\n",
    "N, W, Cin = Xvalid.shape[0], Xvalid.shape[1], Xvalid.shape[2]\n",
    "X = tf.placeholder(dtype=tf.float32, name=None, shape=[N, W, Cin])\n",
    "print(X.shape, X.dtype, Xtrain.shape, Xtrain.dtype, Xvalid.shape, Xvalid.dtype, Xtest.shape, Xtest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443, 5) <dtype: 'float32'> (1033, 5) float64 (443, 5) float64 (1293, 5) float64\n"
     ]
    }
   ],
   "source": [
    "# This is the output tensor for labels\n",
    "N, Cout = Yvalid.shape[0], Yvalid.shape[1]\n",
    "Y = tf.placeholder(dtype=tf.float32, name=None, shape=[N, Cout])\n",
    "print(Y.shape, Y.dtype, Ytrain.shape, Ytrain.dtype, Yvalid.shape, Yvalid.dtype, Ytest.shape, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443, 250, 40) <dtype: 'float32'>\n",
      "(125, 40, 80) <dtype: 'float32_ref'>\n",
      "(443, 125, 80) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X.dtype)\n",
    "Wwidth, Wchannels, Wnumber = X.shape[1].value//2, X.shape[2].value, X.shape[2].value*2\n",
    "shape = [Wwidth, Wchannels, Wnumber]\n",
    "initial_value=tf.random_normal(dtype=X.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "Wconv = tf.Variable(dtype=X.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(Wconv.shape, Wconv.dtype)\n",
    "Xconv = tf.nn.conv1d(data_format='NWC', filters=Wconv, name=None, padding='SAME', stride=2, use_cudnn_on_gpu=True, \n",
    "                     value=X)\n",
    "Xconv = tf.maximum(name=None, x=-0.1*Xconv, y=Xconv)\n",
    "print(Xconv.shape, Xconv.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443, 10000) <dtype: 'float32'>\n",
      "(10000, 5) <dtype: 'float32_ref'>\n",
      "(443, 5) <dtype: 'float32'>\n",
      "(443, 5) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# This is the multiplication layer\n",
    "# this part is flatening the input\n",
    "shape = [Xconv.shape[0].value, Xconv.shape[1].value*Xconv.shape[2].value]\n",
    "Xconv_reshaped = tf.reshape(name=None, shape=shape, tensor=Xconv)\n",
    "print(Xconv_reshaped.shape, Xconv_reshaped.dtype)\n",
    "# their first axis or dimension stay the same\n",
    "shape = [Xconv_reshaped.shape[1].value, Y.shape[1].value]\n",
    "initial_value = tf.random_normal(dtype=Xconv_reshaped.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "W = tf.Variable(dtype=Xconv_reshaped.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(W.shape, W.dtype)\n",
    "# The actual multiplication\n",
    "# Y_ = Xconv_reshaped@W\n",
    "Y_ = tf.matmul(a=Xconv_reshaped, b=W, name=None)\n",
    "print(Y_.shape, Y_.dtype)\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443,) <dtype: 'float32'>\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Now I need to calculate the loss\n",
    "loss_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=Y_, name=None)\n",
    "print(loss_tensor.shape, loss_tensor.dtype)\n",
    "loss = tf.reduce_mean(axis=0, input_tensor=loss_tensor, name=None)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_Variable/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_1/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Backprop and SGD now using adam\n",
    "opt = tf.train.AdamOptimizer().minimize(loss)\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(X, Y, batch_size):\n",
    "    \"\"\" Return a generator for batches \"\"\"\n",
    "    n_batches = len(X) // batch_size\n",
    "    X, Y = X[:n_batches*batch_size], Y[:n_batches*batch_size]\n",
    "\n",
    "    # Loop over batches and yield\n",
    "    for b in range(0, len(X), batch_size):\n",
    "        yield X[b:b+batch_size], Y[b:b+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891.0303\n",
      "3436.7122\n",
      "2593.1082\n",
      "2346.883\n",
      "1914.3386\n",
      "1734.3485\n",
      "1449.2833\n",
      "1288.394\n",
      "1158.5549\n",
      "944.7952\n",
      "825.4406\n",
      "741.09106\n",
      "725.0027\n",
      "681.0395\n",
      "622.04114\n",
      "600.03436\n",
      "438.74533\n",
      "540.5747\n",
      "514.98865\n",
      "562.58136\n"
     ]
    }
   ],
   "source": [
    "# now that we can calculate loss and optimize, we can start a session for calculating the error.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "    \n",
    "    # for every epoch start feeding the arrays into the tensors in the model\n",
    "    for epoch in range(0, 10, 1):\n",
    "        \n",
    "        # get the minibatches and feed them into the tensor\n",
    "        for Xarr, Yarr in get_batches(X=Xtrain, Y=Ytrain, batch_size=Xvalid.shape[0]):\n",
    "#             Xarr, Yarr = XYarr\n",
    "#             print(Xarr.shape, Yarr.shape, Xarr.dtype, Yarr.dtype)\n",
    "            \n",
    "            feed_dict = {X:Xarr, Y:Yarr}\n",
    "            lossarr, _ = sess.run(feed_dict=feed_dict, fetches=[loss, opt])\n",
    "            print(lossarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
