{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR (human activity recognition) using DNN/DL on fNIRS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mP11-4-17-2018\u001b[0m/  \u001b[01;34mP13-4-17-2018\u001b[0m/  \u001b[01;34mP15-4-18-2018\u001b[0m/  \u001b[01;34mP17-4-18-2018\u001b[0m/  \u001b[01;34mP19-4-19-2018\u001b[0m/\r\n",
      "\u001b[01;34mP12-4-17-2018\u001b[0m/  \u001b[01;34mP14-4-18-2018\u001b[0m/  \u001b[01;34mP16-4-18-2018\u001b[0m/  \u001b[01;34mP18-4-19-2018\u001b[0m/  \u001b[01;34mP20-4-19-2018\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "% ls /home/arasdar/datasets/fNIRs-data-10subjects/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m1. Right Hand\u001b[0m/  \u001b[01;34m2. Both Hands\u001b[0m/  \u001b[01;34m3. Left Hand\u001b[0m/  \u001b[01;34m4. Right Leg\u001b[0m/  \u001b[01;34m5. Left Leg\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "% ls /home/arasdar/datasets/fNIRs-data-10subjects/P12-4-17-2018/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m2018-04-17_006\u001b[0m/\r\n",
      "fNIR_data.txt\r\n",
      "head20180417-145130.txt\r\n",
      "NIRS-2018-04-17_006_deoxyhb_T141to2511_C1to20.txt\r\n",
      "NIRS-2018-04-17_006_oxyhb_T141to2511_C1to20.txt\r\n",
      "\u001b[01;34mProcessed\u001b[0m/\r\n",
      "r_hand20180417-145128.txt\r\n",
      "r_lower_arm20180417-145129.txt\r\n",
      "r_upper_arm20180417-145129.txt\r\n"
     ]
    }
   ],
   "source": [
    "% ls /home/arasdar/datasets/fNIRs-data-10subjects/P12-4-17-2018/1.\\ Right\\ Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# % find ../../datasets/fNIRs_data/ | grep fNIR_data # NOT WORKING!!\n",
    "def find_all(name, path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            result.append(os.path.join(root, name))\n",
    "    return result\n",
    "\n",
    "allpaths = find_all(name='fNIR_data.txt', path='/home/arasdar/datasets/fNIRs-data-10subjects/')\n",
    "allpaths = sorted(allpaths, reverse=False)\n",
    "# print(allpaths, len(allpaths))\n",
    "# allpaths, len(allpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/pandas/io/parsers.py:678: UserWarning: Duplicate names specified. This will raise an error in the future.\n",
      "  return _read(filepath_or_buffer, kwds)\n"
     ]
    }
   ],
   "source": [
    "# df: data frame object\n",
    "df = []\n",
    "for each_idx in range(len(allpaths)):\n",
    "    file = pd.read_csv(filepath_or_buffer=allpaths[each_idx], names=['time', 'sample', \n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel'],\n",
    "                         header=None)\n",
    "    df.append(file)\n",
    "    \n",
    "for each in range(len(df)):\n",
    "#     print(df[each].shape, allpaths[each])\n",
    "    df[each]=df[each].drop(axis=1, columns=None, index=None, labels=['time', 'sample'])\n",
    "    df[each] = df[each].dropna()\n",
    "    df[each]['channel.39'] = df[each]['channel.39'].astype(str).str[1:-1].astype(float)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = [], []\n",
    "for each in range(0, len(df), 1):\n",
    "    dfmat = df[each].as_matrix()\n",
    "    label = allpaths[each][59:60]\n",
    "#     print(dfmat.dtype, dfmat.shape, label, allpaths[each])\n",
    "    data.append(dfmat)\n",
    "    labels.append(label)\n",
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is very much like a convolution for extracting the windows\n",
    "# size/width, stride/overlap, padding, dilation, num filters/out channel\n",
    "def minibatching(X, Y, stride, width):\n",
    "    Xmb, Ymb = [], []\n",
    "    print(len(X), len(Y))\n",
    "    # 1st and 1st\n",
    "    for eachX in range(len(X)):\n",
    "        num_mb = ((X[eachX].shape[0]-width)//stride)+1\n",
    "        for each in range(num_mb):\n",
    "            # The max is (num_mb-1)*stride+width==X[idx].shape[0]\n",
    "            # The last each is (num_mb-1)\n",
    "            # each = ((each-1)*stride)+width\n",
    "            each *= stride\n",
    "            Xmb.append(X[eachX][each:each+width])\n",
    "            # There is only one label for one image signal or signal window or temporal window\n",
    "            #Ymb.append(Y[eachX][each:each+1])\n",
    "            Ymb.append(Y[eachX])\n",
    "    return Xmb, Ymb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 48\n",
      "69615 69615\n",
      "(250, 40) float64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Width is based on the sampling rate which is roughly about 233 points per window\n",
    "# for 10sec rest and 20 sec activity\n",
    "width = 250\n",
    "Xmb, Ymb = minibatching(X=data, Y=labels, stride=1, width=width)\n",
    "# for eachX, eachY in zip(Xmb, Ymb):\n",
    "#     print(eachX.shape, eachY)\n",
    "print(len(Xmb), len(Ymb))\n",
    "print(Xmb[0].shape, Xmb[0].dtype)\n",
    "print(Ymb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69615, 250, 40) float64 (69615,) int64\n"
     ]
    }
   ],
   "source": [
    "# Conversion from python list to numpy array\n",
    "X, Y=np.array(object=Xmb, dtype=float), np.array(object=Ymb, dtype=int)\n",
    "print(X.shape, X.dtype, Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48730, 250, 40) (20885, 250, 40) (48730,) (20885,)\n",
      "float64 float64 int64 int64\n"
     ]
    }
   ],
   "source": [
    "# Now I should devide the data into train and test\n",
    "# Train and valid split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 30% of the training data/ entire training data is assigned to validation.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.30)\n",
    "print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)\n",
    "print(Xtrain.dtype, Xtest.dtype, Ytrain.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # standardizing/normalizing the train and test data\n",
    "# # def standardize(train, test):\n",
    "# # \"\"\" Standardize data \"\"\"\n",
    "# # # Standardize train and test\n",
    "# # X_train = (train - np.mean(train, axis=0)[None,:,:]) / np.std(train, axis=0)[None,:,:]\n",
    "# # X_test = (test - np.mean(test, axis=0)[None,:,:]) / np.std(test, axis=0)[None,:,:]\n",
    "# # return X_train, X_test\n",
    "\n",
    "# Xtrain = (Xtrain - Xtrain.mean(axis=0))/ Xtrain.std(axis=0)\n",
    "# Xtest = (Xtest - Xtest.mean(axis=0))/ Xtest.std(axis=0)\n",
    "# print(Xtrain.shape, Xtrain.dtype)\n",
    "# print(Xtest.shape, Xtest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23560809 0.20590258 0.18517964 ... 0.46093329 0.5279274  0.49592215]\n",
      " [0.23561636 0.2058755  0.18519695 ... 0.46097109 0.52793335 0.49596181]\n",
      " [0.23563596 0.20587837 0.18519753 ... 0.46093337 0.52789045 0.49594298]\n",
      " ...\n",
      " [0.23555652 0.20642326 0.18566778 ... 0.46190655 0.52917613 0.49877004]\n",
      " [0.23553725 0.20641371 0.18569792 ... 0.46184699 0.52914537 0.49875218]\n",
      " [0.23553967 0.2064045  0.18566768 ... 0.46187172 0.52917467 0.49876183]] [[0.19317671 0.16669308 0.22277043 ... 0.42603084 0.32873045 0.3955654 ]\n",
      " [0.19313845 0.16665441 0.22276896 ... 0.42603955 0.32870983 0.39565034]\n",
      " [0.1931707  0.16667711 0.22273841 ... 0.42604402 0.32865582 0.39566495]\n",
      " ...\n",
      " [0.1937856  0.16681899 0.22340253 ... 0.42544458 0.33035244 0.39905449]\n",
      " [0.19376731 0.1668185  0.22342971 ... 0.42545467 0.33032835 0.39903573]\n",
      " [0.19377306 0.16687328 0.22346157 ... 0.42542825 0.33035364 0.39903639]]\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.mean(axis=0), Xtrain.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23750688 0.20563448 0.18284557 ... 0.4569635  0.52787929 0.49390254]\n",
      " [0.2374863  0.20570345 0.18281442 ... 0.45689085 0.52786907 0.49384319]\n",
      " [0.23743777 0.20570397 0.1828217  ... 0.45699592 0.52796656 0.49392436]\n",
      " ...\n",
      " [0.23746366 0.20622423 0.18329864 ... 0.45778139 0.52898759 0.49654501]\n",
      " [0.2375106  0.20625165 0.18323827 ... 0.4579245  0.52907577 0.49659166]\n",
      " [0.23751252 0.20628102 0.18331419 ... 0.45787678 0.52901634 0.49657356]] [[0.19255126 0.16571486 0.2190757  ... 0.41900629 0.33053152 0.3915767 ]\n",
      " [0.19264678 0.16579607 0.2190893  ... 0.41899054 0.33058174 0.39144025]\n",
      " [0.1925735  0.16573736 0.21917049 ... 0.4189778  0.33069999 0.39147301]\n",
      " ...\n",
      " [0.19336617 0.16587925 0.2198813  ... 0.41863321 0.33208232 0.39478377]\n",
      " [0.19340748 0.16588515 0.21981469 ... 0.41861174 0.33216975 0.39483916]\n",
      " [0.19340226 0.16576797 0.21974963 ... 0.4186778  0.33213945 0.39484852]]\n"
     ]
    }
   ],
   "source": [
    "print(Xtest.mean(axis=0), Xtest.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34111, 250, 40) (14619, 250, 40) (20885, 250, 40) float64 float64 float64\n",
      "(34111,) (14619,) (20885,) int64 int64 int64\n"
     ]
    }
   ],
   "source": [
    "# Now separating train and validation set\n",
    "# 30% of the training data/ entire training data is assigned to validation.\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtrain, Ytrain, test_size=0.30)\n",
    "print(Xtrain.shape, Xvalid.shape, Xtest.shape, Xtrain.dtype, Xvalid.dtype, Xtest.dtype)\n",
    "print(Ytrain.shape, Yvalid.shape, Ytest.shape, Ytrain.dtype, Yvalid.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.8.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(input_size, output_size):\n",
    "    #     N, W, Cin = Xvalid.shape[0], Xvalid.shape[1], Xvalid.shape[2]\n",
    "    Xinputs = tf.placeholder(dtype=tf.float32, shape=[None, *input_size], name='Xinputs')\n",
    "    \n",
    "    #     N, Cout = Yvalid.shape[0], Yvalid.shape[1]\n",
    "    Yindices = tf.placeholder(dtype=tf.int32, shape=[None], name='Yindices')\n",
    "    \n",
    "    # # Batchnorm mode: training and inference/testing/validation\n",
    "    # #is_bn_training = tf.placeholder(dtype=tf.bool, shape=[], name='is_bn_training')\n",
    "    # training = tf.placeholder(dtype=tf.bool, shape=[], name='training')\n",
    "\n",
    "    # returning input data/sequences, output labels/classes\n",
    "    return Xinputs, Yindices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator/ classifier/ recognizer\n",
    "def discriminator(Xinputs, input_size, output_size, hidden_size, reuse=False, alpha=0.1, training=True):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        \n",
    "        # Flatten/Vectorize the input data tensor for FC/fully connected layer/Dense Layer\n",
    "        Xinputs_vec = tf.reshape(tensor=Xinputs, shape=[-1, input_size[0]*input_size[1]])\n",
    "        \n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=Xinputs_vec, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)\n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)\n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=output_size)   \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "        # return output logits for loss and accuracy\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Discriminator/ classifier/ recognizer\n",
    "# def discriminator(Xinputs, input_size, output_size, hidden_size, reuse=False, alpha=0.1, training=True):\n",
    "#     with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        \n",
    "#         # Flatten/Vectorize the input data tensor for FC/fully connected layer/Dense Layer\n",
    "#         Xinputs_vec = tf.reshape(tensor=Xinputs, shape=[-1, input_size[0]*input_size[1]])\n",
    "        \n",
    "#         # First fully connected layer\n",
    "#         h1 = tf.layers.dense(inputs=Xinputs_vec, units=hidden_size)\n",
    "#         nl1 = tf.maximum(alpha * h1, h1)\n",
    "        \n",
    "#         # Second fully connected layer\n",
    "#         h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "#         nl2 = tf.maximum(alpha * h2, h2)\n",
    "        \n",
    "#         # Output layer\n",
    "#         logits = tf.layers.dense(inputs=nl2, units=output_size)   \n",
    "#         #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "#         # return output logits for loss and accuracy\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the forward propagation of the model to calculate the loss.\n",
    "def model_loss(Xinputs, Yindices, input_size, output_size, hidden_size):\n",
    "    \n",
    "    # Creating logits and labels\n",
    "    Ylogits = discriminator(Xinputs=Xinputs, input_size=input_size, output_size=output_size, \n",
    "                            hidden_size=hidden_size)\n",
    "    Ylabels = tf.one_hot(indices=Yindices, depth=output_size, dtype=Ylogits.dtype)\n",
    "    \n",
    "    # Loss using logits and labels\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits, labels=Ylabels))\n",
    "    \n",
    "    # Accuracy using logits and labels\n",
    "    acc_tensor = tf.equal(x=tf.argmax(axis=1, input=Ylogits), y=tf.argmax(axis=1, input=Ylabels))\n",
    "    acc = tf.reduce_mean(axis=0, input_tensor=tf.cast(dtype=tf.float32, x=acc_tensor))\n",
    "\n",
    "    # returning loss and accuracy\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_opt(loss, learning_rate):\n",
    "#     \"\"\"\n",
    "#     Get optimization operations in order\n",
    "#     :param loss: Discriminator/classifier loss Tensor\n",
    "#     :param learning_rate: Learning Rate Placeholder\n",
    "#     :return: A tuple of (discriminator training)\n",
    "#     \"\"\"\n",
    "#     # Get weights and bias to update\n",
    "#     t_vars = tf.trainable_variables()\n",
    "#     # q_vars = [var for var in t_vars if var.name.startswith('qfunction')] # Q: action At/at\n",
    "#     # g_vars = [var for var in t_vars if var.name.startswith('generator')] # G: next state St/st\n",
    "#     # d_vars = [var for var in t_vars if var.name.startswith('discriminator')] # D: reward Rt/rt\n",
    "#     var_list = [var for var in t_vars if var.name.startswith('discriminator')] # D: reward Rt/rt\n",
    "    \n",
    "#     # Optimize\n",
    "#     with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "#         # q_opt = tf.train.AdamOptimizer(learning_rate).minimize(q_loss, var_list=q_vars)\n",
    "#         # g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "#         # d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "#         opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=var_list)\n",
    "\n",
    "#     return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, input_size, output_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.Xinputs, self.Yindices = model_input(input_size=input_size, output_size=output_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.loss, self.acc = model_loss(Xinputs=self.Xinputs, Yindices=self.Yindices,\n",
    "                                         input_size=input_size, output_size=output_size, hidden_size=hidden_size)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        #self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)\n",
    "        self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(X, Y, batch_size):\n",
    "    \"\"\" Return a generator for batches \"\"\"\n",
    "    n_batches = len(X) // batch_size\n",
    "    X, Y = X[:n_batches*batch_size], Y[:n_batches*batch_size]\n",
    "\n",
    "    # Loop over batches and yield\n",
    "    for b in range(0, len(X), batch_size):\n",
    "        yield X[b:b+batch_size], Y[b:b+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Hyper-parameters\n",
    "\n",
    "# # Input\n",
    "# Xwidth, Xchannels = Xvalid.shape[1], Xvalid.shape[2]\n",
    "\n",
    "# Output layer\n",
    "assert Ytrain.max()==Ytest.max()==Yvalid.max(), 'Output classes'\n",
    "# Ychannels = Yvalid.max()\n",
    "\n",
    "# Hidden layer\n",
    "input_size = [Xvalid.shape[1], Xvalid.shape[2]]\n",
    "hidden_size = Xvalid.shape[1]* Xvalid.shape[2]\n",
    "output_size = Yvalid.max()\n",
    "\n",
    "# learning parameters\n",
    "batch_size = Xvalid.shape[0]//1 # experience mini-batch size\n",
    "train_epochs = 1000              # max number of training episodes/epochs\n",
    "learning_rate = 0.001            # learning rate for training/optimization/adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yvalid.max(), Yvalid.min(): 5 1\n",
      "Yvalid.shape: (14619,)\n",
      "Xvalid.shape: (14619, 250, 40)\n"
     ]
    }
   ],
   "source": [
    "print('Yvalid.max(), Yvalid.min():', Yvalid.max(), Yvalid.min())\n",
    "print('Yvalid.shape:', Yvalid.shape)\n",
    "print('Xvalid.shape:', Xvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = MLP(input_size=input_size, hidden_size=hidden_size, output_size=output_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss: 6.7945423 train_acc: 0.20760652\n",
      "epoch: 1 valid_loss: 13.018539 valid_acc: 0.23531021\n",
      "epoch: 2 train_loss: 11.511367 train_acc: 0.27060676\n",
      "epoch: 2 valid_loss: 7.2873964 valid_acc: 0.31821603\n",
      "epoch: 3 train_loss: 6.666421 train_acc: 0.3046378\n",
      "epoch: 3 valid_loss: 6.0155897 valid_acc: 0.34167865\n",
      "epoch: 4 train_loss: 5.5748844 train_acc: 0.32813463\n",
      "epoch: 4 valid_loss: 4.47367 valid_acc: 0.41965935\n",
      "epoch: 5 train_loss: 4.048591 train_acc: 0.39106643\n",
      "epoch: 5 valid_loss: 3.5599895 valid_acc: 0.3676038\n",
      "epoch: 6 train_loss: 3.143035 train_acc: 0.4101854\n",
      "epoch: 6 valid_loss: 2.8266127 valid_acc: 0.3825843\n",
      "epoch: 7 train_loss: 2.523176 train_acc: 0.36681718\n",
      "epoch: 7 valid_loss: 1.9985411 valid_acc: 0.40652576\n",
      "epoch: 8 train_loss: 1.8668896 train_acc: 0.3531705\n",
      "epoch: 8 valid_loss: 1.8317511 valid_acc: 0.36527807\n",
      "epoch: 9 train_loss: 1.7085202 train_acc: 0.3826185\n",
      "epoch: 9 valid_loss: 1.4748303 valid_acc: 0.417402\n",
      "epoch: 10 train_loss: 1.3289514 train_acc: 0.46118066\n",
      "epoch: 10 valid_loss: 1.1567299 valid_acc: 0.47089404\n",
      "epoch: 11 train_loss: 1.0586903 train_acc: 0.5087899\n",
      "epoch: 11 valid_loss: 0.88990486 valid_acc: 0.53403103\n",
      "epoch: 12 train_loss: 0.8928902 train_acc: 0.53806686\n",
      "epoch: 12 valid_loss: 0.96397346 valid_acc: 0.5315685\n",
      "epoch: 13 train_loss: 0.9625436 train_acc: 0.52072644\n",
      "epoch: 13 valid_loss: 0.9853146 valid_acc: 0.5009919\n",
      "epoch: 14 train_loss: 0.9552516 train_acc: 0.4982215\n",
      "epoch: 14 valid_loss: 0.8449948 valid_acc: 0.58738625\n",
      "epoch: 15 train_loss: 0.82712513 train_acc: 0.599357\n",
      "epoch: 15 valid_loss: 0.8100676 valid_acc: 0.60394007\n",
      "epoch: 16 train_loss: 0.7833499 train_acc: 0.59508175\n",
      "epoch: 16 valid_loss: 0.7127161 valid_acc: 0.64689785\n",
      "epoch: 17 train_loss: 0.71414906 train_acc: 0.6273343\n",
      "epoch: 17 valid_loss: 0.7343306 valid_acc: 0.55058485\n",
      "epoch: 18 train_loss: 0.7069471 train_acc: 0.5488063\n",
      "epoch: 18 valid_loss: 0.69157207 valid_acc: 0.543334\n",
      "epoch: 19 train_loss: 0.6745201 train_acc: 0.56977224\n",
      "epoch: 19 valid_loss: 0.67881393 valid_acc: 0.5811615\n",
      "epoch: 20 train_loss: 0.6577003 train_acc: 0.5896778\n",
      "epoch: 20 valid_loss: 0.62207586 valid_acc: 0.6275395\n",
      "epoch: 21 train_loss: 0.6071033 train_acc: 0.6288392\n",
      "epoch: 21 valid_loss: 0.59391665 valid_acc: 0.61009645\n",
      "epoch: 22 train_loss: 0.57372713 train_acc: 0.63728714\n",
      "epoch: 22 valid_loss: 0.5711249 valid_acc: 0.6705657\n",
      "epoch: 23 train_loss: 0.55613303 train_acc: 0.67408854\n",
      "epoch: 23 valid_loss: 0.5433045 valid_acc: 0.6576373\n",
      "epoch: 24 train_loss: 0.5346371 train_acc: 0.6622204\n",
      "epoch: 24 valid_loss: 0.5480854 valid_acc: 0.6529858\n",
      "epoch: 25 train_loss: 0.5380626 train_acc: 0.66006565\n",
      "epoch: 25 valid_loss: 0.5319343 valid_acc: 0.6533279\n",
      "epoch: 26 train_loss: 0.5187261 train_acc: 0.67668784\n",
      "epoch: 26 valid_loss: 0.5145351 valid_acc: 0.65955263\n",
      "epoch: 27 train_loss: 0.4997432 train_acc: 0.6693344\n",
      "epoch: 27 valid_loss: 0.4894013 valid_acc: 0.66338325\n",
      "epoch: 28 train_loss: 0.47330767 train_acc: 0.67624325\n",
      "epoch: 28 valid_loss: 0.4743069 valid_acc: 0.6675559\n",
      "epoch: 29 train_loss: 0.46389896 train_acc: 0.6852042\n",
      "epoch: 29 valid_loss: 0.47345066 valid_acc: 0.6806895\n",
      "epoch: 30 train_loss: 0.46135637 train_acc: 0.6939941\n",
      "epoch: 30 valid_loss: 0.46496066 valid_acc: 0.67891103\n",
      "epoch: 31 train_loss: 0.4528038 train_acc: 0.6868801\n",
      "epoch: 31 valid_loss: 0.46466747 valid_acc: 0.6708393\n",
      "epoch: 32 train_loss: 0.44971865 train_acc: 0.67969763\n",
      "epoch: 32 valid_loss: 0.45645556 valid_acc: 0.6718654\n",
      "epoch: 33 train_loss: 0.44149962 train_acc: 0.68773514\n",
      "epoch: 33 valid_loss: 0.45063883 valid_acc: 0.68157876\n",
      "epoch: 34 train_loss: 0.43778887 train_acc: 0.7016896\n",
      "epoch: 34 valid_loss: 0.44126138 valid_acc: 0.6986114\n",
      "epoch: 35 train_loss: 0.4269064 train_acc: 0.7121896\n",
      "epoch: 35 valid_loss: 0.42989925 valid_acc: 0.6925234\n",
      "epoch: 36 train_loss: 0.41827825 train_acc: 0.6999453\n",
      "epoch: 36 valid_loss: 0.4272319 valid_acc: 0.6869827\n",
      "epoch: 37 train_loss: 0.4165516 train_acc: 0.6956358\n",
      "epoch: 37 valid_loss: 0.4310426 valid_acc: 0.69573843\n",
      "epoch: 38 train_loss: 0.42274088 train_acc: 0.70637524\n",
      "epoch: 38 valid_loss: 0.43673226 valid_acc: 0.7072303\n",
      "epoch: 39 train_loss: 0.42600167 train_acc: 0.7118476\n",
      "epoch: 39 valid_loss: 0.4308612 valid_acc: 0.70223683\n",
      "epoch: 40 train_loss: 0.41991073 train_acc: 0.7089746\n",
      "epoch: 40 valid_loss: 0.42309645 valid_acc: 0.70292085\n",
      "epoch: 41 train_loss: 0.41169193 train_acc: 0.70928246\n",
      "epoch: 41 valid_loss: 0.42169997 valid_acc: 0.7041521\n",
      "epoch: 42 train_loss: 0.41443086 train_acc: 0.7113688\n",
      "epoch: 42 valid_loss: 0.4232053 valid_acc: 0.7038785\n",
      "epoch: 43 train_loss: 0.41522485 train_acc: 0.71441275\n",
      "epoch: 43 valid_loss: 0.41153795 valid_acc: 0.7094877\n",
      "epoch: 44 train_loss: 0.39582062 train_acc: 0.72180045\n",
      "epoch: 44 valid_loss: 0.39687365 valid_acc: 0.70593065\n",
      "epoch: 45 train_loss: 0.38918173 train_acc: 0.71793556\n",
      "epoch: 45 valid_loss: 0.39921045 valid_acc: 0.7023052\n",
      "epoch: 46 train_loss: 0.3916396 train_acc: 0.72439975\n",
      "epoch: 46 valid_loss: 0.38812926 valid_acc: 0.7205007\n",
      "epoch: 47 train_loss: 0.3955762 train_acc: 0.7289828\n",
      "epoch: 47 valid_loss: 0.44172412 valid_acc: 0.69279706\n",
      "epoch: 48 train_loss: 0.40379226 train_acc: 0.7168411\n",
      "epoch: 48 valid_loss: 0.40379092 valid_acc: 0.72706753\n",
      "epoch: 49 train_loss: 0.39764822 train_acc: 0.7316506\n",
      "epoch: 49 valid_loss: 0.37820953 valid_acc: 0.7386962\n",
      "epoch: 50 train_loss: 0.37909317 train_acc: 0.7419112\n",
      "epoch: 50 valid_loss: 0.44050357 valid_acc: 0.6755592\n",
      "epoch: 51 train_loss: 0.42902523 train_acc: 0.7005267\n",
      "epoch: 51 valid_loss: 0.4070079 valid_acc: 0.7008003\n",
      "epoch: 52 train_loss: 0.3828627 train_acc: 0.7071619\n",
      "epoch: 52 valid_loss: 0.3691729 valid_acc: 0.7337027\n",
      "epoch: 53 train_loss: 0.38114372 train_acc: 0.7202271\n",
      "epoch: 53 valid_loss: 0.472698 valid_acc: 0.6731651\n",
      "epoch: 54 train_loss: 0.49114692 train_acc: 0.6771325\n",
      "epoch: 54 valid_loss: 0.35561153 valid_acc: 0.7166701\n",
      "epoch: 55 train_loss: 0.3875115 train_acc: 0.71923524\n",
      "epoch: 55 valid_loss: 0.5294942 valid_acc: 0.66126275\n",
      "epoch: 56 train_loss: 0.4863301 train_acc: 0.6731993\n",
      "epoch: 56 valid_loss: 0.5479574 valid_acc: 0.6281551\n",
      "epoch: 57 train_loss: 0.5041062 train_acc: 0.6517204\n",
      "epoch: 57 valid_loss: 0.4356799 valid_acc: 0.7003899\n",
      "epoch: 58 train_loss: 0.49120075 train_acc: 0.72087693\n",
      "epoch: 58 valid_loss: 0.46888262 valid_acc: 0.71119773\n",
      "epoch: 59 train_loss: 0.42854404 train_acc: 0.7076749\n",
      "epoch: 59 valid_loss: 0.46426168 valid_acc: 0.68137354\n",
      "epoch: 60 train_loss: 0.44164073 train_acc: 0.69156575\n",
      "epoch: 60 valid_loss: 0.54750496 valid_acc: 0.6494972\n",
      "epoch: 61 train_loss: 0.6231438 train_acc: 0.65777415\n",
      "epoch: 61 valid_loss: 0.40050858 valid_acc: 0.70572543\n",
      "epoch: 62 train_loss: 0.51673925 train_acc: 0.64758193\n",
      "epoch: 62 valid_loss: 0.7784843 valid_acc: 0.61830497\n",
      "epoch: 63 train_loss: 0.6437199 train_acc: 0.67969763\n",
      "epoch: 63 valid_loss: 0.7582304 valid_acc: 0.62528217\n",
      "epoch: 64 train_loss: 0.76805586 train_acc: 0.64607704\n",
      "epoch: 64 valid_loss: 0.70834833 valid_acc: 0.6780217\n",
      "epoch: 65 train_loss: 0.80222154 train_acc: 0.6511731\n",
      "epoch: 65 valid_loss: 0.4979865 valid_acc: 0.7040153\n",
      "epoch: 66 train_loss: 0.51506925 train_acc: 0.6786374\n",
      "epoch: 66 valid_loss: 0.6087523 valid_acc: 0.618989\n",
      "epoch: 67 train_loss: 0.6113715 train_acc: 0.6333538\n",
      "epoch: 67 valid_loss: 0.5254676 valid_acc: 0.65510637\n",
      "epoch: 68 train_loss: 0.61222506 train_acc: 0.6331829\n",
      "epoch: 68 valid_loss: 0.7311011 valid_acc: 0.6675559\n",
      "epoch: 69 train_loss: 0.7897919 train_acc: 0.64946306\n",
      "epoch: 69 valid_loss: 0.8639199 valid_acc: 0.62391406\n",
      "epoch: 70 train_loss: 0.6626594 train_acc: 0.6596894\n",
      "epoch: 70 valid_loss: 0.7882128 valid_acc: 0.70613587\n",
      "epoch: 71 train_loss: 0.77327365 train_acc: 0.6768931\n",
      "epoch: 71 valid_loss: 0.9023139 valid_acc: 0.6423832\n",
      "epoch: 72 train_loss: 0.91565746 train_acc: 0.6418018\n",
      "epoch: 72 valid_loss: 1.3752049 valid_acc: 0.6238457\n",
      "epoch: 73 train_loss: 1.3213 train_acc: 0.6124222\n",
      "epoch: 73 valid_loss: 1.1636024 valid_acc: 0.5808195\n",
      "epoch: 74 train_loss: 1.0725472 train_acc: 0.5981941\n",
      "epoch: 74 valid_loss: 0.75895065 valid_acc: 0.62877077\n",
      "epoch: 75 train_loss: 0.7478791 train_acc: 0.64819753\n",
      "epoch: 75 valid_loss: 0.6106789 valid_acc: 0.6840413\n",
      "epoch: 76 train_loss: 0.68998194 train_acc: 0.6588344\n",
      "epoch: 76 valid_loss: 0.5542261 valid_acc: 0.6923866\n",
      "epoch: 77 train_loss: 0.67138743 train_acc: 0.6908475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 77 valid_loss: 0.75442064 valid_acc: 0.69286543\n",
      "epoch: 78 train_loss: 0.9204589 train_acc: 0.6736781\n",
      "epoch: 78 valid_loss: 0.86517453 valid_acc: 0.62877077\n",
      "epoch: 79 train_loss: 0.7828111 train_acc: 0.635748\n",
      "epoch: 79 valid_loss: 1.2191778 valid_acc: 0.6061974\n",
      "epoch: 80 train_loss: 0.8372953 train_acc: 0.65137833\n",
      "epoch: 80 valid_loss: 0.5044117 valid_acc: 0.68575144\n",
      "epoch: 81 train_loss: 0.5100134 train_acc: 0.6741569\n",
      "epoch: 81 valid_loss: 0.7100329 valid_acc: 0.6439565\n",
      "epoch: 82 train_loss: 0.8458938 train_acc: 0.6257952\n",
      "epoch: 82 valid_loss: 0.9507564 valid_acc: 0.6851358\n",
      "epoch: 83 train_loss: 0.81695604 train_acc: 0.6787058\n",
      "epoch: 83 valid_loss: 0.872762 valid_acc: 0.62644506\n",
      "epoch: 84 train_loss: 0.7108462 train_acc: 0.64518774\n",
      "epoch: 84 valid_loss: 0.90447736 valid_acc: 0.632533\n",
      "epoch: 85 train_loss: 0.7749181 train_acc: 0.66040766\n",
      "epoch: 85 valid_loss: 1.056708 valid_acc: 0.628634\n",
      "epoch: 86 train_loss: 0.9066402 train_acc: 0.64857376\n",
      "epoch: 86 valid_loss: 0.6635743 valid_acc: 0.6445037\n",
      "epoch: 87 train_loss: 0.7212106 train_acc: 0.67610645\n",
      "epoch: 87 valid_loss: 0.979405 valid_acc: 0.6693344\n",
      "epoch: 88 train_loss: 0.74485713 train_acc: 0.68520415\n",
      "epoch: 88 valid_loss: 0.6844907 valid_acc: 0.6726862\n",
      "epoch: 89 train_loss: 0.8140902 train_acc: 0.6424858\n",
      "epoch: 89 valid_loss: 0.8343311 valid_acc: 0.6544907\n",
      "epoch: 90 train_loss: 0.80355096 train_acc: 0.6469321\n",
      "epoch: 90 valid_loss: 0.5103265 valid_acc: 0.72946167\n",
      "epoch: 91 train_loss: 0.58618593 train_acc: 0.6966277\n",
      "epoch: 91 valid_loss: 0.65060174 valid_acc: 0.7003899\n",
      "epoch: 92 train_loss: 0.64211 train_acc: 0.67853475\n",
      "epoch: 92 valid_loss: 0.44722104 valid_acc: 0.734934\n",
      "epoch: 93 train_loss: 0.49573928 train_acc: 0.7197825\n",
      "epoch: 93 valid_loss: 0.4184151 valid_acc: 0.72556263\n",
      "epoch: 94 train_loss: 0.43237156 train_acc: 0.7381148\n",
      "epoch: 94 valid_loss: 0.5479393 valid_acc: 0.6646829\n",
      "epoch: 95 train_loss: 0.48288658 train_acc: 0.6844859\n",
      "epoch: 95 valid_loss: 0.5221114 valid_acc: 0.69286543\n",
      "epoch: 96 train_loss: 0.51437485 train_acc: 0.6834941\n",
      "epoch: 96 valid_loss: 0.75946295 valid_acc: 0.6685136\n",
      "epoch: 97 train_loss: 0.66663146 train_acc: 0.69307065\n",
      "epoch: 97 valid_loss: 0.6189835 valid_acc: 0.6673507\n",
      "epoch: 98 train_loss: 0.56161124 train_acc: 0.6878377\n",
      "epoch: 98 valid_loss: 0.5265611 valid_acc: 0.70394695\n",
      "epoch: 99 train_loss: 0.4694619 train_acc: 0.7123606\n",
      "epoch: 99 valid_loss: 0.41454425 valid_acc: 0.74492097\n",
      "epoch: 100 train_loss: 0.4057561 train_acc: 0.75993574\n",
      "epoch: 100 valid_loss: 0.5258443 valid_acc: 0.7090088\n",
      "epoch: 101 train_loss: 0.63342655 train_acc: 0.6952596\n",
      "epoch: 101 valid_loss: 0.42466608 valid_acc: 0.7482044\n",
      "epoch: 102 train_loss: 0.45389283 train_acc: 0.7524797\n",
      "epoch: 102 valid_loss: 0.51529765 valid_acc: 0.7384226\n",
      "epoch: 103 train_loss: 0.50824404 train_acc: 0.73024833\n",
      "epoch: 103 valid_loss: 0.7863151 valid_acc: 0.79355633\n",
      "epoch: 104 train_loss: 1.0985515 train_acc: 0.72922224\n",
      "epoch: 104 valid_loss: 0.74961066 valid_acc: 0.7003215\n",
      "epoch: 105 train_loss: 0.6980823 train_acc: 0.69286543\n",
      "epoch: 105 valid_loss: 0.7226234 valid_acc: 0.71974826\n",
      "epoch: 106 train_loss: 0.5853639 train_acc: 0.70210004\n",
      "epoch: 106 valid_loss: 0.64859235 valid_acc: 0.6800055\n",
      "epoch: 107 train_loss: 0.6446954 train_acc: 0.67726934\n",
      "epoch: 107 valid_loss: 0.50636715 valid_acc: 0.6772009\n",
      "epoch: 108 train_loss: 0.5117611 train_acc: 0.69943225\n",
      "epoch: 108 valid_loss: 0.59836555 valid_acc: 0.73103493\n",
      "epoch: 109 train_loss: 0.50976694 train_acc: 0.7475203\n",
      "epoch: 109 valid_loss: 0.52705884 valid_acc: 0.71304464\n",
      "epoch: 110 train_loss: 0.60315716 train_acc: 0.69974005\n",
      "epoch: 110 valid_loss: 0.4942276 valid_acc: 0.70640945\n",
      "epoch: 111 train_loss: 0.5332792 train_acc: 0.6953964\n",
      "epoch: 111 valid_loss: 0.9312037 valid_acc: 0.64539295\n",
      "epoch: 112 train_loss: 0.8857273 train_acc: 0.6525412\n",
      "epoch: 112 valid_loss: 0.6420178 valid_acc: 0.70770913\n",
      "epoch: 113 train_loss: 0.66094863 train_acc: 0.72009027\n",
      "epoch: 113 valid_loss: 0.5450221 valid_acc: 0.752035\n",
      "epoch: 114 train_loss: 0.553269 train_acc: 0.7560024\n",
      "epoch: 114 valid_loss: 0.6152185 valid_acc: 0.6896505\n",
      "epoch: 115 train_loss: 0.61189383 train_acc: 0.7078118\n",
      "epoch: 115 valid_loss: 0.7075662 valid_acc: 0.64977086\n",
      "epoch: 116 train_loss: 0.6041552 train_acc: 0.68876123\n",
      "epoch: 116 valid_loss: 0.6345951 valid_acc: 0.7601751\n",
      "epoch: 117 train_loss: 0.6489333 train_acc: 0.72405773\n",
      "epoch: 117 valid_loss: 0.5139403 valid_acc: 0.7244682\n",
      "epoch: 118 train_loss: 0.4772193 train_acc: 0.70705926\n",
      "epoch: 118 valid_loss: 0.62380135 valid_acc: 0.71605444\n",
      "epoch: 119 train_loss: 0.51273566 train_acc: 0.7281278\n",
      "epoch: 119 valid_loss: 0.743298 valid_acc: 0.73308706\n",
      "epoch: 120 train_loss: 0.6250879 train_acc: 0.7368835\n",
      "epoch: 120 valid_loss: 0.84052044 valid_acc: 0.67781657\n",
      "epoch: 121 train_loss: 0.6654147 train_acc: 0.71926945\n",
      "epoch: 121 valid_loss: 0.6888061 valid_acc: 0.72973526\n",
      "epoch: 122 train_loss: 0.52860117 train_acc: 0.73260826\n",
      "epoch: 122 valid_loss: 0.7745249 valid_acc: 0.71441275\n",
      "epoch: 123 train_loss: 0.67179334 train_acc: 0.7075039\n",
      "epoch: 123 valid_loss: 0.4921429 valid_acc: 0.784527\n",
      "epoch: 124 train_loss: 0.6822543 train_acc: 0.7255626\n",
      "epoch: 124 valid_loss: 0.3829473 valid_acc: 0.7717354\n",
      "epoch: 125 train_loss: 0.48590693 train_acc: 0.74604964\n",
      "epoch: 125 valid_loss: 0.4650519 valid_acc: 0.74608386\n",
      "epoch: 126 train_loss: 0.38772076 train_acc: 0.7535057\n",
      "epoch: 126 valid_loss: 0.615702 valid_acc: 0.7491621\n",
      "epoch: 127 train_loss: 0.47556353 train_acc: 0.77758396\n",
      "epoch: 127 valid_loss: 0.34367052 valid_acc: 0.7534715\n",
      "epoch: 128 train_loss: 0.38205642 train_acc: 0.7299063\n",
      "epoch: 128 valid_loss: 0.31897843 valid_acc: 0.7590122\n",
      "epoch: 129 train_loss: 0.4793534 train_acc: 0.7399959\n",
      "epoch: 129 valid_loss: 0.29689032 valid_acc: 0.850879\n",
      "epoch: 130 train_loss: 0.52432835 train_acc: 0.77874684\n",
      "epoch: 130 valid_loss: 0.6684278 valid_acc: 0.6831521\n",
      "epoch: 131 train_loss: 0.61191124 train_acc: 0.71673846\n",
      "epoch: 131 valid_loss: 0.7409558 valid_acc: 0.62706065\n",
      "epoch: 132 train_loss: 0.63679683 train_acc: 0.71930367\n",
      "epoch: 132 valid_loss: 0.77797455 valid_acc: 0.708188\n",
      "epoch: 133 train_loss: 0.6351491 train_acc: 0.7098297\n",
      "epoch: 133 valid_loss: 0.31974876 valid_acc: 0.77221423\n",
      "epoch: 134 train_loss: 0.45363587 train_acc: 0.7437239\n",
      "epoch: 134 valid_loss: 0.25294057 valid_acc: 0.76769954\n",
      "epoch: 135 train_loss: 0.3528641 train_acc: 0.7773788\n",
      "epoch: 135 valid_loss: 0.58453393 valid_acc: 0.7680416\n",
      "epoch: 136 train_loss: 0.49020416 train_acc: 0.77840483\n",
      "epoch: 136 valid_loss: 0.35304293 valid_acc: 0.75442916\n",
      "epoch: 137 train_loss: 0.49650687 train_acc: 0.7549764\n",
      "epoch: 137 valid_loss: 0.541537 valid_acc: 0.70928246\n",
      "epoch: 138 train_loss: 0.5309042 train_acc: 0.7267939\n",
      "epoch: 138 valid_loss: 0.32445005 valid_acc: 0.7705041\n",
      "epoch: 139 train_loss: 0.32544065 train_acc: 0.8050482\n",
      "epoch: 139 valid_loss: 0.42875308 valid_acc: 0.7962925\n",
      "epoch: 140 train_loss: 0.37096637 train_acc: 0.79324853\n",
      "epoch: 140 valid_loss: 0.19398831 valid_acc: 0.7903413\n",
      "epoch: 141 train_loss: 0.20107013 train_acc: 0.7862713\n",
      "epoch: 141 valid_loss: 0.26268843 valid_acc: 0.7547028\n",
      "epoch: 142 train_loss: 0.2284345 train_acc: 0.76544225\n",
      "epoch: 142 valid_loss: 0.25121692 valid_acc: 0.7711882\n",
      "epoch: 143 train_loss: 0.28476483 train_acc: 0.765237\n",
      "epoch: 143 valid_loss: 0.37569126 valid_acc: 0.7612012\n",
      "epoch: 144 train_loss: 0.3941006 train_acc: 0.8011492\n",
      "epoch: 144 valid_loss: 0.64699596 valid_acc: 0.75073534\n",
      "epoch: 145 train_loss: 0.5916643 train_acc: 0.7646556\n",
      "epoch: 145 valid_loss: 0.37228775 valid_acc: 0.77077776\n",
      "epoch: 146 train_loss: 0.34735352 train_acc: 0.7603119\n",
      "epoch: 146 valid_loss: 0.28710884 valid_acc: 0.798071\n",
      "epoch: 147 train_loss: 0.39993966 train_acc: 0.7805253\n",
      "epoch: 147 valid_loss: 0.3862067 valid_acc: 0.7680416\n",
      "epoch: 148 train_loss: 0.28908956 train_acc: 0.84845066\n",
      "epoch: 148 valid_loss: 0.3663176 valid_acc: 0.73972225\n",
      "epoch: 149 train_loss: 0.3365184 train_acc: 0.7499145\n",
      "epoch: 149 valid_loss: 0.21546213 valid_acc: 0.7830221\n",
      "epoch: 150 train_loss: 0.2537448 train_acc: 0.7886312\n",
      "epoch: 150 valid_loss: 0.16071624 valid_acc: 0.8192763\n",
      "epoch: 151 train_loss: 0.23026171 train_acc: 0.7931117\n",
      "epoch: 151 valid_loss: 0.45731387 valid_acc: 0.7453314\n",
      "epoch: 152 train_loss: 0.35341436 train_acc: 0.8160271\n",
      "epoch: 152 valid_loss: 0.3212226 valid_acc: 0.78254324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 153 train_loss: 0.4799577 train_acc: 0.7665025\n",
      "epoch: 153 valid_loss: 0.32272968 valid_acc: 0.7895205\n",
      "epoch: 154 train_loss: 0.42346996 train_acc: 0.7514194\n",
      "epoch: 154 valid_loss: 0.3275203 valid_acc: 0.80039674\n",
      "epoch: 155 train_loss: 0.33331186 train_acc: 0.860524\n",
      "epoch: 155 valid_loss: 0.26189867 valid_acc: 0.7795335\n",
      "epoch: 156 train_loss: 0.23652977 train_acc: 0.784014\n",
      "epoch: 156 valid_loss: 0.27514353 valid_acc: 0.79389834\n",
      "epoch: 157 train_loss: 0.27187985 train_acc: 0.78969145\n",
      "epoch: 157 valid_loss: 0.26864532 valid_acc: 0.7843218\n",
      "epoch: 158 train_loss: 0.28270757 train_acc: 0.7906834\n",
      "epoch: 158 valid_loss: 0.31653082 valid_acc: 0.8062111\n",
      "epoch: 159 train_loss: 0.38202232 train_acc: 0.80846846\n",
      "epoch: 159 valid_loss: 0.22573353 valid_acc: 0.7986866\n",
      "epoch: 160 train_loss: 0.29022118 train_acc: 0.78452694\n",
      "epoch: 160 valid_loss: 0.16295171 valid_acc: 0.8095629\n",
      "epoch: 161 train_loss: 0.29781306 train_acc: 0.79844725\n",
      "epoch: 161 valid_loss: 0.30408296 valid_acc: 0.7847322\n",
      "epoch: 162 train_loss: 0.456506 train_acc: 0.83046037\n",
      "epoch: 162 valid_loss: 0.26304197 valid_acc: 0.8275532\n",
      "epoch: 163 train_loss: 0.29269668 train_acc: 0.8074766\n",
      "epoch: 163 valid_loss: 0.20782782 valid_acc: 0.78876805\n",
      "epoch: 164 train_loss: 0.18517846 train_acc: 0.7953348\n",
      "epoch: 164 valid_loss: 0.17837222 valid_acc: 0.795198\n",
      "epoch: 165 train_loss: 0.2370688 train_acc: 0.78876805\n",
      "epoch: 165 valid_loss: 0.18995252 valid_acc: 0.91593134\n",
      "epoch: 166 train_loss: 0.20138583 train_acc: 0.8579588\n",
      "epoch: 166 valid_loss: 0.1640512 valid_acc: 0.78890485\n",
      "epoch: 167 train_loss: 0.25951526 train_acc: 0.78090155\n",
      "epoch: 167 valid_loss: 0.15470415 valid_acc: 0.8043642\n",
      "epoch: 168 train_loss: 0.15983129 train_acc: 0.8424995\n",
      "epoch: 168 valid_loss: 0.17835103 valid_acc: 0.827348\n",
      "epoch: 169 train_loss: 0.23594426 train_acc: 0.81110203\n",
      "epoch: 169 valid_loss: 0.3772289 valid_acc: 0.7831589\n",
      "epoch: 170 train_loss: 0.39381766 train_acc: 0.7846296\n",
      "epoch: 170 valid_loss: 0.2236364 valid_acc: 0.83240986\n",
      "epoch: 171 train_loss: 0.24661283 train_acc: 0.80788696\n",
      "epoch: 171 valid_loss: 0.39472166 valid_acc: 0.7289828\n",
      "epoch: 172 train_loss: 0.3270223 train_acc: 0.7701963\n",
      "epoch: 172 valid_loss: 0.21788259 valid_acc: 0.7897257\n",
      "epoch: 173 train_loss: 0.1908002 train_acc: 0.8080238\n",
      "epoch: 173 valid_loss: 0.15798633 valid_acc: 0.87707776\n",
      "epoch: 174 train_loss: 0.1833285 train_acc: 0.8429441\n",
      "epoch: 174 valid_loss: 0.18208192 valid_acc: 0.8030645\n",
      "epoch: 175 train_loss: 0.16584894 train_acc: 0.8107942\n",
      "epoch: 175 valid_loss: 0.3652765 valid_acc: 0.79711336\n",
      "epoch: 176 train_loss: 0.2594772 train_acc: 0.8391135\n",
      "epoch: 176 valid_loss: 0.22632545 valid_acc: 0.8156509\n",
      "epoch: 177 train_loss: 0.33396894 train_acc: 0.7930091\n",
      "epoch: 177 valid_loss: 0.17640845 valid_acc: 0.82926327\n",
      "epoch: 178 train_loss: 0.22029808 train_acc: 0.8046378\n",
      "epoch: 178 valid_loss: 0.42672625 valid_acc: 0.7551132\n",
      "epoch: 179 train_loss: 0.39681417 train_acc: 0.7867843\n",
      "epoch: 179 valid_loss: 0.2543746 valid_acc: 0.7934879\n",
      "epoch: 180 train_loss: 0.198393 train_acc: 0.83374375\n",
      "epoch: 180 valid_loss: 0.29854953 valid_acc: 0.76380056\n",
      "epoch: 181 train_loss: 0.25875312 train_acc: 0.77180386\n",
      "epoch: 181 valid_loss: 0.3153373 valid_acc: 0.790957\n",
      "epoch: 182 train_loss: 0.2512677 train_acc: 0.79085433\n",
      "epoch: 182 valid_loss: 0.28717577 valid_acc: 0.8301525\n",
      "epoch: 183 train_loss: 0.24153051 train_acc: 0.8141802\n",
      "epoch: 183 valid_loss: 0.15956299 valid_acc: 0.8350092\n",
      "epoch: 184 train_loss: 0.2497389 train_acc: 0.7847322\n",
      "epoch: 184 valid_loss: 0.2731274 valid_acc: 0.7661947\n",
      "epoch: 185 train_loss: 0.23012221 train_acc: 0.8044668\n",
      "epoch: 185 valid_loss: 0.16374934 valid_acc: 0.87037414\n",
      "epoch: 186 train_loss: 0.2157118 train_acc: 0.8156508\n",
      "epoch: 186 valid_loss: 0.34157473 valid_acc: 0.7718038\n",
      "epoch: 187 train_loss: 0.23850039 train_acc: 0.79420614\n",
      "epoch: 187 valid_loss: 0.33763498 valid_acc: 0.7434845\n",
      "epoch: 188 train_loss: 0.26060966 train_acc: 0.78425336\n",
      "epoch: 188 valid_loss: 0.33775574 valid_acc: 0.84992135\n",
      "epoch: 189 train_loss: 0.2802295 train_acc: 0.8196525\n",
      "epoch: 189 valid_loss: 0.3566085 valid_acc: 0.7468363\n",
      "epoch: 190 train_loss: 0.41598928 train_acc: 0.72874343\n",
      "epoch: 190 valid_loss: 0.45848837 valid_acc: 0.7505301\n",
      "epoch: 191 train_loss: 0.4830277 train_acc: 0.78097\n",
      "epoch: 191 valid_loss: 0.43358657 valid_acc: 0.75579727\n",
      "epoch: 192 train_loss: 0.38075083 train_acc: 0.74420273\n",
      "epoch: 192 valid_loss: 0.5181869 valid_acc: 0.7025104\n",
      "epoch: 193 train_loss: 0.46642262 train_acc: 0.7228949\n",
      "epoch: 193 valid_loss: 0.36712724 valid_acc: 0.82208085\n",
      "epoch: 194 train_loss: 0.39793718 train_acc: 0.76547647\n",
      "epoch: 194 valid_loss: 0.41031826 valid_acc: 0.74095356\n",
      "epoch: 195 train_loss: 0.30994883 train_acc: 0.7688624\n",
      "epoch: 195 valid_loss: 0.51407117 valid_acc: 0.73124015\n",
      "epoch: 196 train_loss: 0.4031998 train_acc: 0.8117176\n",
      "epoch: 196 valid_loss: 0.5492324 valid_acc: 0.7137971\n",
      "epoch: 197 train_loss: 0.4231518 train_acc: 0.738491\n",
      "epoch: 197 valid_loss: 0.41454998 valid_acc: 0.7155072\n",
      "epoch: 198 train_loss: 0.36607498 train_acc: 0.7318216\n",
      "epoch: 198 valid_loss: 0.23910873 valid_acc: 0.8079896\n",
      "epoch: 199 train_loss: 0.2400411 train_acc: 0.8555989\n",
      "epoch: 199 valid_loss: 0.24725668 valid_acc: 0.7656475\n",
      "epoch: 200 train_loss: 0.19760734 train_acc: 0.7867843\n",
      "epoch: 200 valid_loss: 0.2727751 valid_acc: 0.75141937\n",
      "epoch: 201 train_loss: 0.31007272 train_acc: 0.74454474\n",
      "epoch: 201 valid_loss: 0.26007935 valid_acc: 0.79526645\n",
      "epoch: 202 train_loss: 0.25892997 train_acc: 0.8597715\n",
      "epoch: 202 valid_loss: 0.17901157 valid_acc: 0.80060196\n",
      "epoch: 203 train_loss: 0.15869737 train_acc: 0.8034749\n",
      "epoch: 203 valid_loss: 0.37035182 valid_acc: 0.74909365\n",
      "epoch: 204 train_loss: 0.24700013 train_acc: 0.78873384\n",
      "epoch: 204 valid_loss: 0.16953817 valid_acc: 0.7976606\n",
      "epoch: 205 train_loss: 0.15608141 train_acc: 0.83593273\n",
      "epoch: 205 valid_loss: 0.15577815 valid_acc: 0.9086121\n",
      "epoch: 206 train_loss: 0.20932375 train_acc: 0.83541965\n",
      "epoch: 206 valid_loss: 0.122444876 valid_acc: 0.8213284\n",
      "epoch: 207 train_loss: 0.13162905 train_acc: 0.8188317\n",
      "epoch: 207 valid_loss: 0.25391462 valid_acc: 0.7750188\n",
      "epoch: 208 train_loss: 0.21266752 train_acc: 0.7926329\n",
      "epoch: 208 valid_loss: 0.22988708 valid_acc: 0.8360353\n",
      "epoch: 209 train_loss: 0.18760115 train_acc: 0.8916136\n",
      "epoch: 209 valid_loss: 0.12555912 valid_acc: 0.8162665\n",
      "epoch: 210 train_loss: 0.13441621 train_acc: 0.8196525\n",
      "epoch: 210 valid_loss: 0.15884867 valid_acc: 0.82878447\n",
      "epoch: 211 train_loss: 0.129459 train_acc: 0.8292291\n",
      "epoch: 211 valid_loss: 0.07803822 valid_acc: 0.838361\n",
      "epoch: 212 train_loss: 0.098983824 train_acc: 0.8449962\n",
      "epoch: 212 valid_loss: 0.12529776 valid_acc: 0.95608455\n",
      "epoch: 213 train_loss: 0.12892556 train_acc: 0.8903482\n",
      "epoch: 213 valid_loss: 0.1713655 valid_acc: 0.79875505\n",
      "epoch: 214 train_loss: 0.17742471 train_acc: 0.7947192\n",
      "epoch: 214 valid_loss: 0.19222873 valid_acc: 0.7978658\n",
      "epoch: 215 train_loss: 0.18146646 train_acc: 0.7965319\n",
      "epoch: 215 valid_loss: 0.17453721 valid_acc: 0.89342636\n",
      "epoch: 216 train_loss: 0.16669795 train_acc: 0.88836443\n",
      "epoch: 216 valid_loss: 0.28966385 valid_acc: 0.77857584\n",
      "epoch: 217 train_loss: 0.21018066 train_acc: 0.7928381\n",
      "epoch: 217 valid_loss: 0.106854126 valid_acc: 0.83740336\n",
      "epoch: 218 train_loss: 0.25442368 train_acc: 0.78777623\n",
      "epoch: 218 valid_loss: 0.29666078 valid_acc: 0.75791776\n",
      "epoch: 219 train_loss: 0.421099 train_acc: 0.7496409\n",
      "epoch: 219 valid_loss: 0.22784689 valid_acc: 0.87789863\n",
      "epoch: 220 train_loss: 0.33086437 train_acc: 0.79023874\n",
      "epoch: 220 valid_loss: 0.43748748 valid_acc: 0.7332239\n",
      "epoch: 221 train_loss: 0.36005193 train_acc: 0.78028595\n",
      "epoch: 221 valid_loss: 0.33839005 valid_acc: 0.74437374\n",
      "epoch: 222 train_loss: 0.26125354 train_acc: 0.7574389\n",
      "epoch: 222 valid_loss: 0.22995593 valid_acc: 0.79355633\n",
      "epoch: 223 train_loss: 0.25749514 train_acc: 0.7810042\n",
      "epoch: 223 valid_loss: 0.25617632 valid_acc: 0.78069633\n",
      "epoch: 224 train_loss: 0.25193375 train_acc: 0.7838429\n",
      "epoch: 224 valid_loss: 0.11223334 valid_acc: 0.934674\n",
      "epoch: 225 train_loss: 0.16689992 train_acc: 0.8622341\n",
      "epoch: 225 valid_loss: 0.19527432 valid_acc: 0.78938365\n",
      "epoch: 226 train_loss: 0.3326642 train_acc: 0.78226966\n",
      "epoch: 226 valid_loss: 0.4227792 valid_acc: 0.6923866\n",
      "epoch: 227 train_loss: 0.4991246 train_acc: 0.7558999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 227 valid_loss: 0.43208176 valid_acc: 0.74560505\n",
      "epoch: 228 train_loss: 0.44472954 train_acc: 0.75391614\n",
      "epoch: 228 valid_loss: 0.60060084 valid_acc: 0.7054518\n",
      "epoch: 229 train_loss: 1.2412369 train_acc: 0.6450168\n",
      "epoch: 229 valid_loss: 0.41125074 valid_acc: 0.73794377\n",
      "epoch: 230 train_loss: 0.9545927 train_acc: 0.63345647\n",
      "epoch: 230 valid_loss: 1.3031329 valid_acc: 0.6131746\n",
      "epoch: 231 train_loss: 0.98676467 train_acc: 0.6933443\n",
      "epoch: 231 valid_loss: 1.0739104 valid_acc: 0.738833\n",
      "epoch: 232 train_loss: 0.7787745 train_acc: 0.75955945\n",
      "epoch: 232 valid_loss: 0.17357533 valid_acc: 0.8121623\n",
      "epoch: 233 train_loss: 0.44497102 train_acc: 0.7599015\n",
      "epoch: 233 valid_loss: 0.15916811 valid_acc: 0.7897941\n",
      "epoch: 234 train_loss: 0.27862287 train_acc: 0.7725221\n",
      "epoch: 234 valid_loss: 0.32317352 valid_acc: 0.8477324\n",
      "epoch: 235 train_loss: 0.24856603 train_acc: 0.8299815\n",
      "epoch: 235 valid_loss: 0.1687295 valid_acc: 0.86661196\n",
      "epoch: 236 train_loss: 0.25030395 train_acc: 0.8092551\n",
      "epoch: 236 valid_loss: 0.17834157 valid_acc: 0.8122991\n",
      "epoch: 237 train_loss: 0.1952067 train_acc: 0.8138381\n",
      "epoch: 237 valid_loss: 0.16575752 valid_acc: 0.7982078\n",
      "epoch: 238 train_loss: 0.12670992 train_acc: 0.8358301\n",
      "epoch: 238 valid_loss: 0.091845416 valid_acc: 0.9486969\n",
      "epoch: 239 train_loss: 0.17184836 train_acc: 0.86685133\n",
      "epoch: 239 valid_loss: 0.13505654 valid_acc: 0.8143512\n",
      "epoch: 240 train_loss: 0.121775985 train_acc: 0.82037073\n",
      "epoch: 240 valid_loss: 0.20404305 valid_acc: 0.7931459\n",
      "epoch: 241 train_loss: 0.15567157 train_acc: 0.81182027\n",
      "epoch: 241 valid_loss: 0.2276084 valid_acc: 0.8601819\n",
      "epoch: 242 train_loss: 0.19237109 train_acc: 0.89605993\n",
      "epoch: 242 valid_loss: 0.12582926 valid_acc: 0.8198235\n",
      "epoch: 243 train_loss: 0.12182372 train_acc: 0.8172926\n",
      "epoch: 243 valid_loss: 0.10930578 valid_acc: 0.8213968\n",
      "epoch: 244 train_loss: 0.154858 train_acc: 0.80720294\n",
      "epoch: 244 valid_loss: 0.08664918 valid_acc: 0.82406455\n",
      "epoch: 245 train_loss: 0.16911963 train_acc: 0.84161025\n",
      "epoch: 245 valid_loss: 0.102089845 valid_acc: 0.8748204\n",
      "epoch: 246 train_loss: 0.20028274 train_acc: 0.83456457\n",
      "epoch: 246 valid_loss: 0.14493048 valid_acc: 0.8216704\n",
      "epoch: 247 train_loss: 0.13294956 train_acc: 0.85388875\n",
      "epoch: 247 valid_loss: 0.16159785 valid_acc: 0.807716\n",
      "epoch: 248 train_loss: 0.14353622 train_acc: 0.81924206\n",
      "epoch: 248 valid_loss: 0.32756108 valid_acc: 0.87276834\n",
      "epoch: 249 train_loss: 0.23759139 train_acc: 0.834633\n",
      "epoch: 249 valid_loss: 0.17280798 valid_acc: 0.7979342\n",
      "epoch: 250 train_loss: 0.20763093 train_acc: 0.7855189\n",
      "epoch: 250 valid_loss: 0.21788687 valid_acc: 0.80258566\n",
      "epoch: 251 train_loss: 0.3469129 train_acc: 0.8533415\n",
      "epoch: 251 valid_loss: 0.16371998 valid_acc: 0.8177714\n",
      "epoch: 252 train_loss: 0.15762827 train_acc: 0.82204664\n",
      "epoch: 252 valid_loss: 0.19724064 valid_acc: 0.80142283\n",
      "epoch: 253 train_loss: 0.20204547 train_acc: 0.8064847\n",
      "epoch: 253 valid_loss: 0.23343147 valid_acc: 0.8547096\n",
      "epoch: 254 train_loss: 0.2224671 train_acc: 0.868322\n",
      "epoch: 254 valid_loss: 0.24594177 valid_acc: 0.8075108\n",
      "epoch: 255 train_loss: 0.21087894 train_acc: 0.80545866\n",
      "epoch: 255 valid_loss: 0.22571781 valid_acc: 0.7793283\n",
      "epoch: 256 train_loss: 0.16718654 train_acc: 0.8058007\n",
      "epoch: 256 valid_loss: 0.13698576 valid_acc: 0.9008824\n",
      "epoch: 257 train_loss: 0.17996469 train_acc: 0.8316574\n",
      "epoch: 257 valid_loss: 0.07207908 valid_acc: 0.8921951\n",
      "epoch: 258 train_loss: 0.11561247 train_acc: 0.8494767\n",
      "epoch: 258 valid_loss: 0.16677727 valid_acc: 0.8006704\n",
      "epoch: 259 train_loss: 0.1623008 train_acc: 0.79386413\n",
      "epoch: 259 valid_loss: 0.11609498 valid_acc: 0.82522744\n",
      "epoch: 260 train_loss: 0.15689744 train_acc: 0.87724876\n",
      "epoch: 260 valid_loss: 0.13718301 valid_acc: 0.8101785\n",
      "epoch: 261 train_loss: 0.15733522 train_acc: 0.7976606\n",
      "epoch: 261 valid_loss: 0.23867868 valid_acc: 0.8027909\n",
      "epoch: 262 train_loss: 0.17199555 train_acc: 0.8043984\n",
      "epoch: 262 valid_loss: 0.11556677 valid_acc: 0.81893426\n",
      "epoch: 263 train_loss: 0.19810304 train_acc: 0.7976948\n",
      "epoch: 263 valid_loss: 0.17029049 valid_acc: 0.9272864\n",
      "epoch: 264 train_loss: 0.13962728 train_acc: 0.8731787\n",
      "epoch: 264 valid_loss: 0.13363984 valid_acc: 0.8146932\n",
      "epoch: 265 train_loss: 0.11262159 train_acc: 0.83559066\n",
      "epoch: 265 valid_loss: 0.11450605 valid_acc: 0.82023394\n",
      "epoch: 266 train_loss: 0.15102649 train_acc: 0.85901904\n",
      "epoch: 266 valid_loss: 0.08828463 valid_acc: 0.8365141\n",
      "epoch: 267 train_loss: 0.15554854 train_acc: 0.81541145\n",
      "epoch: 267 valid_loss: 0.07684631 valid_acc: 0.8375402\n",
      "epoch: 268 train_loss: 0.17052807 train_acc: 0.8125385\n",
      "epoch: 268 valid_loss: 0.08917482 valid_acc: 0.8443806\n",
      "epoch: 269 train_loss: 0.15635526 train_acc: 0.88125044\n",
      "epoch: 269 valid_loss: 0.15375102 valid_acc: 0.8049798\n",
      "epoch: 270 train_loss: 0.18936345 train_acc: 0.7840824\n",
      "epoch: 270 valid_loss: 0.15965962 valid_acc: 0.78411657\n",
      "epoch: 271 train_loss: 0.18151034 train_acc: 0.80210686\n",
      "epoch: 271 valid_loss: 0.11306534 valid_acc: 0.860524\n",
      "epoch: 272 train_loss: 0.19169113 train_acc: 0.88159245\n",
      "epoch: 272 valid_loss: 0.13552538 valid_acc: 0.8166769\n",
      "epoch: 273 train_loss: 0.15039657 train_acc: 0.808058\n",
      "epoch: 273 valid_loss: 0.24595535 valid_acc: 0.7913674\n",
      "epoch: 274 train_loss: 0.1599777 train_acc: 0.8140776\n",
      "epoch: 274 valid_loss: 0.1795448 valid_acc: 0.81325674\n",
      "epoch: 275 train_loss: 0.22703612 train_acc: 0.79940486\n",
      "epoch: 275 valid_loss: 0.14694557 valid_acc: 0.80894727\n",
      "epoch: 276 train_loss: 0.23685046 train_acc: 0.80590326\n",
      "epoch: 276 valid_loss: 0.16185667 valid_acc: 0.9520487\n",
      "epoch: 277 train_loss: 0.18229216 train_acc: 0.8718107\n",
      "epoch: 277 valid_loss: 0.20670755 valid_acc: 0.78739995\n",
      "epoch: 278 train_loss: 0.14902431 train_acc: 0.81024694\n",
      "epoch: 278 valid_loss: 0.1947642 valid_acc: 0.79458237\n",
      "epoch: 279 train_loss: 0.12988676 train_acc: 0.8179424\n",
      "epoch: 279 valid_loss: 0.15629736 valid_acc: 0.8103154\n",
      "epoch: 280 train_loss: 0.09121212 train_acc: 0.8982147\n",
      "epoch: 280 valid_loss: 0.06616402 valid_acc: 0.8397975\n",
      "epoch: 281 train_loss: 0.074145764 train_acc: 0.84212327\n",
      "epoch: 281 valid_loss: 0.066578545 valid_acc: 0.8375402\n",
      "epoch: 282 train_loss: 0.14212666 train_acc: 0.83480406\n",
      "epoch: 282 valid_loss: 0.12176752 valid_acc: 0.81886584\n",
      "epoch: 283 train_loss: 0.11884433 train_acc: 0.84869003\n",
      "epoch: 283 valid_loss: 0.11311312 valid_acc: 0.92591834\n",
      "epoch: 284 train_loss: 0.12510872 train_acc: 0.8669882\n",
      "epoch: 284 valid_loss: 0.09316717 valid_acc: 0.8310418\n",
      "epoch: 285 train_loss: 0.087154925 train_acc: 0.83240986\n",
      "epoch: 285 valid_loss: 0.14489086 valid_acc: 0.8075108\n",
      "epoch: 286 train_loss: 0.10826339 train_acc: 0.82385933\n",
      "epoch: 286 valid_loss: 0.11749257 valid_acc: 0.850879\n",
      "epoch: 287 train_loss: 0.12738326 train_acc: 0.8990697\n",
      "epoch: 287 valid_loss: 0.24237584 valid_acc: 0.78739995\n",
      "epoch: 288 train_loss: 0.2754843 train_acc: 0.7729667\n",
      "epoch: 288 valid_loss: 0.2014925 valid_acc: 0.7729667\n",
      "epoch: 289 train_loss: 0.19070545 train_acc: 0.77905464\n",
      "epoch: 289 valid_loss: 0.31464368 valid_acc: 0.75723374\n",
      "epoch: 290 train_loss: 0.29437202 train_acc: 0.76308227\n",
      "epoch: 290 valid_loss: 0.30596137 valid_acc: 0.92489225\n",
      "epoch: 291 train_loss: 0.29543704 train_acc: 0.90789384\n",
      "epoch: 291 valid_loss: 0.33814248 valid_acc: 0.739175\n",
      "epoch: 292 train_loss: 0.27032906 train_acc: 0.7658869\n",
      "epoch: 292 valid_loss: 0.19853206 valid_acc: 0.7979342\n",
      "epoch: 293 train_loss: 0.2220948 train_acc: 0.7899993\n",
      "epoch: 293 valid_loss: 0.1710462 valid_acc: 0.7959505\n",
      "epoch: 294 train_loss: 0.19339697 train_acc: 0.7895547\n",
      "epoch: 294 valid_loss: 0.122908995 valid_acc: 0.8181134\n",
      "epoch: 295 train_loss: 0.114463374 train_acc: 0.824646\n",
      "epoch: 295 valid_loss: 0.1324072 valid_acc: 0.82023394\n",
      "epoch: 296 train_loss: 0.12556392 train_acc: 0.8140434\n",
      "epoch: 296 valid_loss: 0.08889207 valid_acc: 0.9673712\n",
      "epoch: 297 train_loss: 0.09812519 train_acc: 0.9636774\n",
      "epoch: 297 valid_loss: 0.124475986 valid_acc: 0.8185238\n",
      "epoch: 298 train_loss: 0.15855865 train_acc: 0.8061427\n",
      "epoch: 298 valid_loss: 0.25570562 valid_acc: 0.7666051\n",
      "epoch: 299 train_loss: 0.33647263 train_acc: 0.7531637\n",
      "epoch: 299 valid_loss: 0.42925596 valid_acc: 0.76140636\n",
      "epoch: 300 train_loss: 0.37786242 train_acc: 0.7756686\n",
      "epoch: 300 valid_loss: 0.46796167 valid_acc: 0.72959846\n",
      "epoch: 301 train_loss: 0.38039422 train_acc: 0.75357413\n",
      "epoch: 301 valid_loss: 0.40723023 valid_acc: 0.758465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 302 train_loss: 0.36989224 train_acc: 0.8492373\n",
      "epoch: 302 valid_loss: 0.33052182 valid_acc: 0.88008755\n",
      "epoch: 303 train_loss: 0.33707285 train_acc: 0.82474864\n",
      "epoch: 303 valid_loss: 0.6071675 valid_acc: 0.67145497\n",
      "epoch: 304 train_loss: 0.64327633 train_acc: 0.6854778\n",
      "epoch: 304 valid_loss: 0.35779434 valid_acc: 0.7540187\n",
      "epoch: 305 train_loss: 0.320847 train_acc: 0.7665709\n",
      "epoch: 305 valid_loss: 0.21621251 valid_acc: 0.7943088\n",
      "epoch: 306 train_loss: 0.19773401 train_acc: 0.7838429\n",
      "epoch: 306 valid_loss: 0.2909949 valid_acc: 0.7858267\n",
      "epoch: 307 train_loss: 0.31385392 train_acc: 0.84462\n",
      "epoch: 307 valid_loss: 0.41520983 valid_acc: 0.74991447\n",
      "epoch: 308 train_loss: 0.38807422 train_acc: 0.7619878\n",
      "epoch: 308 valid_loss: 0.400986 valid_acc: 0.8130515\n",
      "epoch: 309 train_loss: 0.4747457 train_acc: 0.79639506\n",
      "epoch: 309 valid_loss: 0.5024904 valid_acc: 0.7817224\n",
      "epoch: 310 train_loss: 0.4003275 train_acc: 0.77785754\n",
      "epoch: 310 valid_loss: 0.32174966 valid_acc: 0.788084\n",
      "epoch: 311 train_loss: 0.35167742 train_acc: 0.82389355\n",
      "epoch: 311 valid_loss: 0.3470227 valid_acc: 0.78090155\n",
      "epoch: 312 train_loss: 0.30991113 train_acc: 0.7934195\n",
      "epoch: 312 valid_loss: 0.11539675 valid_acc: 0.8120254\n",
      "epoch: 313 train_loss: 0.14669906 train_acc: 0.7991655\n",
      "epoch: 313 valid_loss: 0.09019587 valid_acc: 0.82878447\n",
      "epoch: 314 train_loss: 0.08274174 train_acc: 0.86743283\n",
      "epoch: 314 valid_loss: 0.1568419 valid_acc: 0.85176826\n",
      "epoch: 315 train_loss: 0.113967046 train_acc: 0.8495109\n",
      "epoch: 315 valid_loss: 0.1108039 valid_acc: 0.8375402\n",
      "epoch: 316 train_loss: 0.10713666 train_acc: 0.8274848\n",
      "epoch: 316 valid_loss: 0.0886758 valid_acc: 0.83391476\n",
      "epoch: 317 train_loss: 0.15473348 train_acc: 0.8844996\n",
      "epoch: 317 valid_loss: 0.08663313 valid_acc: 0.82625353\n",
      "epoch: 318 train_loss: 0.082604185 train_acc: 0.8322389\n",
      "epoch: 318 valid_loss: 0.18510118 valid_acc: 0.79362476\n",
      "epoch: 319 train_loss: 0.1498044 train_acc: 0.8040906\n",
      "epoch: 319 valid_loss: 0.1853048 valid_acc: 0.80908406\n",
      "epoch: 320 train_loss: 0.19008356 train_acc: 0.8036802\n",
      "epoch: 320 valid_loss: 0.050208904 valid_acc: 0.85662496\n",
      "epoch: 321 train_loss: 0.1613045 train_acc: 0.8934947\n",
      "epoch: 321 valid_loss: 0.09597426 valid_acc: 0.91976196\n",
      "epoch: 322 train_loss: 0.11021756 train_acc: 0.8659621\n",
      "epoch: 322 valid_loss: 0.10851973 valid_acc: 0.8276216\n",
      "epoch: 323 train_loss: 0.0904906 train_acc: 0.8330255\n",
      "epoch: 323 valid_loss: 0.106756866 valid_acc: 0.82057595\n",
      "epoch: 324 train_loss: 0.09711093 train_acc: 0.82594573\n",
      "epoch: 324 valid_loss: 0.08737778 valid_acc: 0.8248854\n",
      "epoch: 325 train_loss: 0.079901375 train_acc: 0.82892126\n",
      "epoch: 325 valid_loss: 0.076654986 valid_acc: 0.8328887\n",
      "epoch: 326 train_loss: 0.1409317 train_acc: 0.884226\n",
      "epoch: 326 valid_loss: 0.1426329 valid_acc: 0.9485601\n",
      "epoch: 327 train_loss: 0.09235564 train_acc: 0.89992476\n",
      "epoch: 327 valid_loss: 0.09293246 valid_acc: 0.8276216\n",
      "epoch: 328 train_loss: 0.104557574 train_acc: 0.82071275\n",
      "epoch: 328 valid_loss: 0.12191428 valid_acc: 0.8101785\n",
      "epoch: 329 train_loss: 0.16028048 train_acc: 0.8003283\n",
      "epoch: 329 valid_loss: 0.4382756 valid_acc: 0.75374514\n",
      "epoch: 330 train_loss: 0.3615166 train_acc: 0.75029075\n",
      "epoch: 330 valid_loss: 0.14269215 valid_acc: 0.80539024\n",
      "epoch: 331 train_loss: 0.12931204 train_acc: 0.80275667\n",
      "epoch: 331 valid_loss: 0.07627243 valid_acc: 0.901156\n",
      "epoch: 332 train_loss: 0.13013679 train_acc: 0.9178466\n",
      "epoch: 332 valid_loss: 0.19038808 valid_acc: 0.7962241\n",
      "epoch: 333 train_loss: 0.14317942 train_acc: 0.8100075\n",
      "epoch: 333 valid_loss: 0.1958726 valid_acc: 0.7815172\n",
      "epoch: 334 train_loss: 0.17425574 train_acc: 0.80159384\n",
      "epoch: 334 valid_loss: 0.13538945 valid_acc: 0.8183186\n",
      "epoch: 335 train_loss: 0.15185426 train_acc: 0.8691429\n",
      "epoch: 335 valid_loss: 0.16026334 valid_acc: 0.8079212\n",
      "epoch: 336 train_loss: 0.1288005 train_acc: 0.8161297\n",
      "epoch: 336 valid_loss: 0.13062522 valid_acc: 0.81106776\n",
      "epoch: 337 train_loss: 0.17355902 train_acc: 0.8053218\n",
      "epoch: 337 valid_loss: 0.10868657 valid_acc: 0.82926327\n",
      "epoch: 338 train_loss: 0.10219119 train_acc: 0.89824885\n",
      "epoch: 338 valid_loss: 0.07043552 valid_acc: 0.8434914\n",
      "epoch: 339 train_loss: 0.08020617 train_acc: 0.83576167\n",
      "epoch: 339 valid_loss: 0.13906959 valid_acc: 0.8042958\n",
      "epoch: 340 train_loss: 0.12187269 train_acc: 0.8126411\n",
      "epoch: 340 valid_loss: 0.0942392 valid_acc: 0.82823724\n",
      "epoch: 341 train_loss: 0.09241562 train_acc: 0.8933922\n",
      "epoch: 341 valid_loss: 0.32266062 valid_acc: 0.7688624\n",
      "epoch: 342 train_loss: 0.22404423 train_acc: 0.79540324\n",
      "epoch: 342 valid_loss: 0.22800025 valid_acc: 0.7906833\n",
      "epoch: 343 train_loss: 0.19184802 train_acc: 0.8031329\n",
      "epoch: 343 valid_loss: 0.12760055 valid_acc: 0.8095629\n",
      "epoch: 344 train_loss: 0.10908413 train_acc: 0.89445245\n",
      "epoch: 344 valid_loss: 0.08840223 valid_acc: 0.838019\n",
      "epoch: 345 train_loss: 0.088245034 train_acc: 0.8295711\n",
      "epoch: 345 valid_loss: 0.14940427 valid_acc: 0.8081264\n",
      "epoch: 346 train_loss: 0.12706925 train_acc: 0.8116492\n",
      "epoch: 346 valid_loss: 0.14092663 valid_acc: 0.8926739\n",
      "epoch: 347 train_loss: 0.1609591 train_acc: 0.85180247\n",
      "epoch: 347 valid_loss: 0.07448627 valid_acc: 0.8785143\n",
      "epoch: 348 train_loss: 0.119618565 train_acc: 0.89004034\n",
      "epoch: 348 valid_loss: 0.15719698 valid_acc: 0.8061427\n",
      "epoch: 349 train_loss: 0.1721483 train_acc: 0.7949928\n",
      "epoch: 349 valid_loss: 0.12203839 valid_acc: 0.818045\n",
      "epoch: 350 train_loss: 0.2127572 train_acc: 0.8037827\n",
      "epoch: 350 valid_loss: 0.14342669 valid_acc: 0.81708735\n",
      "epoch: 351 train_loss: 0.19268084 train_acc: 0.8008071\n",
      "epoch: 351 valid_loss: 0.13331382 valid_acc: 0.81825024\n",
      "epoch: 352 train_loss: 0.14481887 train_acc: 0.80901563\n",
      "epoch: 352 valid_loss: 0.100064 valid_acc: 0.97954714\n",
      "epoch: 353 train_loss: 0.10454748 train_acc: 0.9721253\n",
      "epoch: 353 valid_loss: 0.12982975 valid_acc: 0.8190027\n",
      "epoch: 354 train_loss: 0.11744884 train_acc: 0.8238251\n",
      "epoch: 354 valid_loss: 0.118029624 valid_acc: 0.8183186\n",
      "epoch: 355 train_loss: 0.14991792 train_acc: 0.8008414\n",
      "epoch: 355 valid_loss: 0.15471514 valid_acc: 0.80046517\n",
      "epoch: 356 train_loss: 0.13292235 train_acc: 0.8066215\n",
      "epoch: 356 valid_loss: 0.0657425 valid_acc: 0.8381558\n",
      "epoch: 357 train_loss: 0.10152675 train_acc: 0.82721114\n",
      "epoch: 357 valid_loss: 0.06542837 valid_acc: 0.84506464\n",
      "epoch: 358 train_loss: 0.10347256 train_acc: 0.8948629\n",
      "epoch: 358 valid_loss: 0.08623422 valid_acc: 0.8336412\n",
      "epoch: 359 train_loss: 0.095348 train_acc: 0.8310418\n",
      "epoch: 359 valid_loss: 0.15557253 valid_acc: 0.92892814\n",
      "epoch: 360 train_loss: 0.15823328 train_acc: 0.85994256\n",
      "epoch: 360 valid_loss: 0.13444607 valid_acc: 0.8061427\n",
      "epoch: 361 train_loss: 0.11953038 train_acc: 0.81028116\n",
      "epoch: 361 valid_loss: 0.20060605 valid_acc: 0.78726315\n",
      "epoch: 362 train_loss: 0.1889728 train_acc: 0.79058075\n",
      "epoch: 362 valid_loss: 0.1819768 valid_acc: 0.79424036\n",
      "epoch: 363 train_loss: 0.2181795 train_acc: 0.7833299\n",
      "epoch: 363 valid_loss: 0.1246113 valid_acc: 0.8246802\n",
      "epoch: 364 train_loss: 0.28971285 train_acc: 0.80556124\n",
      "epoch: 364 valid_loss: 0.22265208 valid_acc: 0.90307134\n",
      "epoch: 365 train_loss: 0.34009868 train_acc: 0.8597031\n",
      "epoch: 365 valid_loss: 0.143494 valid_acc: 0.8164033\n",
      "epoch: 366 train_loss: 0.17144158 train_acc: 0.8095287\n",
      "epoch: 366 valid_loss: 0.121311836 valid_acc: 0.8136671\n",
      "epoch: 367 train_loss: 0.10381529 train_acc: 0.8145222\n",
      "epoch: 367 valid_loss: 0.21858607 valid_acc: 0.79608727\n",
      "epoch: 368 train_loss: 0.21655357 train_acc: 0.7974895\n",
      "epoch: 368 valid_loss: 0.09529339 valid_acc: 0.8343252\n",
      "epoch: 369 train_loss: 0.13281003 train_acc: 0.82235444\n",
      "epoch: 369 valid_loss: 0.2261861 valid_acc: 0.801286\n",
      "epoch: 370 train_loss: 0.28300324 train_acc: 0.8628497\n",
      "epoch: 370 valid_loss: 0.3631158 valid_acc: 0.88521785\n",
      "epoch: 371 train_loss: 0.24748087 train_acc: 0.853752\n",
      "epoch: 371 valid_loss: 0.22801243 valid_acc: 0.794856\n",
      "epoch: 372 train_loss: 0.20330867 train_acc: 0.7929749\n",
      "epoch: 372 valid_loss: 0.19561534 valid_acc: 0.814488\n",
      "epoch: 373 train_loss: 0.12966521 train_acc: 0.8231753\n",
      "epoch: 373 valid_loss: 0.1679645 valid_acc: 0.8073056\n",
      "epoch: 374 train_loss: 0.114631444 train_acc: 0.82536423\n",
      "epoch: 374 valid_loss: 0.12270651 valid_acc: 0.8313838\n",
      "epoch: 375 train_loss: 0.08598922 train_acc: 0.8834736\n",
      "epoch: 375 valid_loss: 0.1522664 valid_acc: 0.9431562\n",
      "epoch: 376 train_loss: 0.12456243 train_acc: 0.88169503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 376 valid_loss: 0.15887211 valid_acc: 0.8236542\n",
      "epoch: 377 train_loss: 0.19855632 train_acc: 0.8106916\n",
      "epoch: 377 valid_loss: 0.097001925 valid_acc: 0.8296053\n",
      "epoch: 378 train_loss: 0.1400661 train_acc: 0.81937885\n",
      "epoch: 378 valid_loss: 0.09409877 valid_acc: 0.95423764\n",
      "epoch: 379 train_loss: 0.14948271 train_acc: 0.8823107\n",
      "epoch: 379 valid_loss: 0.11430642 valid_acc: 0.8109994\n",
      "epoch: 380 train_loss: 0.117043294 train_acc: 0.82457757\n",
      "epoch: 380 valid_loss: 0.13273177 valid_acc: 0.923319\n",
      "epoch: 381 train_loss: 0.09185143 train_acc: 0.881011\n",
      "epoch: 381 valid_loss: 0.12731028 valid_acc: 0.8216704\n",
      "epoch: 382 train_loss: 0.09605994 train_acc: 0.8361037\n",
      "epoch: 382 valid_loss: 0.06297017 valid_acc: 0.86695397\n",
      "epoch: 383 train_loss: 0.085676774 train_acc: 0.87605166\n",
      "epoch: 383 valid_loss: 0.11149434 valid_acc: 0.837677\n",
      "epoch: 384 train_loss: 0.08746072 train_acc: 0.86144745\n",
      "epoch: 384 valid_loss: 0.10533789 valid_acc: 0.81688213\n",
      "epoch: 385 train_loss: 0.10180907 train_acc: 0.82810044\n",
      "epoch: 385 valid_loss: 0.12422299 valid_acc: 0.9668924\n",
      "epoch: 386 train_loss: 0.09998526 train_acc: 0.8988303\n",
      "epoch: 386 valid_loss: 0.15258439 valid_acc: 0.794172\n",
      "epoch: 387 train_loss: 0.12285097 train_acc: 0.8149326\n",
      "epoch: 387 valid_loss: 0.10183108 valid_acc: 0.824817\n",
      "epoch: 388 train_loss: 0.10124709 train_acc: 0.81999457\n",
      "epoch: 388 valid_loss: 0.06291094 valid_acc: 0.8350092\n",
      "epoch: 389 train_loss: 0.07159363 train_acc: 0.90409744\n",
      "epoch: 389 valid_loss: 0.07877835 valid_acc: 0.8311102\n",
      "epoch: 390 train_loss: 0.10116035 train_acc: 0.83507764\n",
      "epoch: 390 valid_loss: 0.12987177 valid_acc: 0.8095629\n",
      "epoch: 391 train_loss: 0.10307092 train_acc: 0.8255011\n",
      "epoch: 391 valid_loss: 0.0781234 valid_acc: 0.8393871\n",
      "epoch: 392 train_loss: 0.12454823 train_acc: 0.8861755\n",
      "epoch: 392 valid_loss: 0.16412131 valid_acc: 0.80025995\n",
      "epoch: 393 train_loss: 0.13032651 train_acc: 0.8101443\n",
      "epoch: 393 valid_loss: 0.15010476 valid_acc: 0.83459884\n",
      "epoch: 394 train_loss: 0.13694997 train_acc: 0.8360011\n",
      "epoch: 394 valid_loss: 0.11101779 valid_acc: 0.81359875\n",
      "epoch: 395 train_loss: 0.11077297 train_acc: 0.8791641\n",
      "epoch: 395 valid_loss: 0.13599025 valid_acc: 0.8639442\n",
      "epoch: 396 train_loss: 0.20848665 train_acc: 0.82088375\n",
      "epoch: 396 valid_loss: 0.2393557 valid_acc: 0.76222724\n",
      "epoch: 397 train_loss: 0.24942835 train_acc: 0.7749504\n",
      "epoch: 397 valid_loss: 0.37561148 valid_acc: 0.7953348\n",
      "epoch: 398 train_loss: 0.3438828 train_acc: 0.7843218\n",
      "epoch: 398 valid_loss: 0.28299594 valid_acc: 0.8265271\n",
      "epoch: 399 train_loss: 0.3203093 train_acc: 0.8645256\n",
      "epoch: 399 valid_loss: 0.22004882 valid_acc: 0.77891785\n",
      "epoch: 400 train_loss: 0.19794165 train_acc: 0.79177785\n",
      "epoch: 400 valid_loss: 0.080488004 valid_acc: 0.8264587\n",
      "epoch: 401 train_loss: 0.094259076 train_acc: 0.8227649\n",
      "epoch: 401 valid_loss: 0.13622041 valid_acc: 0.80190164\n",
      "epoch: 402 train_loss: 0.15998426 train_acc: 0.8589849\n",
      "epoch: 402 valid_loss: 0.19763865 valid_acc: 0.78610027\n",
      "epoch: 403 train_loss: 0.20060718 train_acc: 0.792325\n",
      "epoch: 403 valid_loss: 0.12569076 valid_acc: 0.947534\n",
      "epoch: 404 train_loss: 0.16276488 train_acc: 0.871195\n",
      "epoch: 404 valid_loss: 0.13538413 valid_acc: 0.82892126\n",
      "epoch: 405 train_loss: 0.14731666 train_acc: 0.8085026\n",
      "epoch: 405 valid_loss: 0.20044279 valid_acc: 0.7753608\n",
      "epoch: 406 train_loss: 0.2009851 train_acc: 0.8060401\n",
      "epoch: 406 valid_loss: 0.19238271 valid_acc: 0.81175184\n",
      "epoch: 407 train_loss: 0.21941033 train_acc: 0.8386346\n",
      "epoch: 407 valid_loss: 0.24719352 valid_acc: 0.7859635\n",
      "epoch: 408 train_loss: 0.21901834 train_acc: 0.8076818\n",
      "epoch: 408 valid_loss: 0.17634976 valid_acc: 0.79355633\n",
      "epoch: 409 train_loss: 0.1592037 train_acc: 0.8047062\n",
      "epoch: 409 valid_loss: 0.2440594 valid_acc: 0.76879406\n",
      "epoch: 410 train_loss: 0.17877495 train_acc: 0.8013202\n",
      "epoch: 410 valid_loss: 0.19150852 valid_acc: 0.9335112\n",
      "epoch: 411 train_loss: 0.16288663 train_acc: 0.8709214\n",
      "epoch: 411 valid_loss: 0.17744683 valid_acc: 0.79492444\n",
      "epoch: 412 train_loss: 0.14847772 train_acc: 0.80323553\n",
      "epoch: 412 valid_loss: 0.18547726 valid_acc: 0.81845546\n",
      "epoch: 413 train_loss: 0.13376306 train_acc: 0.82043916\n",
      "epoch: 413 valid_loss: 0.18154997 valid_acc: 0.8434914\n",
      "epoch: 414 train_loss: 0.1955511 train_acc: 0.88593614\n",
      "epoch: 414 valid_loss: 0.25579995 valid_acc: 0.7835009\n",
      "epoch: 415 train_loss: 0.22593465 train_acc: 0.7878446\n",
      "epoch: 415 valid_loss: 0.34366694 valid_acc: 0.75374514\n",
      "epoch: 416 train_loss: 0.32745293 train_acc: 0.75299263\n",
      "epoch: 416 valid_loss: 0.10404379 valid_acc: 0.83719814\n",
      "epoch: 417 train_loss: 0.16531104 train_acc: 0.8726999\n",
      "epoch: 417 valid_loss: 0.21960655 valid_acc: 0.7965661\n",
      "epoch: 418 train_loss: 0.34983587 train_acc: 0.76841784\n",
      "epoch: 418 valid_loss: 0.29360917 valid_acc: 0.76940966\n",
      "epoch: 419 train_loss: 0.27370372 train_acc: 0.8456803\n",
      "epoch: 419 valid_loss: 0.35612223 valid_acc: 0.7590122\n",
      "epoch: 420 train_loss: 0.29478532 train_acc: 0.7859634\n",
      "epoch: 420 valid_loss: 0.247198 valid_acc: 0.76626307\n",
      "epoch: 421 train_loss: 0.17904729 train_acc: 0.79205143\n",
      "epoch: 421 valid_loss: 0.24377577 valid_acc: 0.7879472\n",
      "epoch: 422 train_loss: 0.17220032 train_acc: 0.8760859\n",
      "epoch: 422 valid_loss: 0.07312065 valid_acc: 0.8374718\n",
      "epoch: 423 train_loss: 0.13150147 train_acc: 0.81021273\n",
      "epoch: 423 valid_loss: 0.24496609 valid_acc: 0.7746768\n",
      "epoch: 424 train_loss: 0.15557773 train_acc: 0.85087895\n",
      "epoch: 424 valid_loss: 0.104500584 valid_acc: 0.9516383\n",
      "epoch: 425 train_loss: 0.09796251 train_acc: 0.88480747\n",
      "epoch: 425 valid_loss: 0.09864083 valid_acc: 0.82126\n",
      "epoch: 426 train_loss: 0.07398251 train_acc: 0.83576167\n",
      "epoch: 426 valid_loss: 0.052879248 valid_acc: 0.8378138\n",
      "epoch: 427 train_loss: 0.053484544 train_acc: 0.8428757\n",
      "epoch: 427 valid_loss: 0.057808314 valid_acc: 0.8411656\n",
      "epoch: 428 train_loss: 0.0600183 train_acc: 0.840721\n",
      "epoch: 428 valid_loss: 0.098195136 valid_acc: 0.82379097\n",
      "epoch: 429 train_loss: 0.08095327 train_acc: 0.8345988\n",
      "epoch: 429 valid_loss: 0.076149054 valid_acc: 0.9683289\n",
      "epoch: 430 train_loss: 0.0950408 train_acc: 0.95591354\n",
      "epoch: 430 valid_loss: 0.13120948 valid_acc: 0.8179766\n",
      "epoch: 431 train_loss: 0.18511593 train_acc: 0.80197\n",
      "epoch: 431 valid_loss: 0.05338466 valid_acc: 0.84691155\n",
      "epoch: 432 train_loss: 0.06590817 train_acc: 0.8418155\n",
      "epoch: 432 valid_loss: 0.20384857 valid_acc: 0.801628\n",
      "epoch: 433 train_loss: 0.36525917 train_acc: 0.77440315\n",
      "epoch: 433 valid_loss: 0.48078004 valid_acc: 0.7148232\n",
      "epoch: 434 train_loss: 0.3621717 train_acc: 0.760654\n",
      "epoch: 434 valid_loss: 0.3556413 valid_acc: 0.8916479\n",
      "epoch: 435 train_loss: 0.23343042 train_acc: 0.93292975\n",
      "epoch: 435 valid_loss: 0.3623027 valid_acc: 0.7550448\n",
      "epoch: 436 train_loss: 0.2237896 train_acc: 0.7897941\n",
      "epoch: 436 valid_loss: 0.08307104 valid_acc: 0.82673234\n",
      "epoch: 437 train_loss: 0.09848595 train_acc: 0.8235173\n",
      "epoch: 437 valid_loss: 0.20945625 valid_acc: 0.77761817\n",
      "epoch: 438 train_loss: 0.2389595 train_acc: 0.7779602\n",
      "epoch: 438 valid_loss: 0.14928073 valid_acc: 0.80757916\n",
      "epoch: 439 train_loss: 0.14477175 train_acc: 0.8109652\n",
      "epoch: 439 valid_loss: 0.14865324 valid_acc: 0.8073056\n",
      "epoch: 440 train_loss: 0.12954538 train_acc: 0.8923319\n",
      "epoch: 440 valid_loss: 0.44828442 valid_acc: 0.7470415\n",
      "epoch: 441 train_loss: 0.5087174 train_acc: 0.7874684\n",
      "epoch: 441 valid_loss: 0.20100293 valid_acc: 0.7649634\n",
      "epoch: 442 train_loss: 0.17466004 train_acc: 0.7846638\n",
      "epoch: 442 valid_loss: 0.07649769 valid_acc: 0.83808744\n",
      "epoch: 443 train_loss: 0.1984326 train_acc: 0.82786095\n",
      "epoch: 443 valid_loss: 0.3344422 valid_acc: 0.77905464\n",
      "epoch: 444 train_loss: 0.2533673 train_acc: 0.7851768\n",
      "epoch: 444 valid_loss: 0.23989354 valid_acc: 0.7923251\n",
      "epoch: 445 train_loss: 0.17968072 train_acc: 0.86083174\n",
      "epoch: 445 valid_loss: 0.15064102 valid_acc: 0.9335112\n",
      "epoch: 446 train_loss: 0.12655151 train_acc: 0.8728025\n",
      "epoch: 446 valid_loss: 0.10397926 valid_acc: 0.8192079\n",
      "epoch: 447 train_loss: 0.1204944 train_acc: 0.8197893\n",
      "epoch: 447 valid_loss: 0.12806486 valid_acc: 0.8025173\n",
      "epoch: 448 train_loss: 0.106413536 train_acc: 0.80874205\n",
      "epoch: 448 valid_loss: 0.07123134 valid_acc: 0.83870304\n",
      "epoch: 449 train_loss: 0.08283396 train_acc: 0.82608247\n",
      "epoch: 449 valid_loss: 0.08126648 valid_acc: 0.83056295\n",
      "epoch: 450 train_loss: 0.0711361 train_acc: 0.841063\n",
      "epoch: 450 valid_loss: 0.24988225 valid_acc: 0.8974622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 451 train_loss: 0.19992313 train_acc: 0.85659075\n",
      "epoch: 451 valid_loss: 0.24838568 valid_acc: 0.75572884\n",
      "epoch: 452 train_loss: 0.23261657 train_acc: 0.8576168\n",
      "epoch: 452 valid_loss: 0.29871076 valid_acc: 0.7863739\n",
      "epoch: 453 train_loss: 0.25514686 train_acc: 0.7862371\n",
      "epoch: 453 valid_loss: 0.2060485 valid_acc: 0.7861687\n",
      "epoch: 454 train_loss: 0.15437621 train_acc: 0.8086736\n",
      "epoch: 454 valid_loss: 0.12987076 valid_acc: 0.8164033\n",
      "epoch: 455 train_loss: 0.11667977 train_acc: 0.8211916\n",
      "epoch: 455 valid_loss: 0.36323622 valid_acc: 0.7350024\n",
      "epoch: 456 train_loss: 0.61486447 train_acc: 0.79006773\n",
      "epoch: 456 valid_loss: 0.61582917 valid_acc: 0.74259526\n",
      "epoch: 457 train_loss: 0.32613364 train_acc: 0.7729325\n",
      "epoch: 457 valid_loss: 0.21135025 valid_acc: 0.8547096\n",
      "epoch: 458 train_loss: 0.16656867 train_acc: 0.9058417\n",
      "epoch: 458 valid_loss: 0.3233434 valid_acc: 0.7635269\n",
      "epoch: 459 train_loss: 0.34616494 train_acc: 0.7507695\n",
      "epoch: 459 valid_loss: 0.19151136 valid_acc: 0.7832273\n",
      "epoch: 460 train_loss: 0.1576843 train_acc: 0.8028593\n",
      "epoch: 460 valid_loss: 0.07647667 valid_acc: 0.8304946\n",
      "epoch: 461 train_loss: 0.14843513 train_acc: 0.83203363\n",
      "epoch: 461 valid_loss: 0.13962452 valid_acc: 0.80012316\n",
      "epoch: 462 train_loss: 0.18210727 train_acc: 0.7854847\n",
      "epoch: 462 valid_loss: 0.19806139 valid_acc: 0.79355633\n",
      "epoch: 463 train_loss: 0.28798807 train_acc: 0.8371298\n",
      "epoch: 463 valid_loss: 0.1515037 valid_acc: 0.8562829\n",
      "epoch: 464 train_loss: 0.16027236 train_acc: 0.831589\n",
      "epoch: 464 valid_loss: 0.27829462 valid_acc: 0.7713934\n",
      "epoch: 465 train_loss: 0.17628206 train_acc: 0.8255353\n",
      "epoch: 465 valid_loss: 0.2555306 valid_acc: 0.9320747\n",
      "epoch: 466 train_loss: 0.16596058 train_acc: 0.8851495\n",
      "epoch: 466 valid_loss: 0.24640158 valid_acc: 0.79574525\n",
      "epoch: 467 train_loss: 0.21099634 train_acc: 0.795027\n",
      "epoch: 467 valid_loss: 0.15483867 valid_acc: 0.7965661\n",
      "epoch: 468 train_loss: 0.10705364 train_acc: 0.8219782\n",
      "epoch: 468 valid_loss: 0.04847389 valid_acc: 0.84458584\n",
      "epoch: 469 train_loss: 0.0885493 train_acc: 0.82303846\n",
      "epoch: 469 valid_loss: 0.09965387 valid_acc: 0.82358575\n",
      "epoch: 470 train_loss: 0.108280234 train_acc: 0.82331216\n",
      "epoch: 470 valid_loss: 0.4167198 valid_acc: 0.89472604\n",
      "epoch: 471 train_loss: 0.43216258 train_acc: 0.87991655\n",
      "epoch: 471 valid_loss: 0.58887154 valid_acc: 0.7405431\n",
      "epoch: 472 train_loss: 0.31546593 train_acc: 0.7918804\n",
      "epoch: 472 valid_loss: 0.058687888 valid_acc: 0.8478692\n",
      "epoch: 473 train_loss: 0.06207989 train_acc: 0.8393871\n",
      "epoch: 473 valid_loss: 0.04870876 valid_acc: 0.84020793\n",
      "epoch: 474 train_loss: 0.0471232 train_acc: 0.8443122\n",
      "epoch: 474 valid_loss: 0.035284754 valid_acc: 0.84978455\n",
      "epoch: 475 train_loss: 0.04097046 train_acc: 0.8455777\n",
      "epoch: 475 valid_loss: 0.040336914 valid_acc: 0.8529995\n",
      "epoch: 476 train_loss: 0.044532135 train_acc: 0.8641494\n",
      "epoch: 476 valid_loss: 0.08587538 valid_acc: 0.9621725\n",
      "epoch: 477 train_loss: 0.07469192 train_acc: 0.9605308\n",
      "epoch: 477 valid_loss: 0.09057098 valid_acc: 0.8176346\n",
      "epoch: 478 train_loss: 0.08315782 train_acc: 0.8279978\n",
      "epoch: 478 valid_loss: 0.114456326 valid_acc: 0.82057595\n",
      "epoch: 479 train_loss: 0.10162097 train_acc: 0.83384633\n",
      "epoch: 479 valid_loss: 0.042144764 valid_acc: 0.8434914\n",
      "epoch: 480 train_loss: 0.12541926 train_acc: 0.826664\n",
      "epoch: 480 valid_loss: 0.08297154 valid_acc: 0.8261167\n",
      "epoch: 481 train_loss: 0.1217792 train_acc: 0.8192421\n",
      "epoch: 481 valid_loss: 0.08703463 valid_acc: 0.9570422\n",
      "epoch: 482 train_loss: 0.12445916 train_acc: 0.88330257\n",
      "epoch: 482 valid_loss: 0.075625286 valid_acc: 0.9744853\n",
      "epoch: 483 train_loss: 0.117621005 train_acc: 0.89496547\n",
      "epoch: 483 valid_loss: 0.04831507 valid_acc: 0.8421917\n",
      "epoch: 484 train_loss: 0.06635379 train_acc: 0.83870304\n",
      "epoch: 484 valid_loss: 0.050538603 valid_acc: 0.8449962\n",
      "epoch: 485 train_loss: 0.07464596 train_acc: 0.83692455\n",
      "epoch: 485 valid_loss: 0.19181015 valid_acc: 0.7998495\n",
      "epoch: 486 train_loss: 0.17254409 train_acc: 0.8032013\n",
      "epoch: 486 valid_loss: 0.30260918 valid_acc: 0.90813327\n",
      "epoch: 487 train_loss: 0.36427122 train_acc: 0.8109994\n",
      "epoch: 487 valid_loss: 0.5918643 valid_acc: 0.6845201\n",
      "epoch: 488 train_loss: 0.43507692 train_acc: 0.7949586\n",
      "epoch: 488 valid_loss: 0.30490473 valid_acc: 0.7818592\n",
      "epoch: 489 train_loss: 0.2026012 train_acc: 0.8035091\n",
      "epoch: 489 valid_loss: 0.13891397 valid_acc: 0.80361176\n",
      "epoch: 490 train_loss: 0.107214436 train_acc: 0.8198577\n",
      "epoch: 490 valid_loss: 0.15910576 valid_acc: 0.79690814\n",
      "epoch: 491 train_loss: 0.120744474 train_acc: 0.8108284\n",
      "epoch: 491 valid_loss: 0.11168237 valid_acc: 0.81093097\n",
      "epoch: 492 train_loss: 0.11016402 train_acc: 0.82273066\n",
      "epoch: 492 valid_loss: 0.17597048 valid_acc: 0.9341268\n",
      "epoch: 493 train_loss: 0.23758261 train_acc: 0.8626445\n",
      "epoch: 493 valid_loss: 0.42772552 valid_acc: 0.7426637\n",
      "epoch: 494 train_loss: 0.30297565 train_acc: 0.76609206\n",
      "epoch: 494 valid_loss: 0.34483775 valid_acc: 0.74594706\n",
      "epoch: 495 train_loss: 0.20321757 train_acc: 0.8492373\n",
      "epoch: 495 valid_loss: 0.24722746 valid_acc: 0.7695465\n",
      "epoch: 496 train_loss: 0.27158344 train_acc: 0.7724879\n",
      "epoch: 496 valid_loss: 0.46724746 valid_acc: 0.7254942\n",
      "epoch: 497 train_loss: 0.3109758 train_acc: 0.76756275\n",
      "epoch: 497 valid_loss: 0.20437707 valid_acc: 0.8046378\n",
      "epoch: 498 train_loss: 0.15320836 train_acc: 0.8806348\n",
      "epoch: 498 valid_loss: 0.15335518 valid_acc: 0.82030237\n",
      "epoch: 499 train_loss: 0.139635 train_acc: 0.81842124\n",
      "epoch: 499 valid_loss: 0.11668775 valid_acc: 0.8179082\n",
      "epoch: 500 train_loss: 0.12004508 train_acc: 0.8166427\n",
      "epoch: 500 valid_loss: 0.1106094 valid_acc: 0.82686913\n",
      "epoch: 501 train_loss: 0.18472785 train_acc: 0.8120254\n",
      "epoch: 501 valid_loss: 0.24124846 valid_acc: 0.9222245\n",
      "epoch: 502 train_loss: 0.39693373 train_acc: 0.82385933\n",
      "epoch: 502 valid_loss: 0.23576887 valid_acc: 0.76106435\n",
      "epoch: 503 train_loss: 0.21132477 train_acc: 0.7854847\n",
      "epoch: 503 valid_loss: 0.24391182 valid_acc: 0.79588205\n",
      "epoch: 504 train_loss: 0.23078877 train_acc: 0.79143584\n",
      "epoch: 504 valid_loss: 0.30412057 valid_acc: 0.79506123\n",
      "epoch: 505 train_loss: 0.25269622 train_acc: 0.85676175\n",
      "epoch: 505 valid_loss: 0.14786977 valid_acc: 0.92776525\n",
      "epoch: 506 train_loss: 0.12774292 train_acc: 0.86845887\n",
      "epoch: 506 valid_loss: 0.20593181 valid_acc: 0.7726931\n",
      "epoch: 507 train_loss: 0.13189155 train_acc: 0.8101785\n",
      "epoch: 507 valid_loss: 0.31098711 valid_acc: 0.762022\n",
      "epoch: 508 train_loss: 0.21858895 train_acc: 0.78753674\n",
      "epoch: 508 valid_loss: 0.098737165 valid_acc: 0.81941307\n",
      "epoch: 509 train_loss: 0.15673538 train_acc: 0.8018333\n",
      "epoch: 509 valid_loss: 0.06419439 valid_acc: 0.8413024\n",
      "epoch: 510 train_loss: 0.0469835 train_acc: 0.84776664\n",
      "epoch: 510 valid_loss: 0.039764192 valid_acc: 0.9878241\n",
      "epoch: 511 train_loss: 0.108596355 train_acc: 0.89027977\n",
      "epoch: 511 valid_loss: 0.14687388 valid_acc: 0.7949928\n",
      "epoch: 512 train_loss: 0.1429241 train_acc: 0.87673575\n",
      "epoch: 512 valid_loss: 0.1920771 valid_acc: 0.7928039\n",
      "epoch: 513 train_loss: 0.15274554 train_acc: 0.8119912\n",
      "epoch: 513 valid_loss: 0.06661582 valid_acc: 0.84424376\n",
      "epoch: 514 train_loss: 0.073593765 train_acc: 0.837164\n",
      "epoch: 514 valid_loss: 0.08675079 valid_acc: 0.8339832\n",
      "epoch: 515 train_loss: 0.05677992 train_acc: 0.8453382\n",
      "epoch: 515 valid_loss: 0.062499456 valid_acc: 0.97092825\n",
      "epoch: 516 train_loss: 0.10804988 train_acc: 0.88856965\n",
      "epoch: 516 valid_loss: 0.26315585 valid_acc: 0.7668787\n",
      "epoch: 517 train_loss: 0.21496688 train_acc: 0.78028595\n",
      "epoch: 517 valid_loss: 0.05554675 valid_acc: 0.9438402\n",
      "epoch: 518 train_loss: 0.050996277 train_acc: 0.894384\n",
      "epoch: 518 valid_loss: 0.090878725 valid_acc: 0.86510706\n",
      "epoch: 519 train_loss: 0.12938972 train_acc: 0.8415418\n",
      "epoch: 519 valid_loss: 0.1420968 valid_acc: 0.813804\n",
      "epoch: 520 train_loss: 0.145164 train_acc: 0.84239686\n",
      "epoch: 520 valid_loss: 0.2764615 valid_acc: 0.7876736\n",
      "epoch: 521 train_loss: 0.31468427 train_acc: 0.7626718\n",
      "epoch: 521 valid_loss: 0.40755153 valid_acc: 0.7401327\n",
      "epoch: 522 train_loss: 0.25044233 train_acc: 0.8483138\n",
      "epoch: 522 valid_loss: 0.096433304 valid_acc: 0.9648403\n",
      "epoch: 523 train_loss: 0.07790163 train_acc: 0.9046446\n",
      "epoch: 523 valid_loss: 0.10392775 valid_acc: 0.8291265\n",
      "epoch: 524 train_loss: 0.12956057 train_acc: 0.81718993\n",
      "epoch: 524 valid_loss: 0.17481498 valid_acc: 0.8021752\n",
      "epoch: 525 train_loss: 0.15420336 train_acc: 0.80997336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 525 valid_loss: 0.07873045 valid_acc: 0.82522744\n",
      "epoch: 526 train_loss: 0.08766672 train_acc: 0.8211574\n",
      "epoch: 526 valid_loss: 0.16402161 valid_acc: 0.7938299\n",
      "epoch: 527 train_loss: 0.14914383 train_acc: 0.8051851\n",
      "epoch: 527 valid_loss: 0.19988997 valid_acc: 0.79259866\n",
      "epoch: 528 train_loss: 0.17694855 train_acc: 0.80173063\n",
      "epoch: 528 valid_loss: 0.33008778 valid_acc: 0.7865107\n",
      "epoch: 529 train_loss: 0.33557355 train_acc: 0.793659\n",
      "epoch: 529 valid_loss: 0.5724317 valid_acc: 0.88986933\n",
      "epoch: 530 train_loss: 0.5258852 train_acc: 0.88744104\n",
      "epoch: 530 valid_loss: 0.20024675 valid_acc: 0.8171558\n",
      "epoch: 531 train_loss: 0.13199048 train_acc: 0.8346672\n",
      "epoch: 531 valid_loss: 0.05170969 valid_acc: 0.8441754\n",
      "epoch: 532 train_loss: 0.08089701 train_acc: 0.828032\n",
      "epoch: 532 valid_loss: 0.28486487 valid_acc: 0.78391135\n",
      "epoch: 533 train_loss: 0.5199648 train_acc: 0.7328135\n",
      "epoch: 533 valid_loss: 0.7572676 valid_acc: 0.71092415\n",
      "epoch: 534 train_loss: 0.80387926 train_acc: 0.71208704\n",
      "epoch: 534 valid_loss: 0.70719516 valid_acc: 0.8677748\n",
      "epoch: 535 train_loss: 0.44528818 train_acc: 0.9048841\n",
      "epoch: 535 valid_loss: 0.11497741 valid_acc: 0.81038374\n",
      "epoch: 536 train_loss: 0.17647552 train_acc: 0.78610027\n",
      "epoch: 536 valid_loss: 0.5425823 valid_acc: 0.7220056\n",
      "epoch: 537 train_loss: 0.42809844 train_acc: 0.74242425\n",
      "epoch: 537 valid_loss: 0.18442996 valid_acc: 0.7943088\n",
      "epoch: 538 train_loss: 0.18554491 train_acc: 0.8016964\n",
      "epoch: 538 valid_loss: 0.3727088 valid_acc: 0.76209044\n",
      "epoch: 539 train_loss: 0.5033115 train_acc: 0.7573364\n",
      "epoch: 539 valid_loss: 0.974421 valid_acc: 0.6973801\n",
      "epoch: 540 train_loss: 1.0380809 train_acc: 0.6931391\n",
      "epoch: 540 valid_loss: 0.617753 valid_acc: 0.72953004\n",
      "epoch: 541 train_loss: 0.32794538 train_acc: 0.8409262\n",
      "epoch: 541 valid_loss: 0.25528464 valid_acc: 0.943293\n",
      "epoch: 542 train_loss: 0.17498636 train_acc: 0.90861213\n",
      "epoch: 542 valid_loss: 0.16825329 valid_acc: 0.79540324\n",
      "epoch: 543 train_loss: 0.1924707 train_acc: 0.791299\n",
      "epoch: 543 valid_loss: 0.08751946 valid_acc: 0.8250222\n",
      "epoch: 544 train_loss: 0.11271678 train_acc: 0.81274366\n",
      "epoch: 544 valid_loss: 0.15851457 valid_acc: 0.794172\n",
      "epoch: 545 train_loss: 0.12203486 train_acc: 0.81178606\n",
      "epoch: 545 valid_loss: 0.07313299 valid_acc: 0.8330255\n",
      "epoch: 546 train_loss: 0.076914474 train_acc: 0.82604825\n",
      "epoch: 546 valid_loss: 0.04777613 valid_acc: 0.9858403\n",
      "epoch: 547 train_loss: 0.07376002 train_acc: 0.91080105\n",
      "epoch: 547 valid_loss: 0.16446707 valid_acc: 0.8000547\n",
      "epoch: 548 train_loss: 0.14506128 train_acc: 0.82840824\n",
      "epoch: 548 valid_loss: 0.05622385 valid_acc: 0.9830358\n",
      "epoch: 549 train_loss: 0.07876556 train_acc: 0.9052261\n",
      "epoch: 549 valid_loss: 0.1928432 valid_acc: 0.7914358\n",
      "epoch: 550 train_loss: 0.15947834 train_acc: 0.8135303\n",
      "epoch: 550 valid_loss: 0.18319865 valid_acc: 0.7984814\n",
      "epoch: 551 train_loss: 0.16950546 train_acc: 0.8009782\n",
      "epoch: 551 valid_loss: 0.56737155 valid_acc: 0.72043234\n",
      "epoch: 552 train_loss: 0.47231603 train_acc: 0.7519666\n",
      "epoch: 552 valid_loss: 0.11584032 valid_acc: 0.9488337\n",
      "epoch: 553 train_loss: 0.18746376 train_acc: 0.8630891\n",
      "epoch: 553 valid_loss: 0.20777786 valid_acc: 0.76906765\n",
      "epoch: 554 train_loss: 0.13010655 train_acc: 0.8798481\n",
      "epoch: 554 valid_loss: 0.2953424 valid_acc: 0.7561393\n",
      "epoch: 555 train_loss: 0.25811392 train_acc: 0.7798071\n",
      "epoch: 555 valid_loss: 0.23531431 valid_acc: 0.7991655\n",
      "epoch: 556 train_loss: 0.19942224 train_acc: 0.79040974\n",
      "epoch: 556 valid_loss: 0.061362587 valid_acc: 0.84205484\n",
      "epoch: 557 train_loss: 0.12200678 train_acc: 0.82844245\n",
      "epoch: 557 valid_loss: 0.17090607 valid_acc: 0.7930091\n",
      "epoch: 558 train_loss: 0.15390202 train_acc: 0.87174225\n",
      "epoch: 558 valid_loss: 0.04257519 valid_acc: 0.98775566\n",
      "epoch: 559 train_loss: 0.0618553 train_acc: 0.913332\n",
      "epoch: 559 valid_loss: 0.12813401 valid_acc: 0.80511665\n",
      "epoch: 560 train_loss: 0.07332726 train_acc: 0.8330939\n",
      "epoch: 560 valid_loss: 0.08106964 valid_acc: 0.82905805\n",
      "epoch: 561 train_loss: 0.06528191 train_acc: 0.83743757\n",
      "epoch: 561 valid_loss: 0.060214028 valid_acc: 0.8394555\n",
      "epoch: 562 train_loss: 0.0562059 train_acc: 0.8412682\n",
      "epoch: 562 valid_loss: 0.10613139 valid_acc: 0.80409056\n",
      "epoch: 563 train_loss: 0.058954507 train_acc: 0.83456457\n",
      "epoch: 563 valid_loss: 0.03488227 valid_acc: 0.91456324\n",
      "epoch: 564 train_loss: 0.049335867 train_acc: 0.947363\n",
      "epoch: 564 valid_loss: 0.09437314 valid_acc: 0.88125044\n",
      "epoch: 565 train_loss: 0.07923412 train_acc: 0.8573432\n",
      "epoch: 565 valid_loss: 0.022126455 valid_acc: 0.85655653\n",
      "epoch: 566 train_loss: 0.04158558 train_acc: 0.8475956\n",
      "epoch: 566 valid_loss: 0.03338603 valid_acc: 0.8566933\n",
      "epoch: 567 train_loss: 0.030587759 train_acc: 0.8563513\n",
      "epoch: 567 valid_loss: 0.037592925 valid_acc: 0.8475272\n",
      "epoch: 568 train_loss: 0.04000996 train_acc: 0.8473904\n",
      "epoch: 568 valid_loss: 0.083801605 valid_acc: 0.96073604\n",
      "epoch: 569 train_loss: 0.12978898 train_acc: 0.87868524\n",
      "epoch: 569 valid_loss: 0.095824376 valid_acc: 0.82160205\n",
      "epoch: 570 train_loss: 0.08720738 train_acc: 0.900643\n",
      "epoch: 570 valid_loss: 0.100870475 valid_acc: 0.83370954\n",
      "epoch: 571 train_loss: 0.113051 train_acc: 0.82392776\n",
      "epoch: 571 valid_loss: 0.12702471 valid_acc: 0.80757916\n",
      "epoch: 572 train_loss: 0.09188155 train_acc: 0.826664\n",
      "epoch: 572 valid_loss: 0.08098385 valid_acc: 0.837677\n",
      "epoch: 573 train_loss: 0.06695703 train_acc: 0.8397975\n",
      "epoch: 573 valid_loss: 0.06797509 valid_acc: 0.9756481\n",
      "epoch: 574 train_loss: 0.06348373 train_acc: 0.96374583\n",
      "epoch: 574 valid_loss: 0.12833017 valid_acc: 0.8190027\n",
      "epoch: 575 train_loss: 0.072639234 train_acc: 0.84222585\n",
      "epoch: 575 valid_loss: 0.039723456 valid_acc: 0.84321773\n",
      "epoch: 576 train_loss: 0.041999433 train_acc: 0.84325194\n",
      "epoch: 576 valid_loss: 0.106695786 valid_acc: 0.81510365\n",
      "epoch: 577 train_loss: 0.13630939 train_acc: 0.81363297\n",
      "epoch: 577 valid_loss: 0.084695 valid_acc: 0.8356933\n",
      "epoch: 578 train_loss: 0.08248684 train_acc: 0.8323073\n",
      "epoch: 578 valid_loss: 0.034296464 valid_acc: 0.989329\n",
      "epoch: 579 train_loss: 0.0419657 train_acc: 0.987311\n",
      "epoch: 579 valid_loss: 0.06620404 valid_acc: 0.83206785\n",
      "epoch: 580 train_loss: 0.06269337 train_acc: 0.83394897\n",
      "epoch: 580 valid_loss: 0.033901453 valid_acc: 0.8531363\n",
      "epoch: 581 train_loss: 0.051249124 train_acc: 0.8433545\n",
      "epoch: 581 valid_loss: 0.07490434 valid_acc: 0.838361\n",
      "epoch: 582 train_loss: 0.059371796 train_acc: 0.84202063\n",
      "epoch: 582 valid_loss: 0.12682979 valid_acc: 0.8101785\n",
      "epoch: 583 train_loss: 0.12822857 train_acc: 0.80573225\n",
      "epoch: 583 valid_loss: 0.123341925 valid_acc: 0.7999863\n",
      "epoch: 584 train_loss: 0.14370644 train_acc: 0.816677\n",
      "epoch: 584 valid_loss: 0.14957078 valid_acc: 0.9495177\n",
      "epoch: 585 train_loss: 0.10056098 train_acc: 0.90026677\n",
      "epoch: 585 valid_loss: 0.07289515 valid_acc: 0.9718859\n",
      "epoch: 586 train_loss: 0.05409793 train_acc: 0.91172445\n",
      "epoch: 586 valid_loss: 0.05470379 valid_acc: 0.8361721\n",
      "epoch: 587 train_loss: 0.040355682 train_acc: 0.84489363\n",
      "epoch: 587 valid_loss: 0.08004396 valid_acc: 0.83357275\n",
      "epoch: 588 train_loss: 0.09690172 train_acc: 0.82673234\n",
      "epoch: 588 valid_loss: 0.33308622 valid_acc: 0.7368493\n",
      "epoch: 589 train_loss: 0.23580408 train_acc: 0.7761475\n",
      "epoch: 589 valid_loss: 0.07363676 valid_acc: 0.8310418\n",
      "epoch: 590 train_loss: 0.09913333 train_acc: 0.8948287\n",
      "epoch: 590 valid_loss: 0.16580357 valid_acc: 0.79540324\n",
      "epoch: 591 train_loss: 0.15263103 train_acc: 0.8067925\n",
      "epoch: 591 valid_loss: 0.102970146 valid_acc: 0.9669608\n",
      "epoch: 592 train_loss: 0.07853734 train_acc: 0.93792325\n",
      "epoch: 592 valid_loss: 0.04520013 valid_acc: 0.8446542\n",
      "epoch: 593 train_loss: 0.040610064 train_acc: 0.8468089\n",
      "epoch: 593 valid_loss: 0.04260212 valid_acc: 0.8427389\n",
      "epoch: 594 train_loss: 0.04420559 train_acc: 0.8464327\n",
      "epoch: 594 valid_loss: 0.102664225 valid_acc: 0.82406455\n",
      "epoch: 595 train_loss: 0.08224274 train_acc: 0.83329916\n",
      "epoch: 595 valid_loss: 0.042071722 valid_acc: 0.85019493\n",
      "epoch: 596 train_loss: 0.05355365 train_acc: 0.84321773\n",
      "epoch: 596 valid_loss: 0.058990933 valid_acc: 0.98604554\n",
      "epoch: 597 train_loss: 0.053555958 train_acc: 0.98737943\n",
      "epoch: 597 valid_loss: 0.050435003 valid_acc: 0.8478692\n",
      "epoch: 598 train_loss: 0.07670505 train_acc: 0.83476985\n",
      "epoch: 598 valid_loss: 0.13124548 valid_acc: 0.8013544\n",
      "epoch: 599 train_loss: 0.10712311 train_acc: 0.81209385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 599 valid_loss: 0.122337736 valid_acc: 0.80552703\n",
      "epoch: 600 train_loss: 0.096191466 train_acc: 0.8200971\n",
      "epoch: 600 valid_loss: 0.06729681 valid_acc: 0.8306998\n",
      "epoch: 601 train_loss: 0.062341716 train_acc: 0.8388057\n",
      "epoch: 601 valid_loss: 0.052319117 valid_acc: 0.84520143\n",
      "epoch: 602 train_loss: 0.11631848 train_acc: 0.8965045\n",
      "epoch: 602 valid_loss: 0.5893717 valid_acc: 0.7199535\n",
      "epoch: 603 train_loss: 0.72269744 train_acc: 0.6998085\n",
      "epoch: 603 valid_loss: 0.4552074 valid_acc: 0.8916479\n",
      "epoch: 604 train_loss: 0.46637785 train_acc: 0.79273546\n",
      "epoch: 604 valid_loss: 0.6163509 valid_acc: 0.71256584\n",
      "epoch: 605 train_loss: 0.54454887 train_acc: 0.6890006\n",
      "epoch: 605 valid_loss: 0.089059845 valid_acc: 0.82721114\n",
      "epoch: 606 train_loss: 0.29906687 train_acc: 0.76366377\n",
      "epoch: 606 valid_loss: 0.48586497 valid_acc: 0.7436897\n",
      "epoch: 607 train_loss: 0.41461873 train_acc: 0.8436966\n",
      "epoch: 607 valid_loss: 0.20751956 valid_acc: 0.80244887\n",
      "epoch: 608 train_loss: 0.20581529 train_acc: 0.8035091\n",
      "epoch: 608 valid_loss: 0.21689554 valid_acc: 0.78753674\n",
      "epoch: 609 train_loss: 0.16705161 train_acc: 0.83039194\n",
      "epoch: 609 valid_loss: 0.056852378 valid_acc: 0.98542994\n",
      "epoch: 610 train_loss: 0.069307186 train_acc: 0.90461046\n",
      "epoch: 610 valid_loss: 0.16858876 valid_acc: 0.8062795\n",
      "epoch: 611 train_loss: 0.15343647 train_acc: 0.80692935\n",
      "epoch: 611 valid_loss: 0.16709484 valid_acc: 0.7993023\n",
      "epoch: 612 train_loss: 0.11063388 train_acc: 0.8212942\n",
      "epoch: 612 valid_loss: 0.040282298 valid_acc: 0.8484849\n",
      "epoch: 613 train_loss: 0.046838947 train_acc: 0.84605646\n",
      "epoch: 613 valid_loss: 0.021953786 valid_acc: 0.9953485\n",
      "epoch: 614 train_loss: 0.04388789 train_acc: 0.9170258\n",
      "epoch: 614 valid_loss: 0.024601173 valid_acc: 0.9945277\n",
      "epoch: 615 train_loss: 0.027568553 train_acc: 0.9230454\n",
      "epoch: 615 valid_loss: 0.08328169 valid_acc: 0.82857925\n",
      "epoch: 616 train_loss: 0.05032491 train_acc: 0.844278\n",
      "epoch: 616 valid_loss: 0.031909227 valid_acc: 0.8546412\n",
      "epoch: 617 train_loss: 0.037603263 train_acc: 0.85111845\n",
      "epoch: 617 valid_loss: 0.048573196 valid_acc: 0.8415076\n",
      "epoch: 618 train_loss: 0.032717235 train_acc: 0.84875846\n",
      "epoch: 618 valid_loss: 0.02738564 valid_acc: 0.8548464\n",
      "epoch: 619 train_loss: 0.03501773 train_acc: 0.91777825\n",
      "epoch: 619 valid_loss: 0.06868681 valid_acc: 0.8328887\n",
      "epoch: 620 train_loss: 0.05585514 train_acc: 0.9052261\n",
      "epoch: 620 valid_loss: 0.06669868 valid_acc: 0.8315206\n",
      "epoch: 621 train_loss: 0.03896285 train_acc: 0.84975034\n",
      "epoch: 621 valid_loss: 0.043986607 valid_acc: 0.8495109\n",
      "epoch: 622 train_loss: 0.056318887 train_acc: 0.84236264\n",
      "epoch: 622 valid_loss: 0.11144344 valid_acc: 0.8165401\n",
      "epoch: 623 train_loss: 0.10383612 train_acc: 0.8218415\n",
      "epoch: 623 valid_loss: 0.06510885 valid_acc: 0.834804\n",
      "epoch: 624 train_loss: 0.13260736 train_acc: 0.8197551\n",
      "epoch: 624 valid_loss: 0.18291183 valid_acc: 0.9251659\n",
      "epoch: 625 train_loss: 0.18817672 train_acc: 0.9221219\n",
      "epoch: 625 valid_loss: 0.04444587 valid_acc: 0.84362817\n",
      "epoch: 626 train_loss: 0.028360061 train_acc: 0.8527601\n",
      "epoch: 626 valid_loss: 0.063841514 valid_acc: 0.8443806\n",
      "epoch: 627 train_loss: 0.062418938 train_acc: 0.8441412\n",
      "epoch: 627 valid_loss: 0.19169824 valid_acc: 0.79889184\n",
      "epoch: 628 train_loss: 0.24415398 train_acc: 0.781483\n",
      "epoch: 628 valid_loss: 0.26801977 valid_acc: 0.77522403\n",
      "epoch: 629 train_loss: 0.2585103 train_acc: 0.7710514\n",
      "epoch: 629 valid_loss: 0.27080378 valid_acc: 0.7801491\n",
      "epoch: 630 train_loss: 0.22235645 train_acc: 0.7883918\n",
      "epoch: 630 valid_loss: 0.30230945 valid_acc: 0.74710995\n",
      "epoch: 631 train_loss: 0.36568668 train_acc: 0.81062317\n",
      "epoch: 631 valid_loss: 0.3364027 valid_acc: 0.90170324\n",
      "epoch: 632 train_loss: 0.38685083 train_acc: 0.8301183\n",
      "epoch: 632 valid_loss: 0.17950575 valid_acc: 0.8235173\n",
      "epoch: 633 train_loss: 0.15476885 train_acc: 0.82991314\n",
      "epoch: 633 valid_loss: 0.07998467 valid_acc: 0.8270059\n",
      "epoch: 634 train_loss: 0.0770378 train_acc: 0.830392\n",
      "epoch: 634 valid_loss: 0.059486534 valid_acc: 0.8400027\n",
      "epoch: 635 train_loss: 0.064854294 train_acc: 0.8368561\n",
      "epoch: 635 valid_loss: 0.06939351 valid_acc: 0.8411656\n",
      "epoch: 636 train_loss: 0.11609255 train_acc: 0.8852179\n",
      "epoch: 636 valid_loss: 0.2296159 valid_acc: 0.748478\n",
      "epoch: 637 train_loss: 0.17144781 train_acc: 0.78695536\n",
      "epoch: 637 valid_loss: 0.049555577 valid_acc: 0.98077846\n",
      "epoch: 638 train_loss: 0.07575395 train_acc: 0.8994117\n",
      "epoch: 638 valid_loss: 0.28514978 valid_acc: 0.790957\n",
      "epoch: 639 train_loss: 0.35275888 train_acc: 0.7868185\n",
      "epoch: 639 valid_loss: 0.5044224 valid_acc: 0.74587864\n",
      "epoch: 640 train_loss: 0.30758312 train_acc: 0.77696836\n",
      "epoch: 640 valid_loss: 0.30158347 valid_acc: 0.77412957\n",
      "epoch: 641 train_loss: 0.22250137 train_acc: 0.86958754\n",
      "epoch: 641 valid_loss: 0.5389486 valid_acc: 0.68007386\n",
      "epoch: 642 train_loss: 0.40482092 train_acc: 0.72518635\n",
      "epoch: 642 valid_loss: 0.081833504 valid_acc: 0.8919899\n",
      "epoch: 643 train_loss: 0.16230766 train_acc: 0.83993435\n",
      "epoch: 643 valid_loss: 0.27027604 valid_acc: 0.778097\n",
      "epoch: 644 train_loss: 0.28785962 train_acc: 0.77943087\n",
      "epoch: 644 valid_loss: 0.16479085 valid_acc: 0.8568302\n",
      "epoch: 645 train_loss: 0.13343413 train_acc: 0.9085437\n",
      "epoch: 645 valid_loss: 0.15103619 valid_acc: 0.8081264\n",
      "epoch: 646 train_loss: 0.135061 train_acc: 0.8144196\n",
      "epoch: 646 valid_loss: 0.12613915 valid_acc: 0.8210548\n",
      "epoch: 647 train_loss: 0.08326693 train_acc: 0.8341542\n",
      "epoch: 647 valid_loss: 0.08136538 valid_acc: 0.82844245\n",
      "epoch: 648 train_loss: 0.14951602 train_acc: 0.8204733\n",
      "epoch: 648 valid_loss: 0.5734618 valid_acc: 0.8616868\n",
      "epoch: 649 train_loss: 0.58562934 train_acc: 0.7949928\n",
      "epoch: 649 valid_loss: 0.17151624 valid_acc: 0.80641633\n",
      "epoch: 650 train_loss: 0.1866158 train_acc: 0.8068609\n",
      "epoch: 650 valid_loss: 0.10475396 valid_acc: 0.9418565\n",
      "epoch: 651 train_loss: 0.16734067 train_acc: 0.8604897\n",
      "epoch: 651 valid_loss: 0.11877137 valid_acc: 0.81072575\n",
      "epoch: 652 train_loss: 0.111358464 train_acc: 0.8192079\n",
      "epoch: 652 valid_loss: 0.4053341 valid_acc: 0.77057254\n",
      "epoch: 653 train_loss: 0.3229525 train_acc: 0.7743006\n",
      "epoch: 653 valid_loss: 0.20389925 valid_acc: 0.78726315\n",
      "epoch: 654 train_loss: 0.15358603 train_acc: 0.8419522\n",
      "epoch: 654 valid_loss: 0.18130778 valid_acc: 0.8577878\n",
      "epoch: 655 train_loss: 0.24362083 train_acc: 0.8231411\n",
      "epoch: 655 valid_loss: 0.10010582 valid_acc: 0.8955469\n",
      "epoch: 656 train_loss: 0.100317776 train_acc: 0.8606608\n",
      "epoch: 656 valid_loss: 0.1642154 valid_acc: 0.78692114\n",
      "epoch: 657 train_loss: 0.13863921 train_acc: 0.86178946\n",
      "epoch: 657 valid_loss: 0.108113155 valid_acc: 0.9170942\n",
      "epoch: 658 train_loss: 0.0892957 train_acc: 0.87358916\n",
      "epoch: 658 valid_loss: 0.22999497 valid_acc: 0.78555304\n",
      "epoch: 659 train_loss: 0.1732226 train_acc: 0.80275667\n",
      "epoch: 659 valid_loss: 0.13360636 valid_acc: 0.83391476\n",
      "epoch: 660 train_loss: 0.11248436 train_acc: 0.8384979\n",
      "epoch: 660 valid_loss: 0.13837269 valid_acc: 0.8246802\n",
      "epoch: 661 train_loss: 0.09190947 train_acc: 0.8343594\n",
      "epoch: 661 valid_loss: 0.09910109 valid_acc: 0.8228333\n",
      "epoch: 662 train_loss: 0.08912875 train_acc: 0.89824885\n",
      "epoch: 662 valid_loss: 0.24154982 valid_acc: 0.93809426\n",
      "epoch: 663 train_loss: 0.21983771 train_acc: 0.87273407\n",
      "epoch: 663 valid_loss: 0.24964812 valid_acc: 0.7779602\n",
      "epoch: 664 train_loss: 0.20791867 train_acc: 0.7963267\n",
      "epoch: 664 valid_loss: 0.17772378 valid_acc: 0.7901361\n",
      "epoch: 665 train_loss: 0.097868636 train_acc: 0.82533\n",
      "epoch: 665 valid_loss: 0.20533378 valid_acc: 0.76756275\n",
      "epoch: 666 train_loss: 0.18138278 train_acc: 0.778952\n",
      "epoch: 666 valid_loss: 0.10521156 valid_acc: 0.8205076\n",
      "epoch: 667 train_loss: 0.08807825 train_acc: 0.89123744\n",
      "epoch: 667 valid_loss: 0.1455591 valid_acc: 0.8183186\n",
      "epoch: 668 train_loss: 0.107013375 train_acc: 0.84677476\n",
      "epoch: 668 valid_loss: 0.12019321 valid_acc: 0.9653191\n",
      "epoch: 669 train_loss: 0.11078108 train_acc: 0.88319993\n",
      "epoch: 669 valid_loss: 0.06829451 valid_acc: 0.8308366\n",
      "epoch: 670 train_loss: 0.072351456 train_acc: 0.8315207\n",
      "epoch: 670 valid_loss: 0.07299181 valid_acc: 0.83275187\n",
      "epoch: 671 train_loss: 0.0528126 train_acc: 0.84359396\n",
      "epoch: 671 valid_loss: 0.06399984 valid_acc: 0.8300157\n",
      "epoch: 672 train_loss: 0.051113363 train_acc: 0.9090225\n",
      "epoch: 672 valid_loss: 0.038583603 valid_acc: 0.85142624\n",
      "epoch: 673 train_loss: 0.051124983 train_acc: 0.8489637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 673 valid_loss: 0.029606063 valid_acc: 0.85942954\n",
      "epoch: 674 train_loss: 0.05994983 train_acc: 0.9051919\n",
      "epoch: 674 valid_loss: 0.062320814 valid_acc: 0.83179426\n",
      "epoch: 675 train_loss: 0.045205176 train_acc: 0.8467747\n",
      "epoch: 675 valid_loss: 0.073300034 valid_acc: 0.83240986\n",
      "epoch: 676 train_loss: 0.06487002 train_acc: 0.83726656\n",
      "epoch: 676 valid_loss: 0.12590869 valid_acc: 0.8105205\n",
      "epoch: 677 train_loss: 0.10437645 train_acc: 0.83391476\n",
      "epoch: 677 valid_loss: 0.13776259 valid_acc: 0.9535536\n",
      "epoch: 678 train_loss: 0.18603224 train_acc: 0.86965597\n",
      "epoch: 678 valid_loss: 0.22542524 valid_acc: 0.7817224\n",
      "epoch: 679 train_loss: 0.1766535 train_acc: 0.79485595\n",
      "epoch: 679 valid_loss: 0.1100372 valid_acc: 0.82187563\n",
      "epoch: 680 train_loss: 0.096903935 train_acc: 0.8910322\n",
      "epoch: 680 valid_loss: 0.1586939 valid_acc: 0.7915042\n",
      "epoch: 681 train_loss: 0.15331624 train_acc: 0.8096313\n",
      "epoch: 681 valid_loss: 0.084877625 valid_acc: 0.8353512\n",
      "epoch: 682 train_loss: 0.07079625 train_acc: 0.8358985\n",
      "epoch: 682 valid_loss: 0.06510558 valid_acc: 0.98413026\n",
      "epoch: 683 train_loss: 0.07697703 train_acc: 0.9061837\n",
      "epoch: 683 valid_loss: 0.04074029 valid_acc: 0.84957933\n",
      "epoch: 684 train_loss: 0.074600995 train_acc: 0.8329913\n",
      "epoch: 684 valid_loss: 0.02838014 valid_acc: 0.90327656\n",
      "epoch: 685 train_loss: 0.06039975 train_acc: 0.8588823\n",
      "epoch: 685 valid_loss: 0.07045208 valid_acc: 0.9516383\n",
      "epoch: 686 train_loss: 0.0841102 train_acc: 0.89274234\n",
      "epoch: 686 valid_loss: 0.041924227 valid_acc: 0.84793764\n",
      "epoch: 687 train_loss: 0.027544959 train_acc: 0.85412824\n",
      "epoch: 687 valid_loss: 0.0680693 valid_acc: 0.841234\n",
      "epoch: 688 train_loss: 0.08666361 train_acc: 0.8316232\n",
      "epoch: 688 valid_loss: 0.042538404 valid_acc: 0.8491005\n",
      "epoch: 689 train_loss: 0.057224438 train_acc: 0.9130242\n",
      "epoch: 689 valid_loss: 0.28954673 valid_acc: 0.86975855\n",
      "epoch: 690 train_loss: 0.42176592 train_acc: 0.795027\n",
      "epoch: 690 valid_loss: 0.8986918 valid_acc: 0.69567\n",
      "epoch: 691 train_loss: 1.0360396 train_acc: 0.68643546\n",
      "epoch: 691 valid_loss: 0.460481 valid_acc: 0.7068883\n",
      "epoch: 692 train_loss: 0.44037557 train_acc: 0.7328477\n",
      "epoch: 692 valid_loss: 0.40076852 valid_acc: 0.75955945\n",
      "epoch: 693 train_loss: 0.49366874 train_acc: 0.74208224\n",
      "epoch: 693 valid_loss: 0.8344169 valid_acc: 0.63308024\n",
      "epoch: 694 train_loss: 0.57910544 train_acc: 0.7758397\n",
      "epoch: 694 valid_loss: 0.29628244 valid_acc: 0.7915042\n",
      "epoch: 695 train_loss: 0.21160594 train_acc: 0.8505027\n",
      "epoch: 695 valid_loss: 0.24738573 valid_acc: 0.7714618\n",
      "epoch: 696 train_loss: 0.15002036 train_acc: 0.80433\n",
      "epoch: 696 valid_loss: 0.32927898 valid_acc: 0.728846\n",
      "epoch: 697 train_loss: 0.34308666 train_acc: 0.7348314\n",
      "epoch: 697 valid_loss: 0.29988164 valid_acc: 0.837335\n",
      "epoch: 698 train_loss: 0.20315811 train_acc: 0.8645598\n",
      "epoch: 698 valid_loss: 0.331933 valid_acc: 0.76236403\n",
      "epoch: 699 train_loss: 0.23029856 train_acc: 0.783672\n",
      "epoch: 699 valid_loss: 0.26251262 valid_acc: 0.7581914\n",
      "epoch: 700 train_loss: 0.26250508 train_acc: 0.76602364\n",
      "epoch: 700 valid_loss: 0.8042684 valid_acc: 0.82208085\n",
      "epoch: 701 train_loss: 0.5054237 train_acc: 0.7998837\n",
      "epoch: 701 valid_loss: 0.3774459 valid_acc: 0.7665367\n",
      "epoch: 702 train_loss: 0.24471426 train_acc: 0.78476644\n",
      "epoch: 702 valid_loss: 0.41112158 valid_acc: 0.79506123\n",
      "epoch: 703 train_loss: 0.37650937 train_acc: 0.793659\n",
      "epoch: 703 valid_loss: 0.38993958 valid_acc: 0.7663315\n",
      "epoch: 704 train_loss: 0.43916726 train_acc: 0.79571104\n",
      "epoch: 704 valid_loss: 0.34877306 valid_acc: 0.93788904\n",
      "epoch: 705 train_loss: 0.2886871 train_acc: 0.88487583\n",
      "epoch: 705 valid_loss: 0.037111804 valid_acc: 0.84869003\n",
      "epoch: 706 train_loss: 0.10869797 train_acc: 0.8226623\n",
      "epoch: 706 valid_loss: 0.23567885 valid_acc: 0.8325467\n",
      "epoch: 707 train_loss: 0.17660746 train_acc: 0.8316574\n",
      "epoch: 707 valid_loss: 0.13535132 valid_acc: 0.8111362\n",
      "epoch: 708 train_loss: 0.08515097 train_acc: 0.8300157\n",
      "epoch: 708 valid_loss: 0.14191225 valid_acc: 0.8978042\n",
      "epoch: 709 train_loss: 0.13087744 train_acc: 0.9305014\n",
      "epoch: 709 valid_loss: 0.118154444 valid_acc: 0.83022094\n",
      "epoch: 710 train_loss: 0.08945187 train_acc: 0.8328203\n",
      "epoch: 710 valid_loss: 0.29041037 valid_acc: 0.7933511\n",
      "epoch: 711 train_loss: 0.26347944 train_acc: 0.7866475\n",
      "epoch: 711 valid_loss: 0.17199676 valid_acc: 0.7867159\n",
      "epoch: 712 train_loss: 0.1185942 train_acc: 0.83022094\n",
      "epoch: 712 valid_loss: 0.4007041 valid_acc: 0.89828306\n",
      "epoch: 713 train_loss: 0.4073679 train_acc: 0.82875025\n",
      "epoch: 713 valid_loss: 0.950608 valid_acc: 0.6689924\n",
      "epoch: 714 train_loss: 0.7243993 train_acc: 0.7135235\n",
      "epoch: 714 valid_loss: 0.38782904 valid_acc: 0.7641426\n",
      "epoch: 715 train_loss: 0.20464896 train_acc: 0.80754495\n",
      "epoch: 715 valid_loss: 0.3247545 valid_acc: 0.91004854\n",
      "epoch: 716 train_loss: 0.38752168 train_acc: 0.8298447\n",
      "epoch: 716 valid_loss: 0.648477 valid_acc: 0.76626307\n",
      "epoch: 717 train_loss: 0.3915689 train_acc: 0.78705794\n",
      "epoch: 717 valid_loss: 0.21669878 valid_acc: 0.80197006\n",
      "epoch: 718 train_loss: 0.16272223 train_acc: 0.8161639\n",
      "epoch: 718 valid_loss: 0.13492902 valid_acc: 0.8068267\n",
      "epoch: 719 train_loss: 0.21296567 train_acc: 0.85146046\n",
      "epoch: 719 valid_loss: 0.2393694 valid_acc: 0.8096313\n",
      "epoch: 720 train_loss: 0.23144202 train_acc: 0.80241466\n",
      "epoch: 720 valid_loss: 0.21986839 valid_acc: 0.82823724\n",
      "epoch: 721 train_loss: 0.21234077 train_acc: 0.7993365\n",
      "epoch: 721 valid_loss: 0.09963828 valid_acc: 0.824475\n",
      "epoch: 722 train_loss: 0.18015015 train_acc: 0.7989945\n",
      "epoch: 722 valid_loss: 0.33137098 valid_acc: 0.89123744\n",
      "epoch: 723 train_loss: 0.3742804 train_acc: 0.8325125\n",
      "epoch: 723 valid_loss: 0.43230596 valid_acc: 0.7746084\n",
      "epoch: 724 train_loss: 0.3845284 train_acc: 0.771325\n",
      "epoch: 724 valid_loss: 0.22547138 valid_acc: 0.93399\n",
      "epoch: 725 train_loss: 0.2006967 train_acc: 0.86592793\n",
      "epoch: 725 valid_loss: 0.05889433 valid_acc: 0.8375402\n",
      "epoch: 726 train_loss: 0.06875488 train_acc: 0.83603525\n",
      "epoch: 726 valid_loss: 0.031799287 valid_acc: 0.84992135\n",
      "epoch: 727 train_loss: 0.03737289 train_acc: 0.84698\n",
      "epoch: 727 valid_loss: 0.15336005 valid_acc: 0.8050482\n",
      "epoch: 728 train_loss: 0.13199477 train_acc: 0.8811478\n",
      "epoch: 728 valid_loss: 0.24045847 valid_acc: 0.83576167\n",
      "epoch: 729 train_loss: 0.2028665 train_acc: 0.83145225\n",
      "epoch: 729 valid_loss: 0.17201139 valid_acc: 0.79355633\n",
      "epoch: 730 train_loss: 0.11094534 train_acc: 0.8140092\n",
      "epoch: 730 valid_loss: 0.19918284 valid_acc: 0.8010124\n",
      "epoch: 731 train_loss: 0.11836473 train_acc: 0.82269645\n",
      "epoch: 731 valid_loss: 0.1303786 valid_acc: 0.80757916\n",
      "epoch: 732 train_loss: 0.122088686 train_acc: 0.8898351\n",
      "epoch: 732 valid_loss: 0.17649993 valid_acc: 0.80374855\n",
      "epoch: 733 train_loss: 0.13360365 train_acc: 0.8178398\n",
      "epoch: 733 valid_loss: 0.10788674 valid_acc: 0.8171558\n",
      "epoch: 734 train_loss: 0.15893635 train_acc: 0.83559066\n",
      "epoch: 734 valid_loss: 0.22341795 valid_acc: 0.7726247\n",
      "epoch: 735 train_loss: 0.25375435 train_acc: 0.7664341\n",
      "epoch: 735 valid_loss: 0.34983218 valid_acc: 0.7399959\n",
      "epoch: 736 train_loss: 0.25659883 train_acc: 0.85689855\n",
      "epoch: 736 valid_loss: 0.11842252 valid_acc: 0.81387234\n",
      "epoch: 737 train_loss: 0.11785634 train_acc: 0.81175184\n",
      "epoch: 737 valid_loss: 0.113839254 valid_acc: 0.81024694\n",
      "epoch: 738 train_loss: 0.18098126 train_acc: 0.81274366\n",
      "epoch: 738 valid_loss: 0.09424605 valid_acc: 0.8213284\n",
      "epoch: 739 train_loss: 0.10405111 train_acc: 0.90290034\n",
      "epoch: 739 valid_loss: 0.08463724 valid_acc: 0.89424723\n",
      "epoch: 740 train_loss: 0.061432008 train_acc: 0.86691976\n",
      "epoch: 740 valid_loss: 0.023620257 valid_acc: 0.85457283\n",
      "epoch: 741 train_loss: 0.033155695 train_acc: 0.85450447\n",
      "epoch: 741 valid_loss: 0.04659123 valid_acc: 0.8484849\n",
      "epoch: 742 train_loss: 0.04648403 train_acc: 0.84639853\n",
      "epoch: 742 valid_loss: 0.11520906 valid_acc: 0.8296053\n",
      "epoch: 743 train_loss: 0.07204151 train_acc: 0.914187\n",
      "epoch: 743 valid_loss: 0.07299803 valid_acc: 0.9737328\n",
      "epoch: 744 train_loss: 0.039245315 train_acc: 0.91675216\n",
      "epoch: 744 valid_loss: 0.027437445 valid_acc: 0.848348\n",
      "epoch: 745 train_loss: 0.037608072 train_acc: 0.84489363\n",
      "epoch: 745 valid_loss: 0.046083745 valid_acc: 0.84355974\n",
      "epoch: 746 train_loss: 0.033615805 train_acc: 0.85060537\n",
      "epoch: 746 valid_loss: 0.1083312 valid_acc: 0.8229017\n",
      "epoch: 747 train_loss: 0.12986648 train_acc: 0.81219643\n",
      "epoch: 747 valid_loss: 0.051969722 valid_acc: 0.8431493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 748 train_loss: 0.08544639 train_acc: 0.8377112\n",
      "epoch: 748 valid_loss: 0.31182155 valid_acc: 0.76920444\n",
      "epoch: 749 train_loss: 0.37442923 train_acc: 0.8323415\n",
      "epoch: 749 valid_loss: 0.7682618 valid_acc: 0.70894045\n",
      "epoch: 750 train_loss: 0.5562401 train_acc: 0.8107942\n",
      "epoch: 750 valid_loss: 0.3028017 valid_acc: 0.77761817\n",
      "epoch: 751 train_loss: 0.30696204 train_acc: 0.77973866\n",
      "epoch: 751 valid_loss: 0.30366772 valid_acc: 0.7705041\n",
      "epoch: 752 train_loss: 0.3225354 train_acc: 0.7486148\n",
      "epoch: 752 valid_loss: 0.47101247 valid_acc: 0.7435529\n",
      "epoch: 753 train_loss: 0.27086842 train_acc: 0.8495451\n",
      "epoch: 753 valid_loss: 0.09649814 valid_acc: 0.8242014\n",
      "epoch: 754 train_loss: 0.11246918 train_acc: 0.8085027\n",
      "epoch: 754 valid_loss: 0.07529825 valid_acc: 0.83507764\n",
      "epoch: 755 train_loss: 0.08497096 train_acc: 0.8348382\n",
      "epoch: 755 valid_loss: 0.08128241 valid_acc: 0.8604556\n",
      "epoch: 756 train_loss: 0.10182444 train_acc: 0.9073808\n",
      "epoch: 756 valid_loss: 0.2265879 valid_acc: 0.7947876\n",
      "epoch: 757 train_loss: 0.2187823 train_acc: 0.8076818\n",
      "epoch: 757 valid_loss: 0.109915435 valid_acc: 0.8278952\n",
      "epoch: 758 train_loss: 0.06205731 train_acc: 0.8440728\n",
      "epoch: 758 valid_loss: 0.05391491 valid_acc: 0.83808744\n",
      "epoch: 759 train_loss: 0.059716422 train_acc: 0.84523565\n",
      "epoch: 759 valid_loss: 0.11769484 valid_acc: 0.95909435\n",
      "epoch: 760 train_loss: 0.09536265 train_acc: 0.8953417\n",
      "epoch: 760 valid_loss: 0.036432415 valid_acc: 0.8490321\n",
      "epoch: 761 train_loss: 0.0352313 train_acc: 0.85077643\n",
      "epoch: 761 valid_loss: 0.08412907 valid_acc: 0.8304946\n",
      "epoch: 762 train_loss: 0.06426242 train_acc: 0.83480406\n",
      "epoch: 762 valid_loss: 0.032019243 valid_acc: 0.99124426\n",
      "epoch: 763 train_loss: 0.077166885 train_acc: 0.96326697\n",
      "epoch: 763 valid_loss: 0.4566923 valid_acc: 0.734934\n",
      "epoch: 764 train_loss: 0.69759214 train_acc: 0.717662\n",
      "epoch: 764 valid_loss: 0.6235643 valid_acc: 0.74690473\n",
      "epoch: 765 train_loss: 0.42279825 train_acc: 0.76458716\n",
      "epoch: 765 valid_loss: 0.11744448 valid_acc: 0.8158561\n",
      "epoch: 766 train_loss: 0.13921927 train_acc: 0.8108284\n",
      "epoch: 766 valid_loss: 0.12698504 valid_acc: 0.80689514\n",
      "epoch: 767 train_loss: 0.17173392 train_acc: 0.79506123\n",
      "epoch: 767 valid_loss: 0.13047637 valid_acc: 0.9497914\n",
      "epoch: 768 train_loss: 0.10829115 train_acc: 0.9527328\n",
      "epoch: 768 valid_loss: 0.076359905 valid_acc: 0.82556945\n",
      "epoch: 769 train_loss: 0.16381784 train_acc: 0.8012176\n",
      "epoch: 769 valid_loss: 0.056944378 valid_acc: 0.8430125\n",
      "epoch: 770 train_loss: 0.089288205 train_acc: 0.838019\n",
      "epoch: 770 valid_loss: 0.19846527 valid_acc: 0.7798071\n",
      "epoch: 771 train_loss: 0.20826207 train_acc: 0.7868185\n",
      "epoch: 771 valid_loss: 0.104830086 valid_acc: 0.81537724\n",
      "epoch: 772 train_loss: 0.2006704 train_acc: 0.7974895\n",
      "epoch: 772 valid_loss: 0.37297004 valid_acc: 0.84342295\n",
      "epoch: 773 train_loss: 0.35654616 train_acc: 0.87276834\n",
      "epoch: 773 valid_loss: 0.29580045 valid_acc: 0.7703673\n",
      "epoch: 774 train_loss: 0.16980197 train_acc: 0.7970107\n",
      "epoch: 774 valid_loss: 0.35406306 valid_acc: 0.75237703\n",
      "epoch: 775 train_loss: 0.47667897 train_acc: 0.7504617\n",
      "epoch: 775 valid_loss: 0.85910815 valid_acc: 0.73739654\n",
      "epoch: 776 train_loss: 0.7772076 train_acc: 0.7386278\n",
      "epoch: 776 valid_loss: 0.7458443 valid_acc: 0.6906765\n",
      "epoch: 777 train_loss: 0.7761491 train_acc: 0.6933101\n",
      "epoch: 777 valid_loss: 0.7947417 valid_acc: 0.85607773\n",
      "epoch: 778 train_loss: 0.71355146 train_acc: 0.7949586\n",
      "epoch: 778 valid_loss: 0.6226054 valid_acc: 0.7035365\n",
      "epoch: 779 train_loss: 0.54455733 train_acc: 0.7842876\n",
      "epoch: 779 valid_loss: 0.3858392 valid_acc: 0.74710995\n",
      "epoch: 780 train_loss: 0.45949018 train_acc: 0.7351734\n",
      "epoch: 780 valid_loss: 0.39770544 valid_acc: 0.7458103\n",
      "epoch: 781 train_loss: 0.5299709 train_acc: 0.74044055\n",
      "epoch: 781 valid_loss: 0.57034475 valid_acc: 0.7605171\n",
      "epoch: 782 train_loss: 0.39696294 train_acc: 0.7899993\n",
      "epoch: 782 valid_loss: 0.3400356 valid_acc: 0.8726315\n",
      "epoch: 783 train_loss: 0.3054464 train_acc: 0.82755315\n",
      "epoch: 783 valid_loss: 0.1561685 valid_acc: 0.80087554\n",
      "epoch: 784 train_loss: 0.15918596 train_acc: 0.86777484\n",
      "epoch: 784 valid_loss: 0.24434687 valid_acc: 0.7726247\n",
      "epoch: 785 train_loss: 0.2491715 train_acc: 0.7705041\n",
      "epoch: 785 valid_loss: 0.27905872 valid_acc: 0.77125657\n",
      "epoch: 786 train_loss: 0.30542967 train_acc: 0.76339006\n",
      "epoch: 786 valid_loss: 0.22655636 valid_acc: 0.801286\n",
      "epoch: 787 train_loss: 0.14537862 train_acc: 0.811957\n",
      "epoch: 787 valid_loss: 0.16531935 valid_acc: 0.93973595\n",
      "epoch: 788 train_loss: 0.24717858 train_acc: 0.85375196\n",
      "epoch: 788 valid_loss: 0.62528163 valid_acc: 0.7663999\n",
      "epoch: 789 train_loss: 0.6192874 train_acc: 0.76438195\n",
      "epoch: 789 valid_loss: 0.6723484 valid_acc: 0.7383542\n",
      "epoch: 790 train_loss: 0.512769 train_acc: 0.834975\n",
      "epoch: 790 valid_loss: 0.067109965 valid_acc: 0.85505164\n",
      "epoch: 791 train_loss: 0.036733296 train_acc: 0.85871124\n",
      "epoch: 791 valid_loss: 0.12619361 valid_acc: 0.81257266\n",
      "epoch: 792 train_loss: 0.12580018 train_acc: 0.8168479\n",
      "epoch: 792 valid_loss: 0.124967515 valid_acc: 0.82474864\n",
      "epoch: 793 train_loss: 0.10327625 train_acc: 0.8926397\n",
      "epoch: 793 valid_loss: 0.120871544 valid_acc: 0.8097681\n",
      "epoch: 794 train_loss: 0.098399684 train_acc: 0.8230043\n",
      "epoch: 794 valid_loss: 0.2101131 valid_acc: 0.79396677\n",
      "epoch: 795 train_loss: 0.19551995 train_acc: 0.79119635\n",
      "epoch: 795 valid_loss: 0.17647882 valid_acc: 0.8100417\n",
      "epoch: 796 train_loss: 0.22118548 train_acc: 0.87783027\n",
      "epoch: 796 valid_loss: 0.3302254 valid_acc: 0.75873864\n",
      "epoch: 797 train_loss: 0.23131955 train_acc: 0.7913674\n",
      "epoch: 797 valid_loss: 0.13506474 valid_acc: 0.8131883\n",
      "epoch: 798 train_loss: 0.12012555 train_acc: 0.8893905\n",
      "epoch: 798 valid_loss: 0.173353 valid_acc: 0.79889184\n",
      "epoch: 799 train_loss: 0.13838916 train_acc: 0.8032013\n",
      "epoch: 799 valid_loss: 0.09458116 valid_acc: 0.82509065\n",
      "epoch: 800 train_loss: 0.059978947 train_acc: 0.83846366\n",
      "epoch: 800 valid_loss: 0.036145788 valid_acc: 0.84827965\n",
      "epoch: 801 train_loss: 0.0738533 train_acc: 0.83394897\n",
      "epoch: 801 valid_loss: 0.083379306 valid_acc: 0.976811\n",
      "epoch: 802 train_loss: 0.087969035 train_acc: 0.90296876\n",
      "epoch: 802 valid_loss: 0.0649418 valid_acc: 0.8475272\n",
      "epoch: 803 train_loss: 0.048623703 train_acc: 0.9174704\n",
      "epoch: 803 valid_loss: 0.09322421 valid_acc: 0.82686913\n",
      "epoch: 804 train_loss: 0.05755449 train_acc: 0.8396949\n",
      "epoch: 804 valid_loss: 0.045572598 valid_acc: 0.8404816\n",
      "epoch: 805 train_loss: 0.029422132 train_acc: 0.84961355\n",
      "epoch: 805 valid_loss: 0.08403077 valid_acc: 0.83240986\n",
      "epoch: 806 train_loss: 0.10295007 train_acc: 0.82211506\n",
      "epoch: 806 valid_loss: 0.096168436 valid_acc: 0.8185238\n",
      "epoch: 807 train_loss: 0.056472138 train_acc: 0.88207126\n",
      "epoch: 807 valid_loss: 0.048426513 valid_acc: 0.98112047\n",
      "epoch: 808 train_loss: 0.057821095 train_acc: 0.9101511\n",
      "epoch: 808 valid_loss: 0.103035875 valid_acc: 0.8176346\n",
      "epoch: 809 train_loss: 0.0609999 train_acc: 0.83521444\n",
      "epoch: 809 valid_loss: 0.05986833 valid_acc: 0.8393187\n",
      "epoch: 810 train_loss: 0.11272985 train_acc: 0.8168137\n",
      "epoch: 810 valid_loss: 0.07089618 valid_acc: 0.83863467\n",
      "epoch: 811 train_loss: 0.15910056 train_acc: 0.87687254\n",
      "epoch: 811 valid_loss: 0.26445392 valid_acc: 0.78589505\n",
      "epoch: 812 train_loss: 0.30867857 train_acc: 0.7879472\n",
      "epoch: 812 valid_loss: 0.2822595 valid_acc: 0.7798755\n",
      "epoch: 813 train_loss: 0.27175322 train_acc: 0.7810042\n",
      "epoch: 813 valid_loss: 0.1892598 valid_acc: 0.957179\n",
      "epoch: 814 train_loss: 0.1912489 train_acc: 0.8736576\n",
      "epoch: 814 valid_loss: 0.21244359 valid_acc: 0.79526645\n",
      "epoch: 815 train_loss: 0.24080458 train_acc: 0.7793283\n",
      "epoch: 815 valid_loss: 0.20430876 valid_acc: 0.7800123\n",
      "epoch: 816 train_loss: 0.16568813 train_acc: 0.87447846\n",
      "epoch: 816 valid_loss: 0.15207982 valid_acc: 0.805185\n",
      "epoch: 817 train_loss: 0.17149052 train_acc: 0.8094603\n",
      "epoch: 817 valid_loss: 0.085395396 valid_acc: 0.82071275\n",
      "epoch: 818 train_loss: 0.054390334 train_acc: 0.8377454\n",
      "epoch: 818 valid_loss: 0.058587745 valid_acc: 0.8428757\n",
      "epoch: 819 train_loss: 0.06789221 train_acc: 0.9051235\n",
      "epoch: 819 valid_loss: 0.282872 valid_acc: 0.76140636\n",
      "epoch: 820 train_loss: 0.299711 train_acc: 0.7633901\n",
      "epoch: 820 valid_loss: 0.37968394 valid_acc: 0.75258225\n",
      "epoch: 821 train_loss: 0.39189434 train_acc: 0.73411316\n",
      "epoch: 821 valid_loss: 0.29324237 valid_acc: 0.89445245\n",
      "epoch: 822 train_loss: 0.38828993 train_acc: 0.81339353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 822 valid_loss: 0.29210764 valid_acc: 0.76209044\n",
      "epoch: 823 train_loss: 0.30654532 train_acc: 0.7666735\n",
      "epoch: 823 valid_loss: 0.19805768 valid_acc: 0.7847322\n",
      "epoch: 824 train_loss: 0.11338861 train_acc: 0.81688213\n",
      "epoch: 824 valid_loss: 0.19098078 valid_acc: 0.93843627\n",
      "epoch: 825 train_loss: 0.59438187 train_acc: 0.80569804\n",
      "epoch: 825 valid_loss: 1.4237548 valid_acc: 0.62541896\n",
      "epoch: 826 train_loss: 1.6242986 train_acc: 0.63338804\n",
      "epoch: 826 valid_loss: 0.88651884 valid_acc: 0.6923866\n",
      "epoch: 827 train_loss: 0.73215896 train_acc: 0.70271564\n",
      "epoch: 827 valid_loss: 0.5489988 valid_acc: 0.8822765\n",
      "epoch: 828 train_loss: 0.50487417 train_acc: 0.83052874\n",
      "epoch: 828 valid_loss: 0.42336226 valid_acc: 0.7464943\n",
      "epoch: 829 train_loss: 0.41428027 train_acc: 0.7434161\n",
      "epoch: 829 valid_loss: 0.17985484 valid_acc: 0.8129831\n",
      "epoch: 830 train_loss: 0.17827743 train_acc: 0.80559546\n",
      "epoch: 830 valid_loss: 0.47252727 valid_acc: 0.7460155\n",
      "epoch: 831 train_loss: 0.58992475 train_acc: 0.7734797\n",
      "epoch: 831 valid_loss: 1.0332272 valid_acc: 0.6904029\n",
      "epoch: 832 train_loss: 1.0110576 train_acc: 0.748991\n",
      "epoch: 832 valid_loss: 1.0562123 valid_acc: 0.70422053\n",
      "epoch: 833 train_loss: 0.66214883 train_acc: 0.74560505\n",
      "epoch: 833 valid_loss: 0.096101 valid_acc: 0.8306998\n",
      "epoch: 834 train_loss: 0.1290636 train_acc: 0.8818319\n",
      "epoch: 834 valid_loss: 0.27034253 valid_acc: 0.7646214\n",
      "epoch: 835 train_loss: 0.32225168 train_acc: 0.7467679\n",
      "epoch: 835 valid_loss: 0.89574265 valid_acc: 0.6720022\n",
      "epoch: 836 train_loss: 0.8117002 train_acc: 0.66523015\n",
      "epoch: 836 valid_loss: 0.11403707 valid_acc: 0.8228333\n",
      "epoch: 837 train_loss: 0.08019848 train_acc: 0.83176005\n",
      "epoch: 837 valid_loss: 0.07165723 valid_acc: 0.97592175\n",
      "epoch: 838 train_loss: 0.09267686 train_acc: 0.91476846\n",
      "epoch: 838 valid_loss: 0.110294424 valid_acc: 0.82324374\n",
      "epoch: 839 train_loss: 0.086508505 train_acc: 0.82940006\n",
      "epoch: 839 valid_loss: 0.11428224 valid_acc: 0.8133251\n",
      "epoch: 840 train_loss: 0.07162625 train_acc: 0.9042\n",
      "epoch: 840 valid_loss: 0.043102328 valid_acc: 0.8443122\n",
      "epoch: 841 train_loss: 0.037388597 train_acc: 0.848006\n",
      "epoch: 841 valid_loss: 0.01279859 valid_acc: 0.8575142\n",
      "epoch: 842 train_loss: 0.033455476 train_acc: 0.85009235\n",
      "epoch: 842 valid_loss: 0.024891706 valid_acc: 0.8514946\n",
      "epoch: 843 train_loss: 0.016422132 train_acc: 0.92660236\n",
      "epoch: 843 valid_loss: 0.020508794 valid_acc: 0.85689855\n",
      "epoch: 844 train_loss: 0.053220402 train_acc: 0.84390175\n",
      "epoch: 844 valid_loss: 0.033591293 valid_acc: 0.84698\n",
      "epoch: 845 train_loss: 0.031724688 train_acc: 0.8505027\n",
      "epoch: 845 valid_loss: 0.035643853 valid_acc: 0.8478008\n",
      "epoch: 846 train_loss: 0.058885 train_acc: 0.910972\n",
      "epoch: 846 valid_loss: 0.10626396 valid_acc: 0.9519803\n",
      "epoch: 847 train_loss: 0.119364664 train_acc: 0.8771462\n",
      "epoch: 847 valid_loss: 0.0982107 valid_acc: 0.8158561\n",
      "epoch: 848 train_loss: 0.08854285 train_acc: 0.82358575\n",
      "epoch: 848 valid_loss: 0.06431243 valid_acc: 0.8377454\n",
      "epoch: 849 train_loss: 0.056854956 train_acc: 0.84089196\n",
      "epoch: 849 valid_loss: 0.12739074 valid_acc: 0.8246802\n",
      "epoch: 850 train_loss: 0.13356279 train_acc: 0.81749773\n",
      "epoch: 850 valid_loss: 0.27965066 valid_acc: 0.77419794\n",
      "epoch: 851 train_loss: 0.212803 train_acc: 0.7894521\n",
      "epoch: 851 valid_loss: 0.106342934 valid_acc: 0.82057595\n",
      "epoch: 852 train_loss: 0.0673901 train_acc: 0.9087831\n",
      "epoch: 852 valid_loss: 0.11775384 valid_acc: 0.8213968\n",
      "epoch: 853 train_loss: 0.1237057 train_acc: 0.81753194\n",
      "epoch: 853 valid_loss: 0.18016493 valid_acc: 0.8781722\n",
      "epoch: 854 train_loss: 0.18383543 train_acc: 0.838361\n",
      "epoch: 854 valid_loss: 0.31122857 valid_acc: 0.7938299\n",
      "epoch: 855 train_loss: 0.32411695 train_acc: 0.77607906\n",
      "epoch: 855 valid_loss: 0.2447463 valid_acc: 0.93241674\n",
      "epoch: 856 train_loss: 0.14842066 train_acc: 0.8866544\n",
      "epoch: 856 valid_loss: 0.025987402 valid_acc: 0.86975855\n",
      "epoch: 857 train_loss: 0.09456416 train_acc: 0.84520143\n",
      "epoch: 857 valid_loss: 0.16110171 valid_acc: 0.8029961\n",
      "epoch: 858 train_loss: 0.16970178 train_acc: 0.8013544\n",
      "epoch: 858 valid_loss: 0.26303932 valid_acc: 0.91476846\n",
      "epoch: 859 train_loss: 0.2509637 train_acc: 0.8361721\n",
      "epoch: 859 valid_loss: 0.13324425 valid_acc: 0.813804\n",
      "epoch: 860 train_loss: 0.17594182 train_acc: 0.79660034\n",
      "epoch: 860 valid_loss: 0.2549635 valid_acc: 0.79273546\n",
      "epoch: 861 train_loss: 0.16919053 train_acc: 0.8625761\n",
      "epoch: 861 valid_loss: 0.090306856 valid_acc: 0.83925027\n",
      "epoch: 862 train_loss: 0.11215618 train_acc: 0.82338053\n",
      "epoch: 862 valid_loss: 0.32233143 valid_acc: 0.7547028\n",
      "epoch: 863 train_loss: 0.44106296 train_acc: 0.73832\n",
      "epoch: 863 valid_loss: 0.15213369 valid_acc: 0.94780767\n",
      "epoch: 864 train_loss: 0.12047752 train_acc: 0.8909296\n",
      "epoch: 864 valid_loss: 0.04072339 valid_acc: 0.8428757\n",
      "epoch: 865 train_loss: 0.043914318 train_acc: 0.84448326\n",
      "epoch: 865 valid_loss: 0.13348956 valid_acc: 0.7995075\n",
      "epoch: 866 train_loss: 0.15894505 train_acc: 0.80025995\n",
      "epoch: 866 valid_loss: 0.15869054 valid_acc: 0.8092893\n",
      "epoch: 867 train_loss: 0.11203539 train_acc: 0.8610028\n",
      "epoch: 867 valid_loss: 0.049028534 valid_acc: 0.98761886\n",
      "epoch: 868 train_loss: 0.0485005 train_acc: 0.9160681\n",
      "epoch: 868 valid_loss: 0.046724144 valid_acc: 0.8427389\n",
      "epoch: 869 train_loss: 0.043805107 train_acc: 0.844278\n",
      "epoch: 869 valid_loss: 0.03973645 valid_acc: 0.84827965\n",
      "epoch: 870 train_loss: 0.035473257 train_acc: 0.8496477\n",
      "epoch: 870 valid_loss: 0.076116964 valid_acc: 0.83377796\n",
      "epoch: 871 train_loss: 0.11792512 train_acc: 0.824304\n",
      "epoch: 871 valid_loss: 0.08358695 valid_acc: 0.85908747\n",
      "epoch: 872 train_loss: 0.097348124 train_acc: 0.91534984\n",
      "epoch: 872 valid_loss: 0.040813185 valid_acc: 0.9868664\n",
      "epoch: 873 train_loss: 0.041834835 train_acc: 0.9151447\n",
      "epoch: 873 valid_loss: 0.03132096 valid_acc: 0.8465011\n",
      "epoch: 874 train_loss: 0.026824355 train_acc: 0.8519734\n",
      "epoch: 874 valid_loss: 0.10214589 valid_acc: 0.83172584\n",
      "epoch: 875 train_loss: 0.067803115 train_acc: 0.8395239\n",
      "epoch: 875 valid_loss: 0.06686212 valid_acc: 0.84342295\n",
      "epoch: 876 train_loss: 0.09588753 train_acc: 0.83384633\n",
      "epoch: 876 valid_loss: 0.17683621 valid_acc: 0.7964977\n",
      "epoch: 877 train_loss: 0.18652356 train_acc: 0.791128\n",
      "epoch: 877 valid_loss: 0.25020796 valid_acc: 0.78575826\n",
      "epoch: 878 train_loss: 0.15545404 train_acc: 0.87034\n",
      "epoch: 878 valid_loss: 0.16672927 valid_acc: 0.8353512\n",
      "epoch: 879 train_loss: 0.33704865 train_acc: 0.78391135\n",
      "epoch: 879 valid_loss: 0.5670565 valid_acc: 0.73438674\n",
      "epoch: 880 train_loss: 0.51157236 train_acc: 0.8048772\n",
      "epoch: 880 valid_loss: 0.19246688 valid_acc: 0.78842604\n",
      "epoch: 881 train_loss: 0.13718194 train_acc: 0.811615\n",
      "epoch: 881 valid_loss: 0.15124837 valid_acc: 0.7988235\n",
      "epoch: 882 train_loss: 0.114972785 train_acc: 0.81821597\n",
      "epoch: 882 valid_loss: 0.046398714 valid_acc: 0.84526986\n",
      "epoch: 883 train_loss: 0.06936302 train_acc: 0.83781385\n",
      "epoch: 883 valid_loss: 0.17178819 valid_acc: 0.7871947\n",
      "epoch: 884 train_loss: 0.1286907 train_acc: 0.8756413\n",
      "epoch: 884 valid_loss: 0.11165081 valid_acc: 0.8178398\n",
      "epoch: 885 train_loss: 0.12344962 train_acc: 0.8096313\n",
      "epoch: 885 valid_loss: 0.09235366 valid_acc: 0.9603256\n",
      "epoch: 886 train_loss: 0.110777035 train_acc: 0.8926739\n",
      "epoch: 886 valid_loss: 0.04127935 valid_acc: 0.84574866\n",
      "epoch: 887 train_loss: 0.10993424 train_acc: 0.82208085\n",
      "epoch: 887 valid_loss: 0.19453971 valid_acc: 0.79827625\n",
      "epoch: 888 train_loss: 0.25458372 train_acc: 0.7925645\n",
      "epoch: 888 valid_loss: 0.30826437 valid_acc: 0.77057254\n",
      "epoch: 889 train_loss: 0.1926403 train_acc: 0.8003626\n",
      "epoch: 889 valid_loss: 0.054228466 valid_acc: 0.98207814\n",
      "epoch: 890 train_loss: 0.06139797 train_acc: 0.94007796\n",
      "epoch: 890 valid_loss: 0.16940664 valid_acc: 0.7918462\n",
      "epoch: 891 train_loss: 0.11463608 train_acc: 0.8101785\n",
      "epoch: 891 valid_loss: 0.14339773 valid_acc: 0.8071688\n",
      "epoch: 892 train_loss: 0.07496863 train_acc: 0.831247\n",
      "epoch: 892 valid_loss: 0.02937389 valid_acc: 0.85163146\n",
      "epoch: 893 train_loss: 0.03500572 train_acc: 0.92054856\n",
      "epoch: 893 valid_loss: 0.09261063 valid_acc: 0.8206444\n",
      "epoch: 894 train_loss: 0.13777564 train_acc: 0.8174635\n",
      "epoch: 894 valid_loss: 0.1288757 valid_acc: 0.81859225\n",
      "epoch: 895 train_loss: 0.07166691 train_acc: 0.8505027\n",
      "epoch: 895 valid_loss: 0.13983025 valid_acc: 0.81236744\n",
      "epoch: 896 train_loss: 0.12264675 train_acc: 0.8533758\n",
      "epoch: 896 valid_loss: 0.096306786 valid_acc: 0.8426705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 897 train_loss: 0.08204202 train_acc: 0.847664\n",
      "epoch: 897 valid_loss: 0.15355732 valid_acc: 0.80641633\n",
      "epoch: 898 train_loss: 0.115714185 train_acc: 0.89534163\n",
      "epoch: 898 valid_loss: 0.055034854 valid_acc: 0.84479105\n",
      "epoch: 899 train_loss: 0.09400864 train_acc: 0.8263903\n",
      "epoch: 899 valid_loss: 0.15743461 valid_acc: 0.8239962\n",
      "epoch: 900 train_loss: 0.08728145 train_acc: 0.8297079\n",
      "epoch: 900 valid_loss: 0.069492325 valid_acc: 0.83993435\n",
      "epoch: 901 train_loss: 0.05194435 train_acc: 0.8442096\n",
      "epoch: 901 valid_loss: 0.19842893 valid_acc: 0.7795335\n",
      "epoch: 902 train_loss: 0.1865727 train_acc: 0.8624393\n",
      "epoch: 902 valid_loss: 0.2550319 valid_acc: 0.9291333\n",
      "epoch: 903 train_loss: 0.14517596 train_acc: 0.8822765\n",
      "epoch: 903 valid_loss: 0.115669206 valid_acc: 0.81558245\n",
      "epoch: 904 train_loss: 0.13642554 train_acc: 0.8161297\n",
      "epoch: 904 valid_loss: 0.38820368 valid_acc: 0.73972225\n",
      "epoch: 905 train_loss: 0.26281837 train_acc: 0.77423215\n",
      "epoch: 905 valid_loss: 0.029369531 valid_acc: 0.8518366\n",
      "epoch: 906 train_loss: 0.07121936 train_acc: 0.8336754\n",
      "epoch: 906 valid_loss: 0.25705835 valid_acc: 0.7726247\n",
      "epoch: 907 train_loss: 0.24945304 train_acc: 0.7850058\n",
      "epoch: 907 valid_loss: 0.08967666 valid_acc: 0.8539572\n",
      "epoch: 908 train_loss: 0.17323849 train_acc: 0.8852863\n",
      "epoch: 908 valid_loss: 0.42776844 valid_acc: 0.76393735\n",
      "epoch: 909 train_loss: 0.42220062 train_acc: 0.76790476\n",
      "epoch: 909 valid_loss: 0.26886487 valid_acc: 0.8663383\n",
      "epoch: 910 train_loss: 0.16604993 train_acc: 0.84273887\n",
      "epoch: 910 valid_loss: 0.035093963 valid_acc: 0.85156304\n",
      "epoch: 911 train_loss: 0.06959309 train_acc: 0.8393871\n",
      "epoch: 911 valid_loss: 0.06190318 valid_acc: 0.9800944\n",
      "epoch: 912 train_loss: 0.089236796 train_acc: 0.89807785\n",
      "epoch: 912 valid_loss: 0.11504275 valid_acc: 0.81394076\n",
      "epoch: 913 train_loss: 0.08428536 train_acc: 0.82721114\n",
      "epoch: 913 valid_loss: 0.03139674 valid_acc: 0.8506738\n",
      "epoch: 914 train_loss: 0.10053456 train_acc: 0.8334359\n",
      "epoch: 914 valid_loss: 0.42993516 valid_acc: 0.75059855\n",
      "epoch: 915 train_loss: 0.56911397 train_acc: 0.81205964\n",
      "epoch: 915 valid_loss: 0.92527544 valid_acc: 0.69293386\n",
      "epoch: 916 train_loss: 0.79040146 train_acc: 0.72925645\n",
      "epoch: 916 valid_loss: 0.18903378 valid_acc: 0.9401464\n",
      "epoch: 917 train_loss: 0.12983103 train_acc: 0.89140844\n",
      "epoch: 917 valid_loss: 0.09064292 valid_acc: 0.82892126\n",
      "epoch: 918 train_loss: 0.064600736 train_acc: 0.83907926\n",
      "epoch: 918 valid_loss: 0.1382351 valid_acc: 0.8216704\n",
      "epoch: 919 train_loss: 0.089652 train_acc: 0.83665097\n",
      "epoch: 919 valid_loss: 0.14751956 valid_acc: 0.801628\n",
      "epoch: 920 train_loss: 0.13209942 train_acc: 0.81479585\n",
      "epoch: 920 valid_loss: 0.17561883 valid_acc: 0.9400096\n",
      "epoch: 921 train_loss: 0.124828935 train_acc: 0.94390863\n",
      "epoch: 921 valid_loss: 0.29577905 valid_acc: 0.7734455\n",
      "epoch: 922 train_loss: 0.24616969 train_acc: 0.7795677\n",
      "epoch: 922 valid_loss: 0.14983054 valid_acc: 0.80491143\n",
      "epoch: 923 train_loss: 0.07292013 train_acc: 0.8363431\n",
      "epoch: 923 valid_loss: 0.08526409 valid_acc: 0.83576167\n",
      "epoch: 924 train_loss: 0.23043981 train_acc: 0.772351\n",
      "epoch: 924 valid_loss: 0.82467663 valid_acc: 0.74991447\n",
      "epoch: 925 train_loss: 0.5905462 train_acc: 0.75395036\n",
      "epoch: 925 valid_loss: 0.28006956 valid_acc: 0.89479446\n",
      "epoch: 926 train_loss: 0.15792698 train_acc: 0.88111365\n",
      "epoch: 926 valid_loss: 0.0859774 valid_acc: 0.9640194\n",
      "epoch: 927 train_loss: 0.09094858 train_acc: 0.89205825\n",
      "epoch: 927 valid_loss: 0.15675125 valid_acc: 0.7978658\n",
      "epoch: 928 train_loss: 0.12497501 train_acc: 0.8159245\n",
      "epoch: 928 valid_loss: 0.06083688 valid_acc: 0.8408236\n",
      "epoch: 929 train_loss: 0.07285564 train_acc: 0.8358643\n",
      "epoch: 929 valid_loss: 0.025350971 valid_acc: 0.85457283\n",
      "epoch: 930 train_loss: 0.087840974 train_acc: 0.8283398\n",
      "epoch: 930 valid_loss: 0.12510897 valid_acc: 0.8125043\n",
      "epoch: 931 train_loss: 0.07000841 train_acc: 0.8343252\n",
      "epoch: 931 valid_loss: 0.24521673 valid_acc: 0.9372734\n",
      "epoch: 932 train_loss: 0.48001027 train_acc: 0.8178056\n",
      "epoch: 932 valid_loss: 1.0370301 valid_acc: 0.68937683\n",
      "epoch: 933 train_loss: 0.9084025 train_acc: 0.7680074\n",
      "epoch: 933 valid_loss: 0.2857387 valid_acc: 0.80942607\n",
      "epoch: 934 train_loss: 0.14203508 train_acc: 0.82385933\n",
      "epoch: 934 valid_loss: 0.035259705 valid_acc: 0.85005814\n",
      "epoch: 935 train_loss: 0.14387852 train_acc: 0.81332517\n",
      "epoch: 935 valid_loss: 0.17448285 valid_acc: 0.7928723\n",
      "epoch: 936 train_loss: 0.15733284 train_acc: 0.7983788\n",
      "epoch: 936 valid_loss: 0.09151581 valid_acc: 0.8356933\n",
      "epoch: 937 train_loss: 0.23676674 train_acc: 0.8525207\n",
      "epoch: 937 valid_loss: 0.47735623 valid_acc: 0.7436897\n",
      "epoch: 938 train_loss: 0.54983246 train_acc: 0.72925645\n",
      "epoch: 938 valid_loss: 0.27409184 valid_acc: 0.79547167\n",
      "epoch: 939 train_loss: 0.30757436 train_acc: 0.82474864\n",
      "epoch: 939 valid_loss: 0.35966715 valid_acc: 0.7566181\n",
      "epoch: 940 train_loss: 0.27757975 train_acc: 0.79150426\n",
      "epoch: 940 valid_loss: 0.1555379 valid_acc: 0.9523223\n",
      "epoch: 941 train_loss: 0.22435577 train_acc: 0.857651\n",
      "epoch: 941 valid_loss: 0.19427988 valid_acc: 0.7923251\n",
      "epoch: 942 train_loss: 0.24553356 train_acc: 0.7698201\n",
      "epoch: 942 valid_loss: 0.121597745 valid_acc: 0.81188864\n",
      "epoch: 943 train_loss: 0.16255888 train_acc: 0.81120455\n",
      "epoch: 943 valid_loss: 0.15017648 valid_acc: 0.81872904\n",
      "epoch: 944 train_loss: 0.15808788 train_acc: 0.8240304\n",
      "epoch: 944 valid_loss: 0.28447577 valid_acc: 0.93775225\n",
      "epoch: 945 train_loss: 0.28295872 train_acc: 0.8671934\n",
      "epoch: 945 valid_loss: 0.17361024 valid_acc: 0.7982078\n",
      "epoch: 946 train_loss: 0.11516801 train_acc: 0.8921267\n",
      "epoch: 946 valid_loss: 0.11726878 valid_acc: 0.814146\n",
      "epoch: 947 train_loss: 0.10806673 train_acc: 0.8140434\n",
      "epoch: 947 valid_loss: 0.0859564 valid_acc: 0.8207812\n",
      "epoch: 948 train_loss: 0.052048095 train_acc: 0.84328616\n",
      "epoch: 948 valid_loss: 0.06499141 valid_acc: 0.836993\n",
      "epoch: 949 train_loss: 0.069518484 train_acc: 0.83176005\n",
      "epoch: 949 valid_loss: 0.026904145 valid_acc: 0.9873452\n",
      "epoch: 950 train_loss: 0.048143342 train_acc: 0.9057733\n",
      "epoch: 950 valid_loss: 0.09219944 valid_acc: 0.83624053\n",
      "epoch: 951 train_loss: 0.055524666 train_acc: 0.8448594\n",
      "epoch: 951 valid_loss: 0.04454855 valid_acc: 0.9843355\n",
      "epoch: 952 train_loss: 0.037016302 train_acc: 0.9181545\n",
      "epoch: 952 valid_loss: 0.055724867 valid_acc: 0.84677476\n",
      "epoch: 953 train_loss: 0.028437806 train_acc: 0.8537862\n",
      "epoch: 953 valid_loss: 0.019807262 valid_acc: 0.8566933\n",
      "epoch: 954 train_loss: 0.052550048 train_acc: 0.84691155\n",
      "epoch: 954 valid_loss: 0.025853094 valid_acc: 0.99439085\n",
      "epoch: 955 train_loss: 0.026644953 train_acc: 0.9847801\n",
      "epoch: 955 valid_loss: 0.021075055 valid_acc: 0.8556673\n",
      "epoch: 956 train_loss: 0.029891394 train_acc: 0.85529107\n",
      "epoch: 956 valid_loss: 0.077918336 valid_acc: 0.82741636\n",
      "epoch: 957 train_loss: 0.04044785 train_acc: 0.8479718\n",
      "epoch: 957 valid_loss: 0.053049818 valid_acc: 0.8454751\n",
      "epoch: 958 train_loss: 0.026170826 train_acc: 0.85416234\n",
      "epoch: 958 valid_loss: 0.07702259 valid_acc: 0.82255965\n",
      "epoch: 959 train_loss: 0.100250825 train_acc: 0.82533\n",
      "epoch: 959 valid_loss: 0.28147265 valid_acc: 0.75388193\n",
      "epoch: 960 train_loss: 0.2719708 train_acc: 0.7565839\n",
      "epoch: 960 valid_loss: 0.13131492 valid_acc: 0.95772624\n",
      "epoch: 961 train_loss: 0.1856391 train_acc: 0.9326903\n",
      "epoch: 961 valid_loss: 0.09899329 valid_acc: 0.828032\n",
      "epoch: 962 train_loss: 0.06264517 train_acc: 0.8356591\n",
      "epoch: 962 valid_loss: 0.06839303 valid_acc: 0.83329916\n",
      "epoch: 963 train_loss: 0.053779002 train_acc: 0.84202063\n",
      "epoch: 963 valid_loss: 0.08389675 valid_acc: 0.83644575\n",
      "epoch: 964 train_loss: 0.1270052 train_acc: 0.824133\n",
      "epoch: 964 valid_loss: 0.16084395 valid_acc: 0.8159929\n",
      "epoch: 965 train_loss: 0.15199772 train_acc: 0.81859225\n",
      "epoch: 965 valid_loss: 0.103532836 valid_acc: 0.947534\n",
      "epoch: 966 train_loss: 0.079021454 train_acc: 0.95837605\n",
      "epoch: 966 valid_loss: 0.103155784 valid_acc: 0.82126\n",
      "epoch: 967 train_loss: 0.118293054 train_acc: 0.81188864\n",
      "epoch: 967 valid_loss: 0.04587767 valid_acc: 0.8491689\n",
      "epoch: 968 train_loss: 0.05469858 train_acc: 0.8433545\n",
      "epoch: 968 valid_loss: 0.32079333 valid_acc: 0.7891785\n",
      "epoch: 969 train_loss: 0.29702407 train_acc: 0.7863739\n",
      "epoch: 969 valid_loss: 0.5148638 valid_acc: 0.7223476\n",
      "epoch: 970 train_loss: 0.64587426 train_acc: 0.76821256\n",
      "epoch: 970 valid_loss: 1.2545307 valid_acc: 0.8161297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 971 train_loss: 0.78786045 train_acc: 0.77327454\n",
      "epoch: 971 valid_loss: 0.25348195 valid_acc: 0.7832273\n",
      "epoch: 972 train_loss: 0.15497015 train_acc: 0.8104863\n",
      "epoch: 972 valid_loss: 0.036750965 valid_acc: 0.8493741\n",
      "epoch: 973 train_loss: 0.13645045 train_acc: 0.827348\n",
      "epoch: 973 valid_loss: 0.18362498 valid_acc: 0.81510365\n",
      "epoch: 974 train_loss: 0.15449914 train_acc: 0.8164033\n",
      "epoch: 974 valid_loss: 0.079924956 valid_acc: 0.82686913\n",
      "epoch: 975 train_loss: 0.061331276 train_acc: 0.8381901\n",
      "epoch: 975 valid_loss: 0.100195535 valid_acc: 0.83890826\n",
      "epoch: 976 train_loss: 0.06286548 train_acc: 0.89113486\n",
      "epoch: 976 valid_loss: 0.1649406 valid_acc: 0.8488269\n",
      "epoch: 977 train_loss: 0.17895065 train_acc: 0.8223203\n",
      "epoch: 977 valid_loss: 0.16014773 valid_acc: 0.9196935\n",
      "epoch: 978 train_loss: 0.11722694 train_acc: 0.8807032\n",
      "epoch: 978 valid_loss: 0.116909444 valid_acc: 0.8105205\n",
      "epoch: 979 train_loss: 0.09232283 train_acc: 0.8289896\n",
      "epoch: 979 valid_loss: 0.44409016 valid_acc: 0.7683152\n",
      "epoch: 980 train_loss: 0.43567538 train_acc: 0.75579727\n",
      "epoch: 980 valid_loss: 0.4833439 valid_acc: 0.7603119\n",
      "epoch: 981 train_loss: 0.33620334 train_acc: 0.8520077\n",
      "epoch: 981 valid_loss: 0.10403463 valid_acc: 0.8226281\n",
      "epoch: 982 train_loss: 0.059857603 train_acc: 0.8401737\n",
      "epoch: 982 valid_loss: 0.034221232 valid_acc: 0.9759902\n",
      "epoch: 983 train_loss: 0.101223424 train_acc: 0.8806006\n",
      "epoch: 983 valid_loss: 0.3267099 valid_acc: 0.7902045\n",
      "epoch: 984 train_loss: 0.26579106 train_acc: 0.80197\n",
      "epoch: 984 valid_loss: 0.24133888 valid_acc: 0.8026541\n",
      "epoch: 985 train_loss: 0.2843085 train_acc: 0.77960193\n",
      "epoch: 985 valid_loss: 0.23849054 valid_acc: 0.7661263\n",
      "epoch: 986 train_loss: 0.17060776 train_acc: 0.8661331\n",
      "epoch: 986 valid_loss: 0.23850903 valid_acc: 0.7698885\n"
     ]
    }
   ],
   "source": [
    "# We should save the after training and validation\n",
    "saver = tf.train.Saver() \n",
    "\n",
    "# Loss and accuracy of the model for training and validation\n",
    "train_loss_mean, valid_loss_mean = [], []\n",
    "train_acc_mean, valid_acc_mean = [], []\n",
    "\n",
    "# now that we can calculate loss and optimize, we can start a session for calculating the error.\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize all the model parameters/variables\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "    \n",
    "    #     # Restoring/loading/uploading the trained and validated model\n",
    "    #     saver.restore(sess,'checkpoints/mlp-fnirs-har.ckpt')\n",
    "    \n",
    "    # for every epoch start feeding the arrays into the tensors in the model\n",
    "    for epoch in range(train_epochs):\n",
    "        train_loss, valid_loss = [], []\n",
    "        train_acc, valid_acc = [], []\n",
    "        \n",
    "        # Training\n",
    "        for Xinputs, Yindices in get_batches(X=Xtrain, Y=Ytrain, batch_size=batch_size):\n",
    "            feed_dict = {model.Xinputs: Xinputs, model.Yindices: Yindices}\n",
    "            loss, acc, _ = sess.run(fetches=[model.loss, model.acc, model.opt], feed_dict=feed_dict)\n",
    "            train_loss.append(loss)\n",
    "            train_acc.append(acc)\n",
    "            \n",
    "        # printing out train and validation loss\n",
    "        print('epoch:', epoch+1, 'train_loss:', np.mean(train_loss), 'train_acc:', np.mean(train_acc))\n",
    "        \n",
    "        # Saving the losses for plotting\n",
    "        train_loss_mean.append(np.mean(train_loss))\n",
    "        train_acc_mean.append(np.mean(train_acc))\n",
    "        \n",
    "        # Validation\n",
    "        for Xinputs, Yindices in get_batches(X=Xvalid, Y=Yvalid, batch_size=batch_size):\n",
    "            feed_dict = {model.Xinputs: Xinputs, model.Yindices: Yindices}\n",
    "            loss, acc = sess.run(fetches=[model.loss, model.acc], feed_dict=feed_dict)\n",
    "            valid_loss.append(loss)\n",
    "            valid_acc.append(acc)\n",
    "        \n",
    "        # printing out train and validation loss\n",
    "        print('epoch:', epoch+1, 'valid_loss:', np.mean(valid_loss), 'valid_acc:', np.mean(valid_acc))\n",
    "\n",
    "        # Saving the losses for plotting\n",
    "        valid_loss_mean.append(np.mean(valid_loss))\n",
    "        valid_acc_mean.append(np.mean(valid_acc))        \n",
    "    \n",
    "    # Saving the trained and validated model\n",
    "    saver.save(sess,'checkpoints/mlp-fnirs-har.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "%matplotlib inline\n",
    "\n",
    "mplot.plot(train_loss_mean, label='train_loss_mean')\n",
    "mplot.plot(valid_loss_mean, label='valid_loss_mean')\n",
    "mplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mplot.plot(train_acc_mean, label='train_acc_mean')\n",
    "mplot.plot(valid_acc_mean, label='valid_acc_mean')\n",
    "mplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "    \n",
    "    # Restoring/loading/uploading the trained and validated model\n",
    "    saver.restore(sess,'checkpoints/mlp-fnirs-har.ckpt')\n",
    "    \n",
    "    # Saving the test loss for every batch/minibtch\n",
    "    test_loss, test_acc = [], []\n",
    "    \n",
    "    # Testing\n",
    "    for Xinputs, Yindices in get_batches(X=Xtest, Y=Ytest, batch_size=batch_size):\n",
    "        feed_dict = {model.Xinputs: Xinputs, model.Yindices: Yindices}\n",
    "        loss, acc = sess.run(fetches=[model.loss, model.acc], feed_dict=feed_dict)\n",
    "        test_loss.append(loss)\n",
    "        test_acc.append(acc)\n",
    "        \n",
    "    # Printing the test loss\n",
    "    print('test_loss:', np.mean(test_loss), 'test acc', np.mean(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest test_loss: 0.7203058 test acc 0.67275465"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
