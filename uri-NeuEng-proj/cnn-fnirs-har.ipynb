{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for fNIRS data analysis for Human Activity Recognition (HAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;31mall-fNIRs-data.zip\u001b[0m  \u001b[01;34mP13-4-17-2018\u001b[0m/  \u001b[01;34mP16-4-18-2018\u001b[0m/  \u001b[01;34mP19-4-19-2018\u001b[0m/\r\n",
      "\u001b[01;34mP11-4-17-2018\u001b[0m/      \u001b[01;34mP14-4-18-2018\u001b[0m/  \u001b[01;34mP17-4-18-2018\u001b[0m/  \u001b[01;34mP20-4-19-2018\u001b[0m/\r\n",
      "\u001b[01;34mP12-4-17-2018\u001b[0m/      \u001b[01;34mP15-4-18-2018\u001b[0m/  \u001b[01;34mP18-4-19-2018\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "% ls ../../../datasets/fNIRs_data_10subjects/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m1. Right Hand\u001b[0m/  \u001b[01;34m2. Both Hands\u001b[0m/  \u001b[01;34m3. Left Hand\u001b[0m/  \u001b[01;34m4. Right Leg\u001b[0m/  \u001b[01;34m5. Left Leg\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "% ls ../../../datasets/fNIRs_data_10subjects/P12-4-17-2018/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m2018-04-17_006\u001b[0m/\r\n",
      "fNIR_data.txt\r\n",
      "head20180417-145130.txt\r\n",
      "NIRS-2018-04-17_006_deoxyhb_T141to2511_C1to20.txt\r\n",
      "NIRS-2018-04-17_006_oxyhb_T141to2511_C1to20.txt\r\n",
      "\u001b[01;34mProcessed\u001b[0m/\r\n",
      "r_hand20180417-145128.txt\r\n",
      "r_lower_arm20180417-145129.txt\r\n",
      "r_upper_arm20180417-145129.txt\r\n"
     ]
    }
   ],
   "source": [
    "% ls ../../../datasets/fNIRs_data_10subjects/P12-4-17-2018/1.\\ Right\\ Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/home/arasdar/datasets/fNIRs_data_10subjects/P11-4-17-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P11-4-17-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P11-4-17-2018/3. Left hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P11-4-17-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P20-4-19-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P20-4-19-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P20-4-19-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data_10subjects/P20-4-19-2018/5. Left Leg/fNIR_data.txt'],\n",
       " 48)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# % find ../../datasets/fNIRs_data/ | grep fNIR_data # NOT WORKING!!\n",
    "def find_all(name, path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            result.append(os.path.join(root, name))\n",
    "    return result\n",
    "\n",
    "allpaths = find_all(name='fNIR_data.txt', path='/home/arasdar/datasets/fNIRs_data_10subjects/')\n",
    "allpaths = sorted(allpaths, reverse=False)\n",
    "# print(allpaths, len(allpaths))\n",
    "allpaths, len(allpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelstest=[]\n",
    "# for each in range(len(allpaths)):\n",
    "#     labeltest = allpaths[each][59:60]\n",
    "# #     print(labeltest)\n",
    "#     labelstest.append(labeltest)\n",
    "# # allpaths[each][59:60] - new\n",
    "# # allpaths[each][48:49] - old\n",
    "# len(labelstest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(labelstest)\n",
    "# np.array(labelstest, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/arasdar-DL-env/lib/python3.6/site-packages/pandas/io/parsers.py:709: UserWarning: Duplicate names specified. This will raise an error in the future.\n",
      "  return _read(filepath_or_buffer, kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2388, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P11-4-17-2018/1. Right Hand/fNIR_data.txt\n",
      "(1244, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P11-4-17-2018/2. Both Hands/fNIR_data.txt\n",
      "(2389, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P11-4-17-2018/3. Left hand/fNIR_data.txt\n",
      "(1201, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P11-4-17-2018/5. Left Leg/fNIR_data.txt\n",
      "(2372, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/1. Right Hand/fNIR_data.txt\n",
      "(1210, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/2. Both Hands/fNIR_data.txt\n",
      "(2378, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/3. Left Hand/fNIR_data.txt\n",
      "(1202, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/4. Right Leg/fNIR_data.txt\n",
      "(1222, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/5. Left Leg/fNIR_data.txt\n",
      "(2405, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/1. Right Hand/fNIR_data.txt\n",
      "(1196, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/2. Both Hands/fNIR_data.txt\n",
      "(2380, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/3. Left Hand/fNIR_data.txt\n",
      "(1203, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/4. Right Leg/fNIR_data.txt\n",
      "(1242, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/5. Left Leg/fNIR_data.txt\n",
      "(2373, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/1. Right Hand/fNIR_data.txt\n",
      "(1202, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/2. Both Hands/fNIR_data.txt\n",
      "(2386, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/3. Left Hand/fNIR_data.txt\n",
      "(1196, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/4. Right Leg/fNIR_data.txt\n",
      "(1229, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/5. Left Leg/fNIR_data.txt\n",
      "(2387, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/1. Right Hand/fNIR_data.txt\n",
      "(1224, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/2. Both Hands/fNIR_data.txt\n",
      "(2379, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/3. Left Hand/fNIR_data.txt\n",
      "(1230, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/4. Right Leg/fNIR_data.txt\n",
      "(1227, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/5. Left Leg/fNIR_data.txt\n",
      "(2384, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/1. Right Hand/fNIR_data.txt\n",
      "(1230, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/2. Both Hands/fNIR_data.txt\n",
      "(2375, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/3. Left Hand/fNIR_data.txt\n",
      "(1196, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/4. Right Leg/fNIR_data.txt\n",
      "(1197, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/5. Left Leg/fNIR_data.txt\n",
      "(2373, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/1. Right Hand/fNIR_data.txt\n",
      "(1220, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/2. Both Hands/fNIR_data.txt\n",
      "(2372, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/3. Left Hand/fNIR_data.txt\n",
      "(1223, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/4. Right Leg/fNIR_data.txt\n",
      "(1222, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/5. Left Leg/fNIR_data.txt\n",
      "(2395, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/1. Right Hand/fNIR_data.txt\n",
      "(1201, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/2. Both Hands/fNIR_data.txt\n",
      "(2379, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/3. Left Hand/fNIR_data.txt\n",
      "(1197, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/4. Right Leg/fNIR_data.txt\n",
      "(1196, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/5. Left Leg/fNIR_data.txt\n",
      "(2372, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/1. Right Hand/fNIR_data.txt\n",
      "(1194, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/2. Both Hands/fNIR_data.txt\n",
      "(2383, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/3. Left Hand/fNIR_data.txt\n",
      "(1196, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/4. Right Leg/fNIR_data.txt\n",
      "(1227, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/5. Left Leg/fNIR_data.txt\n",
      "(2381, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P20-4-19-2018/1. Right Hand/fNIR_data.txt\n",
      "(1198, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P20-4-19-2018/2. Both Hands/fNIR_data.txt\n",
      "(2431, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P20-4-19-2018/3. Left Hand/fNIR_data.txt\n",
      "(1208, 42) /home/arasdar/datasets/fNIRs_data_10subjects/P20-4-19-2018/5. Left Leg/fNIR_data.txt\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "# df: data frame object\n",
    "df = []\n",
    "for each_idx in range(len(allpaths)):\n",
    "    file = pd.read_csv(filepath_or_buffer=allpaths[each_idx], names=['time', 'sample', \n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel'],\n",
    "                         header=None)\n",
    "    df.append(file)\n",
    "    \n",
    "for each in range(len(df)):\n",
    "    print(df[each].shape, allpaths[each])\n",
    "    df[each]=df[each].drop(axis=1, columns=None, index=None, labels=['time', 'sample'])\n",
    "    df[each] = df[each].dropna()\n",
    "    df[each]['channel.39'] = df[each]['channel.39'].astype(str).str[1:-1].astype(float)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64 (2387, 40) 1 /home/arasdar/datasets/fNIRs_data_10subjects/P11-4-17-2018/1. Right Hand/fNIR_data.txt\n",
      "float64 (1243, 40) 2 /home/arasdar/datasets/fNIRs_data_10subjects/P11-4-17-2018/2. Both Hands/fNIR_data.txt\n",
      "float64 (2388, 40) 3 /home/arasdar/datasets/fNIRs_data_10subjects/P11-4-17-2018/3. Left hand/fNIR_data.txt\n",
      "float64 (1200, 40) 5 /home/arasdar/datasets/fNIRs_data_10subjects/P11-4-17-2018/5. Left Leg/fNIR_data.txt\n",
      "float64 (2371, 40) 1 /home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/1. Right Hand/fNIR_data.txt\n",
      "float64 (1209, 40) 2 /home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/2. Both Hands/fNIR_data.txt\n",
      "float64 (2377, 40) 3 /home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/3. Left Hand/fNIR_data.txt\n",
      "float64 (1201, 40) 4 /home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/4. Right Leg/fNIR_data.txt\n",
      "float64 (1221, 40) 5 /home/arasdar/datasets/fNIRs_data_10subjects/P12-4-17-2018/5. Left Leg/fNIR_data.txt\n",
      "float64 (2404, 40) 1 /home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/1. Right Hand/fNIR_data.txt\n",
      "float64 (1195, 40) 2 /home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/2. Both Hands/fNIR_data.txt\n",
      "float64 (2379, 40) 3 /home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/3. Left Hand/fNIR_data.txt\n",
      "float64 (1202, 40) 4 /home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/4. Right Leg/fNIR_data.txt\n",
      "float64 (1241, 40) 5 /home/arasdar/datasets/fNIRs_data_10subjects/P13-4-17-2018/5. Left Leg/fNIR_data.txt\n",
      "float64 (2372, 40) 1 /home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/1. Right Hand/fNIR_data.txt\n",
      "float64 (1201, 40) 2 /home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/2. Both Hands/fNIR_data.txt\n",
      "float64 (2385, 40) 3 /home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/3. Left Hand/fNIR_data.txt\n",
      "float64 (1195, 40) 4 /home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/4. Right Leg/fNIR_data.txt\n",
      "float64 (1228, 40) 5 /home/arasdar/datasets/fNIRs_data_10subjects/P14-4-18-2018/5. Left Leg/fNIR_data.txt\n",
      "float64 (2386, 40) 1 /home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/1. Right Hand/fNIR_data.txt\n",
      "float64 (1223, 40) 2 /home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/2. Both Hands/fNIR_data.txt\n",
      "float64 (2378, 40) 3 /home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/3. Left Hand/fNIR_data.txt\n",
      "float64 (1229, 40) 4 /home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/4. Right Leg/fNIR_data.txt\n",
      "float64 (1226, 40) 5 /home/arasdar/datasets/fNIRs_data_10subjects/P15-4-18-2018/5. Left Leg/fNIR_data.txt\n",
      "float64 (2383, 40) 1 /home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/1. Right Hand/fNIR_data.txt\n",
      "float64 (1229, 40) 2 /home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/2. Both Hands/fNIR_data.txt\n",
      "float64 (2374, 40) 3 /home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/3. Left Hand/fNIR_data.txt\n",
      "float64 (1195, 40) 4 /home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/4. Right Leg/fNIR_data.txt\n",
      "float64 (1196, 40) 5 /home/arasdar/datasets/fNIRs_data_10subjects/P16-4-18-2018/5. Left Leg/fNIR_data.txt\n",
      "float64 (2372, 40) 1 /home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/1. Right Hand/fNIR_data.txt\n",
      "float64 (1219, 40) 2 /home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/2. Both Hands/fNIR_data.txt\n",
      "float64 (2371, 40) 3 /home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/3. Left Hand/fNIR_data.txt\n",
      "float64 (1222, 40) 4 /home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/4. Right Leg/fNIR_data.txt\n",
      "float64 (1221, 40) 5 /home/arasdar/datasets/fNIRs_data_10subjects/P17-4-18-2018/5. Left Leg/fNIR_data.txt\n",
      "float64 (2394, 40) 1 /home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/1. Right Hand/fNIR_data.txt\n",
      "float64 (1200, 40) 2 /home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/2. Both Hands/fNIR_data.txt\n",
      "float64 (2378, 40) 3 /home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/3. Left Hand/fNIR_data.txt\n",
      "float64 (1196, 40) 4 /home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/4. Right Leg/fNIR_data.txt\n",
      "float64 (1195, 40) 5 /home/arasdar/datasets/fNIRs_data_10subjects/P18-4-19-2018/5. Left Leg/fNIR_data.txt\n",
      "float64 (2371, 40) 1 /home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/1. Right Hand/fNIR_data.txt\n",
      "float64 (1193, 40) 2 /home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/2. Both Hands/fNIR_data.txt\n",
      "float64 (2382, 40) 3 /home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/3. Left Hand/fNIR_data.txt\n",
      "float64 (1195, 40) 4 /home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/4. Right Leg/fNIR_data.txt\n",
      "float64 (1226, 40) 5 /home/arasdar/datasets/fNIRs_data_10subjects/P19-4-19-2018/5. Left Leg/fNIR_data.txt\n",
      "float64 (2380, 40) 1 /home/arasdar/datasets/fNIRs_data_10subjects/P20-4-19-2018/1. Right Hand/fNIR_data.txt\n",
      "float64 (1197, 40) 2 /home/arasdar/datasets/fNIRs_data_10subjects/P20-4-19-2018/2. Both Hands/fNIR_data.txt\n",
      "float64 (2430, 40) 3 /home/arasdar/datasets/fNIRs_data_10subjects/P20-4-19-2018/3. Left Hand/fNIR_data.txt\n",
      "float64 (1207, 40) 5 /home/arasdar/datasets/fNIRs_data_10subjects/P20-4-19-2018/5. Left Leg/fNIR_data.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = [], []\n",
    "for each in range(0, len(df), 1):\n",
    "    dfmat = df[each].as_matrix()\n",
    "    label = allpaths[each][59:60]\n",
    "    print(dfmat.dtype, dfmat.shape, label, allpaths[each])\n",
    "    data.append(dfmat)\n",
    "    labels.append(label)\n",
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is very much like a convolution for extracting the windows\n",
    "# size/width, stride/overlap, padding, dilation, num filters/out channel\n",
    "def minibatching(X, Y, stride, width):\n",
    "    Xmb, Ymb = [], []\n",
    "    print(len(X), len(Y))\n",
    "    # 1st and 1st\n",
    "    for eachX in range(len(X)):\n",
    "        num_mb = ((X[eachX].shape[0]-width)//stride)+1\n",
    "        for each in range(num_mb):\n",
    "            # The max is (num_mb-1)*stride+width==X[idx].shape[0]\n",
    "            # The last each is (num_mb-1)\n",
    "            # each = ((each-1)*stride)+width\n",
    "            each *= stride\n",
    "            Xmb.append(X[eachX][each:each+width])\n",
    "            # There is only one label for one image signal or signal window or temporal window\n",
    "            #Ymb.append(Y[eachX][each:each+1])\n",
    "            Ymb.append(Y[eachX])\n",
    "    return Xmb, Ymb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 48\n",
      "69615 69615\n",
      "(250, 40) float64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Width is based on the sampling rate which is roughly about 233 points per window\n",
    "# for 10sec rest and 20 sec activity\n",
    "width = 250\n",
    "Xmb, Ymb = minibatching(X=data, Y=labels, stride=1, width=width)\n",
    "# for eachX, eachY in zip(Xmb, Ymb):\n",
    "#     print(eachX.shape, eachY)\n",
    "print(len(Xmb), len(Ymb))\n",
    "print(Xmb[0].shape, Xmb[0].dtype)\n",
    "print(Ymb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69615, 250, 40) float64 (69615,) int64\n"
     ]
    }
   ],
   "source": [
    "# Conversion from python list to numpy array\n",
    "X, Y=np.array(object=Xmb, dtype=float), np.array(object=Ymb, dtype=int)\n",
    "print(X.shape, X.dtype, Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48730, 250, 40) (20885, 250, 40) (48730,) (20885,)\n",
      "float64 float64 int64 int64\n"
     ]
    }
   ],
   "source": [
    "# Now I should devide the data into train and test\n",
    "# Train and valid split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 30% of the training data/ entire training data is assigned to validation.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.30)\n",
    "print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)\n",
    "print(Xtrain.dtype, Xtest.dtype, Ytrain.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48730, 250, 40) float64\n",
      "(20885, 250, 40) float64\n"
     ]
    }
   ],
   "source": [
    "# # standardizing/normalizing the train and test data\n",
    "# def standardize(train, test):\n",
    "# \"\"\" Standardize data \"\"\"\n",
    "# # Standardize train and test\n",
    "# X_train = (train - np.mean(train, axis=0)[None,:,:]) / np.std(train, axis=0)[None,:,:]\n",
    "# X_test = (test - np.mean(test, axis=0)[None,:,:]) / np.std(test, axis=0)[None,:,:]\n",
    "# return X_train, X_test\n",
    "\n",
    "Xtrain = (Xtrain - Xtrain.mean(axis=0))/ Xtrain.std(axis=0)\n",
    "Xtest = (Xtest - Xtest.mean(axis=0))/ Xtest.std(axis=0)\n",
    "print(Xtrain.shape, Xtrain.dtype)\n",
    "print(Xtest.shape, Xtest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.80114117e-17 -4.49055937e-17 -1.72924128e-18 ...  3.54653944e-17\n",
      "  -1.22899160e-16 -3.32041666e-17]\n",
      " [-2.98641564e-17 -6.66543912e-17  1.92529031e-17 ... -4.45339435e-17\n",
      "  -7.08966142e-17  8.45482792e-18]\n",
      " [ 7.58633414e-17 -3.58606821e-18  5.43959159e-17 ...  2.25689909e-17\n",
      "  -8.78131049e-17 -1.04139512e-16]\n",
      " ...\n",
      " [ 1.16080162e-16 -5.02596346e-18 -1.99261452e-17 ...  2.00591419e-17\n",
      "   1.62979282e-16  3.30560761e-17]\n",
      " [ 8.38830111e-17 -5.47843687e-17 -9.92661957e-18 ...  2.89061248e-17\n",
      "  -8.99023200e-18 -8.52887316e-17]\n",
      " [ 3.12448154e-17 -2.73899060e-17 -3.89250162e-17 ...  4.84379791e-17\n",
      "   1.73359286e-16 -7.25415578e-17]] [[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.mean(axis=0), Xtrain.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.37436188e-18  3.39901145e-17  3.11723621e-17 ...  2.44956078e-17\n",
      "   2.00578388e-17 -5.38180412e-17]\n",
      " [ 7.12860463e-18  5.09194707e-17 -3.35538795e-17 ... -9.09016697e-17\n",
      "   5.93841072e-17 -2.16516082e-17]\n",
      " [ 9.25123835e-17 -9.39676076e-17 -3.50848550e-18 ... -2.14761840e-18\n",
      "  -8.23500686e-17  5.11175705e-17]\n",
      " ...\n",
      " [-6.89098447e-17 -5.68893780e-17 -2.56438395e-17 ...  4.63545357e-18\n",
      "  -4.67950898e-17 -1.19713778e-17]\n",
      " [-4.68542291e-17 -5.47210775e-17  3.71048921e-17 ... -2.85994727e-17\n",
      "   1.80009228e-18 -4.87147896e-17]\n",
      " [-1.47622185e-17 -2.47461190e-17  4.53764124e-17 ... -5.74541080e-17\n",
      "  -2.15592447e-17 -7.02760277e-17]] [[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(Xtest.mean(axis=0), Xtest.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 5\n",
      "(48730, 5) float64 (20885, 5) float64\n"
     ]
    }
   ],
   "source": [
    "# Onehotencoding of the output labels\n",
    "def onehot(labels, n_class):\n",
    "\t\"\"\" One-hot encoding \"\"\"\n",
    "\texpansion = np.eye(n_class)\n",
    "\ty = expansion[:, labels-1].T\n",
    "\tassert y.shape[1] == n_class, \"Wrong number of labels!\"\n",
    "\n",
    "\treturn y\n",
    "\n",
    "print(Y.max(axis=0), Ytrain.max(axis=0), Ytest.max(axis=0))\n",
    "# # assert Y.max(axis=0) == Ytrain.max(axis=0) == Ytest.max(axis=0), 'wrong labels'\n",
    "Ytrain=onehot(labels=Ytrain, n_class=Ytrain.max(axis=0))\n",
    "Ytest=onehot(labels=Ytest, n_class=Ytest.max(axis=0))\n",
    "print(Ytrain.shape, Ytrain.dtype, Ytest.shape, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34111, 250, 40) (14619, 250, 40) (20885, 250, 40) float64 float64 float64\n",
      "(34111, 5) (14619, 5) (20885, 5) float64 float64 float64\n"
     ]
    }
   ],
   "source": [
    "# Now separating train and validation set\n",
    "# 30% of the training data/ entire training data is assigned to validation.\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtrain, Ytrain, test_size=0.30)\n",
    "print(Xtrain.shape, Xvalid.shape, Xtest.shape, Xtrain.dtype, Xvalid.dtype, Xtest.dtype)\n",
    "print(Ytrain.shape, Yvalid.shape, Ytest.shape, Ytrain.dtype, Yvalid.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14619, 250, 40) <dtype: 'float32'> (34111, 250, 40) float64 (14619, 250, 40) float64 (20885, 250, 40) float64\n"
     ]
    }
   ],
   "source": [
    "# now I can design the actual input and output tensors\n",
    "N, W, Cin = Xvalid.shape[0], Xvalid.shape[1], Xvalid.shape[2]\n",
    "X = tf.placeholder(dtype=tf.float32, name=None, shape=[N, W, Cin])\n",
    "print(X.shape, X.dtype, Xtrain.shape, Xtrain.dtype, Xvalid.shape, Xvalid.dtype, Xtest.shape, Xtest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14619, 5) <dtype: 'float32'> (34111, 5) float64 (14619, 5) float64 (20885, 5) float64\n"
     ]
    }
   ],
   "source": [
    "# This is the output tensor for labels\n",
    "N, Cout = Yvalid.shape[0], Yvalid.shape[1]\n",
    "Y = tf.placeholder(dtype=tf.float32, name=None, shape=[N, Cout])\n",
    "print(Y.shape, Y.dtype, Ytrain.shape, Ytrain.dtype, Yvalid.shape, Yvalid.dtype, Ytest.shape, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14619, 250, 40) <dtype: 'float32'>\n",
      "(125, 40, 80) <dtype: 'float32_ref'>\n",
      "(14619, 125, 80) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X.dtype)\n",
    "Wwidth, Wchannels, Wnumber = X.shape[1].value//2, X.shape[2].value, X.shape[2].value*2\n",
    "shape = [Wwidth, Wchannels, Wnumber]\n",
    "initial_value=tf.random_normal(dtype=X.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "Wconv = tf.Variable(dtype=X.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(Wconv.shape, Wconv.dtype)\n",
    "Xconv = tf.nn.conv1d(data_format='NWC', filters=Wconv, name=None, padding='SAME', stride=2, use_cudnn_on_gpu=True, \n",
    "                     value=X)\n",
    "Xconv = tf.maximum(name=None, x=(-0.1*Xconv), y=Xconv)\n",
    "print(Xconv.shape, Xconv.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14619, 10000) <dtype: 'float32'>\n",
      "(10000, 5) <dtype: 'float32_ref'>\n",
      "(14619, 5) <dtype: 'float32'>\n",
      "(14619, 5) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# This is the multiplication layer\n",
    "# this part is flatening the input\n",
    "shape = [Xconv.shape[0].value, Xconv.shape[1].value*Xconv.shape[2].value]\n",
    "Xconv_reshaped = tf.reshape(name=None, shape=shape, tensor=Xconv)\n",
    "print(Xconv_reshaped.shape, Xconv_reshaped.dtype)\n",
    "# their first axis or dimension stay the same\n",
    "shape = [Xconv_reshaped.shape[1].value, Y.shape[1].value]\n",
    "initial_value = tf.random_normal(dtype=Xconv_reshaped.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "W = tf.Variable(dtype=Xconv_reshaped.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(W.shape, W.dtype)\n",
    "# The actual multiplication\n",
    "# Y_ = Xconv_reshaped @ W\n",
    "Y_ = tf.matmul(a=Xconv_reshaped, b=W, name=None)\n",
    "print(Y_.shape, Y_.dtype)\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14619,) <dtype: 'float32'>\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Now I need to calculate the loss\n",
    "loss_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=Y_, name=None)\n",
    "print(loss_tensor.shape, loss_tensor.dtype)\n",
    "loss = tf.reduce_mean(axis=0, input_tensor=loss_tensor, name=None)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_Variable/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_1/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Backprop and SGD now using adam\n",
    "opt = tf.train.AdamOptimizer().minimize(loss)\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14619, 5) <dtype: 'float32'> (14619, 5) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(Y_.shape, Y_.dtype, Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14619,) <dtype: 'int64'>\n",
      "(14619,) <dtype: 'int64'>\n",
      "(14619,) <dtype: 'bool'>\n",
      "(14619,) <dtype: 'float32'>\n",
      "() <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "# tf.argmax(\n",
    "#     input,\n",
    "#     axis=None,\n",
    "#     name=None,\n",
    "#     dimension=None,\n",
    "#     output_type=tf.int64\n",
    "# )\n",
    "# Y_NxCout, N:axis 1, Cout: axis 2\n",
    "Y_argmax = tf.argmax(axis=1, name=None, input=Y_)\n",
    "print(Y_argmax.shape, Y_argmax.dtype)\n",
    "Yargmax = tf.argmax(axis=1, name=None, input=Y)\n",
    "print(Yargmax.shape, Yargmax.dtype)\n",
    "\n",
    "acc_tensor = tf.equal(name=None, x=Y_argmax, y=Yargmax)\n",
    "print(acc_tensor.shape, acc_tensor.dtype)\n",
    "# cast bool to int datatype for equal\n",
    "acc_tensor = tf.cast(dtype=tf.float32, name=None, x=acc_tensor)\n",
    "print(acc_tensor.shape, acc_tensor.dtype)\n",
    "acc = tf.reduce_mean(axis=0, input_tensor=acc_tensor)\n",
    "print(acc.shape, acc.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(X, Y, batch_size):\n",
    "    \"\"\" Return a generator for batches \"\"\"\n",
    "    n_batches = len(X) // batch_size\n",
    "    X, Y = X[:n_batches*batch_size], Y[:n_batches*batch_size]\n",
    "\n",
    "    # Loop over batches and yield\n",
    "    for b in range(0, len(X), batch_size):\n",
    "        yield X[b:b+batch_size], Y[b:b+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss: 8973.712 valid_loss: 7603.7856 train_acc: 0.15195978 valid_acc: 0.14590602\n",
      "epoch: 2 train_loss: 7148.1562 valid_loss: 6024.365 train_acc: 0.1539777 valid_acc: 0.15951844\n",
      "epoch: 3 train_loss: 5609.0996 valid_loss: 4545.0615 train_acc: 0.15979205 valid_acc: 0.17080511\n",
      "epoch: 4 train_loss: 4315.392 valid_loss: 3789.1 train_acc: 0.19768794 valid_acc: 0.22080854\n",
      "epoch: 5 train_loss: 3640.5625 valid_loss: 3142.1077 train_acc: 0.21848279 valid_acc: 0.24488679\n",
      "epoch: 6 train_loss: 2999.253 valid_loss: 2599.2795 train_acc: 0.24256104 valid_acc: 0.25911486\n",
      "epoch: 7 train_loss: 2520.0962 valid_loss: 2203.8303 train_acc: 0.24290307 valid_acc: 0.22388673\n",
      "epoch: 8 train_loss: 2160.6963 valid_loss: 1897.2081 train_acc: 0.22385252 valid_acc: 0.24741775\n",
      "epoch: 9 train_loss: 1835.0354 valid_loss: 1529.2705 train_acc: 0.2453314 valid_acc: 0.24474998\n",
      "epoch: 10 train_loss: 1468.6785 valid_loss: 1234.9923 train_acc: 0.24423695 valid_acc: 0.27019632\n",
      "epoch: 11 train_loss: 1173.689 valid_loss: 966.7972 train_acc: 0.26903346 valid_acc: 0.3128121\n",
      "epoch: 12 train_loss: 968.66797 valid_loss: 972.04706 train_acc: 0.32994732 valid_acc: 0.3725973\n",
      "epoch: 13 train_loss: 957.92633 valid_loss: 854.3063 train_acc: 0.3791299 valid_acc: 0.38538888\n",
      "epoch: 14 train_loss: 802.1538 valid_loss: 643.01044 train_acc: 0.39031398 valid_acc: 0.38326836\n",
      "epoch: 15 train_loss: 618.29016 valid_loss: 555.6059 train_acc: 0.38019016 valid_acc: 0.38388398\n",
      "epoch: 16 train_loss: 553.58496 valid_loss: 488.0887 train_acc: 0.3794377 valid_acc: 0.38545728\n",
      "epoch: 17 train_loss: 474.75793 valid_loss: 402.07272 train_acc: 0.3763253 valid_acc: 0.39195567\n",
      "epoch: 18 train_loss: 402.74075 valid_loss: 370.8965 train_acc: 0.390485 valid_acc: 0.41801766\n",
      "epoch: 19 train_loss: 371.12183 valid_loss: 338.6006 train_acc: 0.42468703 valid_acc: 0.4786921\n",
      "epoch: 20 train_loss: 333.4002 valid_loss: 290.73898 train_acc: 0.4817019 valid_acc: 0.52007663\n",
      "epoch: 21 train_loss: 284.08426 valid_loss: 248.08235 train_acc: 0.51436484 valid_acc: 0.5481223\n",
      "epoch: 22 train_loss: 247.5771 valid_loss: 221.6028 train_acc: 0.5380327 valid_acc: 0.5260278\n",
      "epoch: 23 train_loss: 227.9537 valid_loss: 224.98645 train_acc: 0.50054723 valid_acc: 0.48060742\n",
      "epoch: 24 train_loss: 229.51709 valid_loss: 204.28136 train_acc: 0.47291195 valid_acc: 0.5243177\n",
      "epoch: 25 train_loss: 202.75385 valid_loss: 175.20541 train_acc: 0.5280115 valid_acc: 0.58957523\n",
      "epoch: 26 train_loss: 177.23846 valid_loss: 159.98116 train_acc: 0.58543676 valid_acc: 0.6075655\n",
      "epoch: 27 train_loss: 162.45291 valid_loss: 157.4279 train_acc: 0.5924824 valid_acc: 0.5901908\n",
      "epoch: 28 train_loss: 157.72185 valid_loss: 146.58694 train_acc: 0.582427 valid_acc: 0.59538954\n",
      "epoch: 29 train_loss: 145.70737 valid_loss: 135.78023 train_acc: 0.595971 valid_acc: 0.61043847\n",
      "epoch: 30 train_loss: 137.39294 valid_loss: 128.73657 train_acc: 0.6103358 valid_acc: 0.6256242\n",
      "epoch: 31 train_loss: 130.83606 valid_loss: 123.87068 train_acc: 0.62011766 valid_acc: 0.6323962\n",
      "epoch: 32 train_loss: 125.6454 valid_loss: 120.01642 train_acc: 0.6261372 valid_acc: 0.6445037\n",
      "epoch: 33 train_loss: 121.40747 valid_loss: 115.36498 train_acc: 0.63971543 valid_acc: 0.6591422\n",
      "epoch: 34 train_loss: 115.03671 valid_loss: 107.29258 train_acc: 0.65613246 valid_acc: 0.66673505\n",
      "epoch: 35 train_loss: 107.491165 valid_loss: 103.588554 train_acc: 0.66461456 valid_acc: 0.6658458\n",
      "epoch: 36 train_loss: 104.593506 valid_loss: 102.799835 train_acc: 0.6654012 valid_acc: 0.66659826\n",
      "epoch: 37 train_loss: 103.61995 valid_loss: 99.176445 train_acc: 0.6666666 valid_acc: 0.6751488\n",
      "epoch: 38 train_loss: 99.55519 valid_loss: 95.32668 train_acc: 0.6769615 valid_acc: 0.68239963\n",
      "epoch: 39 train_loss: 95.746086 valid_loss: 92.03344 train_acc: 0.68373346 valid_acc: 0.6937547\n",
      "epoch: 40 train_loss: 92.49126 valid_loss: 89.636024 train_acc: 0.692968 valid_acc: 0.69929546\n",
      "epoch: 41 train_loss: 90.023544 valid_loss: 87.40364 train_acc: 0.69857717 valid_acc: 0.7025104\n",
      "epoch: 42 train_loss: 87.81865 valid_loss: 85.58588 train_acc: 0.7005267 valid_acc: 0.7031945\n",
      "epoch: 43 train_loss: 85.78992 valid_loss: 83.21648 train_acc: 0.704631 valid_acc: 0.70941925\n",
      "epoch: 44 train_loss: 83.52076 valid_loss: 81.077805 train_acc: 0.7083932 valid_acc: 0.71256584\n",
      "epoch: 45 train_loss: 81.431946 valid_loss: 79.213684 train_acc: 0.71212125 valid_acc: 0.71461797\n",
      "epoch: 46 train_loss: 79.48804 valid_loss: 77.44122 train_acc: 0.7154046 valid_acc: 0.72125316\n",
      "epoch: 47 train_loss: 77.57005 valid_loss: 75.78754 train_acc: 0.7229633 valid_acc: 0.72740954\n",
      "epoch: 48 train_loss: 75.88374 valid_loss: 74.17406 train_acc: 0.72874343 valid_acc: 0.73089814\n",
      "epoch: 49 train_loss: 74.267494 valid_loss: 72.5546 train_acc: 0.7314796 valid_acc: 0.731719\n",
      "epoch: 50 train_loss: 72.6749 valid_loss: 70.93588 train_acc: 0.7331897 valid_acc: 0.7371229\n",
      "epoch: 51 train_loss: 71.17701 valid_loss: 69.584015 train_acc: 0.73760176 valid_acc: 0.7395171\n",
      "epoch: 52 train_loss: 69.82062 valid_loss: 68.38576 train_acc: 0.73955125 valid_acc: 0.74239004\n",
      "epoch: 53 train_loss: 68.472534 valid_loss: 67.177345 train_acc: 0.74239004 valid_acc: 0.7466311\n",
      "epoch: 54 train_loss: 67.106125 valid_loss: 65.88754 train_acc: 0.74628913 valid_acc: 0.74936724\n",
      "epoch: 55 train_loss: 65.77638 valid_loss: 64.60856 train_acc: 0.74892265 valid_acc: 0.752035\n",
      "epoch: 56 train_loss: 64.53381 valid_loss: 63.43956 train_acc: 0.75206923 valid_acc: 0.7540187\n",
      "epoch: 57 train_loss: 63.36572 valid_loss: 62.28651 train_acc: 0.7552158 valid_acc: 0.7566181\n",
      "epoch: 58 train_loss: 62.218422 valid_loss: 61.21756 train_acc: 0.75784934 valid_acc: 0.75928587\n",
      "epoch: 59 train_loss: 61.112442 valid_loss: 60.16304 train_acc: 0.7600383 valid_acc: 0.761338\n",
      "epoch: 60 train_loss: 60.01098 valid_loss: 59.063145 train_acc: 0.76304805 valid_acc: 0.7649634\n",
      "epoch: 61 train_loss: 58.926495 valid_loss: 58.03516 train_acc: 0.7652712 valid_acc: 0.768452\n",
      "epoch: 62 train_loss: 57.900192 valid_loss: 57.098503 train_acc: 0.7670155 valid_acc: 0.77057254\n",
      "epoch: 63 train_loss: 56.896698 valid_loss: 56.209156 train_acc: 0.76975167 valid_acc: 0.7729667\n",
      "epoch: 64 train_loss: 55.921967 valid_loss: 55.31694 train_acc: 0.77255625 valid_acc: 0.7753608\n",
      "epoch: 65 train_loss: 54.975304 valid_loss: 54.38064 train_acc: 0.7749162 valid_acc: 0.7779602\n",
      "epoch: 66 train_loss: 54.0438 valid_loss: 53.452915 train_acc: 0.77758396 valid_acc: 0.7797387\n",
      "epoch: 67 train_loss: 53.15132 valid_loss: 52.595047 train_acc: 0.7798413 valid_acc: 0.7830221\n",
      "epoch: 68 train_loss: 52.275547 valid_loss: 51.808937 train_acc: 0.7825091 valid_acc: 0.78541625\n",
      "epoch: 69 train_loss: 51.402336 valid_loss: 51.03985 train_acc: 0.7848006 valid_acc: 0.78692114\n",
      "epoch: 70 train_loss: 50.552567 valid_loss: 50.254993 train_acc: 0.78688693 valid_acc: 0.78842604\n",
      "epoch: 71 train_loss: 49.725742 valid_loss: 49.446968 train_acc: 0.78941786 valid_acc: 0.79075176\n",
      "epoch: 72 train_loss: 48.937542 valid_loss: 48.6731 train_acc: 0.79181206 valid_acc: 0.7923251\n",
      "epoch: 73 train_loss: 48.18358 valid_loss: 47.9592 train_acc: 0.7936932 valid_acc: 0.7936931\n",
      "epoch: 74 train_loss: 47.45132 valid_loss: 47.287617 train_acc: 0.7956768 valid_acc: 0.79506123\n",
      "epoch: 75 train_loss: 46.749798 valid_loss: 46.633118 train_acc: 0.79728436 valid_acc: 0.79690814\n",
      "epoch: 76 train_loss: 46.07776 valid_loss: 45.991287 train_acc: 0.79937065 valid_acc: 0.7986866\n",
      "epoch: 77 train_loss: 45.438152 valid_loss: 45.371914 train_acc: 0.8013886 valid_acc: 0.8006704\n",
      "epoch: 78 train_loss: 44.825264 valid_loss: 44.779766 train_acc: 0.8033723 valid_acc: 0.8021752\n",
      "epoch: 79 train_loss: 44.233086 valid_loss: 44.201252 train_acc: 0.8055271 valid_acc: 0.8034749\n",
      "epoch: 80 train_loss: 43.655693 valid_loss: 43.623367 train_acc: 0.8068267 valid_acc: 0.804843\n",
      "epoch: 81 train_loss: 43.08518 valid_loss: 43.06001 train_acc: 0.8081606 valid_acc: 0.8058691\n",
      "epoch: 82 train_loss: 42.531357 valid_loss: 42.515377 train_acc: 0.80997336 valid_acc: 0.80737394\n",
      "epoch: 83 train_loss: 41.991528 valid_loss: 41.987206 train_acc: 0.8113756 valid_acc: 0.80840003\n",
      "epoch: 84 train_loss: 41.46409 valid_loss: 41.46749 train_acc: 0.8128121 valid_acc: 0.8099733\n",
      "epoch: 85 train_loss: 40.94359 valid_loss: 40.94581 train_acc: 0.8140092 valid_acc: 0.81093097\n",
      "epoch: 86 train_loss: 40.432205 valid_loss: 40.443245 train_acc: 0.81476164 valid_acc: 0.81195706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 87 train_loss: 39.93012 valid_loss: 39.953682 train_acc: 0.8162323 valid_acc: 0.81373554\n",
      "epoch: 88 train_loss: 39.434578 valid_loss: 39.4676 train_acc: 0.8183186 valid_acc: 0.8150352\n",
      "epoch: 89 train_loss: 38.94523 valid_loss: 38.984043 train_acc: 0.81996036 valid_acc: 0.81708735\n",
      "epoch: 90 train_loss: 38.465706 valid_loss: 38.517384 train_acc: 0.82122576 valid_acc: 0.8181818\n",
      "epoch: 91 train_loss: 37.989277 valid_loss: 38.058887 train_acc: 0.82208085 valid_acc: 0.8196183\n",
      "epoch: 92 train_loss: 37.51667 valid_loss: 37.601784 train_acc: 0.82324374 valid_acc: 0.8210548\n",
      "epoch: 93 train_loss: 37.049774 valid_loss: 37.14978 train_acc: 0.824646 valid_acc: 0.8224913\n",
      "epoch: 94 train_loss: 36.592407 valid_loss: 36.708702 train_acc: 0.82632196 valid_acc: 0.8233121\n",
      "epoch: 95 train_loss: 36.14332 valid_loss: 36.278286 train_acc: 0.8279978 valid_acc: 0.8244066\n",
      "epoch: 96 train_loss: 35.702393 valid_loss: 35.855026 train_acc: 0.82905805 valid_acc: 0.8260483\n",
      "epoch: 97 train_loss: 35.267555 valid_loss: 35.441338 train_acc: 0.8306998 valid_acc: 0.828032\n",
      "epoch: 98 train_loss: 34.842873 valid_loss: 35.04036 train_acc: 0.8321363 valid_acc: 0.82905805\n",
      "epoch: 99 train_loss: 34.426857 valid_loss: 34.645287 train_acc: 0.8330255 valid_acc: 0.83028936\n",
      "epoch: 100 train_loss: 34.016476 valid_loss: 34.245464 train_acc: 0.8339832 valid_acc: 0.83090496\n",
      "epoch: 101 train_loss: 33.61158 valid_loss: 33.84792 train_acc: 0.83507764 valid_acc: 0.83220464\n",
      "epoch: 102 train_loss: 33.211914 valid_loss: 33.463238 train_acc: 0.8365483 valid_acc: 0.8336412\n",
      "epoch: 103 train_loss: 32.81704 valid_loss: 33.09553 train_acc: 0.83777964 valid_acc: 0.834804\n",
      "epoch: 104 train_loss: 32.427673 valid_loss: 32.74123 train_acc: 0.83853203 valid_acc: 0.8358301\n",
      "epoch: 105 train_loss: 32.046997 valid_loss: 32.39048 train_acc: 0.8398317 valid_acc: 0.836993\n",
      "epoch: 106 train_loss: 31.670809 valid_loss: 32.02803 train_acc: 0.840721 valid_acc: 0.83808744\n",
      "epoch: 107 train_loss: 31.296728 valid_loss: 31.654154 train_acc: 0.84174705 valid_acc: 0.8394555\n",
      "epoch: 108 train_loss: 30.931286 valid_loss: 31.299896 train_acc: 0.8434571 valid_acc: 0.84020793\n",
      "epoch: 109 train_loss: 30.571648 valid_loss: 30.963593 train_acc: 0.84475684 valid_acc: 0.8416444\n",
      "epoch: 110 train_loss: 30.2174 valid_loss: 30.631603 train_acc: 0.8458513 valid_acc: 0.8426021\n",
      "epoch: 111 train_loss: 29.874157 valid_loss: 30.301098 train_acc: 0.8468089 valid_acc: 0.8443122\n",
      "epoch: 112 train_loss: 29.539566 valid_loss: 29.980915 train_acc: 0.8482112 valid_acc: 0.84574866\n",
      "epoch: 113 train_loss: 29.21012 valid_loss: 29.675543 train_acc: 0.8492373 valid_acc: 0.8465011\n",
      "epoch: 114 train_loss: 28.889368 valid_loss: 29.360622 train_acc: 0.8508448 valid_acc: 0.8475956\n",
      "epoch: 115 train_loss: 28.575996 valid_loss: 29.047178 train_acc: 0.8513578 valid_acc: 0.8491689\n",
      "epoch: 116 train_loss: 28.268822 valid_loss: 28.746347 train_acc: 0.8525207 valid_acc: 0.85026336\n",
      "epoch: 117 train_loss: 27.964207 valid_loss: 28.445993 train_acc: 0.85344416 valid_acc: 0.8514946\n",
      "epoch: 118 train_loss: 27.662453 valid_loss: 28.144629 train_acc: 0.85477805 valid_acc: 0.8525207\n",
      "epoch: 119 train_loss: 27.36549 valid_loss: 27.850203 train_acc: 0.8561119 valid_acc: 0.85375196\n",
      "epoch: 120 train_loss: 27.075748 valid_loss: 27.561174 train_acc: 0.85693276 valid_acc: 0.8543676\n",
      "epoch: 121 train_loss: 26.788513 valid_loss: 27.27397 train_acc: 0.857651 valid_acc: 0.85539365\n",
      "epoch: 122 train_loss: 26.505125 valid_loss: 26.981876 train_acc: 0.85836923 valid_acc: 0.8562145\n",
      "epoch: 123 train_loss: 26.224152 valid_loss: 26.694653 train_acc: 0.8595321 valid_acc: 0.85703534\n",
      "epoch: 124 train_loss: 25.945911 valid_loss: 26.424328 train_acc: 0.8607976 valid_acc: 0.85840344\n",
      "epoch: 125 train_loss: 25.670597 valid_loss: 26.15706 train_acc: 0.86172104 valid_acc: 0.85956633\n",
      "epoch: 126 train_loss: 25.395618 valid_loss: 25.879536 train_acc: 0.8621999 valid_acc: 0.8606608\n",
      "epoch: 127 train_loss: 25.123726 valid_loss: 25.601004 train_acc: 0.8627471 valid_acc: 0.86161846\n",
      "epoch: 128 train_loss: 24.854393 valid_loss: 25.33198 train_acc: 0.8640126 valid_acc: 0.8623709\n",
      "epoch: 129 train_loss: 24.584034 valid_loss: 25.069504 train_acc: 0.86507285 valid_acc: 0.86360216\n",
      "epoch: 130 train_loss: 24.320019 valid_loss: 24.814608 train_acc: 0.86606467 valid_acc: 0.86497027\n",
      "epoch: 131 train_loss: 24.061878 valid_loss: 24.555351 train_acc: 0.86726177 valid_acc: 0.8660647\n",
      "epoch: 132 train_loss: 23.802872 valid_loss: 24.298998 train_acc: 0.8685615 valid_acc: 0.8673644\n",
      "epoch: 133 train_loss: 23.546295 valid_loss: 24.056698 train_acc: 0.8695191 valid_acc: 0.8688009\n",
      "epoch: 134 train_loss: 23.29227 valid_loss: 23.816605 train_acc: 0.87078464 valid_acc: 0.8698269\n",
      "epoch: 135 train_loss: 23.04047 valid_loss: 23.578138 train_acc: 0.8712976 valid_acc: 0.8707846\n",
      "epoch: 136 train_loss: 22.793945 valid_loss: 23.345676 train_acc: 0.8721527 valid_acc: 0.8716738\n",
      "epoch: 137 train_loss: 22.556274 valid_loss: 23.126411 train_acc: 0.8728367 valid_acc: 0.8724263\n",
      "epoch: 138 train_loss: 22.326612 valid_loss: 22.913914 train_acc: 0.8737602 valid_acc: 0.8731787\n",
      "epoch: 139 train_loss: 22.103111 valid_loss: 22.698902 train_acc: 0.8745126 valid_acc: 0.8742732\n",
      "epoch: 140 train_loss: 21.88706 valid_loss: 22.485067 train_acc: 0.8752309 valid_acc: 0.8752993\n",
      "epoch: 141 train_loss: 21.678133 valid_loss: 22.284521 train_acc: 0.87591493 valid_acc: 0.87625694\n",
      "epoch: 142 train_loss: 21.476046 valid_loss: 22.093758 train_acc: 0.8767016 valid_acc: 0.87687254\n",
      "epoch: 143 train_loss: 21.27507 valid_loss: 21.905405 train_acc: 0.87724876 valid_acc: 0.8773514\n",
      "epoch: 144 train_loss: 21.079739 valid_loss: 21.719294 train_acc: 0.877967 valid_acc: 0.87789863\n",
      "epoch: 145 train_loss: 20.888977 valid_loss: 21.539612 train_acc: 0.87861687 valid_acc: 0.87892467\n",
      "epoch: 146 train_loss: 20.698303 valid_loss: 21.361454 train_acc: 0.8795403 valid_acc: 0.8794719\n",
      "epoch: 147 train_loss: 20.510921 valid_loss: 21.18385 train_acc: 0.8804638 valid_acc: 0.87995076\n",
      "epoch: 148 train_loss: 20.329868 valid_loss: 21.014595 train_acc: 0.88111365 valid_acc: 0.8807716\n",
      "epoch: 149 train_loss: 20.151005 valid_loss: 20.848232 train_acc: 0.8821397 valid_acc: 0.88172925\n",
      "epoch: 150 train_loss: 19.974802 valid_loss: 20.681194 train_acc: 0.8829947 valid_acc: 0.8824817\n",
      "epoch: 151 train_loss: 19.802708 valid_loss: 20.519709 train_acc: 0.884055 valid_acc: 0.88296056\n",
      "epoch: 152 train_loss: 19.63414 valid_loss: 20.35903 train_acc: 0.8848417 valid_acc: 0.88357615\n",
      "epoch: 153 train_loss: 19.468859 valid_loss: 20.196281 train_acc: 0.88573086 valid_acc: 0.8846706\n",
      "epoch: 154 train_loss: 19.306786 valid_loss: 20.037754 train_acc: 0.8866544 valid_acc: 0.88480747\n",
      "epoch: 155 train_loss: 19.147226 valid_loss: 19.879232 train_acc: 0.8873384 valid_acc: 0.8853547\n",
      "epoch: 156 train_loss: 18.989294 valid_loss: 19.71968 train_acc: 0.88839865 valid_acc: 0.8860387\n",
      "epoch: 157 train_loss: 18.8354 valid_loss: 19.569008 train_acc: 0.8891511 valid_acc: 0.8868596\n",
      "epoch: 158 train_loss: 18.684742 valid_loss: 19.42647 train_acc: 0.88993776 valid_acc: 0.8874752\n",
      "epoch: 159 train_loss: 18.535332 valid_loss: 19.286615 train_acc: 0.8907244 valid_acc: 0.8880224\n",
      "epoch: 160 train_loss: 18.387302 valid_loss: 19.144995 train_acc: 0.89140844 valid_acc: 0.88891166\n",
      "epoch: 161 train_loss: 18.242645 valid_loss: 19.000376 train_acc: 0.89178467 valid_acc: 0.8893221\n",
      "epoch: 162 train_loss: 18.099545 valid_loss: 18.860353 train_acc: 0.89240026 valid_acc: 0.88980097\n",
      "epoch: 163 train_loss: 17.956635 valid_loss: 18.723852 train_acc: 0.89322114 valid_acc: 0.89041656\n",
      "epoch: 164 train_loss: 17.816788 valid_loss: 18.588297 train_acc: 0.89414465 valid_acc: 0.8910322\n",
      "epoch: 165 train_loss: 17.678062 valid_loss: 18.456038 train_acc: 0.89486283 valid_acc: 0.891169\n",
      "epoch: 166 train_loss: 17.539574 valid_loss: 18.326544 train_acc: 0.89571786 valid_acc: 0.8918531\n",
      "epoch: 167 train_loss: 17.403595 valid_loss: 18.194897 train_acc: 0.89626515 valid_acc: 0.8924003\n",
      "epoch: 168 train_loss: 17.269354 valid_loss: 18.057373 train_acc: 0.89691496 valid_acc: 0.8930159\n",
      "epoch: 169 train_loss: 17.135448 valid_loss: 17.921965 train_acc: 0.89742804 valid_acc: 0.89308435\n",
      "epoch: 170 train_loss: 17.003723 valid_loss: 17.788614 train_acc: 0.8980094 valid_acc: 0.8941104\n",
      "epoch: 171 train_loss: 16.872559 valid_loss: 17.651567 train_acc: 0.89872766 valid_acc: 0.89458925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 172 train_loss: 16.74164 valid_loss: 17.515432 train_acc: 0.8990355 valid_acc: 0.89506805\n",
      "epoch: 173 train_loss: 16.61024 valid_loss: 17.378805 train_acc: 0.8997537 valid_acc: 0.89541006\n",
      "epoch: 174 train_loss: 16.477785 valid_loss: 17.237637 train_acc: 0.900472 valid_acc: 0.8961625\n",
      "epoch: 175 train_loss: 16.345928 valid_loss: 17.102789 train_acc: 0.90125865 valid_acc: 0.8968466\n",
      "epoch: 176 train_loss: 16.215668 valid_loss: 16.976633 train_acc: 0.90170324 valid_acc: 0.8971202\n",
      "epoch: 177 train_loss: 16.08522 valid_loss: 16.85133 train_acc: 0.9021821 valid_acc: 0.8975306\n",
      "epoch: 178 train_loss: 15.956564 valid_loss: 16.723953 train_acc: 0.9028661 valid_acc: 0.89828306\n",
      "epoch: 179 train_loss: 15.830872 valid_loss: 16.594223 train_acc: 0.90344757 valid_acc: 0.8993775\n",
      "epoch: 180 train_loss: 15.707208 valid_loss: 16.467093 train_acc: 0.90385795 valid_acc: 0.89978796\n",
      "epoch: 181 train_loss: 15.584494 valid_loss: 16.3448 train_acc: 0.90440524 valid_acc: 0.9001984\n",
      "epoch: 182 train_loss: 15.465401 valid_loss: 16.226755 train_acc: 0.90495247 valid_acc: 0.9005404\n",
      "epoch: 183 train_loss: 15.351427 valid_loss: 16.114319 train_acc: 0.9054997 valid_acc: 0.9008824\n",
      "epoch: 184 train_loss: 15.239632 valid_loss: 16.001535 train_acc: 0.90594435 valid_acc: 0.9016349\n",
      "epoch: 185 train_loss: 15.129263 valid_loss: 15.890459 train_acc: 0.90642315 valid_acc: 0.9021821\n",
      "epoch: 186 train_loss: 15.020791 valid_loss: 15.782597 train_acc: 0.9068335 valid_acc: 0.9024557\n",
      "epoch: 187 train_loss: 14.913046 valid_loss: 15.67679 train_acc: 0.9074492 valid_acc: 0.90313977\n",
      "epoch: 188 train_loss: 14.807804 valid_loss: 15.572438 train_acc: 0.90806484 valid_acc: 0.9036186\n",
      "epoch: 189 train_loss: 14.704565 valid_loss: 15.471529 train_acc: 0.90844107 valid_acc: 0.904029\n",
      "epoch: 190 train_loss: 14.602362 valid_loss: 15.374975 train_acc: 0.9085779 valid_acc: 0.90443945\n",
      "epoch: 191 train_loss: 14.501085 valid_loss: 15.27746 train_acc: 0.90929615 valid_acc: 0.9048498\n",
      "epoch: 192 train_loss: 14.401447 valid_loss: 15.179312 train_acc: 0.90994596 valid_acc: 0.9053287\n",
      "epoch: 193 train_loss: 14.302605 valid_loss: 15.081766 train_acc: 0.91042477 valid_acc: 0.9058075\n",
      "epoch: 194 train_loss: 14.205194 valid_loss: 14.987343 train_acc: 0.91076684 valid_acc: 0.9060127\n",
      "epoch: 195 train_loss: 14.10872 valid_loss: 14.894308 train_acc: 0.9110062 valid_acc: 0.90642315\n",
      "epoch: 196 train_loss: 14.012806 valid_loss: 14.801859 train_acc: 0.91158766 valid_acc: 0.9066284\n",
      "epoch: 197 train_loss: 13.918214 valid_loss: 14.710608 train_acc: 0.9121007 valid_acc: 0.9071756\n",
      "epoch: 198 train_loss: 13.825663 valid_loss: 14.618354 train_acc: 0.9125453 valid_acc: 0.9075176\n",
      "epoch: 199 train_loss: 13.733883 valid_loss: 14.52364 train_acc: 0.9128531 valid_acc: 0.90792805\n",
      "epoch: 200 train_loss: 13.642286 valid_loss: 14.429149 train_acc: 0.9131609 valid_acc: 0.90820163\n",
      "epoch: 201 train_loss: 13.551718 valid_loss: 14.338742 train_acc: 0.9133662 valid_acc: 0.9088173\n",
      "epoch: 202 train_loss: 13.462236 valid_loss: 14.251496 train_acc: 0.91377664 valid_acc: 0.9090225\n",
      "epoch: 203 train_loss: 13.373558 valid_loss: 14.165751 train_acc: 0.91456324 valid_acc: 0.9092277\n",
      "epoch: 204 train_loss: 13.286155 valid_loss: 14.079412 train_acc: 0.91541827 valid_acc: 0.90956974\n",
      "epoch: 205 train_loss: 13.1993475 valid_loss: 13.991809 train_acc: 0.91569185 valid_acc: 0.9098433\n",
      "epoch: 206 train_loss: 13.113335 valid_loss: 13.905778 train_acc: 0.9160339 valid_acc: 0.9103222\n",
      "epoch: 207 train_loss: 13.028426 valid_loss: 13.822146 train_acc: 0.91627336 valid_acc: 0.91107464\n",
      "epoch: 208 train_loss: 12.944265 valid_loss: 13.739819 train_acc: 0.91661537 valid_acc: 0.91155344\n",
      "epoch: 209 train_loss: 12.860561 valid_loss: 13.660298 train_acc: 0.9172994 valid_acc: 0.9120323\n",
      "epoch: 210 train_loss: 12.778088 valid_loss: 13.5824995 train_acc: 0.91781247 valid_acc: 0.9127163\n",
      "epoch: 211 train_loss: 12.696475 valid_loss: 13.499955 train_acc: 0.91812027 valid_acc: 0.91292155\n",
      "epoch: 212 train_loss: 12.616127 valid_loss: 13.417716 train_acc: 0.91870165 valid_acc: 0.91312677\n",
      "epoch: 213 train_loss: 12.536383 valid_loss: 13.340885 train_acc: 0.9191463 valid_acc: 0.913674\n",
      "epoch: 214 train_loss: 12.45735 valid_loss: 13.264653 train_acc: 0.91962516 valid_acc: 0.91408443\n",
      "epoch: 215 train_loss: 12.379325 valid_loss: 13.187966 train_acc: 0.9200698 valid_acc: 0.9148369\n",
      "epoch: 216 train_loss: 12.30234 valid_loss: 13.113307 train_acc: 0.9205144 valid_acc: 0.9149737\n",
      "epoch: 217 train_loss: 12.226301 valid_loss: 13.039807 train_acc: 0.9206512 valid_acc: 0.91524726\n",
      "epoch: 218 train_loss: 12.151005 valid_loss: 12.964995 train_acc: 0.920959 valid_acc: 0.9155893\n",
      "epoch: 219 train_loss: 12.076122 valid_loss: 12.890256 train_acc: 0.921301 valid_acc: 0.9159997\n",
      "epoch: 220 train_loss: 12.001932 valid_loss: 12.814749 train_acc: 0.9217799 valid_acc: 0.9162049\n",
      "epoch: 221 train_loss: 11.928654 valid_loss: 12.738706 train_acc: 0.9221219 valid_acc: 0.9168206\n",
      "epoch: 222 train_loss: 11.856195 valid_loss: 12.664469 train_acc: 0.92242974 valid_acc: 0.917231\n",
      "epoch: 223 train_loss: 11.784346 valid_loss: 12.593609 train_acc: 0.92277175 valid_acc: 0.91743624\n",
      "epoch: 224 train_loss: 11.712988 valid_loss: 12.523996 train_acc: 0.9233874 valid_acc: 0.91777825\n",
      "epoch: 225 train_loss: 11.64319 valid_loss: 12.4524975 train_acc: 0.9236952 valid_acc: 0.9178466\n",
      "epoch: 226 train_loss: 11.574485 valid_loss: 12.381789 train_acc: 0.9241398 valid_acc: 0.91818863\n",
      "epoch: 227 train_loss: 11.5059395 valid_loss: 12.312406 train_acc: 0.9245503 valid_acc: 0.9185307\n",
      "epoch: 228 train_loss: 11.437685 valid_loss: 12.240853 train_acc: 0.92506325 valid_acc: 0.9187359\n",
      "epoch: 229 train_loss: 11.371111 valid_loss: 12.171936 train_acc: 0.9255763 valid_acc: 0.91928315\n",
      "epoch: 230 train_loss: 11.305858 valid_loss: 12.106873 train_acc: 0.926021 valid_acc: 0.91955674\n",
      "epoch: 231 train_loss: 11.240717 valid_loss: 12.041881 train_acc: 0.92626035 valid_acc: 0.92024076\n",
      "epoch: 232 train_loss: 11.175947 valid_loss: 11.976216 train_acc: 0.9266708 valid_acc: 0.92058283\n",
      "epoch: 233 train_loss: 11.111405 valid_loss: 11.910343 train_acc: 0.926876 valid_acc: 0.920788\n",
      "epoch: 234 train_loss: 11.048235 valid_loss: 11.8460655 train_acc: 0.92721796 valid_acc: 0.92140365\n",
      "epoch: 235 train_loss: 10.986313 valid_loss: 11.785683 train_acc: 0.9279704 valid_acc: 0.9220193\n",
      "epoch: 236 train_loss: 10.924818 valid_loss: 11.725682 train_acc: 0.9281757 valid_acc: 0.9222245\n",
      "epoch: 237 train_loss: 10.863907 valid_loss: 11.66387 train_acc: 0.9285861 valid_acc: 0.92277175\n",
      "epoch: 238 train_loss: 10.803843 valid_loss: 11.603974 train_acc: 0.92899656 valid_acc: 0.92304534\n",
      "epoch: 239 train_loss: 10.744312 valid_loss: 11.547588 train_acc: 0.92927015 valid_acc: 0.9234558\n",
      "epoch: 240 train_loss: 10.685447 valid_loss: 11.491514 train_acc: 0.9293728 valid_acc: 0.923661\n",
      "epoch: 241 train_loss: 10.627752 valid_loss: 11.434092 train_acc: 0.9298173 valid_acc: 0.924003\n",
      "epoch: 242 train_loss: 10.570509 valid_loss: 11.378564 train_acc: 0.93019354 valid_acc: 0.92455024\n",
      "epoch: 243 train_loss: 10.513508 valid_loss: 11.324138 train_acc: 0.93043303 valid_acc: 0.9250291\n",
      "epoch: 244 train_loss: 10.457523 valid_loss: 11.26939 train_acc: 0.9306382 valid_acc: 0.9255763\n",
      "epoch: 245 train_loss: 10.402151 valid_loss: 11.21266 train_acc: 0.9308776 valid_acc: 0.9257131\n",
      "epoch: 246 train_loss: 10.3469715 valid_loss: 11.15604 train_acc: 0.93135643 valid_acc: 0.9259867\n",
      "epoch: 247 train_loss: 10.292305 valid_loss: 11.102914 train_acc: 0.93176687 valid_acc: 0.92612356\n",
      "epoch: 248 train_loss: 10.238493 valid_loss: 11.051425 train_acc: 0.93227994 valid_acc: 0.9261919\n",
      "epoch: 249 train_loss: 10.185535 valid_loss: 11.000543 train_acc: 0.9325535 valid_acc: 0.9266708\n",
      "epoch: 250 train_loss: 10.133183 valid_loss: 10.950294 train_acc: 0.93262196 valid_acc: 0.9270128\n",
      "epoch: 251 train_loss: 10.0809145 valid_loss: 10.8994055 train_acc: 0.93272454 valid_acc: 0.92742324\n",
      "epoch: 252 train_loss: 10.028784 valid_loss: 10.848267 train_acc: 0.93320334 valid_acc: 0.92762846\n",
      "epoch: 253 train_loss: 9.977348 valid_loss: 10.798805 train_acc: 0.9333744 valid_acc: 0.92803884\n",
      "epoch: 254 train_loss: 9.926453 valid_loss: 10.748939 train_acc: 0.9336822 valid_acc: 0.9283125\n",
      "epoch: 255 train_loss: 9.876183 valid_loss: 10.695803 train_acc: 0.9339558 valid_acc: 0.9287229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 256 train_loss: 9.826188 valid_loss: 10.643868 train_acc: 0.9345031 valid_acc: 0.92927015\n",
      "epoch: 257 train_loss: 9.776253 valid_loss: 10.596412 train_acc: 0.9346398 valid_acc: 0.92961216\n",
      "epoch: 258 train_loss: 9.72698 valid_loss: 10.551606 train_acc: 0.93494767 valid_acc: 0.92974895\n",
      "epoch: 259 train_loss: 9.678305 valid_loss: 10.505577 train_acc: 0.9351187 valid_acc: 0.9300226\n",
      "epoch: 260 train_loss: 9.629732 valid_loss: 10.45664 train_acc: 0.9352897 valid_acc: 0.93022776\n",
      "epoch: 261 train_loss: 9.581352 valid_loss: 10.405905 train_acc: 0.9355633 valid_acc: 0.9303646\n",
      "epoch: 262 train_loss: 9.533517 valid_loss: 10.355689 train_acc: 0.93573433 valid_acc: 0.930433\n",
      "epoch: 263 train_loss: 9.486068 valid_loss: 10.308105 train_acc: 0.936008 valid_acc: 0.9307066\n",
      "epoch: 264 train_loss: 9.439238 valid_loss: 10.263108 train_acc: 0.93658936 valid_acc: 0.93077505\n",
      "epoch: 265 train_loss: 9.392773 valid_loss: 10.217245 train_acc: 0.9368288 valid_acc: 0.9309802\n",
      "epoch: 266 train_loss: 9.34685 valid_loss: 10.168163 train_acc: 0.937034 valid_acc: 0.93111706\n",
      "epoch: 267 train_loss: 9.301153 valid_loss: 10.117628 train_acc: 0.937376 valid_acc: 0.93111706\n",
      "epoch: 268 train_loss: 9.255639 valid_loss: 10.068871 train_acc: 0.9372734 valid_acc: 0.93152744\n",
      "epoch: 269 train_loss: 9.210535 valid_loss: 10.022262 train_acc: 0.9376154 valid_acc: 0.9316643\n",
      "epoch: 270 train_loss: 9.166038 valid_loss: 9.977142 train_acc: 0.9378207 valid_acc: 0.9322115\n",
      "epoch: 271 train_loss: 9.1216545 valid_loss: 9.932951 train_acc: 0.93809426 valid_acc: 0.9325535\n",
      "epoch: 272 train_loss: 9.077423 valid_loss: 9.888879 train_acc: 0.9385047 valid_acc: 0.9328271\n",
      "epoch: 273 train_loss: 9.0336895 valid_loss: 9.844453 train_acc: 0.9388809 valid_acc: 0.93296397\n",
      "epoch: 274 train_loss: 8.990374 valid_loss: 9.798847 train_acc: 0.9390177 valid_acc: 0.93296397\n",
      "epoch: 275 train_loss: 8.947641 valid_loss: 9.754244 train_acc: 0.93922293 valid_acc: 0.9331692\n",
      "epoch: 276 train_loss: 8.905284 valid_loss: 9.710997 train_acc: 0.93942815 valid_acc: 0.9333744\n",
      "epoch: 277 train_loss: 8.862976 valid_loss: 9.667392 train_acc: 0.9396676 valid_acc: 0.9337164\n",
      "epoch: 278 train_loss: 8.820616 valid_loss: 9.622841 train_acc: 0.9399754 valid_acc: 0.9338532\n",
      "epoch: 279 train_loss: 8.778202 valid_loss: 9.5779295 train_acc: 0.94024897 valid_acc: 0.9341268\n",
      "epoch: 280 train_loss: 8.736349 valid_loss: 9.533948 train_acc: 0.94045424 valid_acc: 0.93453723\n",
      "epoch: 281 train_loss: 8.69493 valid_loss: 9.491345 train_acc: 0.940591 valid_acc: 0.934674\n",
      "epoch: 282 train_loss: 8.65373 valid_loss: 9.448992 train_acc: 0.94106984 valid_acc: 0.9350161\n",
      "epoch: 283 train_loss: 8.61261 valid_loss: 9.40622 train_acc: 0.94113827 valid_acc: 0.93508446\n",
      "epoch: 284 train_loss: 8.571825 valid_loss: 9.364119 train_acc: 0.94120663 valid_acc: 0.9355633\n",
      "epoch: 285 train_loss: 8.5312195 valid_loss: 9.323082 train_acc: 0.94144607 valid_acc: 0.93576854\n",
      "epoch: 286 train_loss: 8.490404 valid_loss: 9.28233 train_acc: 0.9415829 valid_acc: 0.93611056\n",
      "epoch: 287 train_loss: 8.449551 valid_loss: 9.241932 train_acc: 0.9418223 valid_acc: 0.93645257\n",
      "epoch: 288 train_loss: 8.409082 valid_loss: 9.200335 train_acc: 0.9420617 valid_acc: 0.936521\n",
      "epoch: 289 train_loss: 8.36891 valid_loss: 9.158562 train_acc: 0.9422327 valid_acc: 0.9367946\n",
      "epoch: 290 train_loss: 8.328999 valid_loss: 9.119915 train_acc: 0.94257474 valid_acc: 0.9371366\n",
      "epoch: 291 train_loss: 8.289444 valid_loss: 9.081822 train_acc: 0.94291675 valid_acc: 0.9374786\n",
      "epoch: 292 train_loss: 8.250192 valid_loss: 9.042627 train_acc: 0.94305354 valid_acc: 0.93775225\n",
      "epoch: 293 train_loss: 8.211516 valid_loss: 9.003246 train_acc: 0.9433272 valid_acc: 0.93795747\n",
      "epoch: 294 train_loss: 8.173206 valid_loss: 8.964353 train_acc: 0.9434982 valid_acc: 0.9383679\n",
      "epoch: 295 train_loss: 8.13504 valid_loss: 8.92789 train_acc: 0.9437034 valid_acc: 0.93857306\n",
      "epoch: 296 train_loss: 8.097074 valid_loss: 8.892388 train_acc: 0.94387436 valid_acc: 0.9388467\n",
      "epoch: 297 train_loss: 8.05957 valid_loss: 8.855731 train_acc: 0.9441822 valid_acc: 0.93925714\n",
      "epoch: 298 train_loss: 8.022568 valid_loss: 8.818555 train_acc: 0.94438744 valid_acc: 0.93946236\n",
      "epoch: 299 train_loss: 7.9857893 valid_loss: 8.782457 train_acc: 0.94462687 valid_acc: 0.9398044\n",
      "epoch: 300 train_loss: 7.9490156 valid_loss: 8.746487 train_acc: 0.9448663 valid_acc: 0.9400096\n",
      "epoch: 301 train_loss: 7.912595 valid_loss: 8.709949 train_acc: 0.9450031 valid_acc: 0.9401464\n",
      "epoch: 302 train_loss: 7.8762302 valid_loss: 8.674089 train_acc: 0.94507146 valid_acc: 0.9402832\n",
      "epoch: 303 train_loss: 7.840186 valid_loss: 8.639271 train_acc: 0.9452083 valid_acc: 0.9405568\n",
      "epoch: 304 train_loss: 7.804403 valid_loss: 8.60347 train_acc: 0.9454135 valid_acc: 0.9406936\n",
      "epoch: 305 train_loss: 7.7688465 valid_loss: 8.567085 train_acc: 0.9454819 valid_acc: 0.9408304\n",
      "epoch: 306 train_loss: 7.733409 valid_loss: 8.531796 train_acc: 0.9456871 valid_acc: 0.94096726\n",
      "epoch: 307 train_loss: 7.6985545 valid_loss: 8.49813 train_acc: 0.945995 valid_acc: 0.94124085\n",
      "epoch: 308 train_loss: 7.6636515 valid_loss: 8.464789 train_acc: 0.94623435 valid_acc: 0.9413093\n",
      "epoch: 309 train_loss: 7.629221 valid_loss: 8.431367 train_acc: 0.9463712 valid_acc: 0.94158286\n",
      "epoch: 310 train_loss: 7.594834 valid_loss: 8.397668 train_acc: 0.9464738 valid_acc: 0.94192487\n",
      "epoch: 311 train_loss: 7.560835 valid_loss: 8.363359 train_acc: 0.9466448 valid_acc: 0.9421985\n",
      "epoch: 312 train_loss: 7.5269966 valid_loss: 8.330242 train_acc: 0.9469526 valid_acc: 0.94226694\n",
      "epoch: 313 train_loss: 7.4930677 valid_loss: 8.297479 train_acc: 0.9471236 valid_acc: 0.9423353\n",
      "epoch: 314 train_loss: 7.4595146 valid_loss: 8.263487 train_acc: 0.9472604 valid_acc: 0.94260895\n",
      "epoch: 315 train_loss: 7.4262447 valid_loss: 8.231044 train_acc: 0.9474998 valid_acc: 0.94274575\n",
      "epoch: 316 train_loss: 7.393447 valid_loss: 8.198981 train_acc: 0.94777346 valid_acc: 0.94301933\n",
      "epoch: 317 train_loss: 7.360522 valid_loss: 8.16629 train_acc: 0.94794446 valid_acc: 0.943293\n",
      "epoch: 318 train_loss: 7.327553 valid_loss: 8.133555 train_acc: 0.9480128 valid_acc: 0.9434982\n",
      "epoch: 319 train_loss: 7.2949085 valid_loss: 8.101206 train_acc: 0.9482181 valid_acc: 0.9437034\n",
      "epoch: 320 train_loss: 7.2624836 valid_loss: 8.069159 train_acc: 0.94838905 valid_acc: 0.94390863\n",
      "epoch: 321 train_loss: 7.2303963 valid_loss: 8.037933 train_acc: 0.9484917 valid_acc: 0.94411385\n",
      "epoch: 322 train_loss: 7.198662 valid_loss: 8.007466 train_acc: 0.9487653 valid_acc: 0.94438744\n",
      "epoch: 323 train_loss: 7.1670647 valid_loss: 7.9772468 train_acc: 0.94890213 valid_acc: 0.94459265\n",
      "epoch: 324 train_loss: 7.1353655 valid_loss: 7.946792 train_acc: 0.9491073 valid_acc: 0.9447979\n",
      "epoch: 325 train_loss: 7.1038494 valid_loss: 7.916289 train_acc: 0.9491415 valid_acc: 0.9450031\n",
      "epoch: 326 train_loss: 7.0726585 valid_loss: 7.8865156 train_acc: 0.94944936 valid_acc: 0.94541353\n",
      "epoch: 327 train_loss: 7.041508 valid_loss: 7.856783 train_acc: 0.94972295 valid_acc: 0.9455503\n",
      "epoch: 328 train_loss: 7.010568 valid_loss: 7.8265166 train_acc: 0.95009923 valid_acc: 0.94575554\n",
      "epoch: 329 train_loss: 6.979926 valid_loss: 7.798109 train_acc: 0.9502702 valid_acc: 0.9460291\n",
      "epoch: 330 train_loss: 6.9498625 valid_loss: 7.7695293 train_acc: 0.9505096 valid_acc: 0.94623435\n",
      "epoch: 331 train_loss: 6.919537 valid_loss: 7.7428293 train_acc: 0.9508517 valid_acc: 0.94637114\n",
      "epoch: 332 train_loss: 6.889906 valid_loss: 7.7144256 train_acc: 0.95112526 valid_acc: 0.9467816\n",
      "epoch: 333 train_loss: 6.8600454 valid_loss: 7.68736 train_acc: 0.95143306 valid_acc: 0.94685\n",
      "epoch: 334 train_loss: 6.830718 valid_loss: 7.660138 train_acc: 0.95160407 valid_acc: 0.9473288\n",
      "epoch: 335 train_loss: 6.801373 valid_loss: 7.6322274 train_acc: 0.95174086 valid_acc: 0.9474656\n",
      "epoch: 336 train_loss: 6.7721357 valid_loss: 7.6043196 train_acc: 0.9518777 valid_acc: 0.94773924\n",
      "epoch: 337 train_loss: 6.743043 valid_loss: 7.5751038 train_acc: 0.9521171 valid_acc: 0.94794446\n",
      "epoch: 338 train_loss: 6.713992 valid_loss: 7.54722 train_acc: 0.9521513 valid_acc: 0.9480129\n",
      "epoch: 339 train_loss: 6.6850886 valid_loss: 7.5205984 train_acc: 0.95225394 valid_acc: 0.9482865\n",
      "epoch: 340 train_loss: 6.6563807 valid_loss: 7.4936075 train_acc: 0.95232236 valid_acc: 0.9485601\n",
      "epoch: 341 train_loss: 6.6277423 valid_loss: 7.4689016 train_acc: 0.9526644 valid_acc: 0.9488337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 342 train_loss: 6.5992517 valid_loss: 7.442102 train_acc: 0.95290375 valid_acc: 0.94890213\n",
      "epoch: 343 train_loss: 6.571256 valid_loss: 7.414611 train_acc: 0.95307475 valid_acc: 0.94910735\n",
      "epoch: 344 train_loss: 6.543159 valid_loss: 7.3887715 train_acc: 0.953451 valid_acc: 0.9491757\n",
      "epoch: 345 train_loss: 6.515029 valid_loss: 7.363085 train_acc: 0.9535878 valid_acc: 0.94931257\n",
      "epoch: 346 train_loss: 6.486596 valid_loss: 7.337023 train_acc: 0.9535878 valid_acc: 0.94944936\n",
      "epoch: 347 train_loss: 6.4583673 valid_loss: 7.311308 train_acc: 0.9536904 valid_acc: 0.9495177\n",
      "epoch: 348 train_loss: 6.4305863 valid_loss: 7.286237 train_acc: 0.9536904 valid_acc: 0.9496546\n",
      "epoch: 349 train_loss: 6.403133 valid_loss: 7.261087 train_acc: 0.9538614 valid_acc: 0.9497914\n",
      "epoch: 350 train_loss: 6.375569 valid_loss: 7.2352176 train_acc: 0.9540324 valid_acc: 0.9498598\n",
      "epoch: 351 train_loss: 6.347868 valid_loss: 7.208728 train_acc: 0.95406663 valid_acc: 0.9502018\n",
      "epoch: 352 train_loss: 6.3203783 valid_loss: 7.18257 train_acc: 0.95413506 valid_acc: 0.950407\n",
      "epoch: 353 train_loss: 6.29313 valid_loss: 7.1575317 train_acc: 0.9543402 valid_acc: 0.9505438\n",
      "epoch: 354 train_loss: 6.2662373 valid_loss: 7.1334367 train_acc: 0.95457965 valid_acc: 0.95088583\n",
      "epoch: 355 train_loss: 6.2391453 valid_loss: 7.109311 train_acc: 0.95475066 valid_acc: 0.95095426\n",
      "epoch: 356 train_loss: 6.2120028 valid_loss: 7.084822 train_acc: 0.9548191 valid_acc: 0.95095426\n",
      "epoch: 357 train_loss: 6.1848745 valid_loss: 7.0602956 train_acc: 0.9548533 valid_acc: 0.9511595\n",
      "epoch: 358 train_loss: 6.1582747 valid_loss: 7.036507 train_acc: 0.95509267 valid_acc: 0.95136464\n",
      "epoch: 359 train_loss: 6.1321 valid_loss: 7.0125446 train_acc: 0.95529795 valid_acc: 0.95156986\n",
      "epoch: 360 train_loss: 6.1061993 valid_loss: 6.987854 train_acc: 0.95533216 valid_acc: 0.9516383\n",
      "epoch: 361 train_loss: 6.0802217 valid_loss: 6.962885 train_acc: 0.9554347 valid_acc: 0.9516383\n",
      "epoch: 362 train_loss: 6.0544095 valid_loss: 6.9384875 train_acc: 0.9555373 valid_acc: 0.95191187\n",
      "epoch: 363 train_loss: 6.028718 valid_loss: 6.9150524 train_acc: 0.95577675 valid_acc: 0.9521855\n",
      "epoch: 364 train_loss: 6.003169 valid_loss: 6.8917594 train_acc: 0.95591354 valid_acc: 0.95239073\n",
      "epoch: 365 train_loss: 5.977894 valid_loss: 6.867984 train_acc: 0.9561871 valid_acc: 0.9525275\n",
      "epoch: 366 train_loss: 5.9526386 valid_loss: 6.843913 train_acc: 0.9563582 valid_acc: 0.95273274\n",
      "epoch: 367 train_loss: 5.9269543 valid_loss: 6.819396 train_acc: 0.95642656 valid_acc: 0.95280117\n",
      "epoch: 368 train_loss: 5.9019103 valid_loss: 6.7950544 train_acc: 0.9567002 valid_acc: 0.9531432\n",
      "epoch: 369 train_loss: 5.877464 valid_loss: 6.771189 train_acc: 0.95680285 valid_acc: 0.95328\n",
      "epoch: 370 train_loss: 5.8530912 valid_loss: 6.747898 train_acc: 0.9570422 valid_acc: 0.9535536\n",
      "epoch: 371 train_loss: 5.828473 valid_loss: 6.724833 train_acc: 0.95714486 valid_acc: 0.9538272\n",
      "epoch: 372 train_loss: 5.804184 valid_loss: 6.7024884 train_acc: 0.9572132 valid_acc: 0.95375884\n",
      "epoch: 373 train_loss: 5.7802553 valid_loss: 6.681441 train_acc: 0.95741844 valid_acc: 0.9538956\n",
      "epoch: 374 train_loss: 5.756505 valid_loss: 6.6601586 train_acc: 0.95755523 valid_acc: 0.95423764\n",
      "epoch: 375 train_loss: 5.732752 valid_loss: 6.638453 train_acc: 0.9576578 valid_acc: 0.95437443\n",
      "epoch: 376 train_loss: 5.7089634 valid_loss: 6.617469 train_acc: 0.9578289 valid_acc: 0.95444286\n",
      "epoch: 377 train_loss: 5.6853085 valid_loss: 6.596862 train_acc: 0.9578973 valid_acc: 0.9546481\n",
      "epoch: 378 train_loss: 5.661854 valid_loss: 6.5763397 train_acc: 0.95803404 valid_acc: 0.9546481\n",
      "epoch: 379 train_loss: 5.6386776 valid_loss: 6.555667 train_acc: 0.9582735 valid_acc: 0.9546481\n",
      "epoch: 380 train_loss: 5.615349 valid_loss: 6.5345 train_acc: 0.9584445 valid_acc: 0.95478487\n",
      "epoch: 381 train_loss: 5.5919333 valid_loss: 6.5126944 train_acc: 0.9585471 valid_acc: 0.95492166\n",
      "epoch: 382 train_loss: 5.5687494 valid_loss: 6.491241 train_acc: 0.9586839 valid_acc: 0.9551269\n",
      "epoch: 383 train_loss: 5.5456867 valid_loss: 6.4698315 train_acc: 0.95892334 valid_acc: 0.9551953\n",
      "epoch: 384 train_loss: 5.522629 valid_loss: 6.4473715 train_acc: 0.9590943 valid_acc: 0.9551953\n",
      "epoch: 385 train_loss: 5.4997206 valid_loss: 6.4256315 train_acc: 0.95909435 valid_acc: 0.9554689\n",
      "epoch: 386 train_loss: 5.477114 valid_loss: 6.4056773 train_acc: 0.95929956 valid_acc: 0.95574254\n",
      "epoch: 387 train_loss: 5.4546638 valid_loss: 6.386349 train_acc: 0.9595047 valid_acc: 0.9558109\n",
      "epoch: 388 train_loss: 5.4322076 valid_loss: 6.367144 train_acc: 0.9596416 valid_acc: 0.95587933\n",
      "epoch: 389 train_loss: 5.4099517 valid_loss: 6.3481865 train_acc: 0.95974416 valid_acc: 0.95608455\n",
      "epoch: 390 train_loss: 5.387844 valid_loss: 6.3292994 train_acc: 0.95991516 valid_acc: 0.95622134\n",
      "epoch: 391 train_loss: 5.3658323 valid_loss: 6.3102016 train_acc: 0.9601204 valid_acc: 0.95635813\n",
      "epoch: 392 train_loss: 5.343843 valid_loss: 6.291006 train_acc: 0.9603256 valid_acc: 0.95635813\n",
      "epoch: 393 train_loss: 5.321948 valid_loss: 6.2717085 train_acc: 0.96042824 valid_acc: 0.9567002\n",
      "epoch: 394 train_loss: 5.300084 valid_loss: 6.252485 train_acc: 0.9604624 valid_acc: 0.9569738\n",
      "epoch: 395 train_loss: 5.278256 valid_loss: 6.2329526 train_acc: 0.9605992 valid_acc: 0.9571106\n",
      "epoch: 396 train_loss: 5.256617 valid_loss: 6.2130013 train_acc: 0.96077025 valid_acc: 0.95724744\n",
      "epoch: 397 train_loss: 5.2349377 valid_loss: 6.1931477 train_acc: 0.96090704 valid_acc: 0.957179\n",
      "epoch: 398 train_loss: 5.2132874 valid_loss: 6.1742177 train_acc: 0.9610096 valid_acc: 0.957521\n",
      "epoch: 399 train_loss: 5.191759 valid_loss: 6.156293 train_acc: 0.9611465 valid_acc: 0.95772624\n",
      "epoch: 400 train_loss: 5.1704893 valid_loss: 6.138464 train_acc: 0.9611465 valid_acc: 0.95793146\n",
      "epoch: 401 train_loss: 5.1494412 valid_loss: 6.1207185 train_acc: 0.96124905 valid_acc: 0.95786303\n",
      "epoch: 402 train_loss: 5.128416 valid_loss: 6.1038857 train_acc: 0.96135163 valid_acc: 0.95786303\n",
      "epoch: 403 train_loss: 5.1075177 valid_loss: 6.0872836 train_acc: 0.96138585 valid_acc: 0.95793146\n",
      "epoch: 404 train_loss: 5.086817 valid_loss: 6.07019 train_acc: 0.96159106 valid_acc: 0.95806825\n",
      "epoch: 405 train_loss: 5.066318 valid_loss: 6.0530515 train_acc: 0.96172786 valid_acc: 0.9581367\n",
      "epoch: 406 train_loss: 5.0459948 valid_loss: 6.0359187 train_acc: 0.9618305 valid_acc: 0.9581367\n",
      "epoch: 407 train_loss: 5.025743 valid_loss: 6.0183387 train_acc: 0.9621383 valid_acc: 0.95841026\n",
      "epoch: 408 train_loss: 5.005582 valid_loss: 6.0007815 train_acc: 0.9621725 valid_acc: 0.9584787\n",
      "epoch: 409 train_loss: 4.985445 valid_loss: 5.983159 train_acc: 0.96227515 valid_acc: 0.9584787\n",
      "epoch: 410 train_loss: 4.9653816 valid_loss: 5.9653106 train_acc: 0.9623436 valid_acc: 0.9584787\n",
      "epoch: 411 train_loss: 4.9453154 valid_loss: 5.9477305 train_acc: 0.96241194 valid_acc: 0.9586155\n",
      "epoch: 412 train_loss: 4.9253497 valid_loss: 5.930666 train_acc: 0.9625145 valid_acc: 0.9590259\n",
      "epoch: 413 train_loss: 4.9052477 valid_loss: 5.91313 train_acc: 0.96275395 valid_acc: 0.95909435\n",
      "epoch: 414 train_loss: 4.8856134 valid_loss: 5.8952518 train_acc: 0.9628223 valid_acc: 0.95929956\n",
      "epoch: 415 train_loss: 4.8658905 valid_loss: 5.8776307 train_acc: 0.96292496 valid_acc: 0.9595048\n",
      "epoch: 416 train_loss: 4.8467073 valid_loss: 5.8613544 train_acc: 0.963096 valid_acc: 0.95977837\n",
      "epoch: 417 train_loss: 4.8272405 valid_loss: 5.845377 train_acc: 0.9631301 valid_acc: 0.95977837\n",
      "epoch: 418 train_loss: 4.808573 valid_loss: 5.8309636 train_acc: 0.9633354 valid_acc: 0.95991516\n",
      "epoch: 419 train_loss: 4.788907 valid_loss: 5.8160105 train_acc: 0.96343803 valid_acc: 0.960052\n",
      "epoch: 420 train_loss: 4.770686 valid_loss: 5.800105 train_acc: 0.9636774 valid_acc: 0.9599836\n",
      "epoch: 421 train_loss: 4.7506113 valid_loss: 5.7870784 train_acc: 0.96378005 valid_acc: 0.9599836\n",
      "epoch: 422 train_loss: 4.733467 valid_loss: 5.773627 train_acc: 0.96425885 valid_acc: 0.9601204\n",
      "epoch: 423 train_loss: 4.713363 valid_loss: 5.758624 train_acc: 0.9642247 valid_acc: 0.9601204\n",
      "epoch: 424 train_loss: 4.6963377 valid_loss: 5.7440567 train_acc: 0.96439564 valid_acc: 0.9603256\n",
      "epoch: 425 train_loss: 4.6767325 valid_loss: 5.7313237 train_acc: 0.96446407 valid_acc: 0.9602572\n",
      "epoch: 426 train_loss: 4.6591845 valid_loss: 5.7142687 train_acc: 0.9645325 valid_acc: 0.960394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 427 train_loss: 4.640336 valid_loss: 5.6995068 train_acc: 0.96473765 valid_acc: 0.9604624\n",
      "epoch: 428 train_loss: 4.6227884 valid_loss: 5.6847744 train_acc: 0.9648745 valid_acc: 0.96059924\n",
      "epoch: 429 train_loss: 4.6038513 valid_loss: 5.6688366 train_acc: 0.9650113 valid_acc: 0.96059924\n",
      "epoch: 430 train_loss: 4.587098 valid_loss: 5.652974 train_acc: 0.9652165 valid_acc: 0.9608728\n",
      "epoch: 431 train_loss: 4.5685887 valid_loss: 5.6378684 train_acc: 0.9653533 valid_acc: 0.96094126\n",
      "epoch: 432 train_loss: 4.550679 valid_loss: 5.622809 train_acc: 0.9654559 valid_acc: 0.9610096\n",
      "epoch: 433 train_loss: 4.533703 valid_loss: 5.6070514 train_acc: 0.96525073 valid_acc: 0.9610096\n",
      "epoch: 434 train_loss: 4.5154643 valid_loss: 5.5911837 train_acc: 0.96559274 valid_acc: 0.9610096\n",
      "epoch: 435 train_loss: 4.498661 valid_loss: 5.5763493 train_acc: 0.9655243 valid_acc: 0.9610096\n",
      "epoch: 436 train_loss: 4.480674 valid_loss: 5.561096 train_acc: 0.9656953 valid_acc: 0.9611465\n",
      "epoch: 437 train_loss: 4.46393 valid_loss: 5.546608 train_acc: 0.96590054 valid_acc: 0.9611465\n",
      "epoch: 438 train_loss: 4.446504 valid_loss: 5.5321145 train_acc: 0.9658663 valid_acc: 0.96128327\n",
      "epoch: 439 train_loss: 4.4297986 valid_loss: 5.5176387 train_acc: 0.9658663 valid_acc: 0.9613517\n",
      "epoch: 440 train_loss: 4.412739 valid_loss: 5.502798 train_acc: 0.9660716 valid_acc: 0.9616937\n",
      "epoch: 441 train_loss: 4.396659 valid_loss: 5.4886904 train_acc: 0.9660716 valid_acc: 0.9616937\n",
      "epoch: 442 train_loss: 4.379698 valid_loss: 5.47491 train_acc: 0.96614 valid_acc: 0.9616937\n",
      "epoch: 443 train_loss: 4.3640537 valid_loss: 5.4607615 train_acc: 0.96627676 valid_acc: 0.9617621\n",
      "epoch: 444 train_loss: 4.347385 valid_loss: 5.4468603 train_acc: 0.9664478 valid_acc: 0.9618305\n",
      "epoch: 445 train_loss: 4.3315763 valid_loss: 5.4338093 train_acc: 0.96655035 valid_acc: 0.9618305\n",
      "epoch: 446 train_loss: 4.3150916 valid_loss: 5.4202905 train_acc: 0.96658456 valid_acc: 0.9618989\n",
      "epoch: 447 train_loss: 4.2995014 valid_loss: 5.406481 train_acc: 0.9666188 valid_acc: 0.9619673\n",
      "epoch: 448 train_loss: 4.2834406 valid_loss: 5.392132 train_acc: 0.9666872 valid_acc: 0.9623093\n",
      "epoch: 449 train_loss: 4.268007 valid_loss: 5.378608 train_acc: 0.9667556 valid_acc: 0.9623093\n",
      "epoch: 450 train_loss: 4.252034 valid_loss: 5.365572 train_acc: 0.9669266 valid_acc: 0.9625145\n",
      "epoch: 451 train_loss: 4.2364407 valid_loss: 5.35363 train_acc: 0.9673028 valid_acc: 0.96278816\n",
      "epoch: 452 train_loss: 4.2211213 valid_loss: 5.3413515 train_acc: 0.9672686 valid_acc: 0.96285653\n",
      "epoch: 453 train_loss: 4.205737 valid_loss: 5.3281646 train_acc: 0.9675081 valid_acc: 0.96292496\n",
      "epoch: 454 train_loss: 4.1906543 valid_loss: 5.315621 train_acc: 0.96747386 valid_acc: 0.96292496\n",
      "epoch: 455 train_loss: 4.1752615 valid_loss: 5.3025565 train_acc: 0.9676106 valid_acc: 0.96292496\n",
      "epoch: 456 train_loss: 4.1603913 valid_loss: 5.2894197 train_acc: 0.9676448 valid_acc: 0.9629934\n",
      "epoch: 457 train_loss: 4.1451225 valid_loss: 5.275864 train_acc: 0.96795267 valid_acc: 0.9631986\n",
      "epoch: 458 train_loss: 4.1304607 valid_loss: 5.262785 train_acc: 0.96802104 valid_acc: 0.96326697\n",
      "epoch: 459 train_loss: 4.1152587 valid_loss: 5.250411 train_acc: 0.9681579 valid_acc: 0.96326697\n",
      "epoch: 460 train_loss: 4.1009703 valid_loss: 5.23777 train_acc: 0.96802104 valid_acc: 0.9633354\n",
      "epoch: 461 train_loss: 4.086215 valid_loss: 5.225617 train_acc: 0.9683289 valid_acc: 0.96340376\n",
      "epoch: 462 train_loss: 4.07222 valid_loss: 5.2126803 train_acc: 0.9682947 valid_acc: 0.96340376\n",
      "epoch: 463 train_loss: 4.057848 valid_loss: 5.200623 train_acc: 0.9685683 valid_acc: 0.9635406\n",
      "epoch: 464 train_loss: 4.043642 valid_loss: 5.188327 train_acc: 0.9685341 valid_acc: 0.9636774\n",
      "epoch: 465 train_loss: 4.029706 valid_loss: 5.177023 train_acc: 0.9686709 valid_acc: 0.9636774\n",
      "epoch: 466 train_loss: 4.015272 valid_loss: 5.1647043 train_acc: 0.9687393 valid_acc: 0.963609\n",
      "epoch: 467 train_loss: 4.001627 valid_loss: 5.1539273 train_acc: 0.96894455 valid_acc: 0.9636774\n",
      "epoch: 468 train_loss: 3.9874232 valid_loss: 5.140706 train_acc: 0.9690471 valid_acc: 0.9638142\n",
      "epoch: 469 train_loss: 3.9737782 valid_loss: 5.1295776 train_acc: 0.96891034 valid_acc: 0.9638826\n",
      "epoch: 470 train_loss: 3.9597983 valid_loss: 5.1162105 train_acc: 0.9691155 valid_acc: 0.9640194\n",
      "epoch: 471 train_loss: 3.9462 valid_loss: 5.103983 train_acc: 0.9690129 valid_acc: 0.96408784\n",
      "epoch: 472 train_loss: 3.9321744 valid_loss: 5.0920796 train_acc: 0.9691497 valid_acc: 0.9641562\n",
      "epoch: 473 train_loss: 3.918703 valid_loss: 5.079167 train_acc: 0.9691839 valid_acc: 0.9641562\n",
      "epoch: 474 train_loss: 3.9045706 valid_loss: 5.0685387 train_acc: 0.9693208 valid_acc: 0.96422464\n",
      "epoch: 475 train_loss: 3.8911948 valid_loss: 5.056835 train_acc: 0.969355 valid_acc: 0.9643614\n",
      "epoch: 476 train_loss: 3.8773522 valid_loss: 5.04622 train_acc: 0.9694917 valid_acc: 0.96442986\n",
      "epoch: 477 train_loss: 3.8642137 valid_loss: 5.035069 train_acc: 0.9697312 valid_acc: 0.96456665\n",
      "epoch: 478 train_loss: 3.850541 valid_loss: 5.0235615 train_acc: 0.96990216 valid_acc: 0.96456665\n",
      "epoch: 479 train_loss: 3.8375273 valid_loss: 5.012619 train_acc: 0.970039 valid_acc: 0.96470344\n",
      "epoch: 480 train_loss: 3.82395 valid_loss: 5.0012674 train_acc: 0.97020996 valid_acc: 0.96470344\n",
      "epoch: 481 train_loss: 3.8111205 valid_loss: 4.9907365 train_acc: 0.970381 valid_acc: 0.96477187\n",
      "epoch: 482 train_loss: 3.7974818 valid_loss: 4.980122 train_acc: 0.97044945 valid_acc: 0.9648403\n",
      "epoch: 483 train_loss: 3.7846615 valid_loss: 4.96971 train_acc: 0.9706546 valid_acc: 0.9650455\n",
      "epoch: 484 train_loss: 3.7713654 valid_loss: 4.9589353 train_acc: 0.9706204 valid_acc: 0.9651823\n",
      "epoch: 485 train_loss: 3.7585397 valid_loss: 4.948339 train_acc: 0.97079146 valid_acc: 0.96525073\n",
      "epoch: 486 train_loss: 3.7455983 valid_loss: 4.9372706 train_acc: 0.97079146 valid_acc: 0.9653191\n",
      "epoch: 487 train_loss: 3.732995 valid_loss: 4.9260926 train_acc: 0.97109926 valid_acc: 0.9654559\n",
      "epoch: 488 train_loss: 3.7200334 valid_loss: 4.915413 train_acc: 0.9711677 valid_acc: 0.9654559\n",
      "epoch: 489 train_loss: 3.707559 valid_loss: 4.9031634 train_acc: 0.9711677 valid_acc: 0.9655243\n",
      "epoch: 490 train_loss: 3.6946309 valid_loss: 4.8912153 train_acc: 0.97137284 valid_acc: 0.96559274\n",
      "epoch: 491 train_loss: 3.6821647 valid_loss: 4.8792653 train_acc: 0.9714755 valid_acc: 0.9656611\n",
      "epoch: 492 train_loss: 3.6694956 valid_loss: 4.867046 train_acc: 0.9715781 valid_acc: 0.9656611\n",
      "epoch: 493 train_loss: 3.6569781 valid_loss: 4.8552547 train_acc: 0.9715439 valid_acc: 0.9656611\n",
      "epoch: 494 train_loss: 3.6444335 valid_loss: 4.843446 train_acc: 0.9715781 valid_acc: 0.96579796\n",
      "epoch: 495 train_loss: 3.632032 valid_loss: 4.8314085 train_acc: 0.97171485 valid_acc: 0.9660031\n",
      "epoch: 496 train_loss: 3.6196713 valid_loss: 4.819773 train_acc: 0.97171485 valid_acc: 0.9660031\n",
      "epoch: 497 train_loss: 3.607176 valid_loss: 4.8085155 train_acc: 0.97192013 valid_acc: 0.9660031\n",
      "epoch: 498 train_loss: 3.5949671 valid_loss: 4.7969775 train_acc: 0.9720227 valid_acc: 0.96614\n",
      "epoch: 499 train_loss: 3.5826654 valid_loss: 4.785119 train_acc: 0.9720227 valid_acc: 0.96620834\n",
      "epoch: 500 train_loss: 3.5706685 valid_loss: 4.7730355 train_acc: 0.9721595 valid_acc: 0.96627676\n",
      "epoch: 501 train_loss: 3.5586915 valid_loss: 4.761713 train_acc: 0.9723306 valid_acc: 0.9663452\n",
      "epoch: 502 train_loss: 3.5467913 valid_loss: 4.7502956 train_acc: 0.9725015 valid_acc: 0.9663452\n",
      "epoch: 503 train_loss: 3.5349617 valid_loss: 4.7389417 train_acc: 0.97263837 valid_acc: 0.966482\n",
      "epoch: 504 train_loss: 3.5232298 valid_loss: 4.727801 train_acc: 0.97263837 valid_acc: 0.966482\n",
      "epoch: 505 train_loss: 3.5114326 valid_loss: 4.7167025 train_acc: 0.9726726 valid_acc: 0.9666188\n",
      "epoch: 506 train_loss: 3.49967 valid_loss: 4.7059727 train_acc: 0.9726726 valid_acc: 0.9666188\n",
      "epoch: 507 train_loss: 3.4879775 valid_loss: 4.6958156 train_acc: 0.9726726 valid_acc: 0.9666188\n",
      "epoch: 508 train_loss: 3.4763322 valid_loss: 4.6853056 train_acc: 0.9728093 valid_acc: 0.9666188\n",
      "epoch: 509 train_loss: 3.464862 valid_loss: 4.6746645 train_acc: 0.97291195 valid_acc: 0.96675557\n",
      "epoch: 510 train_loss: 3.4532938 valid_loss: 4.6640544 train_acc: 0.9730488 valid_acc: 0.9666872\n",
      "epoch: 511 train_loss: 3.4418352 valid_loss: 4.65319 train_acc: 0.97308296 valid_acc: 0.9666872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 512 train_loss: 3.4303167 valid_loss: 4.6424417 train_acc: 0.97308296 valid_acc: 0.96675557\n",
      "epoch: 513 train_loss: 3.4187584 valid_loss: 4.6318474 train_acc: 0.9731514 valid_acc: 0.9668924\n",
      "epoch: 514 train_loss: 3.4073372 valid_loss: 4.621367 train_acc: 0.97318554 valid_acc: 0.9669608\n",
      "epoch: 515 train_loss: 3.3959212 valid_loss: 4.610575 train_acc: 0.97321975 valid_acc: 0.9670292\n",
      "epoch: 516 train_loss: 3.3846006 valid_loss: 4.5997076 train_acc: 0.97325397 valid_acc: 0.96709764\n",
      "epoch: 517 train_loss: 3.37316 valid_loss: 4.5892415 train_acc: 0.9733566 valid_acc: 0.967166\n",
      "epoch: 518 train_loss: 3.3620257 valid_loss: 4.5788226 train_acc: 0.9735618 valid_acc: 0.967166\n",
      "epoch: 519 train_loss: 3.3506298 valid_loss: 4.568329 train_acc: 0.9737328 valid_acc: 0.96723443\n",
      "epoch: 520 train_loss: 3.3397257 valid_loss: 4.5577645 train_acc: 0.97380126 valid_acc: 0.9673028\n",
      "epoch: 521 train_loss: 3.3282585 valid_loss: 4.54689 train_acc: 0.9738354 valid_acc: 0.9673712\n",
      "epoch: 522 train_loss: 3.3178325 valid_loss: 4.5371885 train_acc: 0.9740064 valid_acc: 0.96743965\n",
      "epoch: 523 train_loss: 3.3060217 valid_loss: 4.527821 train_acc: 0.97414327 valid_acc: 0.96757644\n",
      "epoch: 524 train_loss: 3.2957587 valid_loss: 4.5176024 train_acc: 0.9742117 valid_acc: 0.96757644\n",
      "epoch: 525 train_loss: 3.284686 valid_loss: 4.507735 train_acc: 0.97424585 valid_acc: 0.96771324\n",
      "epoch: 526 train_loss: 3.2739234 valid_loss: 4.4982347 train_acc: 0.97421163 valid_acc: 0.96778166\n",
      "epoch: 527 train_loss: 3.262306 valid_loss: 4.4893694 train_acc: 0.9742117 valid_acc: 0.96771324\n",
      "epoch: 528 train_loss: 3.253079 valid_loss: 4.478009 train_acc: 0.97424585 valid_acc: 0.96791846\n",
      "epoch: 529 train_loss: 3.241539 valid_loss: 4.469554 train_acc: 0.9745879 valid_acc: 0.96791846\n",
      "epoch: 530 train_loss: 3.2308626 valid_loss: 4.4603124 train_acc: 0.9746221 valid_acc: 0.9681237\n",
      "epoch: 531 train_loss: 3.2211695 valid_loss: 4.450393 train_acc: 0.97469044 valid_acc: 0.96826047\n",
      "epoch: 532 train_loss: 3.2109966 valid_loss: 4.4405947 train_acc: 0.9748615 valid_acc: 0.9681921\n",
      "epoch: 533 train_loss: 3.1994088 valid_loss: 4.4330015 train_acc: 0.9748273 valid_acc: 0.9683973\n",
      "epoch: 534 train_loss: 3.190708 valid_loss: 4.4226108 train_acc: 0.9749983 valid_acc: 0.9684657\n",
      "epoch: 535 train_loss: 3.1795142 valid_loss: 4.4133086 train_acc: 0.97527194 valid_acc: 0.9684657\n",
      "epoch: 536 train_loss: 3.170144 valid_loss: 4.404279 train_acc: 0.97530615 valid_acc: 0.9685341\n",
      "epoch: 537 train_loss: 3.1592388 valid_loss: 4.394867 train_acc: 0.9754429 valid_acc: 0.9685341\n",
      "epoch: 538 train_loss: 3.1502538 valid_loss: 4.3857064 train_acc: 0.9754771 valid_acc: 0.9686709\n",
      "epoch: 539 train_loss: 3.1394067 valid_loss: 4.376506 train_acc: 0.9755113 valid_acc: 0.9686709\n",
      "epoch: 540 train_loss: 3.1299574 valid_loss: 4.368914 train_acc: 0.97561395 valid_acc: 0.96873933\n",
      "epoch: 541 train_loss: 3.1198268 valid_loss: 4.358612 train_acc: 0.9755113 valid_acc: 0.9688077\n",
      "epoch: 542 train_loss: 3.1104324 valid_loss: 4.350371 train_acc: 0.97571653 valid_acc: 0.9688077\n",
      "epoch: 543 train_loss: 3.1000736 valid_loss: 4.3425565 train_acc: 0.97561395 valid_acc: 0.9688761\n",
      "epoch: 544 train_loss: 3.0903635 valid_loss: 4.335959 train_acc: 0.97592175 valid_acc: 0.9688761\n",
      "epoch: 545 train_loss: 3.0819159 valid_loss: 4.3236356 train_acc: 0.97578496 valid_acc: 0.96894455\n",
      "epoch: 546 train_loss: 3.0705214 valid_loss: 4.3206263 train_acc: 0.97612697 valid_acc: 0.96894455\n",
      "epoch: 547 train_loss: 3.062903 valid_loss: 4.3083344 train_acc: 0.9759902 valid_acc: 0.9690129\n",
      "epoch: 548 train_loss: 3.0516043 valid_loss: 4.302215 train_acc: 0.97622955 valid_acc: 0.9688761\n",
      "epoch: 549 train_loss: 3.042922 valid_loss: 4.2905726 train_acc: 0.9761269 valid_acc: 0.9690129\n",
      "epoch: 550 train_loss: 3.0326629 valid_loss: 4.2831526 train_acc: 0.97626376 valid_acc: 0.9690129\n",
      "epoch: 551 train_loss: 3.0239968 valid_loss: 4.272336 train_acc: 0.97626376 valid_acc: 0.96908134\n",
      "epoch: 552 train_loss: 3.0131655 valid_loss: 4.266336 train_acc: 0.9763322 valid_acc: 0.96928656\n",
      "epoch: 553 train_loss: 3.0053155 valid_loss: 4.2535734 train_acc: 0.97619534 valid_acc: 0.96928656\n",
      "epoch: 554 train_loss: 2.994022 valid_loss: 4.247742 train_acc: 0.97643477 valid_acc: 0.96942335\n",
      "epoch: 555 train_loss: 2.9869132 valid_loss: 4.2362256 train_acc: 0.97622955 valid_acc: 0.96928656\n",
      "epoch: 556 train_loss: 2.9747279 valid_loss: 4.23037 train_acc: 0.9767768 valid_acc: 0.96942335\n",
      "epoch: 557 train_loss: 2.968223 valid_loss: 4.217888 train_acc: 0.97612697 valid_acc: 0.96956015\n",
      "epoch: 558 train_loss: 2.9557502 valid_loss: 4.2116666 train_acc: 0.9768452 valid_acc: 0.9696286\n",
      "epoch: 559 train_loss: 2.9485693 valid_loss: 4.20086 train_acc: 0.9764348 valid_acc: 0.9694918\n",
      "epoch: 560 train_loss: 2.9367542 valid_loss: 4.1934834 train_acc: 0.9769478 valid_acc: 0.9698338\n",
      "epoch: 561 train_loss: 2.929904 valid_loss: 4.1832647 train_acc: 0.97653735 valid_acc: 0.969697\n",
      "epoch: 562 train_loss: 2.917931 valid_loss: 4.1767755 train_acc: 0.9771873 valid_acc: 0.969697\n",
      "epoch: 563 train_loss: 2.9108245 valid_loss: 4.1652765 train_acc: 0.9767768 valid_acc: 0.9698338\n",
      "epoch: 564 train_loss: 2.8995354 valid_loss: 4.1590447 train_acc: 0.9772556 valid_acc: 0.9699706\n",
      "epoch: 565 train_loss: 2.8927364 valid_loss: 4.1483455 train_acc: 0.9767426 valid_acc: 0.970039\n",
      "epoch: 566 train_loss: 2.8814762 valid_loss: 4.140139 train_acc: 0.9771872 valid_acc: 0.96990216\n",
      "epoch: 567 train_loss: 2.8740034 valid_loss: 4.130548 train_acc: 0.97684515 valid_acc: 0.9702442\n",
      "epoch: 568 train_loss: 2.8632112 valid_loss: 4.1226463 train_acc: 0.9772898 valid_acc: 0.9701758\n",
      "epoch: 569 train_loss: 2.8552766 valid_loss: 4.114425 train_acc: 0.9772214 valid_acc: 0.9703126\n",
      "epoch: 570 train_loss: 2.8451083 valid_loss: 4.105829 train_acc: 0.97742665 valid_acc: 0.9701758\n",
      "epoch: 571 train_loss: 2.836783 valid_loss: 4.0975466 train_acc: 0.97739244 valid_acc: 0.970381\n",
      "epoch: 572 train_loss: 2.826796 valid_loss: 4.0903444 train_acc: 0.97773445 valid_acc: 0.9703126\n",
      "epoch: 573 train_loss: 2.8193197 valid_loss: 4.079959 train_acc: 0.9778371 valid_acc: 0.9705178\n",
      "epoch: 574 train_loss: 2.8089833 valid_loss: 4.073762 train_acc: 0.9779739 valid_acc: 0.9705178\n",
      "epoch: 575 train_loss: 2.800864 valid_loss: 4.065474 train_acc: 0.9781107 valid_acc: 0.97058624\n",
      "epoch: 576 train_loss: 2.792169 valid_loss: 4.055589 train_acc: 0.97807646 valid_acc: 0.97058624\n",
      "epoch: 577 train_loss: 2.7837281 valid_loss: 4.04874 train_acc: 0.9781791 valid_acc: 0.9706546\n",
      "epoch: 578 train_loss: 2.7748196 valid_loss: 4.0394387 train_acc: 0.9782133 valid_acc: 0.9706546\n",
      "epoch: 579 train_loss: 2.7669108 valid_loss: 4.03226 train_acc: 0.9781791 valid_acc: 0.9706546\n",
      "epoch: 580 train_loss: 2.7579033 valid_loss: 4.0234227 train_acc: 0.9784869 valid_acc: 0.97079146\n",
      "epoch: 581 train_loss: 2.7501118 valid_loss: 4.0158844 train_acc: 0.9783159 valid_acc: 0.9708598\n",
      "epoch: 582 train_loss: 2.7411363 valid_loss: 4.007443 train_acc: 0.9784869 valid_acc: 0.9708598\n",
      "epoch: 583 train_loss: 2.733086 valid_loss: 3.9996543 train_acc: 0.9784527 valid_acc: 0.97092825\n",
      "epoch: 584 train_loss: 2.724337 valid_loss: 3.9924138 train_acc: 0.9784527 valid_acc: 0.9711335\n",
      "epoch: 585 train_loss: 2.7164059 valid_loss: 3.9834762 train_acc: 0.9785211 valid_acc: 0.97120184\n",
      "epoch: 586 train_loss: 2.707511 valid_loss: 3.9769444 train_acc: 0.97865796 valid_acc: 0.9713387\n",
      "epoch: 587 train_loss: 2.6993504 valid_loss: 3.9682236 train_acc: 0.9784869 valid_acc: 0.9713387\n",
      "epoch: 588 train_loss: 2.6909537 valid_loss: 3.9597816 train_acc: 0.9786921 valid_acc: 0.9714755\n",
      "epoch: 589 train_loss: 2.68261 valid_loss: 3.95318 train_acc: 0.9786921 valid_acc: 0.97140706\n",
      "epoch: 590 train_loss: 2.6740408 valid_loss: 3.944556 train_acc: 0.9787605 valid_acc: 0.97140706\n",
      "epoch: 591 train_loss: 2.6659048 valid_loss: 3.9372427 train_acc: 0.9787947 valid_acc: 0.97140706\n",
      "epoch: 592 train_loss: 2.6576724 valid_loss: 3.9293082 train_acc: 0.97889733 valid_acc: 0.97140706\n",
      "epoch: 593 train_loss: 2.6492748 valid_loss: 3.9208655 train_acc: 0.97889733 valid_acc: 0.9714755\n",
      "epoch: 594 train_loss: 2.640924 valid_loss: 3.9134345 train_acc: 0.97910255 valid_acc: 0.9714755\n",
      "epoch: 595 train_loss: 2.632752 valid_loss: 3.9052765 train_acc: 0.9789999 valid_acc: 0.9714755\n",
      "epoch: 596 train_loss: 2.6244915 valid_loss: 3.8966248 train_acc: 0.9790683 valid_acc: 0.9714755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 597 train_loss: 2.616095 valid_loss: 3.888915 train_acc: 0.97906834 valid_acc: 0.9716123\n",
      "epoch: 598 train_loss: 2.607901 valid_loss: 3.8810692 train_acc: 0.9791025 valid_acc: 0.9716123\n",
      "epoch: 599 train_loss: 2.5997157 valid_loss: 3.8732314 train_acc: 0.9791367 valid_acc: 0.9716123\n",
      "epoch: 600 train_loss: 2.5915174 valid_loss: 3.8652658 train_acc: 0.97923934 valid_acc: 0.9716123\n",
      "epoch: 601 train_loss: 2.583197 valid_loss: 3.8566976 train_acc: 0.97941035 valid_acc: 0.9716123\n",
      "epoch: 602 train_loss: 2.574986 valid_loss: 3.847742 train_acc: 0.97944456 valid_acc: 0.9716123\n",
      "epoch: 603 train_loss: 2.566546 valid_loss: 3.8400059 train_acc: 0.9794787 valid_acc: 0.9716123\n",
      "epoch: 604 train_loss: 2.5585358 valid_loss: 3.831178 train_acc: 0.97954714 valid_acc: 0.9716807\n",
      "epoch: 605 train_loss: 2.5503964 valid_loss: 3.823118 train_acc: 0.9797524 valid_acc: 0.97174907\n",
      "epoch: 606 train_loss: 2.542697 valid_loss: 3.812389 train_acc: 0.9797866 valid_acc: 0.97174907\n",
      "epoch: 607 train_loss: 2.5345616 valid_loss: 3.8065438 train_acc: 0.980026 valid_acc: 0.97174907\n",
      "epoch: 608 train_loss: 2.5269241 valid_loss: 3.7954855 train_acc: 0.97985494 valid_acc: 0.97174907\n",
      "epoch: 609 train_loss: 2.519217 valid_loss: 3.7876055 train_acc: 0.9800602 valid_acc: 0.9718175\n",
      "epoch: 610 train_loss: 2.51081 valid_loss: 3.7823012 train_acc: 0.9800602 valid_acc: 0.9718859\n",
      "epoch: 611 train_loss: 2.5037918 valid_loss: 3.7698624 train_acc: 0.9800602 valid_acc: 0.9718175\n",
      "epoch: 612 train_loss: 2.4961462 valid_loss: 3.7641687 train_acc: 0.98023117 valid_acc: 0.9718859\n",
      "epoch: 613 train_loss: 2.4876842 valid_loss: 3.7578456 train_acc: 0.9803338 valid_acc: 0.9718175\n",
      "epoch: 614 train_loss: 2.4809856 valid_loss: 3.7445314 train_acc: 0.9802996 valid_acc: 0.9720227\n",
      "epoch: 615 train_loss: 2.4729614 valid_loss: 3.7414389 train_acc: 0.98043644 valid_acc: 0.9719543\n",
      "epoch: 616 train_loss: 2.4657407 valid_loss: 3.7351604 train_acc: 0.9802996 valid_acc: 0.9720227\n",
      "epoch: 617 train_loss: 2.4582868 valid_loss: 3.7215705 train_acc: 0.980368 valid_acc: 0.97209114\n",
      "epoch: 618 train_loss: 2.4510708 valid_loss: 3.7202346 train_acc: 0.98043644 valid_acc: 0.9721595\n",
      "epoch: 619 train_loss: 2.4427316 valid_loss: 3.716536 train_acc: 0.980368 valid_acc: 0.97222793\n",
      "epoch: 620 train_loss: 2.4371169 valid_loss: 3.696649 train_acc: 0.980539 valid_acc: 0.9722963\n",
      "epoch: 621 train_loss: 2.4296865 valid_loss: 3.6956503 train_acc: 0.980368 valid_acc: 0.97243315\n",
      "epoch: 622 train_loss: 2.4208422 valid_loss: 3.6968126 train_acc: 0.98057324 valid_acc: 0.97243315\n",
      "epoch: 623 train_loss: 2.415272 valid_loss: 3.6751728 train_acc: 0.980368 valid_acc: 0.97243315\n",
      "epoch: 624 train_loss: 2.4076018 valid_loss: 3.671065 train_acc: 0.98081267 valid_acc: 0.97256994\n",
      "epoch: 625 train_loss: 2.3994908 valid_loss: 3.6712024 train_acc: 0.98071 valid_acc: 0.97270674\n",
      "epoch: 626 train_loss: 2.393303 valid_loss: 3.656934 train_acc: 0.98057324 valid_acc: 0.97263837\n",
      "epoch: 627 train_loss: 2.3863344 valid_loss: 3.6521866 train_acc: 0.98091525 valid_acc: 0.9728436\n",
      "epoch: 628 train_loss: 2.37821 valid_loss: 3.650677 train_acc: 0.98088104 valid_acc: 0.9728436\n",
      "epoch: 629 train_loss: 2.372281 valid_loss: 3.635141 train_acc: 0.9806416 valid_acc: 0.97277516\n",
      "epoch: 630 train_loss: 2.365124 valid_loss: 3.6286309 train_acc: 0.9811547 valid_acc: 0.9729804\n",
      "epoch: 631 train_loss: 2.3586273 valid_loss: 3.6275246 train_acc: 0.98088104 valid_acc: 0.9731172\n",
      "epoch: 632 train_loss: 2.3509545 valid_loss: 3.622641 train_acc: 0.98112047 valid_acc: 0.9729804\n",
      "epoch: 633 train_loss: 2.344643 valid_loss: 3.6103754 train_acc: 0.98091525 valid_acc: 0.9731856\n",
      "epoch: 634 train_loss: 2.3380404 valid_loss: 3.6009436 train_acc: 0.9812573 valid_acc: 0.97304875\n",
      "epoch: 635 train_loss: 2.3311496 valid_loss: 3.5977185 train_acc: 0.98112047 valid_acc: 0.9731856\n",
      "epoch: 636 train_loss: 2.3240187 valid_loss: 3.595551 train_acc: 0.98135984 valid_acc: 0.9731172\n",
      "epoch: 637 train_loss: 2.3178592 valid_loss: 3.5871768 train_acc: 0.9811889 valid_acc: 0.9731856\n",
      "epoch: 638 train_loss: 2.3103564 valid_loss: 3.5788205 train_acc: 0.9815309 valid_acc: 0.9731172\n",
      "epoch: 639 train_loss: 2.3046947 valid_loss: 3.5696337 train_acc: 0.9810178 valid_acc: 0.9731856\n",
      "epoch: 640 train_loss: 2.2964044 valid_loss: 3.566344 train_acc: 0.98166764 valid_acc: 0.9731856\n",
      "epoch: 641 train_loss: 2.29111 valid_loss: 3.563941 train_acc: 0.98125726 valid_acc: 0.9731856\n",
      "epoch: 642 train_loss: 2.2829843 valid_loss: 3.5497773 train_acc: 0.98156506 valid_acc: 0.9731856\n",
      "epoch: 643 train_loss: 2.277021 valid_loss: 3.5430667 train_acc: 0.98142827 valid_acc: 0.9731856\n",
      "epoch: 644 train_loss: 2.269514 valid_loss: 3.5408561 train_acc: 0.98142827 valid_acc: 0.9731856\n",
      "epoch: 645 train_loss: 2.2632294 valid_loss: 3.5367565 train_acc: 0.98142827 valid_acc: 0.97325397\n",
      "epoch: 646 train_loss: 2.256054 valid_loss: 3.5245643 train_acc: 0.9817703 valid_acc: 0.9733224\n",
      "epoch: 647 train_loss: 2.2502549 valid_loss: 3.5181277 train_acc: 0.9815651 valid_acc: 0.9733224\n",
      "epoch: 648 train_loss: 2.242238 valid_loss: 3.5140584 train_acc: 0.9818387 valid_acc: 0.9733908\n",
      "epoch: 649 train_loss: 2.2365255 valid_loss: 3.5093997 train_acc: 0.9818045 valid_acc: 0.9734592\n",
      "epoch: 650 train_loss: 2.2299283 valid_loss: 3.500611 train_acc: 0.9818045 valid_acc: 0.9733908\n",
      "epoch: 651 train_loss: 2.2236938 valid_loss: 3.496274 train_acc: 0.9817703 valid_acc: 0.9733908\n",
      "epoch: 652 train_loss: 2.2175937 valid_loss: 3.4916656 train_acc: 0.9818729 valid_acc: 0.9735276\n",
      "epoch: 653 train_loss: 2.2103019 valid_loss: 3.4857569 train_acc: 0.9820781 valid_acc: 0.973596\n",
      "epoch: 654 train_loss: 2.2051282 valid_loss: 3.47672 train_acc: 0.98197556 valid_acc: 0.9735276\n",
      "epoch: 655 train_loss: 2.1988301 valid_loss: 3.4731915 train_acc: 0.98194134 valid_acc: 0.9738012\n",
      "epoch: 656 train_loss: 2.1929703 valid_loss: 3.47019 train_acc: 0.9820781 valid_acc: 0.973596\n",
      "epoch: 657 train_loss: 2.1860516 valid_loss: 3.4639957 train_acc: 0.98238593 valid_acc: 0.9738696\n",
      "epoch: 658 train_loss: 2.1809454 valid_loss: 3.4503224 train_acc: 0.9818729 valid_acc: 0.9738696\n",
      "epoch: 659 train_loss: 2.1746144 valid_loss: 3.4492965 train_acc: 0.98231757 valid_acc: 0.9736644\n",
      "epoch: 660 train_loss: 2.1673002 valid_loss: 3.4510434 train_acc: 0.98231757 valid_acc: 0.9737328\n",
      "epoch: 661 train_loss: 2.1640244 valid_loss: 3.439089 train_acc: 0.98194134 valid_acc: 0.9738696\n",
      "epoch: 662 train_loss: 2.155781 valid_loss: 3.4346654 train_acc: 0.9824543 valid_acc: 0.9738012\n",
      "epoch: 663 train_loss: 2.150262 valid_loss: 3.4233801 train_acc: 0.9822149 valid_acc: 0.9738012\n",
      "epoch: 664 train_loss: 2.1446705 valid_loss: 3.4245312 train_acc: 0.9823517 valid_acc: 0.97414327\n",
      "epoch: 665 train_loss: 2.138117 valid_loss: 3.4263802 train_acc: 0.9823175 valid_acc: 0.9740064\n",
      "epoch: 666 train_loss: 2.1307158 valid_loss: 3.4184654 train_acc: 0.9823518 valid_acc: 0.9737328\n",
      "epoch: 667 train_loss: 2.127493 valid_loss: 3.397433 train_acc: 0.98231757 valid_acc: 0.97407484\n",
      "epoch: 668 train_loss: 2.1203098 valid_loss: 3.3877163 train_acc: 0.98228335 valid_acc: 0.97407484\n",
      "epoch: 669 train_loss: 2.1124191 valid_loss: 3.397173 train_acc: 0.9826938 valid_acc: 0.9738696\n",
      "epoch: 670 train_loss: 2.1090379 valid_loss: 3.394133 train_acc: 0.98224914 valid_acc: 0.97393805\n",
      "epoch: 671 train_loss: 2.103589 valid_loss: 3.3818967 train_acc: 0.9824543 valid_acc: 0.97421163\n",
      "epoch: 672 train_loss: 2.0970676 valid_loss: 3.3737745 train_acc: 0.98259115 valid_acc: 0.97407484\n",
      "epoch: 673 train_loss: 2.0905528 valid_loss: 3.3797538 train_acc: 0.98272794 valid_acc: 0.97414327\n",
      "epoch: 674 train_loss: 2.0854151 valid_loss: 3.367052 train_acc: 0.98262537 valid_acc: 0.97421163\n",
      "epoch: 675 train_loss: 2.0798385 valid_loss: 3.354567 train_acc: 0.98289895 valid_acc: 0.97414327\n",
      "epoch: 676 train_loss: 2.0738947 valid_loss: 3.3534677 train_acc: 0.9826596 valid_acc: 0.97441685\n",
      "epoch: 677 train_loss: 2.0695634 valid_loss: 3.3511972 train_acc: 0.98262537 valid_acc: 0.97441685\n",
      "epoch: 678 train_loss: 2.062766 valid_loss: 3.338219 train_acc: 0.98286474 valid_acc: 0.97421163\n",
      "epoch: 679 train_loss: 2.0551205 valid_loss: 3.344044 train_acc: 0.9829674 valid_acc: 0.97421163\n",
      "epoch: 680 train_loss: 2.0530918 valid_loss: 3.3303342 train_acc: 0.98293316 valid_acc: 0.97455364\n",
      "epoch: 681 train_loss: 2.0477858 valid_loss: 3.3169549 train_acc: 0.9828305 valid_acc: 0.97441685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 682 train_loss: 2.0393693 valid_loss: 3.3247893 train_acc: 0.98306996 valid_acc: 0.9743484\n",
      "epoch: 683 train_loss: 2.0341105 valid_loss: 3.3149345 train_acc: 0.9832752 valid_acc: 0.97475886\n",
      "epoch: 684 train_loss: 2.0317101 valid_loss: 3.3068554 train_acc: 0.98317254 valid_acc: 0.9746221\n",
      "epoch: 685 train_loss: 2.022421 valid_loss: 3.3058581 train_acc: 0.98320675 valid_acc: 0.9743484\n",
      "epoch: 686 train_loss: 2.017111 valid_loss: 3.2973773 train_acc: 0.9833778 valid_acc: 0.9746221\n",
      "epoch: 687 train_loss: 2.013652 valid_loss: 3.2889013 train_acc: 0.9836514 valid_acc: 0.97455364\n",
      "epoch: 688 train_loss: 2.0087981 valid_loss: 3.273259 train_acc: 0.9831726 valid_acc: 0.97475886\n",
      "epoch: 689 train_loss: 1.9990175 valid_loss: 3.2842171 train_acc: 0.9834804 valid_acc: 0.97489566\n",
      "epoch: 690 train_loss: 1.9942402 valid_loss: 3.275168 train_acc: 0.98389083 valid_acc: 0.9746905\n",
      "epoch: 691 train_loss: 1.9909201 valid_loss: 3.2638085 train_acc: 0.98344624 valid_acc: 0.9746905\n",
      "epoch: 692 train_loss: 1.981889 valid_loss: 3.2693524 train_acc: 0.9835488 valid_acc: 0.97489566\n",
      "epoch: 693 train_loss: 1.9796841 valid_loss: 3.258382 train_acc: 0.9836856 valid_acc: 0.9751693\n",
      "epoch: 694 train_loss: 1.9734566 valid_loss: 3.24561 train_acc: 0.98382246 valid_acc: 0.97489566\n",
      "epoch: 695 train_loss: 1.9675264 valid_loss: 3.2375927 train_acc: 0.98392504 valid_acc: 0.9751009\n",
      "epoch: 696 train_loss: 1.9621091 valid_loss: 3.239306 train_acc: 0.98378825 valid_acc: 0.9751693\n",
      "epoch: 697 train_loss: 1.9560359 valid_loss: 3.235256 train_acc: 0.983925 valid_acc: 0.9749641\n",
      "epoch: 698 train_loss: 1.9504645 valid_loss: 3.2297347 train_acc: 0.98406184 valid_acc: 0.9748273\n",
      "epoch: 699 train_loss: 1.9469037 valid_loss: 3.2224934 train_acc: 0.9839934 valid_acc: 0.9751693\n",
      "epoch: 700 train_loss: 1.9410442 valid_loss: 3.2180285 train_acc: 0.98406184 valid_acc: 0.9752377\n",
      "epoch: 701 train_loss: 1.9338374 valid_loss: 3.2110343 train_acc: 0.98413026 valid_acc: 0.9751693\n",
      "epoch: 702 train_loss: 1.9302614 valid_loss: 3.205119 train_acc: 0.98426706 valid_acc: 0.9751693\n",
      "epoch: 703 train_loss: 1.9244977 valid_loss: 3.2028723 train_acc: 0.983925 valid_acc: 0.9752377\n",
      "epoch: 704 train_loss: 1.9194212 valid_loss: 3.1926255 train_acc: 0.984267 valid_acc: 0.9753745\n",
      "epoch: 705 train_loss: 1.9145784 valid_loss: 3.195973 train_acc: 0.984267 valid_acc: 0.9755113\n",
      "epoch: 706 train_loss: 1.909679 valid_loss: 3.1867263 train_acc: 0.98423284 valid_acc: 0.9753061\n",
      "epoch: 707 train_loss: 1.903563 valid_loss: 3.1798117 train_acc: 0.9846433 valid_acc: 0.97557974\n",
      "epoch: 708 train_loss: 1.8997824 valid_loss: 3.17707 train_acc: 0.9845065 valid_acc: 0.9756481\n",
      "epoch: 709 train_loss: 1.8948678 valid_loss: 3.1756184 train_acc: 0.98443806 valid_acc: 0.9756481\n",
      "epoch: 710 train_loss: 1.8879782 valid_loss: 3.1628842 train_acc: 0.9846433 valid_acc: 0.97571653\n",
      "epoch: 711 train_loss: 1.8838094 valid_loss: 3.163378 train_acc: 0.9848485 valid_acc: 0.9756481\n",
      "epoch: 712 train_loss: 1.878804 valid_loss: 3.159743 train_acc: 0.98471165 valid_acc: 0.97571653\n",
      "epoch: 713 train_loss: 1.8733377 valid_loss: 3.1455872 train_acc: 0.9847801 valid_acc: 0.9758533\n",
      "epoch: 714 train_loss: 1.8688729 valid_loss: 3.1517148 train_acc: 0.9849169 valid_acc: 0.97592175\n",
      "epoch: 715 train_loss: 1.8645794 valid_loss: 3.143475 train_acc: 0.98454064 valid_acc: 0.9756481\n",
      "epoch: 716 train_loss: 1.8583868 valid_loss: 3.1369174 train_acc: 0.9847801 valid_acc: 0.9759902\n",
      "epoch: 717 train_loss: 1.854471 valid_loss: 3.132065 train_acc: 0.9847801 valid_acc: 0.9758533\n",
      "epoch: 718 train_loss: 1.8507228 valid_loss: 3.13175 train_acc: 0.9845407 valid_acc: 0.9758533\n",
      "epoch: 719 train_loss: 1.8441784 valid_loss: 3.1256104 train_acc: 0.98460907 valid_acc: 0.97612697\n",
      "epoch: 720 train_loss: 1.841574 valid_loss: 3.1151013 train_acc: 0.9846433 valid_acc: 0.97612697\n",
      "epoch: 721 train_loss: 1.835156 valid_loss: 3.1179724 train_acc: 0.9845065 valid_acc: 0.97592175\n",
      "epoch: 722 train_loss: 1.8302815 valid_loss: 3.110821 train_acc: 0.98474586 valid_acc: 0.97612697\n",
      "epoch: 723 train_loss: 1.8256271 valid_loss: 3.1044278 train_acc: 0.9848827 valid_acc: 0.97605854\n",
      "epoch: 724 train_loss: 1.821674 valid_loss: 3.0965722 train_acc: 0.9845065 valid_acc: 0.97619534\n",
      "epoch: 725 train_loss: 1.8150759 valid_loss: 3.1010485 train_acc: 0.98498535 valid_acc: 0.97619534\n",
      "epoch: 726 train_loss: 1.8118732 valid_loss: 3.0921912 train_acc: 0.9847801 valid_acc: 0.97612697\n",
      "epoch: 727 train_loss: 1.8074515 valid_loss: 3.0762157 train_acc: 0.98467743 valid_acc: 0.97619534\n",
      "epoch: 728 train_loss: 1.8014833 valid_loss: 3.0855925 train_acc: 0.9849853 valid_acc: 0.9763322\n",
      "epoch: 729 train_loss: 1.7973738 valid_loss: 3.0842226 train_acc: 0.9849511 valid_acc: 0.97605854\n",
      "epoch: 730 train_loss: 1.7920978 valid_loss: 3.065585 train_acc: 0.9847801 valid_acc: 0.97612697\n",
      "epoch: 731 train_loss: 1.7877964 valid_loss: 3.0613372 train_acc: 0.9849853 valid_acc: 0.976469\n",
      "epoch: 732 train_loss: 1.781954 valid_loss: 3.0692213 train_acc: 0.9853615 valid_acc: 0.97619534\n",
      "epoch: 733 train_loss: 1.7775637 valid_loss: 3.0635233 train_acc: 0.9849853 valid_acc: 0.97626376\n",
      "epoch: 734 train_loss: 1.7727106 valid_loss: 3.042633 train_acc: 0.98525894 valid_acc: 0.97640055\n",
      "epoch: 735 train_loss: 1.7678117 valid_loss: 3.0483465 train_acc: 0.9851563 valid_acc: 0.97626376\n",
      "epoch: 736 train_loss: 1.7631899 valid_loss: 3.04852 train_acc: 0.9852247 valid_acc: 0.97626376\n",
      "epoch: 737 train_loss: 1.7586175 valid_loss: 3.03626 train_acc: 0.9852247 valid_acc: 0.9765374\n",
      "epoch: 738 train_loss: 1.7544775 valid_loss: 3.030967 train_acc: 0.9851905 valid_acc: 0.976469\n",
      "epoch: 739 train_loss: 1.7485397 valid_loss: 3.0306966 train_acc: 0.9849853 valid_acc: 0.9763322\n",
      "epoch: 740 train_loss: 1.7446527 valid_loss: 3.0247853 train_acc: 0.98556674 valid_acc: 0.9766742\n",
      "epoch: 741 train_loss: 1.7405984 valid_loss: 3.0125046 train_acc: 0.98563516 valid_acc: 0.976469\n",
      "epoch: 742 train_loss: 1.7344768 valid_loss: 3.0140057 train_acc: 0.9849853 valid_acc: 0.97640055\n",
      "epoch: 743 train_loss: 1.7302809 valid_loss: 3.0112112 train_acc: 0.9855325 valid_acc: 0.9766742\n",
      "epoch: 744 train_loss: 1.7249792 valid_loss: 3.0066602 train_acc: 0.98560095 valid_acc: 0.976469\n",
      "epoch: 745 train_loss: 1.7212243 valid_loss: 3.0019362 train_acc: 0.98525894 valid_acc: 0.976469\n",
      "epoch: 746 train_loss: 1.7152361 valid_loss: 2.9943447 train_acc: 0.9854641 valid_acc: 0.9766058\n",
      "epoch: 747 train_loss: 1.7113781 valid_loss: 2.9903631 train_acc: 0.98556674 valid_acc: 0.9765374\n",
      "epoch: 748 train_loss: 1.7058084 valid_loss: 2.990011 train_acc: 0.9854983 valid_acc: 0.9766742\n",
      "epoch: 749 train_loss: 1.702071 valid_loss: 2.979117 train_acc: 0.98560095 valid_acc: 0.97674257\n",
      "epoch: 750 train_loss: 1.6970352 valid_loss: 2.9840252 train_acc: 0.98587453 valid_acc: 0.9766058\n",
      "epoch: 751 train_loss: 1.6926376 valid_loss: 2.970375 train_acc: 0.9856693 valid_acc: 0.9765374\n",
      "epoch: 752 train_loss: 1.6884632 valid_loss: 2.9638917 train_acc: 0.9855325 valid_acc: 0.9766058\n",
      "epoch: 753 train_loss: 1.68338 valid_loss: 2.9660609 train_acc: 0.98573774 valid_acc: 0.976811\n",
      "epoch: 754 train_loss: 1.6796341 valid_loss: 2.9569235 train_acc: 0.98563516 valid_acc: 0.9765374\n",
      "epoch: 755 train_loss: 1.6744075 valid_loss: 2.956639 train_acc: 0.9858403 valid_acc: 0.976811\n",
      "epoch: 756 train_loss: 1.6701163 valid_loss: 2.949438 train_acc: 0.98594296 valid_acc: 0.976811\n",
      "epoch: 757 train_loss: 1.6658261 valid_loss: 2.9458697 train_acc: 0.9858061 valid_acc: 0.9768794\n",
      "epoch: 758 train_loss: 1.6606381 valid_loss: 2.939425 train_acc: 0.98625076 valid_acc: 0.9770162\n",
      "epoch: 759 train_loss: 1.6567166 valid_loss: 2.936515 train_acc: 0.9860114 valid_acc: 0.9768794\n",
      "epoch: 760 train_loss: 1.6522448 valid_loss: 2.9350684 train_acc: 0.9857035 valid_acc: 0.9768794\n",
      "epoch: 761 train_loss: 1.6479169 valid_loss: 2.9291365 train_acc: 0.98594296 valid_acc: 0.976811\n",
      "epoch: 762 train_loss: 1.6422778 valid_loss: 2.921843 train_acc: 0.9858403 valid_acc: 0.977153\n",
      "epoch: 763 train_loss: 1.6383922 valid_loss: 2.923949 train_acc: 0.98573774 valid_acc: 0.9768794\n",
      "epoch: 764 train_loss: 1.6340847 valid_loss: 2.9109175 train_acc: 0.9860798 valid_acc: 0.9766742\n",
      "epoch: 765 train_loss: 1.6299794 valid_loss: 2.9086642 train_acc: 0.98590875 valid_acc: 0.9770162\n",
      "epoch: 766 train_loss: 1.6250358 valid_loss: 2.9057548 train_acc: 0.9861482 valid_acc: 0.977153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 767 train_loss: 1.6203297 valid_loss: 2.899558 train_acc: 0.98611397 valid_acc: 0.9770162\n",
      "epoch: 768 train_loss: 1.6155001 valid_loss: 2.8991942 train_acc: 0.9859772 valid_acc: 0.9772214\n",
      "epoch: 769 train_loss: 1.611474 valid_loss: 2.8929834 train_acc: 0.9860114 valid_acc: 0.9772214\n",
      "epoch: 770 train_loss: 1.606311 valid_loss: 2.8868744 train_acc: 0.9861482 valid_acc: 0.977153\n",
      "epoch: 771 train_loss: 1.601815 valid_loss: 2.8826907 train_acc: 0.98618233 valid_acc: 0.97708464\n",
      "epoch: 772 train_loss: 1.5977533 valid_loss: 2.879076 train_acc: 0.9861482 valid_acc: 0.97728986\n",
      "epoch: 773 train_loss: 1.5924997 valid_loss: 2.8708925 train_acc: 0.98642176 valid_acc: 0.9772214\n",
      "epoch: 774 train_loss: 1.5884948 valid_loss: 2.8738205 train_acc: 0.98607975 valid_acc: 0.97728986\n",
      "epoch: 775 train_loss: 1.5839157 valid_loss: 2.8558457 train_acc: 0.98655856 valid_acc: 0.9772214\n",
      "epoch: 776 train_loss: 1.5818164 valid_loss: 2.8571198 train_acc: 0.98611397 valid_acc: 0.97728986\n",
      "epoch: 777 train_loss: 1.5760356 valid_loss: 2.8560362 train_acc: 0.98625076 valid_acc: 0.977153\n",
      "epoch: 778 train_loss: 1.5718622 valid_loss: 2.8449411 train_acc: 0.986285 valid_acc: 0.977153\n",
      "epoch: 779 train_loss: 1.5668535 valid_loss: 2.842209 train_acc: 0.98652434 valid_acc: 0.9773582\n",
      "epoch: 780 train_loss: 1.5631342 valid_loss: 2.8392355 train_acc: 0.98621655 valid_acc: 0.9772214\n",
      "epoch: 781 train_loss: 1.5581949 valid_loss: 2.8317802 train_acc: 0.986798 valid_acc: 0.9773582\n",
      "epoch: 782 train_loss: 1.5548574 valid_loss: 2.8274448 train_acc: 0.9863876 valid_acc: 0.97742665\n",
      "epoch: 783 train_loss: 1.5498581 valid_loss: 2.8212466 train_acc: 0.9864218 valid_acc: 0.9773582\n",
      "epoch: 784 train_loss: 1.5451674 valid_loss: 2.8199542 train_acc: 0.9865244 valid_acc: 0.977495\n",
      "epoch: 785 train_loss: 1.5420394 valid_loss: 2.8128736 train_acc: 0.9866612 valid_acc: 0.97742665\n",
      "epoch: 786 train_loss: 1.5369785 valid_loss: 2.8115416 train_acc: 0.9863876 valid_acc: 0.97756344\n",
      "epoch: 787 train_loss: 1.5330033 valid_loss: 2.804895 train_acc: 0.986969 valid_acc: 0.97756344\n",
      "epoch: 788 train_loss: 1.5286807 valid_loss: 2.8008497 train_acc: 0.9864902 valid_acc: 0.97776866\n",
      "epoch: 789 train_loss: 1.5245941 valid_loss: 2.79253 train_acc: 0.9866612 valid_acc: 0.977495\n",
      "epoch: 790 train_loss: 1.5209062 valid_loss: 2.7930913 train_acc: 0.986798 valid_acc: 0.97742665\n",
      "epoch: 791 train_loss: 1.5169699 valid_loss: 2.7870793 train_acc: 0.98676383 valid_acc: 0.97763187\n",
      "epoch: 792 train_loss: 1.5122042 valid_loss: 2.7838774 train_acc: 0.98642176 valid_acc: 0.97770023\n",
      "epoch: 793 train_loss: 1.5090001 valid_loss: 2.777747 train_acc: 0.9870032 valid_acc: 0.97776866\n",
      "epoch: 794 train_loss: 1.5039482 valid_loss: 2.7647383 train_acc: 0.98642176 valid_acc: 0.97770023\n",
      "epoch: 795 train_loss: 1.5000801 valid_loss: 2.7748227 train_acc: 0.98690057 valid_acc: 0.97770023\n",
      "epoch: 796 train_loss: 1.4965779 valid_loss: 2.7632773 train_acc: 0.9870032 valid_acc: 0.97763187\n",
      "epoch: 797 train_loss: 1.4912977 valid_loss: 2.762765 train_acc: 0.986456 valid_acc: 0.9778371\n",
      "epoch: 798 train_loss: 1.4884543 valid_loss: 2.7566466 train_acc: 0.9867296 valid_acc: 0.97770023\n",
      "epoch: 799 train_loss: 1.4841167 valid_loss: 2.7548385 train_acc: 0.9868322 valid_acc: 0.97776866\n",
      "epoch: 800 train_loss: 1.4808576 valid_loss: 2.7403486 train_acc: 0.9868322 valid_acc: 0.9779739\n",
      "epoch: 801 train_loss: 1.4755781 valid_loss: 2.7467 train_acc: 0.986798 valid_acc: 0.97790545\n",
      "epoch: 802 train_loss: 1.4707141 valid_loss: 2.7342815 train_acc: 0.9870374 valid_acc: 0.97790545\n",
      "epoch: 803 train_loss: 1.4681506 valid_loss: 2.7352002 train_acc: 0.9867296 valid_acc: 0.9779739\n",
      "epoch: 804 train_loss: 1.4631495 valid_loss: 2.7267416 train_acc: 0.9871742 valid_acc: 0.9778371\n",
      "epoch: 805 train_loss: 1.4593221 valid_loss: 2.7246408 train_acc: 0.986969 valid_acc: 0.97770023\n",
      "epoch: 806 train_loss: 1.456186 valid_loss: 2.7220612 train_acc: 0.9870032 valid_acc: 0.97790545\n",
      "epoch: 807 train_loss: 1.4507233 valid_loss: 2.712902 train_acc: 0.9870032 valid_acc: 0.97790545\n",
      "epoch: 808 train_loss: 1.4469494 valid_loss: 2.717497 train_acc: 0.98707163 valid_acc: 0.9779739\n",
      "epoch: 809 train_loss: 1.443711 valid_loss: 2.7054992 train_acc: 0.98690057 valid_acc: 0.97804224\n",
      "epoch: 810 train_loss: 1.4380533 valid_loss: 2.7030299 train_acc: 0.987311 valid_acc: 0.97776866\n",
      "epoch: 811 train_loss: 1.4346488 valid_loss: 2.697269 train_acc: 0.986969 valid_acc: 0.97776866\n",
      "epoch: 812 train_loss: 1.4303985 valid_loss: 2.6929724 train_acc: 0.98714006 valid_acc: 0.9779739\n",
      "epoch: 813 train_loss: 1.4265721 valid_loss: 2.6935246 train_acc: 0.98707163 valid_acc: 0.9781107\n",
      "epoch: 814 train_loss: 1.4224213 valid_loss: 2.682575 train_acc: 0.9872768 valid_acc: 0.97804224\n",
      "epoch: 815 train_loss: 1.4183116 valid_loss: 2.6837733 train_acc: 0.9873452 valid_acc: 0.9781791\n",
      "epoch: 816 train_loss: 1.414905 valid_loss: 2.6752748 train_acc: 0.98755044 valid_acc: 0.9783159\n",
      "epoch: 817 train_loss: 1.4111049 valid_loss: 2.674201 train_acc: 0.9871742 valid_acc: 0.9781107\n",
      "epoch: 818 train_loss: 1.407268 valid_loss: 2.6652336 train_acc: 0.987653 valid_acc: 0.97804224\n",
      "epoch: 819 train_loss: 1.4026315 valid_loss: 2.6733549 train_acc: 0.98744786 valid_acc: 0.97824746\n",
      "epoch: 820 train_loss: 1.3994544 valid_loss: 2.6540096 train_acc: 0.98758465 valid_acc: 0.9783159\n",
      "epoch: 821 train_loss: 1.3960098 valid_loss: 2.6633725 train_acc: 0.9872084 valid_acc: 0.9783843\n",
      "epoch: 822 train_loss: 1.3943167 valid_loss: 2.6455274 train_acc: 0.98758465 valid_acc: 0.9781107\n",
      "epoch: 823 train_loss: 1.389576 valid_loss: 2.6535246 train_acc: 0.98714 valid_acc: 0.97858953\n",
      "epoch: 824 train_loss: 1.386517 valid_loss: 2.6345892 train_acc: 0.9871743 valid_acc: 0.97824746\n",
      "epoch: 825 train_loss: 1.3806603 valid_loss: 2.6484435 train_acc: 0.9872768 valid_acc: 0.97804224\n",
      "epoch: 826 train_loss: 1.3788809 valid_loss: 2.637952 train_acc: 0.98758465 valid_acc: 0.9784527\n",
      "epoch: 827 train_loss: 1.3730787 valid_loss: 2.6223626 train_acc: 0.98741364 valid_acc: 0.9784527\n",
      "epoch: 828 train_loss: 1.3704803 valid_loss: 2.631507 train_acc: 0.98744786 valid_acc: 0.9783843\n",
      "epoch: 829 train_loss: 1.3656698 valid_loss: 2.6261532 train_acc: 0.987653 valid_acc: 0.9781107\n",
      "epoch: 830 train_loss: 1.3614328 valid_loss: 2.620387 train_acc: 0.98714006 valid_acc: 0.9783159\n",
      "epoch: 831 train_loss: 1.3602622 valid_loss: 2.6060338 train_acc: 0.98755044 valid_acc: 0.9783843\n",
      "epoch: 832 train_loss: 1.3554082 valid_loss: 2.621445 train_acc: 0.98761886 valid_acc: 0.9785211\n",
      "epoch: 833 train_loss: 1.3532054 valid_loss: 2.6023247 train_acc: 0.9876188 valid_acc: 0.9783843\n",
      "epoch: 834 train_loss: 1.3467712 valid_loss: 2.6056795 train_acc: 0.98737943 valid_acc: 0.9784527\n",
      "epoch: 835 train_loss: 1.3435631 valid_loss: 2.592763 train_acc: 0.98755044 valid_acc: 0.9785211\n",
      "epoch: 836 train_loss: 1.3417726 valid_loss: 2.5935934 train_acc: 0.9872426 valid_acc: 0.9783159\n",
      "epoch: 837 train_loss: 1.3374116 valid_loss: 2.5931478 train_acc: 0.987653 valid_acc: 0.9784527\n",
      "epoch: 838 train_loss: 1.3337908 valid_loss: 2.5853648 train_acc: 0.98768723 valid_acc: 0.9786579\n",
      "epoch: 839 train_loss: 1.3285904 valid_loss: 2.582535 train_acc: 0.98772144 valid_acc: 0.97858953\n",
      "epoch: 840 train_loss: 1.3258133 valid_loss: 2.5714295 train_acc: 0.987653 valid_acc: 0.9783843\n",
      "epoch: 841 train_loss: 1.3215525 valid_loss: 2.580329 train_acc: 0.9878583 valid_acc: 0.9783159\n",
      "epoch: 842 train_loss: 1.31749 valid_loss: 2.5678782 train_acc: 0.9878241 valid_acc: 0.9786579\n",
      "epoch: 843 train_loss: 1.3128116 valid_loss: 2.5589757 train_acc: 0.98809767 valid_acc: 0.9787947\n",
      "epoch: 844 train_loss: 1.3080506 valid_loss: 2.569518 train_acc: 0.9881319 valid_acc: 0.97858953\n",
      "epoch: 845 train_loss: 1.307338 valid_loss: 2.548579 train_acc: 0.98789245 valid_acc: 0.9786579\n",
      "epoch: 846 train_loss: 1.3021725 valid_loss: 2.5645804 train_acc: 0.98809767 valid_acc: 0.97858953\n",
      "epoch: 847 train_loss: 1.2997124 valid_loss: 2.540182 train_acc: 0.9883371 valid_acc: 0.9786579\n",
      "epoch: 848 train_loss: 1.2965889 valid_loss: 2.5453951 train_acc: 0.987995 valid_acc: 0.97858953\n",
      "epoch: 849 train_loss: 1.29236 valid_loss: 2.5327556 train_acc: 0.9882003 valid_acc: 0.9785211\n",
      "epoch: 850 train_loss: 1.2906349 valid_loss: 2.538627 train_acc: 0.98775566 valid_acc: 0.9786579\n",
      "epoch: 851 train_loss: 1.2879734 valid_loss: 2.5134873 train_acc: 0.9882687 valid_acc: 0.9788631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 852 train_loss: 1.2860518 valid_loss: 2.5334725 train_acc: 0.987653 valid_acc: 0.9788631\n",
      "epoch: 853 train_loss: 1.2826123 valid_loss: 2.5264103 train_acc: 0.9881661 valid_acc: 0.9787947\n",
      "epoch: 854 train_loss: 1.2793331 valid_loss: 2.509631 train_acc: 0.9879609 valid_acc: 0.97906834\n",
      "epoch: 855 train_loss: 1.273426 valid_loss: 2.5087044 train_acc: 0.98840547 valid_acc: 0.9787947\n",
      "epoch: 856 train_loss: 1.2697039 valid_loss: 2.5230472 train_acc: 0.9882003 valid_acc: 0.97893155\n",
      "epoch: 857 train_loss: 1.2709861 valid_loss: 2.514217 train_acc: 0.9885081 valid_acc: 0.9788631\n",
      "epoch: 858 train_loss: 1.2615175 valid_loss: 2.5003815 train_acc: 0.9883713 valid_acc: 0.97893155\n",
      "epoch: 859 train_loss: 1.2574177 valid_loss: 2.517945 train_acc: 0.98840547 valid_acc: 0.9788631\n",
      "epoch: 860 train_loss: 1.255603 valid_loss: 2.4703207 train_acc: 0.9885423 valid_acc: 0.9789999\n",
      "epoch: 861 train_loss: 1.2560325 valid_loss: 2.5008137 train_acc: 0.9883029 valid_acc: 0.97913677\n",
      "epoch: 862 train_loss: 1.257701 valid_loss: 2.4988484 train_acc: 0.9885423 valid_acc: 0.9789999\n",
      "epoch: 863 train_loss: 1.2515209 valid_loss: 2.4785233 train_acc: 0.9879951 valid_acc: 0.97920513\n",
      "epoch: 864 train_loss: 1.2411466 valid_loss: 2.4754918 train_acc: 0.98861074 valid_acc: 0.9793419\n",
      "epoch: 865 train_loss: 1.2369059 valid_loss: 2.468317 train_acc: 0.98823446 valid_acc: 0.9793419\n",
      "epoch: 866 train_loss: 1.2367486 valid_loss: 2.4884744 train_acc: 0.98861074 valid_acc: 0.97927356\n",
      "epoch: 867 train_loss: 1.2318056 valid_loss: 2.450469 train_acc: 0.98891854 valid_acc: 0.97913677\n",
      "epoch: 868 train_loss: 1.2309017 valid_loss: 2.4564257 train_acc: 0.9882345 valid_acc: 0.97927356\n",
      "epoch: 869 train_loss: 1.2260649 valid_loss: 2.4684997 train_acc: 0.9887817 valid_acc: 0.97913677\n",
      "epoch: 870 train_loss: 1.2250636 valid_loss: 2.4449663 train_acc: 0.98837125 valid_acc: 0.9793419\n",
      "epoch: 871 train_loss: 1.2196642 valid_loss: 2.4306672 train_acc: 0.98898697 valid_acc: 0.9794788\n",
      "epoch: 872 train_loss: 1.2164445 valid_loss: 2.4546525 train_acc: 0.9887475 valid_acc: 0.97941035\n",
      "epoch: 873 train_loss: 1.218487 valid_loss: 2.4479816 train_acc: 0.9885423 valid_acc: 0.97954714\n",
      "epoch: 874 train_loss: 1.2101178 valid_loss: 2.4439094 train_acc: 0.9888159 valid_acc: 0.9793419\n",
      "epoch: 875 train_loss: 1.2073237 valid_loss: 2.4358063 train_acc: 0.98912376 valid_acc: 0.9794788\n",
      "epoch: 876 train_loss: 1.1993678 valid_loss: 2.417686 train_acc: 0.98898697 valid_acc: 0.97961557\n",
      "epoch: 877 train_loss: 1.1984725 valid_loss: 2.4253235 train_acc: 0.98895276 valid_acc: 0.9793419\n",
      "epoch: 878 train_loss: 1.1954771 valid_loss: 2.3936062 train_acc: 0.9891921 valid_acc: 0.9794788\n",
      "epoch: 879 train_loss: 1.195469 valid_loss: 2.419595 train_acc: 0.9887475 valid_acc: 0.9793419\n",
      "epoch: 880 train_loss: 1.1964198 valid_loss: 2.432399 train_acc: 0.98891854 valid_acc: 0.97920513\n",
      "epoch: 881 train_loss: 1.1867133 valid_loss: 2.4024296 train_acc: 0.98874754 valid_acc: 0.97961557\n",
      "epoch: 882 train_loss: 1.1810263 valid_loss: 2.4139824 train_acc: 0.9890212 valid_acc: 0.9794788\n",
      "epoch: 883 train_loss: 1.1805362 valid_loss: 2.3874807 train_acc: 0.98908955 valid_acc: 0.9798208\n",
      "epoch: 884 train_loss: 1.1798443 valid_loss: 2.3981173 train_acc: 0.9890211 valid_acc: 0.97954714\n",
      "epoch: 885 train_loss: 1.176485 valid_loss: 2.4017398 train_acc: 0.98939735 valid_acc: 0.97961557\n",
      "epoch: 886 train_loss: 1.1710987 valid_loss: 2.385517 train_acc: 0.9890212 valid_acc: 0.97954714\n",
      "epoch: 887 train_loss: 1.1639127 valid_loss: 2.3963566 train_acc: 0.9893632 valid_acc: 0.97954714\n",
      "epoch: 888 train_loss: 1.1638722 valid_loss: 2.371864 train_acc: 0.98926055 valid_acc: 0.97961557\n",
      "epoch: 889 train_loss: 1.1600193 valid_loss: 2.3655944 train_acc: 0.98922634 valid_acc: 0.9798208\n",
      "epoch: 890 train_loss: 1.1555512 valid_loss: 2.3773086 train_acc: 0.98929477 valid_acc: 0.97975236\n",
      "epoch: 891 train_loss: 1.1537769 valid_loss: 2.3625975 train_acc: 0.9893974 valid_acc: 0.979684\n",
      "epoch: 892 train_loss: 1.1497353 valid_loss: 2.365749 train_acc: 0.989329 valid_acc: 0.9799576\n",
      "epoch: 893 train_loss: 1.1463327 valid_loss: 2.360051 train_acc: 0.98936313 valid_acc: 0.980026\n",
      "epoch: 894 train_loss: 1.1436033 valid_loss: 2.3535242 train_acc: 0.9891921 valid_acc: 0.980026\n",
      "epoch: 895 train_loss: 1.1423752 valid_loss: 2.3505163 train_acc: 0.98953414 valid_acc: 0.980026\n",
      "epoch: 896 train_loss: 1.1366837 valid_loss: 2.3577754 train_acc: 0.98956835 valid_acc: 0.97975236\n",
      "epoch: 897 train_loss: 1.13697 valid_loss: 2.341123 train_acc: 0.9894658 valid_acc: 0.9800944\n",
      "epoch: 898 train_loss: 1.1331027 valid_loss: 2.3518815 train_acc: 0.98943156 valid_acc: 0.9801628\n",
      "epoch: 899 train_loss: 1.1344142 valid_loss: 2.3455877 train_acc: 0.98953414 valid_acc: 0.9798892\n",
      "epoch: 900 train_loss: 1.1277701 valid_loss: 2.3292696 train_acc: 0.9893974 valid_acc: 0.9802996\n",
      "epoch: 901 train_loss: 1.123843 valid_loss: 2.3432403 train_acc: 0.98973936 valid_acc: 0.9800944\n",
      "epoch: 902 train_loss: 1.1180663 valid_loss: 2.3215053 train_acc: 0.98956835 valid_acc: 0.9801628\n",
      "epoch: 903 train_loss: 1.1160325 valid_loss: 2.3315334 train_acc: 0.9897052 valid_acc: 0.9802312\n",
      "epoch: 904 train_loss: 1.113592 valid_loss: 2.3168025 train_acc: 0.9896368 valid_acc: 0.98043644\n",
      "epoch: 905 train_loss: 1.1123903 valid_loss: 2.3212879 train_acc: 0.98956835 valid_acc: 0.9802312\n",
      "epoch: 906 train_loss: 1.1073248 valid_loss: 2.323772 train_acc: 0.9900472 valid_acc: 0.9805048\n",
      "epoch: 907 train_loss: 1.1052113 valid_loss: 2.3015351 train_acc: 0.98943156 valid_acc: 0.9802312\n",
      "epoch: 908 train_loss: 1.1008269 valid_loss: 2.3175042 train_acc: 0.9899446 valid_acc: 0.9805048\n",
      "epoch: 909 train_loss: 1.1019903 valid_loss: 2.3096962 train_acc: 0.9897394 valid_acc: 0.980368\n",
      "epoch: 910 train_loss: 1.0949167 valid_loss: 2.3021495 train_acc: 0.9897394 valid_acc: 0.98057324\n",
      "epoch: 911 train_loss: 1.0926876 valid_loss: 2.3066087 train_acc: 0.98987615 valid_acc: 0.9802996\n",
      "epoch: 912 train_loss: 1.0895255 valid_loss: 2.2883415 train_acc: 0.98977363 valid_acc: 0.98057324\n",
      "epoch: 913 train_loss: 1.0875341 valid_loss: 2.2952213 train_acc: 0.9894658 valid_acc: 0.9805048\n",
      "epoch: 914 train_loss: 1.0833685 valid_loss: 2.2909894 train_acc: 0.9900814 valid_acc: 0.9806416\n",
      "epoch: 915 train_loss: 1.0823004 valid_loss: 2.2853239 train_acc: 0.98953414 valid_acc: 0.980368\n",
      "epoch: 916 train_loss: 1.0786531 valid_loss: 2.2924511 train_acc: 0.9897052 valid_acc: 0.98071\n",
      "epoch: 917 train_loss: 1.0756948 valid_loss: 2.2726262 train_acc: 0.98991036 valid_acc: 0.9805048\n",
      "epoch: 918 train_loss: 1.0718968 valid_loss: 2.282882 train_acc: 0.9898078 valid_acc: 0.9806416\n",
      "epoch: 919 train_loss: 1.0726941 valid_loss: 2.2793024 train_acc: 0.98956835 valid_acc: 0.98043644\n",
      "epoch: 920 train_loss: 1.065892 valid_loss: 2.268303 train_acc: 0.9900472 valid_acc: 0.98043644\n",
      "epoch: 921 train_loss: 1.0653067 valid_loss: 2.273243 train_acc: 0.99014986 valid_acc: 0.98071\n",
      "epoch: 922 train_loss: 1.0611895 valid_loss: 2.265481 train_acc: 0.989842 valid_acc: 0.9805048\n",
      "epoch: 923 train_loss: 1.0577374 valid_loss: 2.2633307 train_acc: 0.9904918 valid_acc: 0.98057324\n",
      "epoch: 924 train_loss: 1.0551424 valid_loss: 2.2638924 train_acc: 0.99021816 valid_acc: 0.9805048\n",
      "epoch: 925 train_loss: 1.0510299 valid_loss: 2.256041 train_acc: 0.99045765 valid_acc: 0.98071\n",
      "epoch: 926 train_loss: 1.0501301 valid_loss: 2.252152 train_acc: 0.9905602 valid_acc: 0.9808468\n",
      "epoch: 927 train_loss: 1.0462421 valid_loss: 2.2585094 train_acc: 0.99011564 valid_acc: 0.9806416\n",
      "epoch: 928 train_loss: 1.0451095 valid_loss: 2.2499588 train_acc: 0.99056023 valid_acc: 0.98077846\n",
      "epoch: 929 train_loss: 1.0409428 valid_loss: 2.2494385 train_acc: 0.990526 valid_acc: 0.9806416\n",
      "epoch: 930 train_loss: 1.0373011 valid_loss: 2.2382278 train_acc: 0.99076545 valid_acc: 0.9808468\n",
      "epoch: 931 train_loss: 1.037987 valid_loss: 2.2432542 train_acc: 0.9902866 valid_acc: 0.9806416\n",
      "epoch: 932 train_loss: 1.0327879 valid_loss: 2.2435265 train_acc: 0.99073124 valid_acc: 0.98077846\n",
      "epoch: 933 train_loss: 1.0312402 valid_loss: 2.2350256 train_acc: 0.9903892 valid_acc: 0.98071\n",
      "epoch: 934 train_loss: 1.0273684 valid_loss: 2.2358644 train_acc: 0.9908681 valid_acc: 0.98091525\n",
      "epoch: 935 train_loss: 1.0263708 valid_loss: 2.2305057 train_acc: 0.99045765 valid_acc: 0.9806416\n",
      "epoch: 936 train_loss: 1.022426 valid_loss: 2.232009 train_acc: 0.9909706 valid_acc: 0.98105204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 937 train_loss: 1.02078 valid_loss: 2.2259796 train_acc: 0.9905261 valid_acc: 0.98077846\n",
      "epoch: 938 train_loss: 1.0164425 valid_loss: 2.221687 train_acc: 0.9910049 valid_acc: 0.9809837\n",
      "epoch: 939 train_loss: 1.0155687 valid_loss: 2.2234282 train_acc: 0.99056023 valid_acc: 0.98077846\n",
      "epoch: 940 train_loss: 1.0110762 valid_loss: 2.2205572 train_acc: 0.99103904 valid_acc: 0.98112047\n",
      "epoch: 941 train_loss: 1.009706 valid_loss: 2.211447 train_acc: 0.99103904 valid_acc: 0.9809837\n",
      "epoch: 942 train_loss: 1.0072793 valid_loss: 2.2154372 train_acc: 0.99103904 valid_acc: 0.98112047\n",
      "epoch: 943 train_loss: 1.0037675 valid_loss: 2.206972 train_acc: 0.9908339 valid_acc: 0.9809837\n",
      "epoch: 944 train_loss: 1.0028431 valid_loss: 2.2117693 train_acc: 0.9908339 valid_acc: 0.9808468\n",
      "epoch: 945 train_loss: 0.99989015 valid_loss: 2.2035904 train_acc: 0.9908339 valid_acc: 0.98105204\n",
      "epoch: 946 train_loss: 0.99696124 valid_loss: 2.1989892 train_acc: 0.99090225 valid_acc: 0.98105204\n",
      "epoch: 947 train_loss: 0.9967072 valid_loss: 2.2053823 train_acc: 0.9909364 valid_acc: 0.98105204\n",
      "epoch: 948 train_loss: 0.9922266 valid_loss: 2.1959827 train_acc: 0.99107325 valid_acc: 0.98112047\n",
      "epoch: 949 train_loss: 0.99126774 valid_loss: 2.1984415 train_acc: 0.9906628 valid_acc: 0.9809837\n",
      "epoch: 950 train_loss: 0.9889151 valid_loss: 2.196952 train_acc: 0.99073124 valid_acc: 0.9811889\n",
      "epoch: 951 train_loss: 0.9870608 valid_loss: 2.182295 train_acc: 0.990697 valid_acc: 0.9809837\n",
      "epoch: 952 train_loss: 0.987054 valid_loss: 2.1837447 train_acc: 0.9908338 valid_acc: 0.9811889\n",
      "epoch: 953 train_loss: 0.9806261 valid_loss: 2.1784842 train_acc: 0.99076545 valid_acc: 0.9811889\n",
      "epoch: 954 train_loss: 0.98128694 valid_loss: 2.1748214 train_acc: 0.9906286 valid_acc: 0.9814625\n",
      "epoch: 955 train_loss: 0.9763242 valid_loss: 2.172475 train_acc: 0.9911759 valid_acc: 0.98125726\n",
      "epoch: 956 train_loss: 0.9731781 valid_loss: 2.1719062 train_acc: 0.9912101 valid_acc: 0.98125726\n",
      "epoch: 957 train_loss: 0.97330344 valid_loss: 2.1831806 train_acc: 0.99090225 valid_acc: 0.9811889\n",
      "epoch: 958 train_loss: 0.96831334 valid_loss: 2.1755352 train_acc: 0.9911417 valid_acc: 0.98112047\n",
      "epoch: 959 train_loss: 0.96698165 valid_loss: 2.1585524 train_acc: 0.9912101 valid_acc: 0.9813257\n",
      "epoch: 960 train_loss: 0.9675959 valid_loss: 2.1659613 train_acc: 0.99056023 valid_acc: 0.9815309\n",
      "epoch: 961 train_loss: 0.9621948 valid_loss: 2.1738765 train_acc: 0.99134684 valid_acc: 0.98125726\n",
      "epoch: 962 train_loss: 0.9609176 valid_loss: 2.1461952 train_acc: 0.9909707 valid_acc: 0.98139405\n",
      "epoch: 963 train_loss: 0.9585644 valid_loss: 2.1643887 train_acc: 0.9905944 valid_acc: 0.98125726\n",
      "epoch: 964 train_loss: 0.95426255 valid_loss: 2.1700788 train_acc: 0.99107325 valid_acc: 0.98105204\n",
      "epoch: 965 train_loss: 0.95419955 valid_loss: 2.153863 train_acc: 0.9911417 valid_acc: 0.9814625\n",
      "epoch: 966 train_loss: 0.9504743 valid_loss: 2.145296 train_acc: 0.99079967 valid_acc: 0.9813257\n",
      "epoch: 967 train_loss: 0.9472465 valid_loss: 2.14338 train_acc: 0.9909023 valid_acc: 0.98125726\n",
      "epoch: 968 train_loss: 0.946198 valid_loss: 2.135088 train_acc: 0.99138105 valid_acc: 0.9815993\n",
      "epoch: 969 train_loss: 0.94210255 valid_loss: 2.1297193 train_acc: 0.99076545 valid_acc: 0.9813257\n",
      "epoch: 970 train_loss: 0.9426743 valid_loss: 2.1258838 train_acc: 0.9912101 valid_acc: 0.9814625\n",
      "epoch: 971 train_loss: 0.9401474 valid_loss: 2.1284826 train_acc: 0.99093646 valid_acc: 0.9815993\n",
      "epoch: 972 train_loss: 0.9385251 valid_loss: 2.1416416 train_acc: 0.9912443 valid_acc: 0.98139405\n",
      "epoch: 973 train_loss: 0.9351988 valid_loss: 2.1268573 train_acc: 0.9909706 valid_acc: 0.98139405\n",
      "epoch: 974 train_loss: 0.9321558 valid_loss: 2.1163983 train_acc: 0.9911417 valid_acc: 0.9814625\n",
      "epoch: 975 train_loss: 0.9302043 valid_loss: 2.1186616 train_acc: 0.9914495 valid_acc: 0.9819413\n",
      "epoch: 976 train_loss: 0.9275227 valid_loss: 2.1104655 train_acc: 0.99141526 valid_acc: 0.9814625\n",
      "epoch: 977 train_loss: 0.92499495 valid_loss: 2.1089392 train_acc: 0.9911417 valid_acc: 0.9814625\n",
      "epoch: 978 train_loss: 0.9227494 valid_loss: 2.1037633 train_acc: 0.9918257 valid_acc: 0.98125726\n",
      "epoch: 979 train_loss: 0.9197535 valid_loss: 2.096085 train_acc: 0.99162054 valid_acc: 0.9815309\n",
      "epoch: 980 train_loss: 0.9171032 valid_loss: 2.105592 train_acc: 0.9914495 valid_acc: 0.9817361\n",
      "epoch: 981 train_loss: 0.9134698 valid_loss: 2.0970802 train_acc: 0.9915179 valid_acc: 0.9816677\n",
      "epoch: 982 train_loss: 0.91240156 valid_loss: 2.0942078 train_acc: 0.9917915 valid_acc: 0.9815993\n",
      "epoch: 983 train_loss: 0.9099716 valid_loss: 2.0954797 train_acc: 0.9918599 valid_acc: 0.9816677\n",
      "epoch: 984 train_loss: 0.90548897 valid_loss: 2.083281 train_acc: 0.9916889 valid_acc: 0.9815309\n",
      "epoch: 985 train_loss: 0.9051528 valid_loss: 2.0872395 train_acc: 0.99196255 valid_acc: 0.9817361\n",
      "epoch: 986 train_loss: 0.9027091 valid_loss: 2.08277 train_acc: 0.9915179 valid_acc: 0.9818729\n",
      "epoch: 987 train_loss: 0.9018123 valid_loss: 2.0785782 train_acc: 0.9918257 valid_acc: 0.9816677\n",
      "epoch: 988 train_loss: 0.89895844 valid_loss: 2.0840805 train_acc: 0.9915863 valid_acc: 0.98139405\n",
      "epoch: 989 train_loss: 0.8977871 valid_loss: 2.0702934 train_acc: 0.9915863 valid_acc: 0.9818729\n",
      "epoch: 990 train_loss: 0.89463353 valid_loss: 2.0640483 train_acc: 0.99172306 valid_acc: 0.98207814\n",
      "epoch: 991 train_loss: 0.89143187 valid_loss: 2.0778744 train_acc: 0.9917231 valid_acc: 0.9817361\n",
      "epoch: 992 train_loss: 0.8908395 valid_loss: 2.0724902 train_acc: 0.9917573 valid_acc: 0.9819413\n",
      "epoch: 993 train_loss: 0.8877268 valid_loss: 2.0618966 train_acc: 0.9918257 valid_acc: 0.9817361\n",
      "epoch: 994 train_loss: 0.88694817 valid_loss: 2.0537555 train_acc: 0.9915863 valid_acc: 0.9818045\n",
      "epoch: 995 train_loss: 0.8827238 valid_loss: 2.0605426 train_acc: 0.9914837 valid_acc: 0.98207814\n",
      "epoch: 996 train_loss: 0.88327795 valid_loss: 2.0537727 train_acc: 0.9917915 valid_acc: 0.9819413\n",
      "epoch: 997 train_loss: 0.8788478 valid_loss: 2.0481813 train_acc: 0.9918257 valid_acc: 0.9821465\n",
      "epoch: 998 train_loss: 0.8798454 valid_loss: 2.0555294 train_acc: 0.99158627 valid_acc: 0.9816677\n",
      "epoch: 999 train_loss: 0.88012207 valid_loss: 2.0459404 train_acc: 0.99138105 valid_acc: 0.98207814\n",
      "epoch: 1000 train_loss: 0.87392795 valid_loss: 2.0437934 train_acc: 0.9918599 valid_acc: 0.9819413\n"
     ]
    }
   ],
   "source": [
    "# We should save the after training and validation\n",
    "saver = tf.train.Saver() \n",
    "train_loss_mean, valid_loss_mean = [], []\n",
    "train_acc_mean, valid_acc_mean = [], []\n",
    "\n",
    "# now that we can calculate loss and optimize, we can start a session for calculating the error.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "    \n",
    "    # for every epoch start feeding the arrays into the tensors in the model\n",
    "    for epoch in range(0, 1000, 1):\n",
    "        train_loss, valid_loss = [], []\n",
    "        train_acc, valid_acc = [], []\n",
    "        \n",
    "        # Training minibatches and feed them into the tensor\n",
    "        for Xarr, Yarr in get_batches(X=Xtrain, Y=Ytrain, batch_size=Xvalid.shape[0]):\n",
    "            # X_NxWxCin, Y_NxCout\n",
    "            feed_dict = {X:Xarr, Y:Yarr}\n",
    "            lossarr, _, accarr = sess.run(feed_dict=feed_dict, fetches=[loss, opt, acc])\n",
    "            train_loss.append(lossarr)\n",
    "            train_acc.append(accarr)\n",
    "            \n",
    "        # Validation now which is one batch on every iteration\n",
    "        for Xarr, Yarr in get_batches(X=Xvalid, Y=Yvalid, batch_size=Xvalid.shape[0]): \n",
    "            # X_NxWxCin, Y_NxCout\n",
    "            feed_dict = {X:Xarr, Y:Yarr}\n",
    "            lossarr, accarr = sess.run(feed_dict=feed_dict, fetches=[loss, acc])\n",
    "            valid_loss.append(lossarr)\n",
    "            valid_acc.append(accarr)\n",
    "        \n",
    "        # printing out train and validation loss\n",
    "        print('epoch:', epoch+1, 'train_loss:', np.mean(train_loss), 'valid_loss:', np.mean(valid_loss),\n",
    "             'train_acc:', np.mean(train_acc), 'valid_acc:', np.mean(valid_acc))\n",
    "        \n",
    "        # Every epoch, for drawing the plot and their learning curve\n",
    "        train_loss_mean.append(np.mean(train_loss))\n",
    "        valid_loss_mean.append(np.mean(valid_loss))\n",
    "        train_acc_mean.append(np.mean(train_acc))\n",
    "        valid_acc_mean.append(np.mean(valid_acc))\n",
    "        \n",
    "    # After all epochs and at the end of training and validation\n",
    "    saver.save(sess,'checkpoints/cnn-fnirs-har-10subjects.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3eec01d7b8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XuUFOWd//H3t7vnCshlRERQZ3Q1XoKCEsGgromJ4oVgElA8yS/AajiJmKhHs+qPZL0snpM1/tQ1MXhZReMhopKg6GFDFMm6MQoygshFAyjCBC8jN4G59vT390fXjDNDd08PDPRQ/XmdM+mup56qfp4pMx+ep6qrzN0REZH8E8l1A0REJDcUACIieUoBICKSpxQAIiJ5SgEgIpKnFAAiInlKASAikqcUACIieUoBICKSp2K5bkAmhx56qJeXl+e6GSIiB5XKysrP3L1/R/W6dQCUl5ezdOnSXDdDROSgYmYfZlNPU0AiInlKASAikqcUACIieapbnwMQka7T2NhIVVUVdXV1uW6KdJHi4mIGDx5MQUHBXm2vABDJE1VVVfTq1Yvy8nLMLNfNkX3k7mzZsoWqqioqKir2ah+aAhLJE3V1dZSVlemPf0iYGWVlZfs0olMAiOQR/fEPl309nqEMgI921HLPn9/j/epduW6KiEi3FcoA+PTzeu5/ZR0btuzOdVNERLqtUAZAJBgWJRI5boiItLF9+3Z++9vfdnq7iy66iO3bt3d6u0mTJjFnzpxOb5cvQhkAzdNiCffcNkRE2kgXAE1NTRm3mz9/Pn369NlfzcpbobwMtGUEoL//Iind/sIqVm/+vEv3edIRh3DrmJMz1rn55ptZv349Q4cOpaCggJ49ezJw4ECWL1/O6tWrufTSS9m0aRN1dXVce+21TJkyBfjivmC7du3iwgsv5KyzzuJvf/sbgwYN4vnnn6ekpKTD9i1cuJAbb7yReDzOV77yFWbMmEFRURE333wz8+bNIxaLcf7553P33Xfz7LPPcvvttxONRunduzevvvpqyn0+/vjjPPfcczQ1NbFy5UpuuOEGGhoaePLJJykqKmL+/Pn069eP9evXM3XqVKqrqyktLeWRRx7hhBNO4IUXXmD69Ok0NDRQVlbGrFmzGDBgALfddhsbN27k/fffZ+PGjVx33XX89Kc/7fxB6UAoRwCRoFeuEYBIt/LLX/6SY489luXLl/OrX/2KJUuWcOedd7J69WoAHnvsMSorK1m6dCn3338/W7Zs2WMfa9euZerUqaxatYo+ffrwhz/8ocPPraurY9KkSTz99NO88847xONxZsyYwdatW5k7dy6rVq1ixYoV/PznPwfgjjvuYMGCBbz99tvMmzcv475XrlzJ73//e5YsWcK0adMoLS1l2bJlnHnmmfzud78DYMqUKfz617+msrKSu+++m6uvvhqAs846izfeeINly5YxYcIE7rrrrpb9vvvuuyxYsIAlS5Zw++2309jYmN0vuRM0AhDJQx39S/1AOeOMM9p8ien+++9n7ty5AGzatIm1a9dSVlbWZpuKigqGDh0KwOmnn86GDRs6/Jz33nuPiooKjj/+eAAmTpzIAw88wDXXXENxcTFXXXUVF198MZdccgkAo0aNYtKkSVx22WV85zvfybjvr33ta/Tq1YtevXrRu3dvxowZA8CQIUNYsWIFu3bt4m9/+xvjx49v2aa+vh5Ifjnv8ssv56OPPqKhoaHN7+Liiy+mqKiIoqIiDjvsMD755BMGDx7cYV87I5wjAJ0DEDko9OjRo+X9X/7yF15++WVef/113n77bYYNG5byS05FRUUt76PRKPF4vMPPSTcbEIvFWLJkCd/97nd57rnnGD16NAAPPvgg06dPZ9OmTQwdOjTlSCRVeyKRSMtyJBIhHo+TSCTo06cPy5cvb/lZs2YNAD/5yU+45ppreOedd3jooYfa9Hdv+tlZoQwAaxkBKABEupNevXqxc+fOlOt27NhB3759KS0t5d133+WNN97oss894YQT2LBhA+vWrQPgySef5J//+Z/ZtWsXO3bs4KKLLuK+++5j+fLlAKxfv54RI0Zwxx13cOihh7Jp06a9/uxDDjmEiooKnn32WSAZRm+//TaQ7POgQYMAeOKJJ/ali3sl5FNACgCR7qSsrIxRo0bx5S9/mZKSEgYMGNCybvTo0Tz44IOccsopfOlLX2LkyJFd9rnFxcXMnDmT8ePHt5wE/tGPfsTWrVsZO3YsdXV1uDv33nsvAD/72c9Yu3Yt7s55553Hqaeeuk+fP2vWLH784x8zffp0GhsbmTBhAqeeeiq33XYb48ePZ9CgQYwcOZIPPvigK7qbNevOJ0qHDx/ue/NEsI1bajjnV4v4f+NP5bund+2cmcjBas2aNZx44om5boZ0sVTH1cwq3X14R9uGdAoo+aoRgIhIeuGcAgrOAuvvv0h+mDp1Kq+99lqbsmuvvZbJkyd3yf4XLFjATTfd1KasoqKi5Yqlg1U4A0AjAJG88sADD+zX/V9wwQVccMEF+/UzciGUU0D6HoCISMdCGQA6ByAi0rFQBkDzCKA7X+EkIpJroQ4ATQGJiKQX0gBIvjYpAUQOaj179gRg8+bNjBs3LmWdc889l0zfFyovL+ezzz7bL+072GUVAGZ2vZmtMrOVZvaUmRWbWYWZLTaztWb2tJkVBnWLguV1wfryVvu5JSh/z8z22yn15stAdQ5AJByOOOIIPdhlP+jwMlAzGwT8FDjJ3WvN7BlgAnARcK+7zzazB4ErgRnB6zZ3/yczmwD8B3C5mZ0UbHcycATwspkd7+6ZnwSxF744B9DVexYJif++GT5+p2v3efgQuPCXGavcdNNNHH300S23Q77tttswM1599VW2bdtGY2Mj06dPZ+zYsW2227BhA5dccgkrV66ktraWyZMns3r1ak488URqa2uzbuI999zDY489BsBVV13Fddddx+7du7nsssuoqqqiqamJX/ziF1x++eUpnxOQyqRJkygpKeHdd9/lww8/ZObMmTzxxBO8/vrrjBgxgscffxyAP//5z9x6663U19dz7LHHMnPmTHr27Mkdd9zBCy+8QG1tLV/96ld56KGHMDPOPfdcRowYwaJFi9i+fTuPPvooZ599dtZ9zUa2U0AxoMTMYkAp8BHwdaA5kp8ALg3ejw2WCdafZ8m7s40FZrt7vbt/AKwDztj3LuxJ3wMQ6Z4mTJjA008/3bL8zDPPMHnyZObOnctbb73FokWLuOGGGzJewDFjxgxKS0tZsWIF06ZNo7KyMqvPrqysZObMmSxevJg33niDRx55hGXLlvGnP/2JI444grfffpuVK1cyevTotM8JSGfbtm288sor3HvvvYwZM4brr7+eVatW8c4777B8+XI+++wzpk+fzssvv8xbb73F8OHDueeeewC45pprePPNN1vC7cUXX2zZbzweZ8mSJdx3333cfvvtWfWzMzocAbj7P8zsbmAjUAv8GagEtrt78/1Jq4BBwftBwKZg27iZ7QDKgvLWt/drvU2X0klgkQ508C/1/WXYsGF8+umnbN68merqavr27cvAgQO5/vrrefXVV4lEIvzjH//gk08+4fDDD0+5j1dffbXl6VinnHIKp5xySlaf/de//pVvf/vbLbeg/s53vsP//u//Mnr0aG688UZuuukmLrnkEs4++2zi8XjK5wSkM2bMGMyMIUOGMGDAAIYMGQLAySefzIYNG6iqqmL16tWMGjUKgIaGBs4880wAFi1axF133UVNTQ1bt27l5JNPbnmmQPOzCLJ97kFnZTMF1Jfkv94rgO3As8CFKao2/7m1NOvSlbf/vCnAFICjjjqqo+alpO8BiHRf48aNY86cOXz88cdMmDCBWbNmUV1dTWVlJQUFBZSXl6d8DkBrzbd874x0o4rjjz+eyspK5s+fzy233ML555/Pv/3bv7FkyRIWLlzI7Nmz+c1vfsMrr7ySdt+tnwHQ/vkA8XicaDTKN7/5TZ566qk229XV1XH11VezdOlSjjzySG677baUzwTI5fMAvgF84O7V7t4I/BH4KtAnmBICGAxsDt5XAUcCBOt7A1tbl6fYpoW7P+zuw919eP/+/feiS/oegEh3NmHCBGbPns2cOXMYN24cO3bs4LDDDqOgoIBFixbx4YcfZtz+nHPOYdasWUDycYwrVqzI6nPPOeccnnvuOWpqati9ezdz587l7LPPZvPmzZSWlvL973+fG2+8kbfeeivtcwL21siRI3nttddankdQU1PD3//+95Y/9oceeii7du064Ce6s7kX0EZgpJmVkpwCOg9YCiwCxgGzgYnA80H9ecHy68H6V9zdzWwe8Hszu4fkSeDjgCVd2JcWmgIS6b5OPvlkdu7cyaBBgxg4cCDf+973GDNmDMOHD2fo0KGccMIJGbf/8Y9/zOTJkznllFMYOnQoZ5yR3anE0047jUmTJrXUv+qqqxg2bBgLFizgZz/7GZFIhIKCAmbMmMHOnTtTPidgb/Xv35/HH3+cK664ouVxkNOnT+f444/nhz/8IUOGDKG8vJyvfOUr+/Q5nZXV8wDM7HbgciAOLAOuIjl/PxvoF5R9393rzawYeBIYRvJf/hPc/f1gP9OAfwn2c527/3emz93b5wG4OxW3zOe6bxzHdd84vtPbi4SRngcQTvvyPICs7gbq7rcCt7Yrfp8UV/G4ex0wvn15sO5O4M5sPnNftDwSUkMAEZG0Qnk7aIBoxDQFJJJHRowY0TK90uzJJ59suSJnX915550tz/VtNn78eKZNm9Yl+8+F0AZAxHQVkEh77r5XV9AcDBYvXrxf9z9t2rRu98d+Xy90CeW9gKjZyujIYkrqdf8PkWbFxcVs2bJFV8eFhLuzZcsWiouL93of4RwBbP2AX0fv45ndRwJn5bo1It3C4MGDqaqqorq6OtdNkS5SXFzM4MGD93r7cAZAJBjYdP1thkQOWgUFBVRUVOS6GdKNhHMKyJLdcp0FFhFJK9QBoBGAiEh6IQ2AaPLFEzluiIhI9xXSAGieAlIAiIikE+oA0BSQiEh6IQ8AnQQWEUknnAGgy0BFRDoUzgBoGQHoHICISDoKABGRPBXSAEheBqoAEBFJL6QBkOyWvgcgIpJeqANAIwARkfTCGQCR5ikgXQUkIpJOOANA3wMQEelQSAMg+cQj0whARCStkAaArgISEelISANAU0AiIh0JdQBoCkhEJL1wBkBEU0AiIh0JZwA0jwBQAIiIpBPqANAIQEQkvVAHgOmJYCIiaYU0AIwEBpoCEhFJK5wBADimm8GJiGQQ2gBIENU5ABGRDEIbAI7pKiARkQxCGwAJ0xSQiEgmoQ0AJ6IAEBHJILQBkCAC6F5AIiLphDYA3DQCEBHJJKsAMLM+ZjbHzN41szVmdqaZ9TOzl8xsbfDaN6hrZna/ma0zsxVmdlqr/UwM6q81s4n7q1Ogy0BFRDqS7QjgP4E/ufsJwKnAGuBmYKG7HwcsDJYBLgSOC36mADMAzKwfcCswAjgDuLU5NPYHnQMQEcmswwAws0OAc4BHAdy9wd23A2OBJ4JqTwCXBu/HAr/zpDeAPmY2ELgAeMndt7r7NuAlYHSX9qYVt4guAxURySCbEcAxQDUw08yWmdl/mVkPYIC7fwQQvB4W1B8EbGq1fVVQlq58v9AUkIhIZtkEQAw4DZjh7sOA3Xwx3ZOKpSjzDOVtNzabYmZLzWxpdXV1Fs1LLWFRjQBERDLIJgCqgCp3XxwszyEZCJ8EUzsEr5+2qn9kq+0HA5szlLfh7g+7+3B3H96/f//O9KXtfjA9ElJEJIMOA8DdPwY2mdmXgqLzgNXAPKD5Sp6JwPPB+3nAD4KrgUYCO4IpogXA+WbWNzj5e35Qtl+4RYhoBCAiklYsy3o/AWaZWSHwPjCZZHg8Y2ZXAhuB8UHd+cBFwDqgJqiLu281s38H3gzq3eHuW7ukFynoKiARkcyyCgB3Xw4MT7HqvBR1HZiaZj+PAY91poF7S1cBiYhkFt5vAusqIBGRjMIbALoKSEQkoxAHgGG6CkhEJK3wBgC6CkhEJJPwBoDuBioiklFoAwBdBSQiklFoA0BTQCIimYU3ACyik8AiIhmENgA0BSQiklloA0AngUVEMgttAKCbwYmIZBTaAHAi2J6PGxARkUBoA6B5BOA6ESwiklLIA8BJ6O+/iEhKoQ2A5ttBJzQCEBFJKbQB0DwCaNIQQEQkpVAHQFQjABGRtEIcAFGNAEREMghtACTPAegksIhIOqENAMySU0BKABGRlMIbAJEoERI06RyAiEhK4Q2A5ikgjQBERFIKdQAkrwLKdUNERLqnEAdAcBWQpoBERFIKcQBEMNMUkIhIOqENAIvoi2AiIpmENgCwKFES+iKYiEga4Q2ASIQoTRoBiIikEdoA8EghBTTRpIeCiYikFNoAIBIjphGAiEhaoQ0AjxYQI65zACIiaYQ2AIgUUGhNJBKaAxIRSSW0AWDRGADxpniOWyIi0j2FNgAi0UIA4g0NOW6JiEj3FNoAsFgBAE1xBYCISCpZB4CZRc1smZm9GCxXmNliM1trZk+bWWFQXhQsrwvWl7faxy1B+XtmdkFXd6a1SCwYATQqAEREUunMCOBaYE2r5f8A7nX344BtwJVB+ZXANnf/J+DeoB5mdhIwATgZGA381syi+9b89CLBCCCuEYCISEpZBYCZDQYuBv4rWDbg68CcoMoTwKXB+7HBMsH684L6Y4HZ7l7v7h8A64AzuqITqUSjwRSQRgAiIillOwK4D/hXoPmayjJgu7s3X2JTBQwK3g8CNgEE63cE9VvKU2zT5ZqngHQOQEQktQ4DwMwuAT5198rWxSmqegfrMm3T+vOmmNlSM1taXV3dUfPSihYkAyDR2LjX+xARCbNsRgCjgG+Z2QZgNsmpn/uAPmYWC+oMBjYH76uAIwGC9b2Bra3LU2zTwt0fdvfh7j68f//+ne5Qs6jOAYiIZNRhALj7Le4+2N3LSZ7EfcXdvwcsAsYF1SYCzwfv5wXLBOtfcXcPyicEVwlVAMcBS7qsJ+1EgymgRFwjABGRVGIdV0nrJmC2mU0HlgGPBuWPAk+a2TqS//KfAODuq8zsGWA1EAemunvTPnx+Ri1TQE0aAYiIpNKpAHD3vwB/Cd6/T4qreNy9DhifZvs7gTs728i90TwFpBGAiEhqof0mcCyYAnIFgIhISqENgObLQDUFJCKSWmgDgOCLYK67gYqIpBTeAIgkT294vD7HDRER6Z7CGwAtIwCdAxARSSW8ARBRAIiIZBLeAAhGAOgcgIhISqEPAE9oBCAikkp4AyDSPAJQAIiIpBLeAIgqAEREMglvAASXgZLQOQARkVTCGwDBCMB0DkBEJKXwBkBEASAikkmIAyD5vHnTFJCISErhDQAzGq2AiEYAIiIphTcAgEYrJJrQ3UBFRFIJdQA0WSFR183gRERSCXUAxCOFxDQFJCKSUqgDoClSQMw1BSQikkq4A8CKKFAAiIikFO4AiBYSc00BiYikEuoASEQKKdQIQEQkpdAHQAFxEgnPdVNERLqdcAdAtIgiGmhMJHLdFBGRbifUAeDRQgqJ09ikEYCISHuhDoDkCKCRxrhGACIi7YU6ADxWTKE10tikABARaS/UAUC0kCIaqdcIQERkD6EOAIsVU0QjdY1NuW6KiEi3E+oAiBYWUUgjNQ0KABGR9kIdAJGCEgqtidoGfRtYRKS9UAdArKAIgPra2hy3RESk+wl1AESLSgCor6/JcUtERLqfUAdAQWEQAHUaAYiItBfqAIgVFQMQr9ud45aIiHQ/HQaAmR1pZovMbI2ZrTKza4Pyfmb2kpmtDV77BuVmZveb2TozW2Fmp7Xa18Sg/lozm7j/upVUUHIIAPF6BYCISHvZjADiwA3ufiIwEphqZicBNwML3f04YGGwDHAhcFzwMwWYAcnAAG4FRgBnALc2h8b+UljSE4AmBYCIyB46DAB3/8jd3wre7wTWAIOAscATQbUngEuD92OB33nSG0AfMxsIXAC85O5b3X0b8BIwukt70060KBkAifpd+/NjREQOSp06B2Bm5cAwYDEwwN0/gmRIAIcF1QYBm1ptVhWUpSvffwpLAfAGjQBERNrLOgDMrCfwB+A6d/88U9UUZZ6hvP3nTDGzpWa2tLq6OtvmpVbQI/mqKSARkT1kFQBmVkDyj/8sd/9jUPxJMLVD8PppUF4FHNlq88HA5gzlbbj7w+4+3N2H9+/fvzN92VNhEACN+h6AiEh72VwFZMCjwBp3v6fVqnlA85U8E4HnW5X/ILgaaCSwI5giWgCcb2Z9g5O/5wdl+08wBRRt1AhARKS9WBZ1RgH/B3jHzJYHZf8X+CXwjJldCWwExgfr5gMXAeuAGmAygLtvNbN/B94M6t3h7lu7pBfpBFNAkbi+CCYi0l6HAeDufyX1/D3AeSnqOzA1zb4eAx7rTAP3SayQODEicU0BiYi0F+pvAgPUR0ooaNIIQESkvdAHQEOkmJgCQERkD6EPgMZoKYUJTQGJiLQX+gCIR0soStTluhkiIt1O6AOgKVpCkdeSPDctIiLNwh8ABaWUUE9DUyLXTRER6VZCHwAeK6UHddTqwfAiIm2EPwAKe1Bi9dQ2KgBERFoLfQBQkBwB1GgEICLSRvgDoKgnJdRrCkhEpJ3QB0CksAeF1kSdHgwvItJG+AMgeCpYfa2eCiYi0lroAyBWnLwjaEONAkBEpLXQB0BB8GD4hppMDzETEck/oQ+Akh69Aait2ZnjloiIdC95EACHABoBiIi0F/oAiBYnp4B81z4+YF5EJGRCHwCU9AXgxE1P5bghIiLdS/gDoOxYAOKNDTQldEdQEZFm4Q8AYP0RYzjMtrOtpiHXTRER6TbyIgASPQZwGNvYuqs+100REek28iIACnv2o9Ca2LZDVwKJiDTLjwDo1Q+Ands/y3FLRES6j7wIgNJDkgFQ+7kCQESkWV4EQI/ehwJQ9/mWHLdERKT7yIsAiJUdA4BvWZfjloiIdB95EQD0OZp6KyZSvSbXLRER6TbyIwAiEbb3PJYBdR+wXd8FEBEB8iUAADvsRE6IbGLZxu25boqISLeQNwHQp/xU+tsO1qx/P9dNERHpFvImAAqPGQVA0XvP57glIiLdQ94EAINO5+OeJ/HV7S+yaWtNrlsjIpJz+RMAQMlpl3FiZCMLXluS66aIiORcXgVA71O/BcDX3vwRq6v0pTARyW95FQCUHcuW4y7j2MhHvP/7G/i8VncHFZH8dcADwMxGm9l7ZrbOzG4+0J9f9r1H2DTwAi6pmcvau77O//xhBp9Vf3qgmyEiknPmfuCekmVmUeDvwDeBKuBN4Ap3X52q/vDhw33p0qVd35CmOB/++Tf0XnIvfXw7cY+w3o5iW8nRcMgR0HsQsT6DKS47ikPKDqdXnzJ69u5HQUFh17dFRKSLmVmluw/vqF7sQDSmlTOAde7+PoCZzQbGAikDYL+Jxjj6wuvggp+wftn/8PnK/6a0ejmDa9dR9vHrlHyS+tvCu72I3daDGiulIVpKU6SQeKSQpkgRiUghiWgxiWghHi3CY0UQLYZYEZFYARaJQSQG0RgWiWGpXqPJepFo8BNLlkUiMSIRA4tgEcMsilkEM7BIFDAikSgYyXVB3UgkgplhkUhQP9Lq/RflRCJEgvWRiAXrDCP5Hmj1GgwazQhKMGteNgjqEaz9YjlFWZt1InKgHegAGARsarVcBYw4wG34QiTKsad/HU7/ekuRJxLs2PYp2z7+kJrqD6nd8Qnxmh147edYw+dE6j8n1riTaLyWaKKegngNpb6dmDdQ4A0UegOFNFLoDRRbY866djBKeDIQmsekjrV7bfZFcLRf17LcLlw62lf79W3r0K72nvvtSDb1mj+vo5rZ7avr2rWHNJt0Zbuy0RV9tCzqtN3Xvn1e68/tqF5V/3M44+pHsmrX3jrQAZCqx21+p2Y2BZgCcNRRRx2INrVhkQi9yw6nd9nh7Gs2eSJBQ0Md9Y2NxBvjNMUbSDQl33uikaZ4nERTnKZ4Ix6P09TUiCcaScTjeFNyXaKpEU/ESSQcPAHuuDt4E+6OeyJZjuOJ5PrmepBI1k04TuKLcm/9PlmPln0l1zsE61q9tj5U3vw/3lLFcJzkK3tMLXqrbdIsp/qs9vvxxB6/Z+twW2+p176dyWXwVv93dMBafW6qd6kW0/vi95RV1Qya+5qpmqVvcdt6WU3/Ztdua1cvZXimKPQUNff5T7GnXUipfdvT7S6betn9TrPrY7zvMVnta18c6ACoAo5stTwY2Ny6grs/DDwMyXMAB65pXc8iEYqKSykqznVLRET2dKCvAnoTOM7MKsysEJgAzDvAbRAREQ7wCMDd42Z2DbAAiAKPufuqA9kGERFJOtBTQLj7fGD+gf5cERFpK7++CSwiIi0UACIieUoBICKSpxQAIiJ5SgEgIpKnDujN4DrLzKqBD/dhF4cCn3VRcw4G+dZfUJ/zhfrcOUe7e/+OKnXrANhXZrY0mzvihUW+9RfU53yhPu8fmgISEclTCgARkTwV9gB4ONcNOMDyrb+gPucL9Xk/CPU5ABERSS/sIwAREUkjlAGQ6wfP7y9mdqSZLTKzNWa2ysyuDcr7mdlLZrY2eO0blJuZ3R/8HlaY2Wm57cHeMbOomS0zsxeD5QozWxz09+ng1uKYWVGwvC5YX57Ldu8LM+tjZnPM7N3geJ+ZB8f5+uC/65Vm9pSZFYftWJvZY2b2qZmtbFXW6eNqZhOD+mvNbOLetid0ARA8eP4B4ELgJOAKMzspt63qMnHgBnc/ERgJTA36djOw0N2PAxYGy5D8HRwX/EwBZhz4JneJa4E1rZb/A7g36O824Mqg/Epgm7v/E3BvUO9g9Z/An9z9BOBUkv0P7XE2s0HAT4Hh7v5lkreLn0D4jvXjwOh2ZZ06rmbWD7iV5CMLzwBubQ6NTvPgEYNh+QHOBBa0Wr4FuCXX7dpPfX0e+CbwHjAwKBsIvBe8fwi4olX9lnoHyw/Jp8YtBL4OvEjyaXqfAbH2x5vkcybODN7HgnqW6z7sRZ8PAT5o3/aQH+fm54X3C47di8AFYTzWQDmwcm+PK3AF8FB0TuCmAAACW0lEQVSr8jb1OvMTuhEAqR88PyhHbdlvgiHvMGAxMMDdPwIIXg8LqoXhd3Ef8K9A88OAy4Dt7h4Pllv3qaW/wfodQf2DzTFANTAzmPr6LzPrQYiPs7v/A7gb2Ah8RPLYVRL+Yw2dP65ddrzDGAAdPnj+YGdmPYE/ANe5++eZqqYoO2h+F2Z2CfCpu1e2Lk5R1bNYdzCJAacBM9x9GLCbL6YFUjno+x1MYYwFKoAjgB4kp0DaC9uxziRdH7us72EMgA4fPH8wM7MCkn/8Z7n7H4PiT8xsYLB+IPBpUH6w/y5GAd8ysw3AbJLTQPcBfcys+Wl2rfvU0t9gfW9g64FscBepAqrcfXGwPIdkIIT1OAN8A/jA3avdvRH4I/BVwn+sofPHtcuOdxgDILQPnjczAx4F1rj7Pa1WzQOarwSYSPLcQHP5D4KrCUYCO5qHmgcDd7/F3Qe7eznJ4/iKu38PWASMC6q172/z72FcUP+g+1ehu38MbDKzLwVF5wGrCelxDmwERppZafDfeXOfQ32sA509rguA882sbzByOj8o67xcnxDZTydZLgL+DqwHpuW6PV3Yr7NIDvVWAMuDn4tIzn0uBNYGr/2C+kbyiqj1wDskr7DIeT/2su/nAi8G748BlgDrgGeBoqC8OFheF6w/Jtft3of+DgWWBsf6OaBv2I8zcDvwLrASeBIoCtuxBp4ieY6jkeS/5K/cm+MK/EvQ93XA5L1tj74JLCKSp8I4BSQiIllQAIiI5CkFgIhInlIAiIjkKQWAiEieUgCIiOQpBYCISJ5SAIiI5Kn/D1wASZToBbBvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "%matplotlib inline\n",
    "\n",
    "mplot.plot(train_loss_mean, label='train_loss_mean')\n",
    "mplot.plot(valid_loss_mean, label='valid_loss_mean')\n",
    "mplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3ecc080ba8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmUVPWd9/H3t25VdXXTDTQ7QkvjjghCQsAlKhMTt0cx5pAZHTMzkkRiXMfJZKJjJhqjzyQxk6jncYg4LtH4qITEJR4zIorhmbgBCsimoIDdsjUNvddev+ePW9002EAD3RRV9XmdU6fvvXXr1vfWhU//+lf3/q455xARkcISyHUBIiLS8xTuIiIFSOEuIlKAFO4iIgVI4S4iUoAU7iIiBUjhLiJSgBTuIiIFSOEuIlKAgrl640GDBrnq6upcvb2ISF5asmTJdufc4P2tl7Nwr66uZvHixbl6exGRvGRmG7uznrplREQKkMJdRKQAKdxFRArQfsPdzB4xs21mtmIvz5uZ3W9m68xsuZl9rufLFBGRA9GdlvtjwAX7eP5C4PjsYyYw69DLEhGRQ7HfcHfOLQR27GOVS4HHne8toL+ZDe+pAkVE5MD1RJ/7CKCm03xtdtlnmNlMM1tsZovr6up64K1FRKQrPXGeu3WxrMt79znnZgOzASZNmqT7+4lITjnnyDgIZFPMzGiMJtnZmiDjHI3RJIlUhlTGkXGORCpDxkHGuY7XtsZTDOkbIZZME09l8MzY0RonkXYk0/58IGAk0xmCAaMpmmTahKM4bkhFr+5bT4R7LVDVaX4ksKkHtisiRzjnHMlsiCXTGRLpDIlUpmNZIuUviybSeAEjk3FEk2nab93sgJZ4kkwG0s7RGk/RlkhjBqFAgJBntMRTOAeJtB+y8WSG5liSVMZhBqm0H7qtiRQAjdEkXsAwoC2RBiCaTJPJvmkilSGWzBBNpklnHOnMrnZmwCBzGJqdA8tL8iLcXwCuN7OngSlAo3Nucw9sV0T2oj0kzfywiibTRBNp2hLpjmkv21pMZxwNbX7gNcWStMRT1LckSGdboy2xFM3ZAI0mU7TE07TFU3gBI+hZR1j7P/2wTrYvS2cO636HPCPkBaiIBEmkMjTHUgwsD1MRCQEQT6WJBD36lAQpDXsMKi8BwAxKQx4BM7yA0ackSDBgOCDoGaFAgKZY0n9dyKOyLETICxAJeQQCRsBgQJ8wFSUhzPztBQBchh2t/mcZsThBHOVhI2IpKsoihC3l/xJKRvHCEVKJOJZJ0ndQ317/rPYb7mb2FDAVGGRmtcDtQAjAOfdr4CXgImAd0AbM6K1iRfJNKtvabIol2dYUZ2dbgmjC//O9PYRbEyn/ZzxNNJmiNe6HdFvCb8XGUxkyGcf2ljhp53DZroDUITYxw16AshKPikiQslAQh6NvJES/0hCDy0sAv9sh7AUIBwOEvADhoB+uYS9AKLusJBjoCF3/OaMk4AgHoIQYYQ+cM4IuRgkpIqEAoVQMXBLLpPFIUhoAz9JEPIdHGjJpUukMmBHMxAh6HmEykEmBS2d/OkgnIR3355MxSLQCDlJxf71A0F+eTkDAg3gzxOPQlti1TjIKLuPPm4FX4m+v/ZGMQrLN31Ym5b9nex0H6+JfwaRvHtLx25/9hrtz7or9PO+A63qsIpEjgHOOeCpDWyJNcyxJY7SLR1uSbc1x2hIpYslMR59rLJlmY30b0WT3//MHDMrCQcrCHmVhj9JwkD5hP3gHBT3A8blR/QkHjKBL0C+YotTihFyaihIo9TJEAhnKLIGXbCHiOUoCkMmkCQcyVITApaKUWoqSTCvBYAmBZAtEd0IwArEGP9wSrZCK+dPJqB+KLuMHacDz51NxP+Bcxg/WdApw2ZBM+8tzwiDcByzgB3EgCJmkv7yk3O8DKqnw98MMwuUQLIPyoX7NAQ/M2/VLwTz/Z7AEQmV+oHth8EL+uu3v4Zz/PsGI/3AZ/zUW8NfPpHbV1P76oyb0+qeRs4HDRA6XTMbRHE/RFE3SmkjRGk9R15ygriXO9uY421v8x47WBA1tfnDvbEuQTO+7ZRwOBhjcJ8zASIZ+XoLBXpx+gRgVZQlCZUn6B9OUeyn6enEGea30C8SpCKYJuQShTIxQooFgqg0vAAEclvFbrLu1TtvadrUca6KQivbshxPp52+/tNIPpnAf/2eoFCJ9/TAyz1/Xpf35YEl2ebaV64UA85e3B17A8wMtVJoNwIw/7ZX4rwuV+tsIBLMhGIJAaNdrA9n3TKf8QHaZXc/h/Brbw7N9O14YArrovp3CXfKOc44drQk2N8aoa47TlkjTEPWDuaHN/7m1OU5dc5ymaJK6ljiJVHtr0hEhQTkxyixGOVGGRVIML00xpiTFgJIElWVx+g2NU25xylwbpS5GqWujxMUIp1sJpdrwUq1YogXiLRA/gD/PvXC2hVcCpQP8FiXWqbXpQTC8q+UYKvVbmKHS7KOs08/IrmBrfwQjfmC3B6R5u1qZ7eEb6e8HdbAUPEVAodKRlSNGJuPY3hpnS2OMbU27WtTbW3a1src2Rmlp2kFJqoVyi1JBGxXZn4OtkQovyTGhNkZ59QwItFJGjLLyGKUuSigdJZRqxdij28Dhf1vUtkdBXokfvuFyv/UY7gNlA6FklL8sXL7r+d2m+/ih2xHIpdkgr9jVIhXpZQp3OSycc9S3JtjcEGNTY5TNDVE2N8b4tCHKpoYoWxqiJFu2M8DtZKjtZIg1MIQGhthOTgg2clSggSHWQGVmB6Fgct//cq0U+h7tB3F4iB+2JeUQrug03SmwO6bLd3/eCx22z0ekpyncpUe0xFPU7GijdmeUjfWt1OxooyGaZGtTjM2NMVoa6xmW3sKxtokqq2Oo7eTzgQamBZsYYjupzOwkGE5+ZruupC9WMRwqhkLFBP/Lr/KhftdDSUX2Z18/kPsM3hXK1tW1dSLFQ+EuB6ShLcH67a1saojx4dZmVm9uYvWWJrbtaOQ4+5RjbRNH2zZOCjVR5e1khG1naGYrZcHW3f61ZSL9sYrhfnCXT4SKYbse5cP8MC8fhoXLcrezInlM4S6fkc44ana0sW5bC2u3tbBuWwvrt7ewfnsrDW1xRth2TrQaTgzU8teRzYwJ1DKs9BM8l9q1kUh/6HsU9D8B+n8Z+lVB5SgYdAJUVhMIleZuB0WKgMK9iDnnqNkRZeWmRlZtbuLDrc1srG/j4+2tJFJpqmwbJ9snTIp8yl+HN1EdqmVg2WaCmfiujfSpgiFjYMg0OGoiDD4RKkf7Z3KISM4o3ItEOuNYu62ZZTUNLK1p5IMtTazb1kJTzL8AZVRgO1/p+wlfC2/g5P7rGBZbRyjV6r84Y1B2DAweCwMu9lvfg0+CISf5fd4icsRRuBeoxmiSJRt38Ma6et7/tJHVm5toiiUZxg6OjTRxbv+d/GvlKkZnNtIvWkMw0QQxIBWBYeNh+BUw9BQYNs5vmYf75HqXROQAKNwLRCbjeP/TRuat2sKrq7fxwdZmwi7BuGAtF/Sv4Yf9PuS4khWUxrPj6Dfgn3s9/FQYeLof4CO/AENO1imAIgVA4Z7H4qk0b328g1dWbWH+qm1saYpxbGALMwat4uyh7zOy6T0CmQS04H+hecJUqJoC/Y+GfiNh8Bhdri1SoBTueaahLcF/r9jC80s38V7NTizZxudCNfzboLV8seQd+jV/CE34feKTvw1HnwZHfQ76V+132yJSOBTueSCeSrNgTR2Pv7mBt9fv4Ci3hW/0Xcq/91vO0a3vE3ApaAjA0afDGVfByZf6LXMRKVoK9yNULJnmhWWbmLdyK298tJ3KxBaurFjCLyvfYVjrGogD/cfBqdf7rfORk6HPwFyXLSJHCIX7EcQ5x6INO3nqnU+Yv6KGien3uaR0Bf+7dAVDAhshCQz5PJzxE791Xjkq1yWLyBFK4X4EaImnmLOohqffXs+w+rf4eugN/j30LhGvFWelWNWZcOx34MQLYcAxuS5XRPKAwj2HtrfEefh/1vOHtz7gS8k/81TJcwwM1+Mi/bAxl8FJl2DHTNXVniJywBTuORBNpHnirQ28+OrrXJp+hdfDf6Y01AZDJ8BZ92LHn6dAF5FDonA/jJxzzF38CW+89Fv+Lv0HZgbW+Ufg5OkweSZUTdZQtSLSIxTuh8lHW3bw56f+g9N3vsDXA58Q63s0TP43mHAl9B2e6/JEpMAo3HtZNJ7klbkPMunDX/JNq6eh73FkvvwgkXHTdf9KEek1SpdetPSVJ+n3xr8zzdWwKXIMDRc/QP9xF+a6LBEpAgr3XlBXV8eHv7mOM1teZmOgirVfvI/j/+rvdHNkETlsFO49bOE7Sxj10pWc5rawpPpqxl95N6FwSa7LEpEio3DvIal0hufnL+D0N66mbyDGlst+z+dPPTfXZYlIkVK494BNDVEeffj/8I9N95D2SgnOeIkRVRNyXZaIFDGF+yFatH477z/+fW5zf2BH5Tj6XfUMXv8RuS5LRIqcwv0QPPPmWsr/dD3fDLxF45grGPC1e3VlqYgcERTuByGZznDPs29x7vKbmRJYQ/Sc2+k39WZdXSoiRwyF+wFKpjPc8fifmLH+n6n26shc9jCl46fnuiwRkd0o3A9AXXOcnz/6NP9S/2/0DWcIfuN5qD4z12WJiHyGwr2bPqlv48H/msUdbT/DygZQMuM5GHJSrssSEemSwr0b1mxp4tkH7+RO919EB55Mnxl/gIphuS5LRGSvArku4Ei3blszv33wHm51DxGr/jLl35mnYBeRI55a7vuwfnsrjzz4S+50DxA96jT6/N3TGslRRPKCWu57EU2keerh/+An6XtJDJ9E6d//TsEuInmjW+FuZheY2Qdmts7Mbuni+aPNbIGZvWdmy83sop4v9fCJJdPc/fBT/FPb/TQP+TxlM56DSN9clyUi0m37DXcz84AHgAuBk4ErzOzkPVb7ITDHOTcRuBz4z54u9HBJpDL8n4f/i3/d8k9kSgfQ/++fgnBZrssSETkg3Wm5TwbWOec+ds4lgKeBS/dYxwHtTdt+wKaeK/HwevqZ33L95tuIV1RRdu2foXxwrksSETlg3elEHgHUdJqvBabssc4dwDwzuwHoA3y5R6o7zJa8u4ivfvgDGkurGPrdl6HPoFyXJCJyULrTcu9qwBS3x/wVwGPOuZHARcATZvaZbZvZTDNbbGaL6+rqDrzaXtS4s57KP87ABTz6ffMPCnYRyWvdCfdaoKrT/Eg+2+3yLWAOgHPuTSACfCYdnXOznXOTnHOTBg8+gro7nGPLo9+gKrOJ+gtnExkyOtcViYgcku6E+yLgeDMbbWZh/C9MX9hjnU+AcwHMbAx+uB9ZTfN92PzKvZzY9AavVN3AMZPz+kQfERGgG+HunEsB1wMvA6vxz4pZaWZ3mtm07GrfA642s2XAU8BVzrk9u26OSK7uA4a8cSevM4kzr/jXXJcjItIjunVVjnPuJeClPZb9qNP0KiAvh0fc+sLtVLgQ9ef+gn59dCNrESkMRX2Fqtu0lGE1f+L3oWlMO/PUXJcjItJjivd6eufY+ez3wZXT99ybCXlF/XtORApM0SZaesMbDKh7hydKruDiyWNyXY6ISI8q2nDf+OpDtLoSjjv/GoJqtYtIgSnKVItuXsPRtc/z/8rO5aLPHZvrckREelxRhvvW539E3IUYcsmPMevqAlwRkfxWdOHutrxP9ZaX+WPZZUwcc3yuyxER6RVFF+5bFjxIzIUoO/tGtdpFpGAVV7jHmui79lkW2Bc4b9JJua5GRKTXFFW4b1/4EH0yLWwf9x0iIS/X5YiI9JriCfdMhviS/8sH7mguOv/CXFcjItKriibcG1f8NyPi69g4choDyzWGjIgUtqIZfqBhxTxKXIiBX7oh16WIiPS6omm5e1uWssqNYkyV7rAkIoWvOMI9nWJQ8xo+KTmRsnDR/LEiIkWsKMI9+u5TRFyUlqqpuS5FROSwKIpmbNPbT/Jp5ihOPmd6rksRETksCr/lvn0dQ7e/yYrwKUw8ujLX1YiIHBYFH+71Cx8k6Ty2n3qthhsQkaJR8N0y0Zpl1LpRTJt6eq5LERE5bAq+5d6n+WM2BasYUhHJdSkiIodNYYd7vJnKVB1N5aNzXYmIyGFV0OHu6j4EIDlA47aLSHEp6HBv+XQlACXDdANsESkuhR3utatIOo/BR2vsdhEpLoUb7tEGhq54iA1uGKOH9s91NSIih1XBhnt88W8JuBSrgycxsrIs1+WIiBxWBRvuLdvWA5D6X7/CC+jiJREpLgUb7umGGj7KDGfUoL65LkVE5LAr2HD3mjexyQ1kaF/ddUlEik/BhntJ22Y2u4EMrlC4i0jxKcxwTyUoS9TTEBpCSdDLdTUiIoddYYZ782YCOFojw3JdiYhIThRmuDd9CkCq/KgcFyIikhuFGe71HwHg+h+d40JERHKjIMdzT29eTtRF8AYdm+tSRERyoiDDvWXbRja5wZw4vF+uSxERyYmC7JZJNW2l3vVlzHBdwCQixalb4W5mF5jZB2a2zsxu2cs6f21mq8xspZn9354t88B4sXrq6cewvrr7kogUp/12y5iZBzwAfAWoBRaZ2QvOuVWd1jkeuBU40zm308yG9FbB+7XkN/SP1tAUGEefkoLsdRIR2a/utNwnA+uccx875xLA08Cle6xzNfCAc24ngHNuW8+WeQD+eCMAiciAnJUgIpJr3Qn3EUBNp/na7LLOTgBOMLO/mNlbZnZBTxV4sDJlg3JdgohIznSn36Kr8XJdF9s5HpgKjAT+n5md4pxr2G1DZjOBmQBHH90L56CnEh2TgfLBPb99EZE80Z2Wey1Q1Wl+JLCpi3Wed84lnXPrgQ/ww343zrnZzrlJzrlJgwf3QvhGd3ZMpgec0PPbFxHJE90J90XA8WY22szCwOXAC3us8xzwVwBmNgi/m+bjniy0W+JNHZMtZbo6VUSK137D3TmXAq4HXgZWA3OccyvN7E4zm5Zd7WWg3sxWAQuA7zvn6nur6L1KJwG4NnEjnqfRIEWkeHXrXEHn3EvAS3ss+1GnaQf8U/aRO2m/zz2Fxze/WJ3TUkREcqmwrlDNpAA4/fhhVERCOS5GRCR3Civcs90yFgznuBARkdwqrHDP+OGOp1a7iBS3wgr3bMs9oHAXkSJXWOGe7XMPeOqWEZHiVlDhns5eoRoIquUuIsWtcMJ9+zq8Od8AFO4iIoUT7i/9c8ekp7NlRKTIFU64B3ZdkRpQuItIkSuYcI9ndk0r3EWk2BVMuKfdrpa7F1Kfu4gUt4IJ90ynYeeDIbXcRaS4FUy4pzrdPkRfqIpIsSuYcM+kUh3TXrg0h5WIiORewYR7Op3umA7qPHcRKXIFE+4uvev+qeGgbtQhIsWtcMI9Fe+YDgULZrdERA5K4aRgp5Z7yCuc3RIRORgFk4K2W7jbPtYUESl8BRPu7WO5A4TVcheRIlcwKRjI7Gq5BxXuIlLkCiYFA5ldLXd1y4hIsSuYcPc6tdzVLSMixa5gUtBzSd7OnMQF8Z8SCKjlLiLFrWDCPeiSLM8cwxp3NCU6z11Eilww1wX0lKBL0b+inP+Z+VdURDT8gIgUt8Jo4mYyBEkRCIYZWVmW62pERHKuMMI9ewFTJqChfkVEoMDC3XnqjhERgQILd7XcRUR8BRXueAp3EREolHDPDvfrFO4iIkChhHt20DBTuIuIAAUT7tmWu26MLSICFEy4+33uarmLiPgKI9xT2VMh1XIXEQEKJNwz2S9UvWAkx5WIiBwZCiLcE/EoAMGwwl1EBLoZ7mZ2gZl9YGbrzOyWfaw33cycmU3quRL3LxVtAiAQqTicbysicsTab7ibmQc8AFwInAxcYWYnd7FeBXAj8HZPF7k/yWgzAF6k/HC/tYjIEak7LffJwDrn3MfOuQTwNHBpF+v9BPg5EOvB+rqlveXuqeUuIgJ0L9xHADWd5muzyzqY2USgyjn3Yg/W1m2ZWAsAodK+uXh7EZEjTnfCvat71rmOJ80CwK+A7+13Q2YzzWyxmS2uq6vrfpX7kYk3E3MhIpGSHtumiEg+60641wJVneZHAps6zVcApwCvm9kG4DTgha6+VHXOzXbOTXLOTRo8ePDBV93Jc+99yv8sXUMjfYiEvB7ZpohIvutOuC8Cjjez0WYWBi4HXmh/0jnX6Jwb5Jyrds5VA28B05xzi3ul4j2smXsnXw8uZHVmFJVluohJRAS6Ee7OuRRwPfAysBqY45xbaWZ3mtm03i5wf24JPQ3A79NnMbhc3TIiItDNG2Q7514CXtpj2Y/2su7UQy+rm5wjhcd/p7/AHzNncH9pwdzvW0TkkOT3FaqxBoKkeS9zLH932ijMuvruV0Sk+OR3UzfuX7x0bNUI/varp+S4GBGRI0d+t9yzN+lwuneqiMhuCiLcLZjff4CIiPS0PA933aRDRKQr+R3umfZ7p4ZyXIiIyJElv8M92y2DWu4iIrvJ63B32W6ZgG6vJyKym7wO93QyG+7qlhER2U1eh3sq6d871UIadkBEpLO8Dvd00u9zDwTVchcR6SzPw91vuXvqcxcR2U1+h3vK73P31C0jIrKbPA93v+Wus2VERHaX1+GeSfl97uqWERHZXX6He3ufeziS40pERI4seR7uMUDhLiKyp7wOd9ce7iGFu4hIZ/kd7qkYSecRCuk8dxGRzvI63EnGiBMi5OX3boiI9LS8TkWXihMnRFjhLiKym/xOxbQf7qGgbowtItJZfod7KkbcqVtGRGRPeZ2KloqTULeMiMhn5PWdpS0dJ0GQfgp3EQCSySS1tbXEYrFclyKHKBKJMHLkyIM+GzCvwz2QbKONCCVBhbsIQG1tLRUVFVRXV2Om76LylXOO+vp6amtrGT169EFtI39TsaGGSLyOFldKeSSvf0eJ9JhYLMbAgQMV7HnOzBg4cOAh/QWWv6l47ylUAlEbqS9URTpRsBeGQz2O+ZmKyWjHZMIry2EhIiJHpvwM95ZtHZMZTzfqEDmSNDQ08J//+Z8H/LqLLrqIhoaGXqioOOVnuLfWdUyOSqzNYSEisqe9hXs6nd7n61566SX69+/fW2UVnfzsc4/t+u3+dN9v8oUcliJypPrxH1eyalNTj27z5KP6cvslY/e5zi233MJHH33EhAkTCIVClJeXM3z4cJYuXcqqVav46le/Sk1NDbFYjJtuuomZM2cCUF1dzeLFi2lpaeHCCy/ki1/8Im+88QYjRozg+eefp7S0tMv3e+ihh5g9ezaJRILjjjuOJ554grKyMrZu3co111zDxx9/DMCsWbM444wzePzxx/nFL36BmTF+/HieeOKJLrd71VVXUVpaypo1a9i4cSOPPvoov/nNb3jzzTeZMmUKjz32GADz5s3j9ttvJx6Pc+yxx/Loo49SXl7OnXfeyR//+Eei0ShnnHEGDz74IGbG1KlTmTJlCgsWLKChoYGHH36Ys8466yCPyN7lZcs9HWvumD7rrC/lsBIR2dNPf/pTjj32WJYuXco999zDO++8w913382qVasAeOSRR1iyZAmLFy/m/vvvp76+/jPbWLt2Lddddx0rV66kf//+/P73v9/r+33ta19j0aJFLFu2jDFjxvDwww8DcOONN3LOOeewbNky3n33XcaOHcvKlSu5++67ee2111i2bBn33XffPvdl586dvPbaa/zqV7/ikksu4eabb2blypW8//77LF26lO3bt3PXXXcxf/583n33XSZNmsQvf/lLAK6//noWLVrEihUriEajvPjiix3bTaVSvPPOO9x77738+Mc/PuDPuDvysuUeb2mg/WtUr6Q8p7WIHKn218I+XCZPnrzbudr3338/zz77LAA1NTWsXbuWgQMH7vaa0aNHM2HCBAA+//nPs2HDhr1uf8WKFfzwhz+koaGBlpYWzj//fABee+01Hn/8cQA8z6Nfv348/vjjTJ8+nUGDBgEwYMCAfdZ+ySWXYGaMGzeOoUOHMm7cOADGjh3Lhg0bqK2tZdWqVZx55pkAJBIJTj/9dAAWLFjAz3/+c9ra2tixYwdjx47lkksuAfxfSN3Zt0ORn+HeuivcMzmtRET2p0+fPh3Tr7/+OvPnz+fNN9+krKyMqVOndnkud0nJrhMlPM8jGo1+Zp12V111Fc899xynnnoqjz32GK+//vpe13XOHdAphu11BAKB3WoKBAKkUik8z+MrX/kKTz311G6vi8ViXHvttSxevJiqqiruuOOO3fazfVue55FKpbpdz4HIy26ZZNuufsTKMt0cW+RIUlFRQXNzc5fPNTY2UllZSVlZGWvWrOGtt9465Pdrbm5m+PDhJJNJnnzyyY7l5557LrNmzQL8L3Obmpo499xzmTNnTkdX0I4dOw7pvU877TT+8pe/sG7dOgDa2tr48MMPO4J80KBBtLS0MHfu3EN6n4ORly33dNQP91nHz+aa4wfluBoR6WzgwIGceeaZnHLKKZSWljJ06NCO5y644AJ+/etfM378eE488UROO+20Q36/n/zkJ0yZMoVRo0Yxbty4jl8s9913HzNnzuThhx/G8zxmzZrF6aefzm233cY555yD53lMnDix44vRgzF48GAee+wxrrjiCuLxOAB33XUXJ5xwAldffTXjxo2jurqaL3zh8J/2Yc65w/6mAJMmTXKLFy8+qNfW/PY6KtY+y4Zvr2JClU6dEmm3evVqxowZk+sypId0dTzNbIlzbtL+Xtutbhkzu8DMPjCzdWZ2SxfP/5OZrTKz5Wb2qpmN6nb1ByGd9If6rdCYMiIiXdpvOpqZBzwAfAWoBRaZ2QvOuVWdVnsPmOScazOz7wI/B/6mNwoGSCdjJAgq3EWKyHXXXcdf/vKX3ZbddNNNzJgx45C2e/fdd/O73/1ut2Vf//rXue222w5pu7nWnXScDKxzzn0MYGZPA5cCHeHunFvQaf23gG/0ZJF7SicTJFyQQZGDG+dYRPLPAw880Cvbve222/I+yLvSnW6ZEUBNp/na7LK9+Rbwp66eMLOZZrbYzBbX1dV1tUq3uFScpIU0jruIyF50Jx27Oim0y29hzewbwCTgnq6ed87Nds5Ncs5NGjx4cPer3PN90nFSFtLQpiIie9FRgwX9AAAKLElEQVSdbplaoKrT/Ehg054rmdmXgduAc5xz8Z4pr2uWSZI2dcmIiOxNd1rui4DjzWy0mYWBy4EXOq9gZhOBB4FpzrltXWyjRwXSCVIKdxGRvdpvuDvnUsD1wMvAamCOc26lmd1pZtOyq90DlAO/M7OlZvbCXjbXIwKZhFruIgWivNwfH2rTpk1Mnz69y3WmTp3KwV4XU6y6dS6hc+4l4KU9lv2o0/SXe7iufQpkkmQCfQ/nW4pILzvqqKNycpl+ocrLE8U9lyTjaUwZkX360y2w5f2e3eawcXDhT/e5yg9+8ANGjRrFtddeC8Add9yBmbFw4UJ27txJMpnkrrvu4tJLL93tdRs2bODiiy/uGCJ3xowZrFq1ijFjxuxz4DCA7373uyxatIhoNMr06dM7htFdtGgRN910E62trZSUlPDqq69SVlbGD37wA15++WXMjKuvvpobbrihy+1WV1fzt3/7tyxYsIBkMsns2bO59dZbWbduHd///ve55pprALjnnnuYM2cO8Xicyy67rOP99zZ2fXl5OTfddBMvvvgipaWlPP/887sN09AT8vJcwrJMC4lgn/2vKCKH3eWXX84zzzzTMT9nzhxmzJjBs88+y7vvvsuCBQv43ve+x76GPpk1axZlZWUsX76c2267jSVLluzzPe+++24WL17M8uXL+fOf/8zy5ctJJBL8zd/8Dffddx/Lli1j/vz5lJaWMnv2bNavX897773H8uXLufLKK/e57aqqKt58803OOussrrrqKubOnctbb73Fj37kd17MmzePtWvX8s4777B06VKWLFnCwoULgb2PXd/a2sppp53GsmXLOPvss3nooYe69dkeiPxruadT9Ms00BQ6+FMpRYrCflrYvWXixIls27aNTZs2UVdXR2VlJcOHD+fmm29m4cKFBAIBPv30U7Zu3cqwYcO63MbChQu58cYbARg/fjzjx4/f53vOmTOH2bNnk0ql2Lx5M6tWrcLMGD58eMegXX37+l258+fP55prriEY9ONvf2O6T5vmf7U4btw4WlpaqKiooKKigkgkQkNDA/PmzWPevHlMnDgRgJaWFtauXcvZZ5+917Hrw+EwF198MeCP6f7KK6/s93M9UPkX7q3b8MjQGla4ixyppk+fzty5c9myZQuXX345Tz75JHV1dSxZsoRQKER1dXWX47h31t3rWNavX88vfvELFi1aRGVlJVdddRWxWGyvY7f39JjuzjluvfVWvvOd7+z2un2NXR8K7bpOp7fGdM+7bpnGbZ8A0GdQ1X7WFJFcufzyy3n66aeZO3cu06dPp7GxkSFDhhAKhViwYAEbN27c5+vPPvvsjrHZV6xYwfLly/e6blNTE3369KFfv35s3bqVP/3Jv0D+pJNOYtOmTSxatAjwx31PpVKcd955/PrXv+4I1EMd0/3888/nkUceoaWlBYBPP/2Ubdu29crY9Qci71ruC95ZyleBU8aclOtSRGQvxo4dS3NzMyNGjGD48OFceeWVXHLJJUyaNIkJEyZw0kn7/v/73e9+lxkzZjB+/HgmTJjA5MmT97ruqaeeysSJExk7dizHHHNMxy3vwuEwzzzzDDfccAPRaJTS0lLmz5/Pt7/9bT788EPGjx9PKBTi6quv5vrrrz/ofT3vvPNYvXp1x+31ysvL+e1vf9srY9cfiLwbzz35xq8JzfsB/PNaKB/SC5WJ5C+N515Yen089yNJqHIknPi/oEx3YBIR2Zu865ZhzMX+Q0SKzpQpUzpuZ9fuiSeeYNy4cYe03csuu4z169fvtuxnP/sZ559//iFtN5fyL9xFpGi9/fbbvbLd9tMVC0nedcuIyL7l6ns06VmHehwV7iIFJBKJUF9fr4DPc8456uvriUQiB70NdcuIFJCRI0dSW1vLodzpTI4MkUiEkSNHHvTrFe4iBSQUCjF69OhclyFHAHXLiIgUIIW7iEgBUriLiBSgnA0/YGZ1wL5HD9q7QcD2HiwnH2ifi4P2uTgcyj6Pcs7td1jcnIX7oTCzxd0ZW6GQaJ+Lg/a5OByOfVa3jIhIAVK4i4gUoHwN99m5LiAHtM/FQftcHHp9n/Oyz11ERPYtX1vuIiKyD3kX7mZ2gZl9YGbrzOyWXNfTU8ysyswWmNlqM1tpZjdllw8ws1fMbG32Z2V2uZnZ/dnPYbmZfS63e3BwzMwzs/fM7MXs/Ggzezu7v8+YWTi7vCQ7vy77fHUu6z5YZtbfzOaa2ZrssT69CI7xzdl/0yvM7CkzixTicTazR8xsm5mt6LTsgI+tmf1Ddv21ZvYPB1tPXoW7mXnAA8CFwMnAFWZ2cm6r6jEp4HvOuTHAacB12X27BXjVOXc88Gp2HvzP4PjsYyYw6/CX3CNuAlZ3mv8Z8Kvs/u4EvpVd/i1gp3PuOOBX2fXy0X3AfzvnTgJOxd/3gj3GZjYCuBGY5Jw7BfCAyynM4/wYcMEeyw7o2JrZAOB2YAowGbi9/RfCAXPO5c0DOB14udP8rcCtua6rl/b1eeArwAfA8Oyy4cAH2ekHgSs6rd+xXr48gJHZf/BfAl4EDP/CjuCexxt4GTg9Ox3Mrme53ocD3N++wPo96y7wYzwCqAEGZI/bi8D5hXqcgWpgxcEeW+AK4MFOy3db70AeedVyZ9c/lHa12WUFJfun6ETgbWCoc24zQPZn+13BC+GzuBf4FyCTnR8INDjnUtn5zvvUsb/Z5xuz6+eTY4A64NFsV9R/mVkfCvgYO+c+BX4BfAJsxj9uSyjs49zZgR7bHjvm+Rbu1sWygjrdx8zKgd8D/+ica9rXql0sy5vPwswuBrY555Z0XtzFqq4bz+WLIPA5YJZzbiLQyq4/07uS9/uc7VK4FBgNHAX0we+S2FMhHefu2Nt+9tj+51u41wJVneZHAptyVEuPM7MQfrA/6Zz7Q3bxVjMbnn1+OLAtuzzfP4szgWlmtgF4Gr9r5l6gv5m132eg8z517G/2+X7AjsNZcA+oBWqdc+03Ap2LH/aFeowBvgysd87VOeeSwB+AMyjs49zZgR7bHjvm+Rbui4Djs9+0h/G/mHkhxzX1CDMz4GFgtXPul52eegFo/8b8H/D74tuX/332W/fTgMb2P//ygXPuVufcSOdcNf5xfM05dyWwAJieXW3P/W3/HKZn18+rFp1zbgtQY2YnZhedC6yiQI9x1ifAaWZWlv033r7PBXuc93Cgx/Zl4Dwzq8z+1XNedtmBy/UXEAfxhcVFwIfAR8Btua6nB/fri/h/fi0HlmYfF+H3N74KrM3+HJBd3/DPHPoIeB//bISc78dB7vtU4MXs9DHAO8A64HdASXZ5JDu/Lvv8Mbmu+yD3dQKwOHucnwMqC/0YAz8G1gArgCeAkkI8zsBT+N8rJPFb4N86mGMLfDO7/+uAGQdbj65QFREpQPnWLSMiIt2gcBcRKUAKdxGRAqRwFxEpQAp3EZECpHAXESlACncRkQKkcBcRKUD/H162O5kgdgs8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mplot.plot(train_acc_mean, label='train_acc_mean')\n",
    "mplot.plot(valid_acc_mean, label='valid_acc_mean')\n",
    "mplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/cnn-fnirs-har-10subjects.ckpt\n",
      "test_loss: 1.8538384 test acc 0.9813257\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "    \n",
    "    # Loading the trained and validated model\n",
    "#     saver.restore(save_path=tf.train.latest_checkpoint(checkpoint_dir='checkpoints/'), sess=sess)\n",
    "    saver.restore(save_path='checkpoints/cnn-fnirs-har-10subjects.ckpt', sess=sess)\n",
    "    \n",
    "    # Saving the test loss for every batch/minibtch\n",
    "    test_loss, test_acc = [], []\n",
    "    \n",
    "    # applying the loaded model on test data\n",
    "    for Xarr, Yarr in get_batches(X=Xtest, Y=Ytest, batch_size=Xvalid.shape[0]): \n",
    "        # X_NxWXCin, Y_NxCout\n",
    "        feed_dict={X:Xarr, Y:Yarr}\n",
    "        lossarr, accarr = sess.run(feed_dict=feed_dict, fetches=[loss, acc])\n",
    "        test_loss.append(lossarr)\n",
    "        test_acc.append(accarr)\n",
    "        \n",
    "    # Printing the test loss\n",
    "    print('test_loss:', np.mean(test_loss), 'test acc', np.mean(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
