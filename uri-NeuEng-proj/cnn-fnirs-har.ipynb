{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for fNIRS data analysis for Human Activity Recognition (HAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mP12-4-17-2018\u001b[0m/  \u001b[01;34mP14-4-18-2018\u001b[0m/  \u001b[01;34mP16-4-18-2018\u001b[0m/\r\n",
      "\u001b[01;34mP13-4-17-2018\u001b[0m/  \u001b[01;34mP15-4-18-2018\u001b[0m/  \u001b[01;34mP17-4-18-2018\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "% ls ../../../datasets/fNIRs_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m1. Right Hand\u001b[0m/  \u001b[01;34m2. Both Hands\u001b[0m/  \u001b[01;34m3. Left Hand\u001b[0m/  \u001b[01;34m4. Right Leg\u001b[0m/  \u001b[01;34m5. Left Leg\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "% ls ../../../datasets/fNIRs_data/P12-4-17-2018/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m2018-04-17_006\u001b[0m/\r\n",
      "fNIR_data.txt\r\n",
      "head20180417-145130.txt\r\n",
      "NIRS-2018-04-17_006_deoxyhb_T141to2511_C1to20.txt\r\n",
      "NIRS-2018-04-17_006_oxyhb_T141to2511_C1to20.txt\r\n",
      "\u001b[01;34mProcessed\u001b[0m/\r\n",
      "r_hand20180417-145128.txt\r\n",
      "r_lower_arm20180417-145129.txt\r\n",
      "r_upper_arm20180417-145129.txt\r\n"
     ]
    }
   ],
   "source": [
    "% ls ../../../datasets/fNIRs_data/P12-4-17-2018/1.\\ Right\\ Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/home/arasdar/datasets/fNIRs_data/P12-4-17-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P12-4-17-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P12-4-17-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P12-4-17-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P12-4-17-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P13-4-17-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P13-4-17-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P13-4-17-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P13-4-17-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P13-4-17-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P14-4-18-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P14-4-18-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P14-4-18-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P14-4-18-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P14-4-18-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P15-4-18-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P15-4-18-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P15-4-18-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P15-4-18-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P15-4-18-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P16-4-18-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P16-4-18-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P16-4-18-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P16-4-18-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P16-4-18-2018/5. Left Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P17-4-18-2018/1. Right Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P17-4-18-2018/2. Both Hands/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P17-4-18-2018/3. Left Hand/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P17-4-18-2018/4. Right Leg/fNIR_data.txt',\n",
       "  '/home/arasdar/datasets/fNIRs_data/P17-4-18-2018/5. Left Leg/fNIR_data.txt'],\n",
       " 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# % find ../../datasets/fNIRs_data/ | grep fNIR_data # NOT WORKING!!\n",
    "def find_all(name, path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            result.append(os.path.join(root, name))\n",
    "    return result\n",
    "\n",
    "allpaths = find_all(name='fNIR_data.txt', path='/home/arasdar/datasets/fNIRs_data/')\n",
    "allpaths = sorted(allpaths, reverse=False)\n",
    "# print(allpaths, len(allpaths))\n",
    "allpaths, len(allpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/arasdar-DL-env/lib/python3.6/site-packages/pandas/io/parsers.py:709: UserWarning: Duplicate names specified. This will raise an error in the future.\n",
      "  return _read(filepath_or_buffer, kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2372, 42)\n",
      "(1210, 42)\n",
      "(2378, 42)\n",
      "(1202, 42)\n",
      "(1222, 42)\n",
      "(2405, 42)\n",
      "(1196, 42)\n",
      "(2380, 42)\n",
      "(1203, 42)\n",
      "(1242, 42)\n",
      "(2373, 42)\n",
      "(1202, 42)\n",
      "(2386, 42)\n",
      "(1196, 42)\n",
      "(1229, 42)\n",
      "(2387, 42)\n",
      "(1224, 42)\n",
      "(2379, 42)\n",
      "(1230, 42)\n",
      "(1227, 42)\n",
      "(2384, 42)\n",
      "(1230, 42)\n",
      "(2375, 42)\n",
      "(1196, 42)\n",
      "(1197, 42)\n",
      "(2373, 42)\n",
      "(1220, 42)\n",
      "(2372, 42)\n",
      "(1223, 42)\n",
      "(1222, 42)\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# df: data frame object\n",
    "df = []\n",
    "for each_idx in range(len(allpaths)):\n",
    "    file = pd.read_csv(filepath_or_buffer=allpaths[each_idx], names=['time', 'sample', \n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel',\n",
    "                       'channel', 'channel', 'channel', 'channel', 'channel'],\n",
    "                         header=None)\n",
    "    df.append(file)\n",
    "    \n",
    "for each in range(len(df)):\n",
    "    print(df[each].shape)\n",
    "    df[each]=df[each].drop(axis=1, columns=None, index=None, labels=['time', 'sample'])\n",
    "    df[each] = df[each].dropna()\n",
    "    df[each]['channel.39'] = df[each]['channel.39'].astype(str).str[1:-1].astype(float)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64 (2371, 40) 1\n",
      "float64 (1209, 40) 2\n",
      "float64 (2377, 40) 3\n",
      "float64 (1201, 40) 4\n",
      "float64 (1221, 40) 5\n",
      "float64 (2404, 40) 1\n",
      "float64 (1195, 40) 2\n",
      "float64 (2379, 40) 3\n",
      "float64 (1202, 40) 4\n",
      "float64 (1241, 40) 5\n",
      "float64 (2372, 40) 1\n",
      "float64 (1201, 40) 2\n",
      "float64 (2385, 40) 3\n",
      "float64 (1195, 40) 4\n",
      "float64 (1228, 40) 5\n",
      "float64 (2386, 40) 1\n",
      "float64 (1223, 40) 2\n",
      "float64 (2378, 40) 3\n",
      "float64 (1229, 40) 4\n",
      "float64 (1226, 40) 5\n",
      "float64 (2383, 40) 1\n",
      "float64 (1229, 40) 2\n",
      "float64 (2374, 40) 3\n",
      "float64 (1195, 40) 4\n",
      "float64 (1196, 40) 5\n",
      "float64 (2372, 40) 1\n",
      "float64 (1219, 40) 2\n",
      "float64 (2371, 40) 3\n",
      "float64 (1222, 40) 4\n",
      "float64 (1221, 40) 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = [], []\n",
    "for each in range(0, len(df), 1):\n",
    "    dfmat = df[each].as_matrix()\n",
    "    label = (each%5)+1\n",
    "    print(dfmat.dtype, dfmat.shape, label)\n",
    "    data.append(dfmat)\n",
    "    labels.append(label)\n",
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is very much like a convolution for extracting the windows\n",
    "# size/width, stride/overlap, padding, dilation, num filters/out channel\n",
    "def minibatching(X, Y, stride, width):\n",
    "    Xmb, Ymb = [], []\n",
    "    print(len(X), len(Y))\n",
    "    # 1st and 1st\n",
    "    for eachX in range(len(X)):\n",
    "        num_mb = ((X[eachX].shape[0]-width)//stride)+1\n",
    "        for each in range(num_mb):\n",
    "            # The max is (num_mb-1)*stride+width==X[idx].shape[0]\n",
    "            # The last each is (num_mb-1)\n",
    "            # each = ((each-1)*stride)+width\n",
    "            each *= stride\n",
    "            Xmb.append(X[eachX][each:each+width])\n",
    "            # There is only one label for one image signal or signal window or temporal window\n",
    "            #Ymb.append(Y[eachX][each:each+1])\n",
    "            Ymb.append(Y[eachX])\n",
    "    return Xmb, Ymb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n",
      "42935 42935\n",
      "(250, 40) float64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Width is based on the sampling rate which is roughly about 233 points per window\n",
    "# for 10sec rest and 20 sec activity\n",
    "width = 250\n",
    "Xmb, Ymb = minibatching(X=data, Y=labels, stride=1, width=width)\n",
    "# for eachX, eachY in zip(Xmb, Ymb):\n",
    "#     print(eachX.shape, eachY)\n",
    "print(len(Xmb), len(Ymb))\n",
    "print(Xmb[0].shape, Xmb[0].dtype)\n",
    "print(Ymb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42935, 250, 40) float64 (42935,) int64\n"
     ]
    }
   ],
   "source": [
    "# Conversion from python list to numpy array\n",
    "X, Y=np.array(object=Xmb, dtype=float), np.array(object=Ymb, dtype=int)\n",
    "print(X.shape, X.dtype, Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30054, 250, 40) (12881, 250, 40) (30054,) (12881,)\n",
      "float64 float64 int64 int64\n"
     ]
    }
   ],
   "source": [
    "# Now I should devide the data into train and test\n",
    "# Train and valid split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 30% of the training data/ entire training data is assigned to validation.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.30)\n",
    "print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)\n",
    "print(Xtrain.dtype, Xtest.dtype, Ytrain.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30054, 250, 40) float64\n",
      "(12881, 250, 40) float64\n"
     ]
    }
   ],
   "source": [
    "# # standardizing/normalizing the train and test data\n",
    "# def standardize(train, test):\n",
    "# \"\"\" Standardize data \"\"\"\n",
    "# # Standardize train and test\n",
    "# X_train = (train - np.mean(train, axis=0)[None,:,:]) / np.std(train, axis=0)[None,:,:]\n",
    "# X_test = (test - np.mean(test, axis=0)[None,:,:]) / np.std(test, axis=0)[None,:,:]\n",
    "# return X_train, X_test\n",
    "\n",
    "Xtrain = (Xtrain - Xtrain.mean(axis=0))/ Xtrain.std(axis=0)\n",
    "Xtest = (Xtest - Xtest.mean(axis=0))/ Xtest.std(axis=0)\n",
    "print(Xtrain.shape, Xtrain.dtype)\n",
    "print(Xtest.shape, Xtest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.40043105e-17 -5.13169692e-17  2.25302796e-17 ...  2.37825775e-17\n",
      "   1.03515903e-16  3.79383459e-17]\n",
      " [-1.81601663e-17  1.20554912e-16 -2.31250287e-18 ...  1.81564722e-17\n",
      "   4.40336010e-18 -4.64753972e-17]\n",
      " [ 1.47763762e-18  1.23180489e-16 -6.99661412e-18 ...  1.01343776e-16\n",
      "   5.51749887e-17 -8.19387000e-17]\n",
      " ...\n",
      " [ 7.03798798e-17  7.88596726e-18 -8.83627296e-18 ... -1.15436745e-16\n",
      "  -5.94453614e-17 -9.88835094e-17]\n",
      " [ 4.09047034e-17  1.90296175e-16  6.60282370e-17 ...  3.67931767e-17\n",
      "  -7.68076034e-17  2.56037658e-17]\n",
      " [-4.83556911e-17  2.23446514e-17 -4.54004158e-18 ... -1.02289464e-17\n",
      "  -3.45619439e-17 -3.15253986e-17]] [[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.mean(axis=0), Xtrain.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.98815852e-17 -8.57770324e-17 -4.38710907e-17 ... -3.61570188e-17\n",
      "   7.18141312e-17 -9.29567217e-17]\n",
      " [ 5.19040684e-17  7.18486075e-17 -9.60337314e-17 ...  7.64770507e-17\n",
      "   1.06307669e-16 -4.17421792e-17]\n",
      " [ 1.03963280e-16  9.01210461e-17  1.33595659e-18 ...  1.04195995e-16\n",
      "   1.47903324e-16  6.36260102e-17]\n",
      " ...\n",
      " [-6.62634470e-17 -1.56936114e-16  1.73329594e-17 ... -6.61944944e-18\n",
      "   4.85167720e-17  6.83923585e-17]\n",
      " [ 8.54495075e-17  1.84137914e-16 -4.93700604e-17 ...  8.20363539e-17\n",
      "  -1.34293804e-16  6.71253545e-17]\n",
      " [ 3.38902021e-17  8.90867571e-17 -4.69481004e-17 ... -6.02214756e-17\n",
      "  -3.05115248e-18 -9.96796000e-17]] [[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(Xtest.mean(axis=0), Xtest.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 5\n",
      "(30054, 5) float64 (12881, 5) float64\n"
     ]
    }
   ],
   "source": [
    "# Onehotencoding of the output labels\n",
    "def onehot(labels, n_class):\n",
    "\t\"\"\" One-hot encoding \"\"\"\n",
    "\texpansion = np.eye(n_class)\n",
    "\ty = expansion[:, labels-1].T\n",
    "\tassert y.shape[1] == n_class, \"Wrong number of labels!\"\n",
    "\n",
    "\treturn y\n",
    "\n",
    "print(Y.max(axis=0), Ytrain.max(axis=0), Ytest.max(axis=0))\n",
    "# # assert Y.max(axis=0) == Ytrain.max(axis=0) == Ytest.max(axis=0), 'wrong labels'\n",
    "Ytrain=onehot(labels=Ytrain, n_class=Ytrain.max(axis=0))\n",
    "Ytest=onehot(labels=Ytest, n_class=Ytest.max(axis=0))\n",
    "print(Ytrain.shape, Ytrain.dtype, Ytest.shape, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21037, 250, 40) (9017, 250, 40) (12881, 250, 40) float64 float64 float64\n",
      "(21037, 5) (9017, 5) (12881, 5) float64 float64 float64\n"
     ]
    }
   ],
   "source": [
    "# Now separating train and validation set\n",
    "# 30% of the training data/ entire training data is assigned to validation.\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtrain, Ytrain, test_size=0.30)\n",
    "print(Xtrain.shape, Xvalid.shape, Xtest.shape, Xtrain.dtype, Xvalid.dtype, Xtest.dtype)\n",
    "print(Ytrain.shape, Yvalid.shape, Ytest.shape, Ytrain.dtype, Yvalid.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9017, 250, 40) <dtype: 'float32'> (21037, 250, 40) float64 (9017, 250, 40) float64 (12881, 250, 40) float64\n"
     ]
    }
   ],
   "source": [
    "# now I can design the actual input and output tensors\n",
    "N, W, Cin = Xvalid.shape[0], Xvalid.shape[1], Xvalid.shape[2]\n",
    "X = tf.placeholder(dtype=tf.float32, name=None, shape=[N, W, Cin])\n",
    "print(X.shape, X.dtype, Xtrain.shape, Xtrain.dtype, Xvalid.shape, Xvalid.dtype, Xtest.shape, Xtest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9017, 5) <dtype: 'float32'> (21037, 5) float64 (9017, 5) float64 (12881, 5) float64\n"
     ]
    }
   ],
   "source": [
    "# This is the output tensor for labels\n",
    "N, Cout = Yvalid.shape[0], Yvalid.shape[1]\n",
    "Y = tf.placeholder(dtype=tf.float32, name=None, shape=[N, Cout])\n",
    "print(Y.shape, Y.dtype, Ytrain.shape, Ytrain.dtype, Yvalid.shape, Yvalid.dtype, Ytest.shape, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9017, 250, 40) <dtype: 'float32'>\n",
      "(125, 40, 80) <dtype: 'float32_ref'>\n",
      "(9017, 125, 80) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X.dtype)\n",
    "Wwidth, Wchannels, Wnumber = X.shape[1].value//2, X.shape[2].value, X.shape[2].value*2\n",
    "shape = [Wwidth, Wchannels, Wnumber]\n",
    "initial_value=tf.random_normal(dtype=X.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "Wconv = tf.Variable(dtype=X.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(Wconv.shape, Wconv.dtype)\n",
    "Xconv = tf.nn.conv1d(data_format='NWC', filters=Wconv, name=None, padding='SAME', stride=2, use_cudnn_on_gpu=True, \n",
    "                     value=X)\n",
    "Xconv = tf.maximum(name=None, x=(-0.1*Xconv), y=Xconv)\n",
    "print(Xconv.shape, Xconv.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9017, 10000) <dtype: 'float32'>\n",
      "(10000, 5) <dtype: 'float32_ref'>\n",
      "(9017, 5) <dtype: 'float32'>\n",
      "(9017, 5) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# This is the multiplication layer\n",
    "# this part is flatening the input\n",
    "shape = [Xconv.shape[0].value, Xconv.shape[1].value*Xconv.shape[2].value]\n",
    "Xconv_reshaped = tf.reshape(name=None, shape=shape, tensor=Xconv)\n",
    "print(Xconv_reshaped.shape, Xconv_reshaped.dtype)\n",
    "# their first axis or dimension stay the same\n",
    "shape = [Xconv_reshaped.shape[1].value, Y.shape[1].value]\n",
    "initial_value = tf.random_normal(dtype=Xconv_reshaped.dtype, mean=0.0, name=None, shape=shape, stddev=1.0)\n",
    "W = tf.Variable(dtype=Xconv_reshaped.dtype, initial_value=initial_value, name=None, trainable=True)\n",
    "print(W.shape, W.dtype)\n",
    "# The actual multiplication\n",
    "# Y_ = Xconv_reshaped @ W\n",
    "Y_ = tf.matmul(a=Xconv_reshaped, b=W, name=None)\n",
    "print(Y_.shape, Y_.dtype)\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9017,) <dtype: 'float32'>\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Now I need to calculate the loss\n",
    "loss_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=Y_, name=None)\n",
    "print(loss_tensor.shape, loss_tensor.dtype)\n",
    "loss = tf.reduce_mean(axis=0, input_tensor=loss_tensor, name=None)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_Variable/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_1/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Backprop and SGD now using adam\n",
    "opt = tf.train.AdamOptimizer().minimize(loss)\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9017, 5) <dtype: 'float32'> (9017, 5) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(Y_.shape, Y_.dtype, Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9017,) <dtype: 'int64'>\n",
      "(9017,) <dtype: 'int64'>\n",
      "(9017,) <dtype: 'bool'>\n",
      "(9017,) <dtype: 'float32'>\n",
      "() <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "# tf.argmax(\n",
    "#     input,\n",
    "#     axis=None,\n",
    "#     name=None,\n",
    "#     dimension=None,\n",
    "#     output_type=tf.int64\n",
    "# )\n",
    "# Y_NxCout, N:axis 1, Cout: axis 2\n",
    "Y_argmax = tf.argmax(axis=1, name=None, input=Y_)\n",
    "print(Y_argmax.shape, Y_argmax.dtype)\n",
    "Yargmax = tf.argmax(axis=1, name=None, input=Y)\n",
    "print(Yargmax.shape, Yargmax.dtype)\n",
    "\n",
    "acc_tensor = tf.equal(name=None, x=Y_argmax, y=Yargmax)\n",
    "print(acc_tensor.shape, acc_tensor.dtype)\n",
    "# cast bool to int datatype for equal\n",
    "acc_tensor = tf.cast(dtype=tf.float32, name=None, x=acc_tensor)\n",
    "print(acc_tensor.shape, acc_tensor.dtype)\n",
    "acc = tf.reduce_mean(axis=0, input_tensor=acc_tensor)\n",
    "print(acc.shape, acc.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(X, Y, batch_size):\n",
    "    \"\"\" Return a generator for batches \"\"\"\n",
    "    n_batches = len(X) // batch_size\n",
    "    X, Y = X[:n_batches*batch_size], Y[:n_batches*batch_size]\n",
    "\n",
    "    # Loop over batches and yield\n",
    "    for b in range(0, len(X), batch_size):\n",
    "        yield X[b:b+batch_size], Y[b:b+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss: 5121.334 valid_loss: 3748.1282 train_acc: 0.26971278 valid_acc: 0.2860153\n",
      "epoch: 2 train_loss: 3404.0205 valid_loss: 2624.844 train_acc: 0.26827103 valid_acc: 0.26128423\n",
      "epoch: 3 train_loss: 2502.4678 valid_loss: 2323.0046 train_acc: 0.2521903 valid_acc: 0.27692136\n",
      "epoch: 4 train_loss: 2212.067 valid_loss: 1924.8176 train_acc: 0.2789176 valid_acc: 0.27015638\n",
      "epoch: 5 train_loss: 1769.689 valid_loss: 1400.1132 train_acc: 0.2771986 valid_acc: 0.27681047\n",
      "epoch: 6 train_loss: 1268.7295 valid_loss: 1017.82635 train_acc: 0.27187535 valid_acc: 0.23988022\n",
      "epoch: 7 train_loss: 951.7152 valid_loss: 894.6488 train_acc: 0.25135854 valid_acc: 0.26882556\n",
      "epoch: 8 train_loss: 855.3025 valid_loss: 843.7209 train_acc: 0.2727071 valid_acc: 0.27625597\n",
      "epoch: 9 train_loss: 761.7766 valid_loss: 612.6397 train_acc: 0.28379726 valid_acc: 0.34523678\n",
      "epoch: 10 train_loss: 569.6199 valid_loss: 531.6949 train_acc: 0.37673283 valid_acc: 0.39625153\n",
      "epoch: 11 train_loss: 497.33557 valid_loss: 433.47134 train_acc: 0.41710103 valid_acc: 0.42464235\n",
      "epoch: 12 train_loss: 408.28268 valid_loss: 348.821 train_acc: 0.4353998 valid_acc: 0.42386603\n",
      "epoch: 13 train_loss: 328.3186 valid_loss: 290.04843 train_acc: 0.4375624 valid_acc: 0.47554618\n",
      "epoch: 14 train_loss: 277.2483 valid_loss: 259.80167 train_acc: 0.48946434 valid_acc: 0.5274482\n",
      "epoch: 15 train_loss: 258.5238 valid_loss: 267.63757 train_acc: 0.5392592 valid_acc: 0.5520683\n",
      "epoch: 16 train_loss: 264.69873 valid_loss: 253.94882 train_acc: 0.5509038 valid_acc: 0.5393146\n",
      "epoch: 17 train_loss: 244.49496 valid_loss: 224.72086 train_acc: 0.5470223 valid_acc: 0.5538427\n",
      "epoch: 18 train_loss: 209.12347 valid_loss: 175.31732 train_acc: 0.5664301 valid_acc: 0.5740268\n",
      "epoch: 19 train_loss: 160.63046 valid_loss: 148.04724 train_acc: 0.5904957 valid_acc: 0.604303\n",
      "epoch: 20 train_loss: 146.13159 valid_loss: 154.79628 train_acc: 0.6132306 valid_acc: 0.60696465\n",
      "epoch: 21 train_loss: 151.23799 valid_loss: 150.83426 train_acc: 0.6145614 valid_acc: 0.6112898\n",
      "epoch: 22 train_loss: 144.87036 valid_loss: 141.96568 train_acc: 0.62426525 valid_acc: 0.6230454\n",
      "epoch: 23 train_loss: 134.73404 valid_loss: 128.08907 train_acc: 0.6325275 valid_acc: 0.62903404\n",
      "epoch: 24 train_loss: 123.17121 valid_loss: 124.97322 train_acc: 0.6383498 valid_acc: 0.6230454\n",
      "epoch: 25 train_loss: 123.44209 valid_loss: 121.906555 train_acc: 0.62825775 valid_acc: 0.625707\n",
      "epoch: 26 train_loss: 116.7753 valid_loss: 109.59612 train_acc: 0.6406233 valid_acc: 0.6526561\n",
      "epoch: 27 train_loss: 105.62277 valid_loss: 106.89319 train_acc: 0.664578 valid_acc: 0.6679605\n",
      "epoch: 28 train_loss: 104.067055 valid_loss: 106.529526 train_acc: 0.67727625 valid_acc: 0.67162025\n",
      "epoch: 29 train_loss: 102.30794 valid_loss: 99.40848 train_acc: 0.6809915 valid_acc: 0.67893976\n",
      "epoch: 30 train_loss: 95.22154 valid_loss: 93.66878 train_acc: 0.6877564 valid_acc: 0.68969727\n",
      "epoch: 31 train_loss: 90.87337 valid_loss: 93.30178 train_acc: 0.6941333 valid_acc: 0.68969727\n",
      "epoch: 32 train_loss: 90.43765 valid_loss: 89.927216 train_acc: 0.693357 valid_acc: 0.6916935\n",
      "epoch: 33 train_loss: 86.28026 valid_loss: 86.09335 train_acc: 0.70006657 valid_acc: 0.70300543\n",
      "epoch: 34 train_loss: 83.072525 valid_loss: 85.23177 train_acc: 0.7124875 valid_acc: 0.70866144\n",
      "epoch: 35 train_loss: 81.87387 valid_loss: 83.168144 train_acc: 0.7191971 valid_acc: 0.7148719\n",
      "epoch: 36 train_loss: 79.18599 valid_loss: 79.39045 train_acc: 0.7230786 valid_acc: 0.7219696\n",
      "epoch: 37 train_loss: 75.96228 valid_loss: 77.59738 train_acc: 0.7277365 valid_acc: 0.7227459\n",
      "epoch: 38 train_loss: 74.786415 valid_loss: 76.18365 train_acc: 0.7291782 valid_acc: 0.7252967\n",
      "epoch: 39 train_loss: 72.95018 valid_loss: 74.44878 train_acc: 0.7318953 valid_acc: 0.7261839\n",
      "epoch: 40 train_loss: 71.0562 valid_loss: 73.42091 train_acc: 0.7376622 valid_acc: 0.7289564\n",
      "epoch: 41 train_loss: 69.82808 valid_loss: 71.766716 train_acc: 0.7423755 valid_acc: 0.7340579\n",
      "epoch: 42 train_loss: 68.18669 valid_loss: 70.03452 train_acc: 0.74708885 valid_acc: 0.7401575\n",
      "epoch: 43 train_loss: 66.68083 valid_loss: 68.96284 train_acc: 0.7510813 valid_acc: 0.74703336\n",
      "epoch: 44 train_loss: 65.617134 valid_loss: 67.553955 train_acc: 0.7528557 valid_acc: 0.75146943\n",
      "epoch: 45 train_loss: 64.1901 valid_loss: 66.1392 train_acc: 0.75546193 valid_acc: 0.75158036\n",
      "epoch: 46 train_loss: 62.925217 valid_loss: 65.09626 train_acc: 0.76006436 valid_acc: 0.75402015\n",
      "epoch: 47 train_loss: 61.88958 valid_loss: 63.972786 train_acc: 0.7637241 valid_acc: 0.75823444\n",
      "epoch: 48 train_loss: 60.65079 valid_loss: 62.920353 train_acc: 0.76610845 valid_acc: 0.761007\n",
      "epoch: 49 train_loss: 59.58039 valid_loss: 61.98457 train_acc: 0.7681601 valid_acc: 0.7645558\n",
      "epoch: 50 train_loss: 58.567566 valid_loss: 60.820324 train_acc: 0.76993454 valid_acc: 0.76610845\n",
      "epoch: 51 train_loss: 57.462227 valid_loss: 59.708454 train_acc: 0.7741488 valid_acc: 0.7676611\n",
      "epoch: 52 train_loss: 56.48239 valid_loss: 58.73132 train_acc: 0.77686596 valid_acc: 0.7693246\n",
      "epoch: 53 train_loss: 55.46667 valid_loss: 57.802147 train_acc: 0.77908397 valid_acc: 0.7724299\n",
      "epoch: 54 train_loss: 54.468983 valid_loss: 56.88968 train_acc: 0.7797494 valid_acc: 0.77564603\n",
      "epoch: 55 train_loss: 53.551865 valid_loss: 55.895878 train_acc: 0.78207827 valid_acc: 0.77875125\n",
      "epoch: 56 train_loss: 52.616707 valid_loss: 54.87092 train_acc: 0.7844627 valid_acc: 0.78063655\n",
      "epoch: 57 train_loss: 51.67284 valid_loss: 53.926647 train_acc: 0.78767884 valid_acc: 0.7828546\n",
      "epoch: 58 train_loss: 50.73197 valid_loss: 53.050663 train_acc: 0.7900632 valid_acc: 0.78496176\n",
      "epoch: 59 train_loss: 49.790306 valid_loss: 52.145287 train_acc: 0.79183763 valid_acc: 0.78662527\n",
      "epoch: 60 train_loss: 48.82703 valid_loss: 51.169567 train_acc: 0.79416656 valid_acc: 0.7901741\n",
      "epoch: 61 train_loss: 47.851143 valid_loss: 50.182186 train_acc: 0.7967728 valid_acc: 0.79383385\n",
      "epoch: 62 train_loss: 46.857513 valid_loss: 49.131947 train_acc: 0.7996007 valid_acc: 0.7964955\n",
      "epoch: 63 train_loss: 45.85669 valid_loss: 48.161892 train_acc: 0.80231786 valid_acc: 0.79871356\n",
      "epoch: 64 train_loss: 44.904648 valid_loss: 47.331753 train_acc: 0.8052567 valid_acc: 0.801597\n",
      "epoch: 65 train_loss: 44.020348 valid_loss: 46.558933 train_acc: 0.80841744 valid_acc: 0.8052567\n",
      "epoch: 66 train_loss: 43.208374 valid_loss: 45.77841 train_acc: 0.80997 valid_acc: 0.8065876\n",
      "epoch: 67 train_loss: 42.463932 valid_loss: 45.027122 train_acc: 0.8130199 valid_acc: 0.8092492\n",
      "epoch: 68 train_loss: 41.743484 valid_loss: 44.320473 train_acc: 0.8152379 valid_acc: 0.81246537\n",
      "epoch: 69 train_loss: 41.059895 valid_loss: 43.634647 train_acc: 0.81817675 valid_acc: 0.81435066\n",
      "epoch: 70 train_loss: 40.4018 valid_loss: 42.955772 train_acc: 0.8203393 valid_acc: 0.8159033\n",
      "epoch: 71 train_loss: 39.753685 valid_loss: 42.35436 train_acc: 0.8220583 valid_acc: 0.81801045\n",
      "epoch: 72 train_loss: 39.12982 valid_loss: 41.73656 train_acc: 0.8244982 valid_acc: 0.8203394\n",
      "epoch: 73 train_loss: 38.517784 valid_loss: 41.08699 train_acc: 0.8264944 valid_acc: 0.82155925\n",
      "epoch: 74 train_loss: 37.926266 valid_loss: 40.52141 train_acc: 0.8286015 valid_acc: 0.8235555\n",
      "epoch: 75 train_loss: 37.351196 valid_loss: 40.009563 train_acc: 0.83087504 valid_acc: 0.82499725\n",
      "epoch: 76 train_loss: 36.791424 valid_loss: 39.442898 train_acc: 0.83220583 valid_acc: 0.8267717\n",
      "epoch: 77 train_loss: 36.249847 valid_loss: 38.87223 train_acc: 0.83403575 valid_acc: 0.828657\n",
      "epoch: 78 train_loss: 35.71902 valid_loss: 38.310158 train_acc: 0.8355329 valid_acc: 0.8299878\n",
      "epoch: 79 train_loss: 35.194862 valid_loss: 37.78296 train_acc: 0.83752906 valid_acc: 0.8313186\n",
      "epoch: 80 train_loss: 34.682564 valid_loss: 37.270714 train_acc: 0.8391926 valid_acc: 0.83264947\n",
      "epoch: 81 train_loss: 34.188408 valid_loss: 36.74977 train_acc: 0.8410225 valid_acc: 0.83453476\n",
      "epoch: 82 train_loss: 33.70719 valid_loss: 36.23547 train_acc: 0.84318507 valid_acc: 0.8357547\n",
      "epoch: 83 train_loss: 33.236313 valid_loss: 35.74977 train_acc: 0.84429413 valid_acc: 0.8370855\n",
      "epoch: 84 train_loss: 32.76976 valid_loss: 35.28872 train_acc: 0.8457358 valid_acc: 0.83930355\n",
      "epoch: 85 train_loss: 32.316154 valid_loss: 34.826797 train_acc: 0.847233 valid_acc: 0.8407453\n",
      "epoch: 86 train_loss: 31.873417 valid_loss: 34.360283 train_acc: 0.8480648 valid_acc: 0.84207606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 87 train_loss: 31.438358 valid_loss: 33.910286 train_acc: 0.84961736 valid_acc: 0.8437396\n",
      "epoch: 88 train_loss: 31.013988 valid_loss: 33.495117 train_acc: 0.8516691 valid_acc: 0.84518135\n",
      "epoch: 89 train_loss: 30.602188 valid_loss: 33.082928 train_acc: 0.8531108 valid_acc: 0.84651214\n",
      "epoch: 90 train_loss: 30.194344 valid_loss: 32.670635 train_acc: 0.853998 valid_acc: 0.84817564\n",
      "epoch: 91 train_loss: 29.791212 valid_loss: 32.270584 train_acc: 0.8547743 valid_acc: 0.8499501\n",
      "epoch: 92 train_loss: 29.394224 valid_loss: 31.869226 train_acc: 0.8564378 valid_acc: 0.8519463\n",
      "epoch: 93 train_loss: 29.002346 valid_loss: 31.459045 train_acc: 0.8579905 valid_acc: 0.85349894\n",
      "epoch: 94 train_loss: 28.616241 valid_loss: 31.097378 train_acc: 0.8592658 valid_acc: 0.85471886\n",
      "epoch: 95 train_loss: 28.237682 valid_loss: 30.735853 train_acc: 0.86059666 valid_acc: 0.8564933\n",
      "epoch: 96 train_loss: 27.868942 valid_loss: 30.36384 train_acc: 0.8614838 valid_acc: 0.8577132\n",
      "epoch: 97 train_loss: 27.50415 valid_loss: 30.008913 train_acc: 0.8628701 valid_acc: 0.8584895\n",
      "epoch: 98 train_loss: 27.144594 valid_loss: 29.650965 train_acc: 0.8644228 valid_acc: 0.85970944\n",
      "epoch: 99 train_loss: 26.791681 valid_loss: 29.292776 train_acc: 0.86558723 valid_acc: 0.860153\n",
      "epoch: 100 train_loss: 26.444176 valid_loss: 28.956903 train_acc: 0.8664744 valid_acc: 0.8620384\n",
      "epoch: 101 train_loss: 26.10278 valid_loss: 28.626036 train_acc: 0.8677498 valid_acc: 0.8632583\n",
      "epoch: 102 train_loss: 25.771116 valid_loss: 28.28844 train_acc: 0.86896974 valid_acc: 0.86447823\n",
      "epoch: 103 train_loss: 25.446632 valid_loss: 27.964018 train_acc: 0.87007874 valid_acc: 0.86558723\n",
      "epoch: 104 train_loss: 25.13101 valid_loss: 27.655266 train_acc: 0.87174225 valid_acc: 0.86647445\n",
      "epoch: 105 train_loss: 24.818974 valid_loss: 27.33096 train_acc: 0.87285125 valid_acc: 0.86780524\n",
      "epoch: 106 train_loss: 24.511395 valid_loss: 27.012499 train_acc: 0.87362754 valid_acc: 0.86847067\n",
      "epoch: 107 train_loss: 24.210234 valid_loss: 26.73238 train_acc: 0.8749584 valid_acc: 0.8694688\n",
      "epoch: 108 train_loss: 23.916859 valid_loss: 26.469471 train_acc: 0.8762338 valid_acc: 0.8700233\n",
      "epoch: 109 train_loss: 23.629616 valid_loss: 26.183382 train_acc: 0.87739825 valid_acc: 0.8704669\n",
      "epoch: 110 train_loss: 23.350027 valid_loss: 25.867754 train_acc: 0.8786737 valid_acc: 0.871465\n",
      "epoch: 111 train_loss: 23.075642 valid_loss: 25.58555 train_acc: 0.8793945 valid_acc: 0.8730176\n",
      "epoch: 112 train_loss: 22.805029 valid_loss: 25.320843 train_acc: 0.88044804 valid_acc: 0.87457025\n",
      "epoch: 113 train_loss: 22.538532 valid_loss: 25.061304 train_acc: 0.8820007 valid_acc: 0.8757902\n",
      "epoch: 114 train_loss: 22.279892 valid_loss: 24.809034 train_acc: 0.8828324 valid_acc: 0.8767883\n",
      "epoch: 115 train_loss: 22.02785 valid_loss: 24.553738 train_acc: 0.8837751 valid_acc: 0.8778973\n",
      "epoch: 116 train_loss: 21.776506 valid_loss: 24.294481 train_acc: 0.88438505 valid_acc: 0.87878454\n",
      "epoch: 117 train_loss: 21.52706 valid_loss: 24.0433 train_acc: 0.8856604 valid_acc: 0.88011533\n",
      "epoch: 118 train_loss: 21.285488 valid_loss: 23.810116 train_acc: 0.88665855 valid_acc: 0.88122433\n",
      "epoch: 119 train_loss: 21.047668 valid_loss: 23.569796 train_acc: 0.8881557 valid_acc: 0.8820007\n",
      "epoch: 120 train_loss: 20.813189 valid_loss: 23.335005 train_acc: 0.8889874 valid_acc: 0.882777\n",
      "epoch: 121 train_loss: 20.58157 valid_loss: 23.112907 train_acc: 0.8895974 valid_acc: 0.8837751\n",
      "epoch: 122 train_loss: 20.35151 valid_loss: 22.890827 train_acc: 0.8905401 valid_acc: 0.8848841\n",
      "epoch: 123 train_loss: 20.127586 valid_loss: 22.672245 train_acc: 0.8918154 valid_acc: 0.8851059\n",
      "epoch: 124 train_loss: 19.90905 valid_loss: 22.45982 train_acc: 0.8925363 valid_acc: 0.8859931\n",
      "epoch: 125 train_loss: 19.693817 valid_loss: 22.240612 train_acc: 0.89397806 valid_acc: 0.88665855\n",
      "epoch: 126 train_loss: 19.479897 valid_loss: 22.03187 train_acc: 0.89442164 valid_acc: 0.8873239\n",
      "epoch: 127 train_loss: 19.26917 valid_loss: 21.81786 train_acc: 0.8952534 valid_acc: 0.888433\n",
      "epoch: 128 train_loss: 19.064114 valid_loss: 21.605991 train_acc: 0.89619607 valid_acc: 0.889542\n",
      "epoch: 129 train_loss: 18.86139 valid_loss: 21.39674 train_acc: 0.8965842 valid_acc: 0.8900965\n",
      "epoch: 130 train_loss: 18.658993 valid_loss: 21.194864 train_acc: 0.89719415 valid_acc: 0.8913164\n",
      "epoch: 131 train_loss: 18.46233 valid_loss: 20.990463 train_acc: 0.89835864 valid_acc: 0.8920927\n",
      "epoch: 132 train_loss: 18.266039 valid_loss: 20.791363 train_acc: 0.8989686 valid_acc: 0.89253634\n",
      "epoch: 133 train_loss: 18.073708 valid_loss: 20.592838 train_acc: 0.90029943 valid_acc: 0.89364535\n",
      "epoch: 134 train_loss: 17.88427 valid_loss: 20.40158 train_acc: 0.9010757 valid_acc: 0.89386714\n",
      "epoch: 135 train_loss: 17.70066 valid_loss: 20.206545 train_acc: 0.9025729 valid_acc: 0.89475435\n",
      "epoch: 136 train_loss: 17.51848 valid_loss: 20.026487 train_acc: 0.90301657 valid_acc: 0.89608514\n",
      "epoch: 137 train_loss: 17.339924 valid_loss: 19.847958 train_acc: 0.9041256 valid_acc: 0.89641786\n",
      "epoch: 138 train_loss: 17.16194 valid_loss: 19.668976 train_acc: 0.9049573 valid_acc: 0.897416\n",
      "epoch: 139 train_loss: 16.987305 valid_loss: 19.490253 train_acc: 0.9056227 valid_acc: 0.8981923\n",
      "epoch: 140 train_loss: 16.817595 valid_loss: 19.314043 train_acc: 0.90595543 valid_acc: 0.8990795\n",
      "epoch: 141 train_loss: 16.650364 valid_loss: 19.137197 train_acc: 0.90678716 valid_acc: 0.899634\n",
      "epoch: 142 train_loss: 16.48267 valid_loss: 18.966286 train_acc: 0.90756345 valid_acc: 0.90074307\n",
      "epoch: 143 train_loss: 16.316269 valid_loss: 18.796007 train_acc: 0.9083953 valid_acc: 0.90129757\n",
      "epoch: 144 train_loss: 16.152618 valid_loss: 18.631908 train_acc: 0.90928245 valid_acc: 0.90151936\n",
      "epoch: 145 train_loss: 15.991977 valid_loss: 18.478203 train_acc: 0.909837 valid_acc: 0.90207386\n",
      "epoch: 146 train_loss: 15.834211 valid_loss: 18.318039 train_acc: 0.9104469 valid_acc: 0.903072\n",
      "epoch: 147 train_loss: 15.677222 valid_loss: 18.15659 train_acc: 0.9111678 valid_acc: 0.9032938\n",
      "epoch: 148 train_loss: 15.522179 valid_loss: 17.997265 train_acc: 0.912055 valid_acc: 0.90373737\n",
      "epoch: 149 train_loss: 15.3671055 valid_loss: 17.849121 train_acc: 0.91272044 valid_acc: 0.90484643\n",
      "epoch: 150 train_loss: 15.216898 valid_loss: 17.699272 train_acc: 0.9129977 valid_acc: 0.9055118\n",
      "epoch: 151 train_loss: 15.06469 valid_loss: 17.551052 train_acc: 0.913774 valid_acc: 0.90628815\n",
      "epoch: 152 train_loss: 14.917648 valid_loss: 17.396896 train_acc: 0.9148275 valid_acc: 0.90650994\n",
      "epoch: 153 train_loss: 14.770819 valid_loss: 17.25036 train_acc: 0.9153266 valid_acc: 0.90706444\n",
      "epoch: 154 train_loss: 14.62652 valid_loss: 17.114866 train_acc: 0.9157702 valid_acc: 0.90761894\n",
      "epoch: 155 train_loss: 14.4869175 valid_loss: 16.97352 train_acc: 0.91632473 valid_acc: 0.9080626\n",
      "epoch: 156 train_loss: 14.346609 valid_loss: 16.831623 train_acc: 0.9167129 valid_acc: 0.90817344\n",
      "epoch: 157 train_loss: 14.205561 valid_loss: 16.700932 train_acc: 0.91715646 valid_acc: 0.90894973\n",
      "epoch: 158 train_loss: 14.066771 valid_loss: 16.563843 train_acc: 0.91776645 valid_acc: 0.9097261\n",
      "epoch: 159 train_loss: 13.934452 valid_loss: 16.422478 train_acc: 0.9187091 valid_acc: 0.91016966\n",
      "epoch: 160 train_loss: 13.79829 valid_loss: 16.284931 train_acc: 0.9189309 valid_acc: 0.9108351\n",
      "epoch: 161 train_loss: 13.6633005 valid_loss: 16.13944 train_acc: 0.9197627 valid_acc: 0.9112787\n",
      "epoch: 162 train_loss: 13.532452 valid_loss: 15.999868 train_acc: 0.920539 valid_acc: 0.912055\n",
      "epoch: 163 train_loss: 13.4026785 valid_loss: 15.871179 train_acc: 0.9215371 valid_acc: 0.9126095\n",
      "epoch: 164 train_loss: 13.277384 valid_loss: 15.73743 train_acc: 0.92225796 valid_acc: 0.9133858\n",
      "epoch: 165 train_loss: 13.154209 valid_loss: 15.604045 train_acc: 0.9225352 valid_acc: 0.9144949\n",
      "epoch: 166 train_loss: 13.030855 valid_loss: 15.490933 train_acc: 0.92264616 valid_acc: 0.91493845\n",
      "epoch: 167 train_loss: 12.909613 valid_loss: 15.372775 train_acc: 0.92331153 valid_acc: 0.915382\n",
      "epoch: 168 train_loss: 12.791416 valid_loss: 15.242221 train_acc: 0.92392147 valid_acc: 0.9159366\n",
      "epoch: 169 train_loss: 12.67415 valid_loss: 15.116786 train_acc: 0.92453146 valid_acc: 0.91626924\n",
      "epoch: 170 train_loss: 12.558132 valid_loss: 15.003131 train_acc: 0.9247532 valid_acc: 0.9170456\n",
      "epoch: 171 train_loss: 12.442236 valid_loss: 14.897204 train_acc: 0.92530775 valid_acc: 0.9173783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 172 train_loss: 12.329479 valid_loss: 14.779029 train_acc: 0.9259732 valid_acc: 0.9178219\n",
      "epoch: 173 train_loss: 12.217733 valid_loss: 14.660808 train_acc: 0.9266386 valid_acc: 0.9179328\n",
      "epoch: 174 train_loss: 12.107006 valid_loss: 14.549437 train_acc: 0.92735946 valid_acc: 0.9182655\n",
      "epoch: 175 train_loss: 11.99752 valid_loss: 14.434343 train_acc: 0.9279694 valid_acc: 0.9189309\n",
      "epoch: 176 train_loss: 11.89092 valid_loss: 14.315993 train_acc: 0.92857933 valid_acc: 0.9195963\n",
      "epoch: 177 train_loss: 11.783695 valid_loss: 14.211712 train_acc: 0.9291339 valid_acc: 0.9198181\n",
      "epoch: 178 train_loss: 11.678003 valid_loss: 14.109973 train_acc: 0.9296329 valid_acc: 0.92026174\n",
      "epoch: 179 train_loss: 11.574734 valid_loss: 13.998531 train_acc: 0.93018746 valid_acc: 0.92059445\n",
      "epoch: 180 train_loss: 11.471933 valid_loss: 13.884702 train_acc: 0.9310746 valid_acc: 0.92103803\n",
      "epoch: 181 train_loss: 11.370491 valid_loss: 13.780915 train_acc: 0.931241 valid_acc: 0.92103803\n",
      "epoch: 182 train_loss: 11.270102 valid_loss: 13.682269 train_acc: 0.9316292 valid_acc: 0.92114896\n",
      "epoch: 183 train_loss: 11.170397 valid_loss: 13.581237 train_acc: 0.9321836 valid_acc: 0.92159253\n",
      "epoch: 184 train_loss: 11.071146 valid_loss: 13.476765 train_acc: 0.9329045 valid_acc: 0.9220362\n",
      "epoch: 185 train_loss: 10.973946 valid_loss: 13.378804 train_acc: 0.9334036 valid_acc: 0.92214704\n",
      "epoch: 186 train_loss: 10.877162 valid_loss: 13.2811775 train_acc: 0.9338472 valid_acc: 0.92270154\n",
      "epoch: 187 train_loss: 10.780877 valid_loss: 13.176442 train_acc: 0.9343462 valid_acc: 0.9232561\n",
      "epoch: 188 train_loss: 10.687458 valid_loss: 13.06787 train_acc: 0.9346789 valid_acc: 0.9236997\n",
      "epoch: 189 train_loss: 10.594137 valid_loss: 12.9662 train_acc: 0.9352889 valid_acc: 0.92392147\n",
      "epoch: 190 train_loss: 10.502729 valid_loss: 12.870616 train_acc: 0.9360652 valid_acc: 0.92447597\n",
      "epoch: 191 train_loss: 10.413544 valid_loss: 12.7821865 train_acc: 0.9363979 valid_acc: 0.9245869\n",
      "epoch: 192 train_loss: 10.32564 valid_loss: 12.691146 train_acc: 0.93711877 valid_acc: 0.9252523\n",
      "epoch: 193 train_loss: 10.2389145 valid_loss: 12.603093 train_acc: 0.9371742 valid_acc: 0.9256959\n",
      "epoch: 194 train_loss: 10.152792 valid_loss: 12.517583 train_acc: 0.93756235 valid_acc: 0.92613953\n",
      "epoch: 195 train_loss: 10.067822 valid_loss: 12.431483 train_acc: 0.93772876 valid_acc: 0.9263613\n",
      "epoch: 196 train_loss: 9.982926 valid_loss: 12.350274 train_acc: 0.93850505 valid_acc: 0.9269158\n",
      "epoch: 197 train_loss: 9.900643 valid_loss: 12.266774 train_acc: 0.93883777 valid_acc: 0.92724854\n",
      "epoch: 198 train_loss: 9.818946 valid_loss: 12.181419 train_acc: 0.93928134 valid_acc: 0.92758125\n",
      "epoch: 199 train_loss: 9.738163 valid_loss: 12.091958 train_acc: 0.9397249 valid_acc: 0.92791396\n",
      "epoch: 200 train_loss: 9.657619 valid_loss: 12.000478 train_acc: 0.93961406 valid_acc: 0.9282466\n",
      "epoch: 201 train_loss: 9.579657 valid_loss: 11.919453 train_acc: 0.9403349 valid_acc: 0.92835754\n",
      "epoch: 202 train_loss: 9.503366 valid_loss: 11.844096 train_acc: 0.9406676 valid_acc: 0.92857933\n",
      "epoch: 203 train_loss: 9.427317 valid_loss: 11.772474 train_acc: 0.9414439 valid_acc: 0.92891204\n",
      "epoch: 204 train_loss: 9.352533 valid_loss: 11.681231 train_acc: 0.94183207 valid_acc: 0.92924476\n",
      "epoch: 205 train_loss: 9.277879 valid_loss: 11.596848 train_acc: 0.94188756 valid_acc: 0.92924476\n",
      "epoch: 206 train_loss: 9.204914 valid_loss: 11.514738 train_acc: 0.9423312 valid_acc: 0.92979926\n",
      "epoch: 207 train_loss: 9.132492 valid_loss: 11.432994 train_acc: 0.94266385 valid_acc: 0.93002105\n",
      "epoch: 208 train_loss: 9.060333 valid_loss: 11.355831 train_acc: 0.9427193 valid_acc: 0.9304647\n",
      "epoch: 209 train_loss: 8.989126 valid_loss: 11.283912 train_acc: 0.9431629 valid_acc: 0.93090826\n",
      "epoch: 210 train_loss: 8.917676 valid_loss: 11.211162 train_acc: 0.9433293 valid_acc: 0.9315737\n",
      "epoch: 211 train_loss: 8.847322 valid_loss: 11.1387415 train_acc: 0.9439392 valid_acc: 0.9316846\n",
      "epoch: 212 train_loss: 8.778183 valid_loss: 11.069235 train_acc: 0.9442719 valid_acc: 0.9321282\n",
      "epoch: 213 train_loss: 8.709547 valid_loss: 11.001541 train_acc: 0.9447155 valid_acc: 0.9324609\n",
      "epoch: 214 train_loss: 8.64222 valid_loss: 10.927969 train_acc: 0.9452146 valid_acc: 0.93290454\n",
      "epoch: 215 train_loss: 8.575108 valid_loss: 10.860832 train_acc: 0.9456028 valid_acc: 0.9333481\n",
      "epoch: 216 train_loss: 8.509617 valid_loss: 10.7952175 train_acc: 0.9462127 valid_acc: 0.9335699\n",
      "epoch: 217 train_loss: 8.44459 valid_loss: 10.73231 train_acc: 0.9462127 valid_acc: 0.93368083\n",
      "epoch: 218 train_loss: 8.379528 valid_loss: 10.668367 train_acc: 0.94648993 valid_acc: 0.93423533\n",
      "epoch: 219 train_loss: 8.315176 valid_loss: 10.600908 train_acc: 0.9470999 valid_acc: 0.9341244\n",
      "epoch: 220 train_loss: 8.251718 valid_loss: 10.532692 train_acc: 0.94743264 valid_acc: 0.93456805\n",
      "epoch: 221 train_loss: 8.188547 valid_loss: 10.468043 train_acc: 0.9477099 valid_acc: 0.93512255\n",
      "epoch: 222 train_loss: 8.1261425 valid_loss: 10.408364 train_acc: 0.94798714 valid_acc: 0.93534434\n",
      "epoch: 223 train_loss: 8.064265 valid_loss: 10.348955 train_acc: 0.9483753 valid_acc: 0.9355661\n",
      "epoch: 224 train_loss: 8.003275 valid_loss: 10.283215 train_acc: 0.94887435 valid_acc: 0.935788\n",
      "epoch: 225 train_loss: 7.9435415 valid_loss: 10.219133 train_acc: 0.9494843 valid_acc: 0.935788\n",
      "epoch: 226 train_loss: 7.884775 valid_loss: 10.161825 train_acc: 0.9498725 valid_acc: 0.9363425\n",
      "epoch: 227 train_loss: 7.8267565 valid_loss: 10.107056 train_acc: 0.9498725 valid_acc: 0.93700784\n",
      "epoch: 228 train_loss: 7.769588 valid_loss: 10.0454035 train_acc: 0.949817 valid_acc: 0.9376733\n",
      "epoch: 229 train_loss: 7.7122855 valid_loss: 9.987419 train_acc: 0.95026064 valid_acc: 0.9381169\n",
      "epoch: 230 train_loss: 7.6561255 valid_loss: 9.929307 train_acc: 0.9506488 valid_acc: 0.9381169\n",
      "epoch: 231 train_loss: 7.6002207 valid_loss: 9.876189 train_acc: 0.95075965 valid_acc: 0.9381169\n",
      "epoch: 232 train_loss: 7.5464664 valid_loss: 9.814806 train_acc: 0.9509815 valid_acc: 0.9385605\n",
      "epoch: 233 train_loss: 7.4916806 valid_loss: 9.764429 train_acc: 0.9513142 valid_acc: 0.939115\n",
      "epoch: 234 train_loss: 7.439251 valid_loss: 9.703137 train_acc: 0.9517578 valid_acc: 0.9387823\n",
      "epoch: 235 train_loss: 7.385273 valid_loss: 9.649105 train_acc: 0.95192415 valid_acc: 0.93933684\n",
      "epoch: 236 train_loss: 7.333334 valid_loss: 9.5938835 train_acc: 0.95214593 valid_acc: 0.93933684\n",
      "epoch: 237 train_loss: 7.2819815 valid_loss: 9.535212 train_acc: 0.9525341 valid_acc: 0.9394477\n",
      "epoch: 238 train_loss: 7.2309303 valid_loss: 9.479811 train_acc: 0.9529777 valid_acc: 0.940224\n",
      "epoch: 239 train_loss: 7.1809235 valid_loss: 9.4214525 train_acc: 0.9529222 valid_acc: 0.9406676\n",
      "epoch: 240 train_loss: 7.1311655 valid_loss: 9.3628025 train_acc: 0.9531995 valid_acc: 0.9406676\n",
      "epoch: 241 train_loss: 7.081956 valid_loss: 9.308656 train_acc: 0.95358765 valid_acc: 0.9411112\n",
      "epoch: 242 train_loss: 7.0333714 valid_loss: 9.2579975 train_acc: 0.95386493 valid_acc: 0.9414439\n",
      "epoch: 243 train_loss: 6.98465 valid_loss: 9.206908 train_acc: 0.95419765 valid_acc: 0.94155484\n",
      "epoch: 244 train_loss: 6.9364843 valid_loss: 9.155397 train_acc: 0.95475215 valid_acc: 0.94177663\n",
      "epoch: 245 train_loss: 6.8891883 valid_loss: 9.10612 train_acc: 0.9546412 valid_acc: 0.9419984\n",
      "epoch: 246 train_loss: 6.8419027 valid_loss: 9.058483 train_acc: 0.95502937 valid_acc: 0.9422203\n",
      "epoch: 247 train_loss: 6.795059 valid_loss: 9.008725 train_acc: 0.95502937 valid_acc: 0.94233114\n",
      "epoch: 248 train_loss: 6.7485814 valid_loss: 8.956302 train_acc: 0.95558393 valid_acc: 0.942553\n",
      "epoch: 249 train_loss: 6.7024374 valid_loss: 8.901162 train_acc: 0.9554175 valid_acc: 0.94288564\n",
      "epoch: 250 train_loss: 6.6565037 valid_loss: 8.848623 train_acc: 0.9557502 valid_acc: 0.9433293\n",
      "epoch: 251 train_loss: 6.611132 valid_loss: 8.800433 train_acc: 0.9563048 valid_acc: 0.94355106\n",
      "epoch: 252 train_loss: 6.56605 valid_loss: 8.755977 train_acc: 0.9563048 valid_acc: 0.94355106\n",
      "epoch: 253 train_loss: 6.5213747 valid_loss: 8.713188 train_acc: 0.9565266 valid_acc: 0.94377285\n",
      "epoch: 254 train_loss: 6.477207 valid_loss: 8.667994 train_acc: 0.9566375 valid_acc: 0.94377285\n",
      "epoch: 255 train_loss: 6.4331865 valid_loss: 8.618847 train_acc: 0.95697016 valid_acc: 0.94410557\n",
      "epoch: 256 train_loss: 6.389634 valid_loss: 8.568087 train_acc: 0.9572474 valid_acc: 0.9445492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 257 train_loss: 6.346431 valid_loss: 8.518897 train_acc: 0.9574692 valid_acc: 0.9451037\n",
      "epoch: 258 train_loss: 6.303527 valid_loss: 8.475075 train_acc: 0.9579683 valid_acc: 0.9453255\n",
      "epoch: 259 train_loss: 6.261119 valid_loss: 8.431366 train_acc: 0.9581901 valid_acc: 0.9456582\n",
      "epoch: 260 train_loss: 6.2195125 valid_loss: 8.384898 train_acc: 0.95846736 valid_acc: 0.94588\n",
      "epoch: 261 train_loss: 6.1781425 valid_loss: 8.337752 train_acc: 0.9588001 valid_acc: 0.9459909\n",
      "epoch: 262 train_loss: 6.137 valid_loss: 8.294894 train_acc: 0.9589664 valid_acc: 0.94588\n",
      "epoch: 263 train_loss: 6.0966096 valid_loss: 8.252884 train_acc: 0.9591882 valid_acc: 0.9462127\n",
      "epoch: 264 train_loss: 6.055725 valid_loss: 8.211405 train_acc: 0.9596318 valid_acc: 0.9464345\n",
      "epoch: 265 train_loss: 6.0156817 valid_loss: 8.1668415 train_acc: 0.95979816 valid_acc: 0.9465454\n",
      "epoch: 266 train_loss: 5.976445 valid_loss: 8.122058 train_acc: 0.9601309 valid_acc: 0.9466563\n",
      "epoch: 267 train_loss: 5.937119 valid_loss: 8.081701 train_acc: 0.9605745 valid_acc: 0.9467672\n",
      "epoch: 268 train_loss: 5.8983264 valid_loss: 8.041023 train_acc: 0.9608517 valid_acc: 0.946989\n",
      "epoch: 269 train_loss: 5.85958 valid_loss: 8.003178 train_acc: 0.96096265 valid_acc: 0.9473217\n",
      "epoch: 270 train_loss: 5.821988 valid_loss: 7.9552193 train_acc: 0.96112895 valid_acc: 0.9473217\n",
      "epoch: 271 train_loss: 5.7834535 valid_loss: 7.9173646 train_acc: 0.9615171 valid_acc: 0.9473217\n",
      "epoch: 272 train_loss: 5.7465973 valid_loss: 7.867204 train_acc: 0.9616281 valid_acc: 0.94743264\n",
      "epoch: 273 train_loss: 5.7082644 valid_loss: 7.830458 train_acc: 0.9620162 valid_acc: 0.94776535\n",
      "epoch: 274 train_loss: 5.6712933 valid_loss: 7.787142 train_acc: 0.9617944 valid_acc: 0.94809806\n",
      "epoch: 275 train_loss: 5.6343446 valid_loss: 7.7470922 train_acc: 0.9621825 valid_acc: 0.9482089\n",
      "epoch: 276 train_loss: 5.5979633 valid_loss: 7.7023225 train_acc: 0.96223795 valid_acc: 0.9482089\n",
      "epoch: 277 train_loss: 5.5615883 valid_loss: 7.6614738 train_acc: 0.96229345 valid_acc: 0.9484307\n",
      "epoch: 278 train_loss: 5.5263386 valid_loss: 7.616607 train_acc: 0.9623489 valid_acc: 0.94865257\n",
      "epoch: 279 train_loss: 5.4904833 valid_loss: 7.583351 train_acc: 0.96262616 valid_acc: 0.94887435\n",
      "epoch: 280 train_loss: 5.45646 valid_loss: 7.5375066 train_acc: 0.9627925 valid_acc: 0.9489853\n",
      "epoch: 281 train_loss: 5.4208508 valid_loss: 7.5028644 train_acc: 0.96318066 valid_acc: 0.94931793\n",
      "epoch: 282 train_loss: 5.3868732 valid_loss: 7.455707 train_acc: 0.9632361 valid_acc: 0.94942886\n",
      "epoch: 283 train_loss: 5.353018 valid_loss: 7.412582 train_acc: 0.96362424 valid_acc: 0.9495398\n",
      "epoch: 284 train_loss: 5.31971 valid_loss: 7.366308 train_acc: 0.9635134 valid_acc: 0.94976157\n",
      "epoch: 285 train_loss: 5.286374 valid_loss: 7.3346224 train_acc: 0.9639015 valid_acc: 0.94987243\n",
      "epoch: 286 train_loss: 5.25432 valid_loss: 7.288263 train_acc: 0.96373516 valid_acc: 0.95020515\n",
      "epoch: 287 train_loss: 5.220151 valid_loss: 7.2547965 train_acc: 0.9641788 valid_acc: 0.9503161\n",
      "epoch: 288 train_loss: 5.188115 valid_loss: 7.2187414 train_acc: 0.96428967 valid_acc: 0.95075965\n",
      "epoch: 289 train_loss: 5.156557 valid_loss: 7.1758432 train_acc: 0.9641788 valid_acc: 0.95109236\n",
      "epoch: 290 train_loss: 5.1242685 valid_loss: 7.138697 train_acc: 0.96456695 valid_acc: 0.9509815\n",
      "epoch: 291 train_loss: 5.0927496 valid_loss: 7.104304 train_acc: 0.96489966 valid_acc: 0.9513142\n",
      "epoch: 292 train_loss: 5.062157 valid_loss: 7.0538836 train_acc: 0.9649551 valid_acc: 0.951536\n",
      "epoch: 293 train_loss: 5.0297384 valid_loss: 7.0169077 train_acc: 0.9655096 valid_acc: 0.9518687\n",
      "epoch: 294 train_loss: 4.9994273 valid_loss: 6.9913764 train_acc: 0.9656205 valid_acc: 0.9519796\n",
      "epoch: 295 train_loss: 4.969266 valid_loss: 6.95232 train_acc: 0.9655096 valid_acc: 0.9524232\n",
      "epoch: 296 train_loss: 4.9378505 valid_loss: 6.9105186 train_acc: 0.9658423 valid_acc: 0.9524232\n",
      "epoch: 297 train_loss: 4.9082565 valid_loss: 6.8763695 train_acc: 0.9660641 valid_acc: 0.952645\n",
      "epoch: 298 train_loss: 4.8782797 valid_loss: 6.8399453 train_acc: 0.9661195 valid_acc: 0.9527559\n",
      "epoch: 299 train_loss: 4.848036 valid_loss: 6.805116 train_acc: 0.9665077 valid_acc: 0.95331043\n",
      "epoch: 300 train_loss: 4.8176904 valid_loss: 6.769087 train_acc: 0.9663414 valid_acc: 0.9531995\n",
      "epoch: 301 train_loss: 4.788289 valid_loss: 6.733407 train_acc: 0.9669513 valid_acc: 0.9530886\n",
      "epoch: 302 train_loss: 4.759101 valid_loss: 6.7015724 train_acc: 0.9670068 valid_acc: 0.9531995\n",
      "epoch: 303 train_loss: 4.7295856 valid_loss: 6.669886 train_acc: 0.9672286 valid_acc: 0.9534213\n",
      "epoch: 304 train_loss: 4.7005053 valid_loss: 6.6371646 train_acc: 0.9675058 valid_acc: 0.9535322\n",
      "epoch: 305 train_loss: 4.6717334 valid_loss: 6.6058226 train_acc: 0.9676167 valid_acc: 0.9539758\n",
      "epoch: 306 train_loss: 4.642933 valid_loss: 6.576231 train_acc: 0.9677831 valid_acc: 0.9539758\n",
      "epoch: 307 train_loss: 4.6141 valid_loss: 6.5459723 train_acc: 0.9677831 valid_acc: 0.9540867\n",
      "epoch: 308 train_loss: 4.5850606 valid_loss: 6.513245 train_acc: 0.96789396 valid_acc: 0.9543085\n",
      "epoch: 309 train_loss: 4.556279 valid_loss: 6.4808216 train_acc: 0.96817124 valid_acc: 0.95441943\n",
      "epoch: 310 train_loss: 4.527909 valid_loss: 6.4475036 train_acc: 0.9682267 valid_acc: 0.95441943\n",
      "epoch: 311 train_loss: 4.499955 valid_loss: 6.41642 train_acc: 0.96833754 valid_acc: 0.95441943\n",
      "epoch: 312 train_loss: 4.4719887 valid_loss: 6.388508 train_acc: 0.9682267 valid_acc: 0.9546412\n",
      "epoch: 313 train_loss: 4.4437027 valid_loss: 6.3593225 train_acc: 0.9684485 valid_acc: 0.95497394\n",
      "epoch: 314 train_loss: 4.415904 valid_loss: 6.3278713 train_acc: 0.9686148 valid_acc: 0.95508486\n",
      "epoch: 315 train_loss: 4.388393 valid_loss: 6.295334 train_acc: 0.96900296 valid_acc: 0.95508486\n",
      "epoch: 316 train_loss: 4.361388 valid_loss: 6.263866 train_acc: 0.9691694 valid_acc: 0.95497394\n",
      "epoch: 317 train_loss: 4.3348656 valid_loss: 6.2362275 train_acc: 0.9694466 valid_acc: 0.95508486\n",
      "epoch: 318 train_loss: 4.308356 valid_loss: 6.2126565 train_acc: 0.9695575 valid_acc: 0.95552844\n",
      "epoch: 319 train_loss: 4.2825055 valid_loss: 6.1895266 train_acc: 0.9695021 valid_acc: 0.9557502\n",
      "epoch: 320 train_loss: 4.257141 valid_loss: 6.165215 train_acc: 0.9695575 valid_acc: 0.95586115\n",
      "epoch: 321 train_loss: 4.2320232 valid_loss: 6.139276 train_acc: 0.9697238 valid_acc: 0.95619386\n",
      "epoch: 322 train_loss: 4.2070174 valid_loss: 6.1130853 train_acc: 0.9696684 valid_acc: 0.9563047\n",
      "epoch: 323 train_loss: 4.181642 valid_loss: 6.08859 train_acc: 0.9700011 valid_acc: 0.95608294\n",
      "epoch: 324 train_loss: 4.15691 valid_loss: 6.064027 train_acc: 0.96989024 valid_acc: 0.95641565\n",
      "epoch: 325 train_loss: 4.1321106 valid_loss: 6.039977 train_acc: 0.97022295 valid_acc: 0.95663744\n",
      "epoch: 326 train_loss: 4.1079316 valid_loss: 6.016233 train_acc: 0.97022295 valid_acc: 0.95663744\n",
      "epoch: 327 train_loss: 4.08319 valid_loss: 5.9932785 train_acc: 0.9703338 valid_acc: 0.95674837\n",
      "epoch: 328 train_loss: 4.058798 valid_loss: 5.9697037 train_acc: 0.9703338 valid_acc: 0.95674837\n",
      "epoch: 329 train_loss: 4.0345254 valid_loss: 5.9461184 train_acc: 0.9706665 valid_acc: 0.95719194\n",
      "epoch: 330 train_loss: 4.0106745 valid_loss: 5.9233155 train_acc: 0.9706665 valid_acc: 0.9577465\n",
      "epoch: 331 train_loss: 3.986959 valid_loss: 5.900341 train_acc: 0.9708883 valid_acc: 0.9577465\n",
      "epoch: 332 train_loss: 3.9633167 valid_loss: 5.879605 train_acc: 0.9711101 valid_acc: 0.9577465\n",
      "epoch: 333 train_loss: 3.9398189 valid_loss: 5.858949 train_acc: 0.97133195 valid_acc: 0.9578574\n",
      "epoch: 334 train_loss: 3.9164033 valid_loss: 5.8370433 train_acc: 0.9714428 valid_acc: 0.9579683\n",
      "epoch: 335 train_loss: 3.8937664 valid_loss: 5.8138986 train_acc: 0.97166467 valid_acc: 0.9584119\n",
      "epoch: 336 train_loss: 3.8713632 valid_loss: 5.79083 train_acc: 0.97166467 valid_acc: 0.9584119\n",
      "epoch: 337 train_loss: 3.8490515 valid_loss: 5.769614 train_acc: 0.97177553 valid_acc: 0.9588555\n",
      "epoch: 338 train_loss: 3.8272958 valid_loss: 5.746849 train_acc: 0.9720528 valid_acc: 0.9591882\n",
      "epoch: 339 train_loss: 3.805818 valid_loss: 5.720908 train_acc: 0.9722746 valid_acc: 0.9591882\n",
      "epoch: 340 train_loss: 3.7845964 valid_loss: 5.69569 train_acc: 0.9723855 valid_acc: 0.9592991\n",
      "epoch: 341 train_loss: 3.7627344 valid_loss: 5.668412 train_acc: 0.9725518 valid_acc: 0.9592991\n",
      "epoch: 342 train_loss: 3.7425888 valid_loss: 5.646365 train_acc: 0.9725518 valid_acc: 0.9592991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 343 train_loss: 3.7208529 valid_loss: 5.622283 train_acc: 0.97288454 valid_acc: 0.9592991\n",
      "epoch: 344 train_loss: 3.7003145 valid_loss: 5.598086 train_acc: 0.97299546 valid_acc: 0.9597427\n",
      "epoch: 345 train_loss: 3.679484 valid_loss: 5.571985 train_acc: 0.9731064 valid_acc: 0.9598536\n",
      "epoch: 346 train_loss: 3.6590304 valid_loss: 5.548875 train_acc: 0.9733836 valid_acc: 0.9599645\n",
      "epoch: 347 train_loss: 3.6385689 valid_loss: 5.5250983 train_acc: 0.9733282 valid_acc: 0.9602972\n",
      "epoch: 348 train_loss: 3.6185656 valid_loss: 5.502196 train_acc: 0.9733281 valid_acc: 0.9607408\n",
      "epoch: 349 train_loss: 3.5984383 valid_loss: 5.479993 train_acc: 0.97354996 valid_acc: 0.96118444\n",
      "epoch: 350 train_loss: 3.578201 valid_loss: 5.4586363 train_acc: 0.9733836 valid_acc: 0.9612953\n",
      "epoch: 351 train_loss: 3.558845 valid_loss: 5.434724 train_acc: 0.9736608 valid_acc: 0.96140623\n",
      "epoch: 352 train_loss: 3.538525 valid_loss: 5.4094057 train_acc: 0.9736608 valid_acc: 0.9612953\n",
      "epoch: 353 train_loss: 3.5193987 valid_loss: 5.38438 train_acc: 0.97377175 valid_acc: 0.96151716\n",
      "epoch: 354 train_loss: 3.4996662 valid_loss: 5.362798 train_acc: 0.97382724 valid_acc: 0.96151716\n",
      "epoch: 355 train_loss: 3.480527 valid_loss: 5.340643 train_acc: 0.974049 valid_acc: 0.961628\n",
      "epoch: 356 train_loss: 3.4610848 valid_loss: 5.32104 train_acc: 0.97410446 valid_acc: 0.961628\n",
      "epoch: 357 train_loss: 3.4430285 valid_loss: 5.298295 train_acc: 0.9744372 valid_acc: 0.96173894\n",
      "epoch: 358 train_loss: 3.4233065 valid_loss: 5.2758546 train_acc: 0.9742708 valid_acc: 0.96184987\n",
      "epoch: 359 train_loss: 3.4059439 valid_loss: 5.255383 train_acc: 0.9747699 valid_acc: 0.9621825\n",
      "epoch: 360 train_loss: 3.3860033 valid_loss: 5.2314744 train_acc: 0.97488075 valid_acc: 0.96184987\n",
      "epoch: 361 train_loss: 3.3679304 valid_loss: 5.212631 train_acc: 0.9750471 valid_acc: 0.9621825\n",
      "epoch: 362 train_loss: 3.3503742 valid_loss: 5.1894035 train_acc: 0.97510254 valid_acc: 0.96207166\n",
      "epoch: 363 train_loss: 3.3309467 valid_loss: 5.168915 train_acc: 0.9752135 valid_acc: 0.96229345\n",
      "epoch: 364 train_loss: 3.3160198 valid_loss: 5.1478157 train_acc: 0.9753798 valid_acc: 0.96229345\n",
      "epoch: 365 train_loss: 3.2959418 valid_loss: 5.127175 train_acc: 0.97571254 valid_acc: 0.96251523\n",
      "epoch: 366 train_loss: 3.2812352 valid_loss: 5.1065545 train_acc: 0.97576797 valid_acc: 0.962737\n",
      "epoch: 367 train_loss: 3.2636867 valid_loss: 5.0874877 train_acc: 0.9758789 valid_acc: 0.96306974\n",
      "epoch: 368 train_loss: 3.246292 valid_loss: 5.0642614 train_acc: 0.9759898 valid_acc: 0.9629589\n",
      "epoch: 369 train_loss: 3.231462 valid_loss: 5.0510855 train_acc: 0.97604525 valid_acc: 0.96306974\n",
      "epoch: 370 train_loss: 3.2162175 valid_loss: 5.034301 train_acc: 0.9759898 valid_acc: 0.96340245\n",
      "epoch: 371 train_loss: 3.1974466 valid_loss: 5.0113597 train_acc: 0.97659975 valid_acc: 0.96318066\n",
      "epoch: 372 train_loss: 3.18223 valid_loss: 4.991068 train_acc: 0.9762671 valid_acc: 0.96340245\n",
      "epoch: 373 train_loss: 3.167376 valid_loss: 4.973942 train_acc: 0.9767661 valid_acc: 0.96362424\n",
      "epoch: 374 train_loss: 3.152563 valid_loss: 4.9617352 train_acc: 0.9766552 valid_acc: 0.9638461\n",
      "epoch: 375 train_loss: 3.1337218 valid_loss: 4.9412637 train_acc: 0.9769324 valid_acc: 0.9635134\n",
      "epoch: 376 train_loss: 3.120655 valid_loss: 4.923457 train_acc: 0.9767661 valid_acc: 0.9638461\n",
      "epoch: 377 train_loss: 3.1053562 valid_loss: 4.9101496 train_acc: 0.97715425 valid_acc: 0.96451145\n",
      "epoch: 378 train_loss: 3.0896559 valid_loss: 4.88637 train_acc: 0.9772097 valid_acc: 0.96451145\n",
      "epoch: 379 train_loss: 3.072666 valid_loss: 4.8700495 train_acc: 0.97743154 valid_acc: 0.9644006\n",
      "epoch: 380 train_loss: 3.0609019 valid_loss: 4.8549986 train_acc: 0.9772097 valid_acc: 0.9646224\n",
      "epoch: 381 train_loss: 3.042911 valid_loss: 4.836538 train_acc: 0.9778197 valid_acc: 0.96484417\n",
      "epoch: 382 train_loss: 3.029747 valid_loss: 4.821106 train_acc: 0.9776533 valid_acc: 0.9647333\n",
      "epoch: 383 train_loss: 3.0140986 valid_loss: 4.8077865 train_acc: 0.977986 valid_acc: 0.9649551\n",
      "epoch: 384 train_loss: 2.999967 valid_loss: 4.7862787 train_acc: 0.9778197 valid_acc: 0.965066\n",
      "epoch: 385 train_loss: 2.986661 valid_loss: 4.770662 train_acc: 0.9784297 valid_acc: 0.9651769\n",
      "epoch: 386 train_loss: 2.9714136 valid_loss: 4.756576 train_acc: 0.97854054 valid_acc: 0.9651769\n",
      "epoch: 387 train_loss: 2.957745 valid_loss: 4.740422 train_acc: 0.97854054 valid_acc: 0.9651769\n",
      "epoch: 388 train_loss: 2.943586 valid_loss: 4.725289 train_acc: 0.97854054 valid_acc: 0.965066\n",
      "epoch: 389 train_loss: 2.929429 valid_loss: 4.706153 train_acc: 0.9787623 valid_acc: 0.9651769\n",
      "epoch: 390 train_loss: 2.9161353 valid_loss: 4.690442 train_acc: 0.97870684 valid_acc: 0.965066\n",
      "epoch: 391 train_loss: 2.903522 valid_loss: 4.677079 train_acc: 0.9789841 valid_acc: 0.965066\n",
      "epoch: 392 train_loss: 2.8895023 valid_loss: 4.663231 train_acc: 0.9789841 valid_acc: 0.9652878\n",
      "epoch: 393 train_loss: 2.8765583 valid_loss: 4.6434875 train_acc: 0.97887325 valid_acc: 0.96539867\n",
      "epoch: 394 train_loss: 2.86302 valid_loss: 4.630183 train_acc: 0.97903955 valid_acc: 0.9655096\n",
      "epoch: 395 train_loss: 2.85052 valid_loss: 4.6140194 train_acc: 0.9794832 valid_acc: 0.96539867\n",
      "epoch: 396 train_loss: 2.8373427 valid_loss: 4.5985293 train_acc: 0.97942775 valid_acc: 0.9656205\n",
      "epoch: 397 train_loss: 2.824132 valid_loss: 4.585111 train_acc: 0.979705 valid_acc: 0.9656205\n",
      "epoch: 398 train_loss: 2.8119109 valid_loss: 4.569042 train_acc: 0.97964954 valid_acc: 0.9657314\n",
      "epoch: 399 train_loss: 2.7998524 valid_loss: 4.55399 train_acc: 0.979705 valid_acc: 0.9660641\n",
      "epoch: 400 train_loss: 2.7867575 valid_loss: 4.5426903 train_acc: 0.979705 valid_acc: 0.9660641\n",
      "epoch: 401 train_loss: 2.774825 valid_loss: 4.5225782 train_acc: 0.979705 valid_acc: 0.9663968\n",
      "epoch: 402 train_loss: 2.762914 valid_loss: 4.507803 train_acc: 0.97976047 valid_acc: 0.9663968\n",
      "epoch: 403 train_loss: 2.7502036 valid_loss: 4.497873 train_acc: 0.97998226 valid_acc: 0.96650773\n",
      "epoch: 404 train_loss: 2.738206 valid_loss: 4.4795346 train_acc: 0.9799268 valid_acc: 0.9663968\n",
      "epoch: 405 train_loss: 2.7269056 valid_loss: 4.4620056 train_acc: 0.98025954 valid_acc: 0.9666186\n",
      "epoch: 406 train_loss: 2.7128983 valid_loss: 4.453993 train_acc: 0.97998226 valid_acc: 0.9668404\n",
      "epoch: 407 train_loss: 2.7010596 valid_loss: 4.4354825 train_acc: 0.9800931 valid_acc: 0.96706223\n",
      "epoch: 408 train_loss: 2.6892233 valid_loss: 4.420685 train_acc: 0.98042583 valid_acc: 0.9671731\n",
      "epoch: 409 train_loss: 2.6765604 valid_loss: 4.411629 train_acc: 0.98025954 valid_acc: 0.96706223\n",
      "epoch: 410 train_loss: 2.6656175 valid_loss: 4.3919783 train_acc: 0.98020405 valid_acc: 0.96706223\n",
      "epoch: 411 train_loss: 2.6534615 valid_loss: 4.380942 train_acc: 0.98042583 valid_acc: 0.96706223\n",
      "epoch: 412 train_loss: 2.639967 valid_loss: 4.3700213 train_acc: 0.9801486 valid_acc: 0.9671731\n",
      "epoch: 413 train_loss: 2.6297064 valid_loss: 4.3509636 train_acc: 0.98042583 valid_acc: 0.967284\n",
      "epoch: 414 train_loss: 2.6166382 valid_loss: 4.3431096 train_acc: 0.98048127 valid_acc: 0.9671731\n",
      "epoch: 415 train_loss: 2.6055937 valid_loss: 4.324037 train_acc: 0.9803704 valid_acc: 0.9675058\n",
      "epoch: 416 train_loss: 2.593016 valid_loss: 4.310249 train_acc: 0.98059225 valid_acc: 0.9675058\n",
      "epoch: 417 train_loss: 2.5806584 valid_loss: 4.2965555 train_acc: 0.98048127 valid_acc: 0.9675058\n",
      "epoch: 418 train_loss: 2.5695648 valid_loss: 4.280894 train_acc: 0.9809249 valid_acc: 0.96761674\n",
      "epoch: 419 train_loss: 2.557303 valid_loss: 4.270094 train_acc: 0.98053676 valid_acc: 0.96761674\n",
      "epoch: 420 train_loss: 2.5450394 valid_loss: 4.2524686 train_acc: 0.980814 valid_acc: 0.9678385\n",
      "epoch: 421 train_loss: 2.5339947 valid_loss: 4.2455072 train_acc: 0.9807031 valid_acc: 0.9678385\n",
      "epoch: 422 train_loss: 2.521822 valid_loss: 4.227463 train_acc: 0.9809249 valid_acc: 0.9680603\n",
      "epoch: 423 train_loss: 2.5108972 valid_loss: 4.213387 train_acc: 0.98081404 valid_acc: 0.96817124\n",
      "epoch: 424 train_loss: 2.4976974 valid_loss: 4.2043386 train_acc: 0.9812576 valid_acc: 0.96817124\n",
      "epoch: 425 train_loss: 2.4870586 valid_loss: 4.191848 train_acc: 0.9811467 valid_acc: 0.96817124\n",
      "epoch: 426 train_loss: 2.4743156 valid_loss: 4.1752024 train_acc: 0.9814794 valid_acc: 0.96828216\n",
      "epoch: 427 train_loss: 2.4644458 valid_loss: 4.165301 train_acc: 0.9813131 valid_acc: 0.968393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 428 train_loss: 2.4509912 valid_loss: 4.155894 train_acc: 0.9817567 valid_acc: 0.96828216\n",
      "epoch: 429 train_loss: 2.4410872 valid_loss: 4.1398025 train_acc: 0.9812576 valid_acc: 0.968393\n",
      "epoch: 430 train_loss: 2.4293065 valid_loss: 4.126975 train_acc: 0.98159033 valid_acc: 0.9686148\n",
      "epoch: 431 train_loss: 2.418664 valid_loss: 4.1112666 train_acc: 0.98153484 valid_acc: 0.96850395\n",
      "epoch: 432 train_loss: 2.4070127 valid_loss: 4.1000586 train_acc: 0.9816458 valid_acc: 0.9686148\n",
      "epoch: 433 train_loss: 2.3960266 valid_loss: 4.090211 train_acc: 0.9817567 valid_acc: 0.96883667\n",
      "epoch: 434 train_loss: 2.3845773 valid_loss: 4.072353 train_acc: 0.98170125 valid_acc: 0.9689475\n",
      "epoch: 435 train_loss: 2.3728147 valid_loss: 4.0581107 train_acc: 0.9817567 valid_acc: 0.9691693\n",
      "epoch: 436 train_loss: 2.3617663 valid_loss: 4.047977 train_acc: 0.98220026 valid_acc: 0.96928024\n",
      "epoch: 437 train_loss: 2.3504386 valid_loss: 4.033617 train_acc: 0.9820894 valid_acc: 0.96928024\n",
      "epoch: 438 train_loss: 2.339435 valid_loss: 4.020717 train_acc: 0.98203397 valid_acc: 0.96939117\n",
      "epoch: 439 train_loss: 2.3296466 valid_loss: 4.0144863 train_acc: 0.98186755 valid_acc: 0.96939117\n",
      "epoch: 440 train_loss: 2.3178144 valid_loss: 3.9984624 train_acc: 0.9823112 valid_acc: 0.96950203\n",
      "epoch: 441 train_loss: 2.3080254 valid_loss: 3.9891593 train_acc: 0.9820894 valid_acc: 0.96950203\n",
      "epoch: 442 train_loss: 2.2970088 valid_loss: 3.9744112 train_acc: 0.9826439 valid_acc: 0.9697239\n",
      "epoch: 443 train_loss: 2.286625 valid_loss: 3.9642742 train_acc: 0.982533 valid_acc: 0.9697239\n",
      "epoch: 444 train_loss: 2.276383 valid_loss: 3.949398 train_acc: 0.9827548 valid_acc: 0.96983474\n",
      "epoch: 445 train_loss: 2.2659183 valid_loss: 3.9457521 train_acc: 0.98281026 valid_acc: 0.9702784\n",
      "epoch: 446 train_loss: 2.2562735 valid_loss: 3.929502 train_acc: 0.98308754 valid_acc: 0.9702784\n",
      "epoch: 447 train_loss: 2.2459154 valid_loss: 3.9186177 train_acc: 0.98308754 valid_acc: 0.9702784\n",
      "epoch: 448 train_loss: 2.2356415 valid_loss: 3.9117062 train_acc: 0.98336476 valid_acc: 0.9708329\n",
      "epoch: 449 train_loss: 2.2263575 valid_loss: 3.894859 train_acc: 0.98325384 valid_acc: 0.9710547\n",
      "epoch: 450 train_loss: 2.215504 valid_loss: 3.888635 train_acc: 0.9831984 valid_acc: 0.9710547\n",
      "epoch: 451 train_loss: 2.2070823 valid_loss: 3.8763266 train_acc: 0.98358655 valid_acc: 0.97127646\n",
      "epoch: 452 train_loss: 2.1975245 valid_loss: 3.8653948 train_acc: 0.9834757 valid_acc: 0.9711656\n",
      "epoch: 453 train_loss: 2.1870394 valid_loss: 3.8545043 train_acc: 0.9835311 valid_acc: 0.9711656\n",
      "epoch: 454 train_loss: 2.1800246 valid_loss: 3.847593 train_acc: 0.98358655 valid_acc: 0.9713874\n",
      "epoch: 455 train_loss: 2.1686983 valid_loss: 3.8319497 train_acc: 0.9837529 valid_acc: 0.9713874\n",
      "epoch: 456 train_loss: 2.1612608 valid_loss: 3.8239992 train_acc: 0.9837529 valid_acc: 0.9714983\n",
      "epoch: 457 train_loss: 2.1514745 valid_loss: 3.8145509 train_acc: 0.9840856 valid_acc: 0.9713874\n",
      "epoch: 458 train_loss: 2.1419702 valid_loss: 3.7988882 train_acc: 0.98380834 valid_acc: 0.9714983\n",
      "epoch: 459 train_loss: 2.1330452 valid_loss: 3.7936702 train_acc: 0.98408556 valid_acc: 0.9716092\n",
      "epoch: 460 train_loss: 2.1242738 valid_loss: 3.7828083 train_acc: 0.984252 valid_acc: 0.9717201\n",
      "epoch: 461 train_loss: 2.1150444 valid_loss: 3.7698812 train_acc: 0.98414105 valid_acc: 0.9720528\n",
      "epoch: 462 train_loss: 2.1058297 valid_loss: 3.7637773 train_acc: 0.984252 valid_acc: 0.9720528\n",
      "epoch: 463 train_loss: 2.0982418 valid_loss: 3.751517 train_acc: 0.9841411 valid_acc: 0.9722746\n",
      "epoch: 464 train_loss: 2.087449 valid_loss: 3.7366953 train_acc: 0.9841411 valid_acc: 0.97238547\n",
      "epoch: 465 train_loss: 2.0793228 valid_loss: 3.730895 train_acc: 0.9840856 valid_acc: 0.97238547\n",
      "epoch: 466 train_loss: 2.0703275 valid_loss: 3.7219617 train_acc: 0.9840856 valid_acc: 0.9722746\n",
      "epoch: 467 train_loss: 2.060744 valid_loss: 3.7076893 train_acc: 0.984252 valid_acc: 0.9724964\n",
      "epoch: 468 train_loss: 2.0526395 valid_loss: 3.7045932 train_acc: 0.98452926 valid_acc: 0.97238547\n",
      "epoch: 469 train_loss: 2.0441103 valid_loss: 3.693254 train_acc: 0.9845292 valid_acc: 0.9727182\n",
      "epoch: 470 train_loss: 2.0352283 valid_loss: 3.681222 train_acc: 0.98419654 valid_acc: 0.9727182\n",
      "epoch: 471 train_loss: 2.0286627 valid_loss: 3.6769047 train_acc: 0.98469555 valid_acc: 0.9728291\n",
      "epoch: 472 train_loss: 2.018745 valid_loss: 3.6634495 train_acc: 0.98452926 valid_acc: 0.9728291\n",
      "epoch: 473 train_loss: 2.01027 valid_loss: 3.6528363 train_acc: 0.98447376 valid_acc: 0.9727182\n",
      "epoch: 474 train_loss: 2.0041757 valid_loss: 3.646912 train_acc: 0.98497283 valid_acc: 0.9731618\n",
      "epoch: 475 train_loss: 1.9938796 valid_loss: 3.6331353 train_acc: 0.98447376 valid_acc: 0.9730509\n",
      "epoch: 476 train_loss: 1.9855012 valid_loss: 3.6254556 train_acc: 0.9845847 valid_acc: 0.9727182\n",
      "epoch: 477 train_loss: 1.9803115 valid_loss: 3.616584 train_acc: 0.98502827 valid_acc: 0.9732727\n",
      "epoch: 478 train_loss: 1.9699943 valid_loss: 3.6001434 train_acc: 0.9846401 valid_acc: 0.9732727\n",
      "epoch: 479 train_loss: 1.9627914 valid_loss: 3.600918 train_acc: 0.98502827 valid_acc: 0.9731618\n",
      "epoch: 480 train_loss: 1.9587662 valid_loss: 3.5903683 train_acc: 0.9851946 valid_acc: 0.9734945\n",
      "epoch: 481 train_loss: 1.9486804 valid_loss: 3.5777802 train_acc: 0.9839747 valid_acc: 0.9734945\n",
      "epoch: 482 train_loss: 1.940411 valid_loss: 3.5785162 train_acc: 0.9852501 valid_acc: 0.9730509\n",
      "epoch: 483 train_loss: 1.9374104 valid_loss: 3.5579967 train_acc: 0.9850837 valid_acc: 0.9736054\n",
      "epoch: 484 train_loss: 1.9237165 valid_loss: 3.5519087 train_acc: 0.984751 valid_acc: 0.9736054\n",
      "epoch: 485 train_loss: 1.9212987 valid_loss: 3.5488756 train_acc: 0.9851392 valid_acc: 0.9739381\n",
      "epoch: 486 train_loss: 1.9098938 valid_loss: 3.5210187 train_acc: 0.9850837 valid_acc: 0.9741599\n",
      "epoch: 487 train_loss: 1.9000223 valid_loss: 3.5249696 train_acc: 0.9851946 valid_acc: 0.9739381\n",
      "epoch: 488 train_loss: 1.8980296 valid_loss: 3.5288506 train_acc: 0.98497283 valid_acc: 0.97404903\n",
      "epoch: 489 train_loss: 1.8853755 valid_loss: 3.498672 train_acc: 0.9854164 valid_acc: 0.97404903\n",
      "epoch: 490 train_loss: 1.8779181 valid_loss: 3.4910257 train_acc: 0.9850837 valid_acc: 0.9739381\n",
      "epoch: 491 train_loss: 1.8753827 valid_loss: 3.490707 train_acc: 0.985361 valid_acc: 0.97404903\n",
      "epoch: 492 train_loss: 1.8632327 valid_loss: 3.47605 train_acc: 0.98530555 valid_acc: 0.9741599\n",
      "epoch: 493 train_loss: 1.8538538 valid_loss: 3.4757798 train_acc: 0.9857491 valid_acc: 0.9739381\n",
      "epoch: 494 train_loss: 1.8495983 valid_loss: 3.4653268 train_acc: 0.9857491 valid_acc: 0.9741599\n",
      "epoch: 495 train_loss: 1.8415275 valid_loss: 3.4522684 train_acc: 0.985361 valid_acc: 0.9742708\n",
      "epoch: 496 train_loss: 1.8333704 valid_loss: 3.4488537 train_acc: 0.9855828 valid_acc: 0.9741599\n",
      "epoch: 497 train_loss: 1.8258767 valid_loss: 3.4384623 train_acc: 0.98563826 valid_acc: 0.9741599\n",
      "epoch: 498 train_loss: 1.8184309 valid_loss: 3.430293 train_acc: 0.98563826 valid_acc: 0.9741599\n",
      "epoch: 499 train_loss: 1.8114891 valid_loss: 3.419069 train_acc: 0.9858046 valid_acc: 0.9741599\n",
      "epoch: 500 train_loss: 1.8028402 valid_loss: 3.4114761 train_acc: 0.9856937 valid_acc: 0.97438174\n",
      "epoch: 501 train_loss: 1.7968946 valid_loss: 3.4079862 train_acc: 0.98608184 valid_acc: 0.9742708\n",
      "epoch: 502 train_loss: 1.7895815 valid_loss: 3.3964937 train_acc: 0.9855828 valid_acc: 0.9742708\n",
      "epoch: 503 train_loss: 1.7827032 valid_loss: 3.389407 train_acc: 0.98608184 valid_acc: 0.97438174\n",
      "epoch: 504 train_loss: 1.7747002 valid_loss: 3.3798401 train_acc: 0.98608184 valid_acc: 0.97438174\n",
      "epoch: 505 train_loss: 1.766789 valid_loss: 3.3729117 train_acc: 0.98563826 valid_acc: 0.97438174\n",
      "epoch: 506 train_loss: 1.7615016 valid_loss: 3.3682134 train_acc: 0.9860264 valid_acc: 0.97460353\n",
      "epoch: 507 train_loss: 1.7519993 valid_loss: 3.3539567 train_acc: 0.98619276 valid_acc: 0.97460353\n",
      "epoch: 508 train_loss: 1.7446159 valid_loss: 3.3473995 train_acc: 0.98608184 valid_acc: 0.97471446\n",
      "epoch: 509 train_loss: 1.7379856 valid_loss: 3.3411524 train_acc: 0.98647 valid_acc: 0.9748253\n",
      "epoch: 510 train_loss: 1.7312034 valid_loss: 3.330278 train_acc: 0.985971 valid_acc: 0.9748253\n",
      "epoch: 511 train_loss: 1.7235878 valid_loss: 3.323408 train_acc: 0.9866364 valid_acc: 0.9748253\n",
      "epoch: 512 train_loss: 1.7164172 valid_loss: 3.314291 train_acc: 0.98647 valid_acc: 0.9748253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 513 train_loss: 1.7101803 valid_loss: 3.3089938 train_acc: 0.9861927 valid_acc: 0.9748253\n",
      "epoch: 514 train_loss: 1.702738 valid_loss: 3.296846 train_acc: 0.9868027 valid_acc: 0.9748253\n",
      "epoch: 515 train_loss: 1.6972554 valid_loss: 3.2889225 train_acc: 0.98647 valid_acc: 0.97493625\n",
      "epoch: 516 train_loss: 1.6910123 valid_loss: 3.278469 train_acc: 0.98641455 valid_acc: 0.97493625\n",
      "epoch: 517 train_loss: 1.6816361 valid_loss: 3.2743385 train_acc: 0.98658085 valid_acc: 0.9748253\n",
      "epoch: 518 train_loss: 1.6792016 valid_loss: 3.2680686 train_acc: 0.9862482 valid_acc: 0.97493625\n",
      "epoch: 519 train_loss: 1.6715126 valid_loss: 3.252212 train_acc: 0.98708 valid_acc: 0.9750471\n",
      "epoch: 520 train_loss: 1.6637664 valid_loss: 3.2419555 train_acc: 0.98674726 valid_acc: 0.9750471\n",
      "epoch: 521 train_loss: 1.6573162 valid_loss: 3.237609 train_acc: 0.98674726 valid_acc: 0.97493625\n",
      "epoch: 522 train_loss: 1.6505244 valid_loss: 3.2380114 train_acc: 0.9866364 valid_acc: 0.9750471\n",
      "epoch: 523 train_loss: 1.6467116 valid_loss: 3.215215 train_acc: 0.9869136 valid_acc: 0.97515804\n",
      "epoch: 524 train_loss: 1.6353967 valid_loss: 3.2041383 train_acc: 0.98691356 valid_acc: 0.97493625\n",
      "epoch: 525 train_loss: 1.6304321 valid_loss: 3.209174 train_acc: 0.9873572 valid_acc: 0.97526896\n",
      "epoch: 526 train_loss: 1.6273623 valid_loss: 3.1897094 train_acc: 0.9868027 valid_acc: 0.9756016\n",
      "epoch: 527 train_loss: 1.6166481 valid_loss: 3.181154 train_acc: 0.98674726 valid_acc: 0.97526896\n",
      "epoch: 528 train_loss: 1.6164486 valid_loss: 3.1807632 train_acc: 0.98708 valid_acc: 0.9753798\n",
      "epoch: 529 train_loss: 1.6048249 valid_loss: 3.1708975 train_acc: 0.98708 valid_acc: 0.9753798\n",
      "epoch: 530 train_loss: 1.5986587 valid_loss: 3.1601155 train_acc: 0.9868581 valid_acc: 0.97571254\n",
      "epoch: 531 train_loss: 1.5926754 valid_loss: 3.1572175 train_acc: 0.9873572 valid_acc: 0.97571254\n",
      "epoch: 532 train_loss: 1.5873144 valid_loss: 3.139029 train_acc: 0.9868581 valid_acc: 0.97582346\n",
      "epoch: 533 train_loss: 1.5787225 valid_loss: 3.1332972 train_acc: 0.98708 valid_acc: 0.97571254\n",
      "epoch: 534 train_loss: 1.5749499 valid_loss: 3.1364477 train_acc: 0.98724633 valid_acc: 0.9753798\n",
      "epoch: 535 train_loss: 1.5665559 valid_loss: 3.1123202 train_acc: 0.98719084 valid_acc: 0.9759343\n",
      "epoch: 536 train_loss: 1.5621676 valid_loss: 3.106677 train_acc: 0.9874681 valid_acc: 0.97582346\n",
      "epoch: 537 train_loss: 1.5549536 valid_loss: 3.110647 train_acc: 0.9873572 valid_acc: 0.9759343\n",
      "epoch: 538 train_loss: 1.5477195 valid_loss: 3.1044822 train_acc: 0.98730177 valid_acc: 0.97626704\n",
      "epoch: 539 train_loss: 1.542582 valid_loss: 3.0959272 train_acc: 0.98730177 valid_acc: 0.9761562\n",
      "epoch: 540 train_loss: 1.5369005 valid_loss: 3.084128 train_acc: 0.98752356 valid_acc: 0.9759343\n",
      "epoch: 541 train_loss: 1.5290992 valid_loss: 3.0735958 train_acc: 0.98774534 valid_acc: 0.97626704\n",
      "epoch: 542 train_loss: 1.521235 valid_loss: 3.06681 train_acc: 0.9874127 valid_acc: 0.9764888\n",
      "epoch: 543 train_loss: 1.5163741 valid_loss: 3.069811 train_acc: 0.987579 valid_acc: 0.97626704\n",
      "epoch: 544 train_loss: 1.5123227 valid_loss: 3.0590417 train_acc: 0.9876899 valid_acc: 0.97571254\n",
      "epoch: 545 train_loss: 1.5028741 valid_loss: 3.0304096 train_acc: 0.9874681 valid_acc: 0.97637796\n",
      "epoch: 546 train_loss: 1.5002968 valid_loss: 3.0496864 train_acc: 0.9876899 valid_acc: 0.97637796\n",
      "epoch: 547 train_loss: 1.4982808 valid_loss: 3.0491009 train_acc: 0.9873572 valid_acc: 0.97626704\n",
      "epoch: 548 train_loss: 1.4835434 valid_loss: 3.0081859 train_acc: 0.98780084 valid_acc: 0.9759343\n",
      "epoch: 549 train_loss: 1.485128 valid_loss: 3.0143106 train_acc: 0.9874127 valid_acc: 0.9764888\n",
      "epoch: 550 train_loss: 1.483315 valid_loss: 3.0379655 train_acc: 0.98780084 valid_acc: 0.97682154\n",
      "epoch: 551 train_loss: 1.4662393 valid_loss: 2.983838 train_acc: 0.9879117 valid_acc: 0.97637796\n",
      "epoch: 552 train_loss: 1.4628022 valid_loss: 2.9803658 train_acc: 0.9876344 valid_acc: 0.97637796\n",
      "epoch: 553 train_loss: 1.4632163 valid_loss: 3.0002477 train_acc: 0.98780084 valid_acc: 0.9767107\n",
      "epoch: 554 train_loss: 1.4516575 valid_loss: 2.9731314 train_acc: 0.98796713 valid_acc: 0.9767107\n",
      "epoch: 555 train_loss: 1.4430029 valid_loss: 2.9737575 train_acc: 0.9882444 valid_acc: 0.97682154\n",
      "epoch: 556 train_loss: 1.442992 valid_loss: 2.985684 train_acc: 0.9879117 valid_acc: 0.9770434\n",
      "epoch: 557 train_loss: 1.4321868 valid_loss: 2.953202 train_acc: 0.98829985 valid_acc: 0.97693247\n",
      "epoch: 558 train_loss: 1.4256883 valid_loss: 2.9535842 train_acc: 0.988189 valid_acc: 0.9770434\n",
      "epoch: 559 train_loss: 1.4262594 valid_loss: 2.9610274 train_acc: 0.9880226 valid_acc: 0.97715425\n",
      "epoch: 560 train_loss: 1.4136698 valid_loss: 2.9311907 train_acc: 0.98829985 valid_acc: 0.97693247\n",
      "epoch: 561 train_loss: 1.410505 valid_loss: 2.9435499 train_acc: 0.9882444 valid_acc: 0.9770434\n",
      "epoch: 562 train_loss: 1.4112012 valid_loss: 2.949646 train_acc: 0.9879117 valid_acc: 0.9772652\n",
      "epoch: 563 train_loss: 1.3959371 valid_loss: 2.9077246 train_acc: 0.98835534 valid_acc: 0.97693247\n",
      "epoch: 564 train_loss: 1.3949642 valid_loss: 2.9080024 train_acc: 0.98813355 valid_acc: 0.9772652\n",
      "epoch: 565 train_loss: 1.3951955 valid_loss: 2.9309287 train_acc: 0.98813355 valid_acc: 0.97737604\n",
      "epoch: 566 train_loss: 1.3819023 valid_loss: 2.894824 train_acc: 0.9884108 valid_acc: 0.9772652\n",
      "epoch: 567 train_loss: 1.3758576 valid_loss: 2.8806682 train_acc: 0.98846626 valid_acc: 0.9772652\n",
      "epoch: 568 train_loss: 1.3765862 valid_loss: 2.9006665 train_acc: 0.9882444 valid_acc: 0.9772652\n",
      "epoch: 569 train_loss: 1.3651724 valid_loss: 2.8768234 train_acc: 0.9882444 valid_acc: 0.9772652\n",
      "epoch: 570 train_loss: 1.360748 valid_loss: 2.8705063 train_acc: 0.98807806 valid_acc: 0.9775979\n",
      "epoch: 571 train_loss: 1.3591441 valid_loss: 2.8819296 train_acc: 0.98835534 valid_acc: 0.97737604\n",
      "epoch: 572 train_loss: 1.3494353 valid_loss: 2.8683748 train_acc: 0.9883553 valid_acc: 0.97737604\n",
      "epoch: 573 train_loss: 1.3442838 valid_loss: 2.8467453 train_acc: 0.98863256 valid_acc: 0.9778197\n",
      "epoch: 574 train_loss: 1.3420386 valid_loss: 2.860131 train_acc: 0.9883553 valid_acc: 0.97748697\n",
      "epoch: 575 train_loss: 1.33564 valid_loss: 2.8533165 train_acc: 0.98829985 valid_acc: 0.97737604\n",
      "epoch: 576 train_loss: 1.3277254 valid_loss: 2.826466 train_acc: 0.9883553 valid_acc: 0.97748697\n",
      "epoch: 577 train_loss: 1.3264804 valid_loss: 2.8290732 train_acc: 0.9887435 valid_acc: 0.97793055\n",
      "epoch: 578 train_loss: 1.3224708 valid_loss: 2.8331168 train_acc: 0.9883553 valid_acc: 0.9775979\n",
      "epoch: 579 train_loss: 1.3094609 valid_loss: 2.818938 train_acc: 0.98902076 valid_acc: 0.97737604\n",
      "epoch: 580 train_loss: 1.3083159 valid_loss: 2.81984 train_acc: 0.98835534 valid_acc: 0.9781524\n",
      "epoch: 581 train_loss: 1.3051059 valid_loss: 2.8069503 train_acc: 0.9882444 valid_acc: 0.9778197\n",
      "epoch: 582 train_loss: 1.2944188 valid_loss: 2.79212 train_acc: 0.9888544 valid_acc: 0.97793055\n",
      "epoch: 583 train_loss: 1.2904468 valid_loss: 2.7938268 train_acc: 0.9888544 valid_acc: 0.9775979\n",
      "epoch: 584 train_loss: 1.2837768 valid_loss: 2.8018942 train_acc: 0.9890762 valid_acc: 0.9781524\n",
      "epoch: 585 train_loss: 1.2803197 valid_loss: 2.782532 train_acc: 0.9885771 valid_acc: 0.9784851\n",
      "epoch: 586 train_loss: 1.2743018 valid_loss: 2.7784145 train_acc: 0.9891317 valid_acc: 0.9783742\n",
      "epoch: 587 train_loss: 1.2698455 valid_loss: 2.7706194 train_acc: 0.988799 valid_acc: 0.97826326\n",
      "epoch: 588 train_loss: 1.2616649 valid_loss: 2.772831 train_acc: 0.9890762 valid_acc: 0.978596\n",
      "epoch: 589 train_loss: 1.2617862 valid_loss: 2.773285 train_acc: 0.9887435 valid_acc: 0.9784851\n",
      "epoch: 590 train_loss: 1.2549118 valid_loss: 2.7503905 train_acc: 0.98924255 valid_acc: 0.9783742\n",
      "epoch: 591 train_loss: 1.2487234 valid_loss: 2.758157 train_acc: 0.9885771 valid_acc: 0.9783742\n",
      "epoch: 592 train_loss: 1.2447271 valid_loss: 2.7350976 train_acc: 0.98924255 valid_acc: 0.9789287\n",
      "epoch: 593 train_loss: 1.2331107 valid_loss: 2.7344942 train_acc: 0.98924255 valid_acc: 0.97881776\n",
      "epoch: 594 train_loss: 1.2381182 valid_loss: 2.7423606 train_acc: 0.9889653 valid_acc: 0.97881776\n",
      "epoch: 595 train_loss: 1.2298422 valid_loss: 2.7202332 train_acc: 0.98907614 valid_acc: 0.978596\n",
      "epoch: 596 train_loss: 1.2179246 valid_loss: 2.698165 train_acc: 0.9894644 valid_acc: 0.9790396\n",
      "epoch: 597 train_loss: 1.2189596 valid_loss: 2.7068064 train_acc: 0.98951983 valid_acc: 0.9791505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 598 train_loss: 1.2115096 valid_loss: 2.7141447 train_acc: 0.9895198 valid_acc: 0.9791505\n",
      "epoch: 599 train_loss: 1.2028003 valid_loss: 2.6927931 train_acc: 0.989298 valid_acc: 0.9791505\n",
      "epoch: 600 train_loss: 1.2033482 valid_loss: 2.6930172 train_acc: 0.989298 valid_acc: 0.9791505\n",
      "epoch: 601 train_loss: 1.1973312 valid_loss: 2.6863759 train_acc: 0.98957527 valid_acc: 0.97881776\n",
      "epoch: 602 train_loss: 1.1862464 valid_loss: 2.6735773 train_acc: 0.98940885 valid_acc: 0.9793723\n",
      "epoch: 603 train_loss: 1.187871 valid_loss: 2.6757054 train_acc: 0.989298 valid_acc: 0.9792614\n",
      "epoch: 604 train_loss: 1.1821344 valid_loss: 2.6740758 train_acc: 0.98946434 valid_acc: 0.9792614\n",
      "epoch: 605 train_loss: 1.172723 valid_loss: 2.6526115 train_acc: 0.98968613 valid_acc: 0.979705\n",
      "epoch: 606 train_loss: 1.1725068 valid_loss: 2.656312 train_acc: 0.9896307 valid_acc: 0.9795941\n",
      "epoch: 607 train_loss: 1.1655941 valid_loss: 2.6546981 train_acc: 0.9896307 valid_acc: 0.9795941\n",
      "epoch: 608 train_loss: 1.15962 valid_loss: 2.6338465 train_acc: 0.98985255 valid_acc: 0.979705\n",
      "epoch: 609 train_loss: 1.1542364 valid_loss: 2.6390064 train_acc: 0.98968613 valid_acc: 0.979705\n",
      "epoch: 610 train_loss: 1.149671 valid_loss: 2.6408837 train_acc: 0.99001884 valid_acc: 0.979705\n",
      "epoch: 611 train_loss: 1.1443868 valid_loss: 2.6209168 train_acc: 0.9898525 valid_acc: 0.9799268\n",
      "epoch: 612 train_loss: 1.1419137 valid_loss: 2.625616 train_acc: 0.98979706 valid_acc: 0.979705\n",
      "epoch: 613 train_loss: 1.1343564 valid_loss: 2.6151361 train_acc: 0.9900743 valid_acc: 0.9798159\n",
      "epoch: 614 train_loss: 1.1283255 valid_loss: 2.6070418 train_acc: 0.9901852 valid_acc: 0.9798159\n",
      "epoch: 615 train_loss: 1.1282711 valid_loss: 2.6190271 train_acc: 0.9897416 valid_acc: 0.979705\n",
      "epoch: 616 train_loss: 1.1199895 valid_loss: 2.5900252 train_acc: 0.990407 valid_acc: 0.9799268\n",
      "epoch: 617 train_loss: 1.112923 valid_loss: 2.5906396 train_acc: 0.9902407 valid_acc: 0.9798159\n",
      "epoch: 618 train_loss: 1.1149716 valid_loss: 2.5995874 train_acc: 0.99001884 valid_acc: 0.9799268\n",
      "epoch: 619 train_loss: 1.1058215 valid_loss: 2.5779576 train_acc: 0.99035156 valid_acc: 0.9798159\n",
      "epoch: 620 train_loss: 1.0995808 valid_loss: 2.5671039 train_acc: 0.9902407 valid_acc: 0.9798159\n",
      "epoch: 621 train_loss: 1.1005065 valid_loss: 2.585649 train_acc: 0.99035156 valid_acc: 0.9800377\n",
      "epoch: 622 train_loss: 1.0923576 valid_loss: 2.568789 train_acc: 0.990407 valid_acc: 0.9798159\n",
      "epoch: 623 train_loss: 1.0850811 valid_loss: 2.562668 train_acc: 0.99057335 valid_acc: 0.9799268\n",
      "epoch: 624 train_loss: 1.085614 valid_loss: 2.5695279 train_acc: 0.9901297 valid_acc: 0.9800377\n",
      "epoch: 625 train_loss: 1.0774277 valid_loss: 2.5487938 train_acc: 0.99085057 valid_acc: 0.9799268\n",
      "epoch: 626 train_loss: 1.0720842 valid_loss: 2.5445788 train_acc: 0.99035156 valid_acc: 0.9799268\n",
      "epoch: 627 train_loss: 1.0715257 valid_loss: 2.5582638 train_acc: 0.9905179 valid_acc: 0.98025954\n",
      "epoch: 628 train_loss: 1.0632495 valid_loss: 2.5285234 train_acc: 0.9904624 valid_acc: 0.9801486\n",
      "epoch: 629 train_loss: 1.0621773 valid_loss: 2.5302582 train_acc: 0.9902961 valid_acc: 0.9803704\n",
      "epoch: 630 train_loss: 1.0568225 valid_loss: 2.538869 train_acc: 0.9902961 valid_acc: 0.98025954\n",
      "epoch: 631 train_loss: 1.0503491 valid_loss: 2.5237083 train_acc: 0.9906843 valid_acc: 0.9801486\n",
      "epoch: 632 train_loss: 1.0454729 valid_loss: 2.5220795 train_acc: 0.9900743 valid_acc: 0.9801486\n",
      "epoch: 633 train_loss: 1.0427048 valid_loss: 2.5202115 train_acc: 0.99096155 valid_acc: 0.9803704\n",
      "epoch: 634 train_loss: 1.0372877 valid_loss: 2.507728 train_acc: 0.9909615 valid_acc: 0.98025954\n",
      "epoch: 635 train_loss: 1.0306115 valid_loss: 2.5078952 train_acc: 0.99062884 valid_acc: 0.9800377\n",
      "epoch: 636 train_loss: 1.0302594 valid_loss: 2.5012212 train_acc: 0.9906843 valid_acc: 0.9801486\n",
      "epoch: 637 train_loss: 1.0226097 valid_loss: 2.4899285 train_acc: 0.99096155 valid_acc: 0.98025954\n",
      "epoch: 638 train_loss: 1.0179932 valid_loss: 2.493756 train_acc: 0.99079514 valid_acc: 0.9801486\n",
      "epoch: 639 train_loss: 1.0148789 valid_loss: 2.4819145 train_acc: 0.990407 valid_acc: 0.9803704\n",
      "epoch: 640 train_loss: 1.0091885 valid_loss: 2.4837923 train_acc: 0.9906843 valid_acc: 0.9803704\n",
      "epoch: 641 train_loss: 1.0060319 valid_loss: 2.477539 train_acc: 0.9905734 valid_acc: 0.98025954\n",
      "epoch: 642 train_loss: 1.0003219 valid_loss: 2.4719553 train_acc: 0.99112785 valid_acc: 0.9805922\n",
      "epoch: 643 train_loss: 0.99630517 valid_loss: 2.46682 train_acc: 0.9913497 valid_acc: 0.9804813\n",
      "epoch: 644 train_loss: 0.9899963 valid_loss: 2.4625247 train_acc: 0.9910724 valid_acc: 0.9805922\n",
      "epoch: 645 train_loss: 0.9898301 valid_loss: 2.4607635 train_acc: 0.9911833 valid_acc: 0.9805922\n",
      "epoch: 646 train_loss: 0.97961104 valid_loss: 2.4515688 train_acc: 0.99118334 valid_acc: 0.9809249\n",
      "epoch: 647 train_loss: 0.98466265 valid_loss: 2.4518428 train_acc: 0.99085057 valid_acc: 0.9805922\n",
      "epoch: 648 train_loss: 0.97390556 valid_loss: 2.4470584 train_acc: 0.99112785 valid_acc: 0.9805922\n",
      "epoch: 649 train_loss: 0.97310877 valid_loss: 2.4478 train_acc: 0.99057335 valid_acc: 0.9807031\n",
      "epoch: 650 train_loss: 0.96863836 valid_loss: 2.4432259 train_acc: 0.9914051 valid_acc: 0.98081404\n",
      "epoch: 651 train_loss: 0.9614475 valid_loss: 2.4211009 train_acc: 0.99096155 valid_acc: 0.9809249\n",
      "epoch: 652 train_loss: 0.9615215 valid_loss: 2.4352632 train_acc: 0.9911833 valid_acc: 0.98081404\n",
      "epoch: 653 train_loss: 0.95561385 valid_loss: 2.4209535 train_acc: 0.9912388 valid_acc: 0.98081404\n",
      "epoch: 654 train_loss: 0.95001835 valid_loss: 2.4174147 train_acc: 0.99129426 valid_acc: 0.98081404\n",
      "epoch: 655 train_loss: 0.94835067 valid_loss: 2.413659 train_acc: 0.991516 valid_acc: 0.98081404\n",
      "epoch: 656 train_loss: 0.9410279 valid_loss: 2.4115882 train_acc: 0.9914051 valid_acc: 0.9810358\n",
      "epoch: 657 train_loss: 0.94127613 valid_loss: 2.3983166 train_acc: 0.99112785 valid_acc: 0.98136854\n",
      "epoch: 658 train_loss: 0.93384004 valid_loss: 2.4028344 train_acc: 0.99173784 valid_acc: 0.9805922\n",
      "epoch: 659 train_loss: 0.93281174 valid_loss: 2.3880713 train_acc: 0.9912388 valid_acc: 0.9810358\n",
      "epoch: 660 train_loss: 0.92712146 valid_loss: 2.3999465 train_acc: 0.9912942 valid_acc: 0.9810358\n",
      "epoch: 661 train_loss: 0.9242904 valid_loss: 2.3804374 train_acc: 0.9913497 valid_acc: 0.9809249\n",
      "epoch: 662 train_loss: 0.9181947 valid_loss: 2.3814585 train_acc: 0.99173784 valid_acc: 0.9812576\n",
      "epoch: 663 train_loss: 0.9168427 valid_loss: 2.3839164 train_acc: 0.99146056 valid_acc: 0.98081404\n",
      "epoch: 664 train_loss: 0.91046035 valid_loss: 2.368037 train_acc: 0.99207056 valid_acc: 0.9812576\n",
      "epoch: 665 train_loss: 0.90837467 valid_loss: 2.3757174 train_acc: 0.991516 valid_acc: 0.9811467\n",
      "epoch: 666 train_loss: 0.9043902 valid_loss: 2.3599672 train_acc: 0.9918487 valid_acc: 0.9810358\n",
      "epoch: 667 train_loss: 0.90089226 valid_loss: 2.3550127 train_acc: 0.99207056 valid_acc: 0.9812576\n",
      "epoch: 668 train_loss: 0.89714 valid_loss: 2.3633354 train_acc: 0.99173784 valid_acc: 0.9810358\n",
      "epoch: 669 train_loss: 0.8923969 valid_loss: 2.3482804 train_acc: 0.99223685 valid_acc: 0.9811467\n",
      "epoch: 670 train_loss: 0.88865256 valid_loss: 2.350674 train_acc: 0.99223685 valid_acc: 0.9809249\n",
      "epoch: 671 train_loss: 0.8854718 valid_loss: 2.337191 train_acc: 0.9922369 valid_acc: 0.98136854\n",
      "epoch: 672 train_loss: 0.88010454 valid_loss: 2.3434854 train_acc: 0.99223685 valid_acc: 0.9811467\n",
      "epoch: 673 train_loss: 0.87845695 valid_loss: 2.334371 train_acc: 0.9923478 valid_acc: 0.98159033\n",
      "epoch: 674 train_loss: 0.87412345 valid_loss: 2.337143 train_acc: 0.9922923 valid_acc: 0.9812576\n",
      "epoch: 675 train_loss: 0.87104046 valid_loss: 2.3254967 train_acc: 0.99240327 valid_acc: 0.9818121\n",
      "epoch: 676 train_loss: 0.8653118 valid_loss: 2.33016 train_acc: 0.99240327 valid_acc: 0.9811467\n",
      "epoch: 677 train_loss: 0.86480427 valid_loss: 2.3215024 train_acc: 0.99240327 valid_acc: 0.9812576\n",
      "epoch: 678 train_loss: 0.8587041 valid_loss: 2.3257763 train_acc: 0.9921814 valid_acc: 0.9814794\n",
      "epoch: 679 train_loss: 0.8576989 valid_loss: 2.3164613 train_acc: 0.9923478 valid_acc: 0.9814794\n",
      "epoch: 680 train_loss: 0.85159624 valid_loss: 2.3105242 train_acc: 0.99256957 valid_acc: 0.98159033\n",
      "epoch: 681 train_loss: 0.84946346 valid_loss: 2.3113997 train_acc: 0.99251413 valid_acc: 0.9814794\n",
      "epoch: 682 train_loss: 0.8457532 valid_loss: 2.3078566 train_acc: 0.99251413 valid_acc: 0.9811467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 683 train_loss: 0.84098613 valid_loss: 2.297133 train_acc: 0.992625 valid_acc: 0.98170125\n",
      "epoch: 684 train_loss: 0.83808184 valid_loss: 2.2954104 train_acc: 0.99251413 valid_acc: 0.98159033\n",
      "epoch: 685 train_loss: 0.8356147 valid_loss: 2.2919402 train_acc: 0.9927914 valid_acc: 0.9814794\n",
      "epoch: 686 train_loss: 0.83166033 valid_loss: 2.292385 train_acc: 0.9926805 valid_acc: 0.9814794\n",
      "epoch: 687 train_loss: 0.8286767 valid_loss: 2.2862685 train_acc: 0.992625 valid_acc: 0.9818121\n",
      "epoch: 688 train_loss: 0.8239716 valid_loss: 2.2869134 train_acc: 0.992736 valid_acc: 0.98136854\n",
      "epoch: 689 train_loss: 0.8222444 valid_loss: 2.276334 train_acc: 0.9927914 valid_acc: 0.98170125\n",
      "epoch: 690 train_loss: 0.8198967 valid_loss: 2.2727783 train_acc: 0.99256957 valid_acc: 0.9814794\n",
      "epoch: 691 train_loss: 0.81493634 valid_loss: 2.276331 train_acc: 0.9930132 valid_acc: 0.9812576\n",
      "epoch: 692 train_loss: 0.8124197 valid_loss: 2.267218 train_acc: 0.99284685 valid_acc: 0.98170125\n",
      "epoch: 693 train_loss: 0.80874616 valid_loss: 2.269173 train_acc: 0.9927914 valid_acc: 0.98159033\n",
      "epoch: 694 train_loss: 0.8050782 valid_loss: 2.259303 train_acc: 0.99284685 valid_acc: 0.98159033\n",
      "epoch: 695 train_loss: 0.8030747 valid_loss: 2.2618937 train_acc: 0.99306864 valid_acc: 0.9818121\n",
      "epoch: 696 train_loss: 0.799766 valid_loss: 2.2541485 train_acc: 0.9929023 valid_acc: 0.98159033\n",
      "epoch: 697 train_loss: 0.79580665 valid_loss: 2.256638 train_acc: 0.9930132 valid_acc: 0.98159033\n",
      "epoch: 698 train_loss: 0.7941308 valid_loss: 2.2541728 train_acc: 0.9929577 valid_acc: 0.98192304\n",
      "epoch: 699 train_loss: 0.7900801 valid_loss: 2.250123 train_acc: 0.99284685 valid_acc: 0.98159033\n",
      "epoch: 700 train_loss: 0.7860204 valid_loss: 2.2460327 train_acc: 0.9930687 valid_acc: 0.9818121\n",
      "epoch: 701 train_loss: 0.7861247 valid_loss: 2.2426674 train_acc: 0.99284685 valid_acc: 0.9818121\n",
      "epoch: 702 train_loss: 0.77937555 valid_loss: 2.2413385 train_acc: 0.9929023 valid_acc: 0.98170125\n",
      "epoch: 703 train_loss: 0.77778584 valid_loss: 2.2358558 train_acc: 0.99317956 valid_acc: 0.9820339\n",
      "epoch: 704 train_loss: 0.7735815 valid_loss: 2.238924 train_acc: 0.99284685 valid_acc: 0.98159033\n",
      "epoch: 705 train_loss: 0.771207 valid_loss: 2.2244346 train_acc: 0.9930687 valid_acc: 0.98192304\n",
      "epoch: 706 train_loss: 0.768764 valid_loss: 2.2305505 train_acc: 0.9930687 valid_acc: 0.98192304\n",
      "epoch: 707 train_loss: 0.7652512 valid_loss: 2.2280006 train_acc: 0.9930132 valid_acc: 0.98170125\n",
      "epoch: 708 train_loss: 0.7630327 valid_loss: 2.2186763 train_acc: 0.9929023 valid_acc: 0.9823666\n",
      "epoch: 709 train_loss: 0.7593385 valid_loss: 2.2221 train_acc: 0.9929577 valid_acc: 0.98225576\n",
      "epoch: 710 train_loss: 0.75686115 valid_loss: 2.2109344 train_acc: 0.993235 valid_acc: 0.9818121\n",
      "epoch: 711 train_loss: 0.7511996 valid_loss: 2.209236 train_acc: 0.99317956 valid_acc: 0.9820339\n",
      "epoch: 712 train_loss: 0.7522299 valid_loss: 2.2170517 train_acc: 0.99306864 valid_acc: 0.9823666\n",
      "epoch: 713 train_loss: 0.74531376 valid_loss: 2.2023144 train_acc: 0.99317956 valid_acc: 0.98225576\n",
      "epoch: 714 train_loss: 0.74346733 valid_loss: 2.2009702 train_acc: 0.9930687 valid_acc: 0.98225576\n",
      "epoch: 715 train_loss: 0.74371016 valid_loss: 2.2011373 train_acc: 0.99317956 valid_acc: 0.9823666\n",
      "epoch: 716 train_loss: 0.73700523 valid_loss: 2.1896636 train_acc: 0.9929577 valid_acc: 0.98247755\n",
      "epoch: 717 train_loss: 0.73531264 valid_loss: 2.1897902 train_acc: 0.9930132 valid_acc: 0.98247755\n",
      "epoch: 718 train_loss: 0.7328465 valid_loss: 2.1955404 train_acc: 0.993235 valid_acc: 0.9820339\n",
      "epoch: 719 train_loss: 0.72959685 valid_loss: 2.1866977 train_acc: 0.9929577 valid_acc: 0.98258847\n",
      "epoch: 720 train_loss: 0.7258639 valid_loss: 2.1749167 train_acc: 0.9930687 valid_acc: 0.98258847\n",
      "epoch: 721 train_loss: 0.7237405 valid_loss: 2.1933486 train_acc: 0.9934014 valid_acc: 0.98225576\n",
      "epoch: 722 train_loss: 0.721317 valid_loss: 2.1750073 train_acc: 0.9932904 valid_acc: 0.98258847\n",
      "epoch: 723 train_loss: 0.7168329 valid_loss: 2.1640904 train_acc: 0.9932904 valid_acc: 0.98269933\n",
      "epoch: 724 train_loss: 0.7173679 valid_loss: 2.1765807 train_acc: 0.9932904 valid_acc: 0.98281026\n",
      "epoch: 725 train_loss: 0.7131753 valid_loss: 2.1628976 train_acc: 0.99340135 valid_acc: 0.98247755\n",
      "epoch: 726 train_loss: 0.70568866 valid_loss: 2.1644497 train_acc: 0.9931241 valid_acc: 0.98247755\n",
      "epoch: 727 train_loss: 0.70829314 valid_loss: 2.1698515 train_acc: 0.993235 valid_acc: 0.98258847\n",
      "epoch: 728 train_loss: 0.70513314 valid_loss: 2.1503224 train_acc: 0.9930687 valid_acc: 0.98247755\n",
      "epoch: 729 train_loss: 0.69860184 valid_loss: 2.1505585 train_acc: 0.99367857 valid_acc: 0.98258847\n",
      "epoch: 730 train_loss: 0.6983729 valid_loss: 2.1580226 train_acc: 0.99362314 valid_acc: 0.98281026\n",
      "epoch: 731 train_loss: 0.69337726 valid_loss: 2.1434321 train_acc: 0.9929578 valid_acc: 0.98303205\n",
      "epoch: 732 train_loss: 0.6899514 valid_loss: 2.1441045 train_acc: 0.9935677 valid_acc: 0.98303205\n",
      "epoch: 733 train_loss: 0.6886611 valid_loss: 2.1436353 train_acc: 0.99317956 valid_acc: 0.983143\n",
      "epoch: 734 train_loss: 0.68506324 valid_loss: 2.135115 train_acc: 0.99378955 valid_acc: 0.98281026\n",
      "epoch: 735 train_loss: 0.68055296 valid_loss: 2.1347325 train_acc: 0.99345684 valid_acc: 0.98281026\n",
      "epoch: 736 train_loss: 0.6800122 valid_loss: 2.1385188 train_acc: 0.993235 valid_acc: 0.9829211\n",
      "epoch: 737 train_loss: 0.6760687 valid_loss: 2.1300664 train_acc: 0.99367857 valid_acc: 0.98303205\n",
      "epoch: 738 train_loss: 0.67272437 valid_loss: 2.1230907 train_acc: 0.9932904 valid_acc: 0.9829211\n",
      "epoch: 739 train_loss: 0.67224157 valid_loss: 2.1257231 train_acc: 0.9937895 valid_acc: 0.98281026\n",
      "epoch: 740 train_loss: 0.6687314 valid_loss: 2.1157691 train_acc: 0.9934014 valid_acc: 0.9829211\n",
      "epoch: 741 train_loss: 0.6648042 valid_loss: 2.11985 train_acc: 0.99362314 valid_acc: 0.98336476\n",
      "epoch: 742 train_loss: 0.6624229 valid_loss: 2.1164765 train_acc: 0.99362314 valid_acc: 0.983143\n",
      "epoch: 743 train_loss: 0.6586412 valid_loss: 2.1126244 train_acc: 0.99367857 valid_acc: 0.9829211\n",
      "epoch: 744 train_loss: 0.6574662 valid_loss: 2.10265 train_acc: 0.9935677 valid_acc: 0.98325384\n",
      "epoch: 745 train_loss: 0.654215 valid_loss: 2.1040175 train_acc: 0.99373406 valid_acc: 0.98336476\n",
      "epoch: 746 train_loss: 0.64998484 valid_loss: 2.1002433 train_acc: 0.99367857 valid_acc: 0.98336476\n",
      "epoch: 747 train_loss: 0.64862394 valid_loss: 2.0963547 train_acc: 0.9939004 valid_acc: 0.98325384\n",
      "epoch: 748 train_loss: 0.6440816 valid_loss: 2.0957289 train_acc: 0.9937895 valid_acc: 0.98325384\n",
      "epoch: 749 train_loss: 0.64272225 valid_loss: 2.0927906 train_acc: 0.99395585 valid_acc: 0.9834757\n",
      "epoch: 750 train_loss: 0.6389476 valid_loss: 2.0897164 train_acc: 0.9940667 valid_acc: 0.98336476\n",
      "epoch: 751 train_loss: 0.63621783 valid_loss: 2.085075 train_acc: 0.993845 valid_acc: 0.9834757\n",
      "epoch: 752 train_loss: 0.6338362 valid_loss: 2.0871646 train_acc: 0.9937895 valid_acc: 0.98336476\n",
      "epoch: 753 train_loss: 0.6308458 valid_loss: 2.085223 train_acc: 0.9940667 valid_acc: 0.98325384\n",
      "epoch: 754 train_loss: 0.6267337 valid_loss: 2.0804229 train_acc: 0.99395585 valid_acc: 0.98336476\n",
      "epoch: 755 train_loss: 0.62577873 valid_loss: 2.0791926 train_acc: 0.9941222 valid_acc: 0.9834757\n",
      "epoch: 756 train_loss: 0.6223251 valid_loss: 2.075012 train_acc: 0.99378955 valid_acc: 0.9834757\n",
      "epoch: 757 train_loss: 0.61941564 valid_loss: 2.0726697 train_acc: 0.99423313 valid_acc: 0.9834757\n",
      "epoch: 758 train_loss: 0.6167778 valid_loss: 2.070654 train_acc: 0.99378955 valid_acc: 0.9834757\n",
      "epoch: 759 train_loss: 0.61412305 valid_loss: 2.0675015 train_acc: 0.99428856 valid_acc: 0.9834757\n",
      "epoch: 760 train_loss: 0.6114105 valid_loss: 2.0659761 train_acc: 0.9940668 valid_acc: 0.98358655\n",
      "epoch: 761 train_loss: 0.6091148 valid_loss: 2.0617955 train_acc: 0.9940667 valid_acc: 0.9834757\n",
      "epoch: 762 train_loss: 0.60660756 valid_loss: 2.060887 train_acc: 0.99395585 valid_acc: 0.98358655\n",
      "epoch: 763 train_loss: 0.6035754 valid_loss: 2.057697 train_acc: 0.99423313 valid_acc: 0.98358655\n",
      "epoch: 764 train_loss: 0.60118985 valid_loss: 2.0553272 train_acc: 0.9940668 valid_acc: 0.98358655\n",
      "epoch: 765 train_loss: 0.5983889 valid_loss: 2.052359 train_acc: 0.99428856 valid_acc: 0.9836975\n",
      "epoch: 766 train_loss: 0.59605706 valid_loss: 2.0516129 train_acc: 0.9940113 valid_acc: 0.9836975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 767 train_loss: 0.5931011 valid_loss: 2.0472622 train_acc: 0.9941222 valid_acc: 0.9836975\n",
      "epoch: 768 train_loss: 0.5904581 valid_loss: 2.0454264 train_acc: 0.99428856 valid_acc: 0.9836975\n",
      "epoch: 769 train_loss: 0.58819145 valid_loss: 2.0430138 train_acc: 0.99428856 valid_acc: 0.98380834\n",
      "epoch: 770 train_loss: 0.58541334 valid_loss: 2.0406876 train_acc: 0.99423313 valid_acc: 0.98380834\n",
      "epoch: 771 train_loss: 0.5826987 valid_loss: 2.037578 train_acc: 0.994344 valid_acc: 0.9836975\n",
      "epoch: 772 train_loss: 0.5804033 valid_loss: 2.0349133 train_acc: 0.99423313 valid_acc: 0.98391926\n",
      "epoch: 773 train_loss: 0.57731247 valid_loss: 2.0335708 train_acc: 0.9944549 valid_acc: 0.98391926\n",
      "epoch: 774 train_loss: 0.5751998 valid_loss: 2.0288086 train_acc: 0.9941777 valid_acc: 0.98380834\n",
      "epoch: 775 train_loss: 0.571911 valid_loss: 2.0288088 train_acc: 0.994344 valid_acc: 0.9836975\n",
      "epoch: 776 train_loss: 0.5699171 valid_loss: 2.026922 train_acc: 0.99428856 valid_acc: 0.9836975\n",
      "epoch: 777 train_loss: 0.56734604 valid_loss: 2.0249205 train_acc: 0.9943994 valid_acc: 0.98358655\n",
      "epoch: 778 train_loss: 0.5648245 valid_loss: 2.018363 train_acc: 0.994344 valid_acc: 0.98358655\n",
      "epoch: 779 train_loss: 0.56226516 valid_loss: 2.0241237 train_acc: 0.99451035 valid_acc: 0.9836975\n",
      "epoch: 780 train_loss: 0.56024563 valid_loss: 2.0152426 train_acc: 0.9944549 valid_acc: 0.98358655\n",
      "epoch: 781 train_loss: 0.55712366 valid_loss: 2.0196242 train_acc: 0.9946767 valid_acc: 0.98391926\n",
      "epoch: 782 train_loss: 0.5561773 valid_loss: 2.0083747 train_acc: 0.994344 valid_acc: 0.98380834\n",
      "epoch: 783 train_loss: 0.5550997 valid_loss: 2.0122974 train_acc: 0.994344 valid_acc: 0.98391926\n",
      "epoch: 784 train_loss: 0.55302167 valid_loss: 2.0025384 train_acc: 0.9941777 valid_acc: 0.98391926\n",
      "epoch: 785 train_loss: 0.55061334 valid_loss: 2.0084553 train_acc: 0.99456584 valid_acc: 0.9836975\n",
      "epoch: 786 train_loss: 0.54916924 valid_loss: 2.0058804 train_acc: 0.9940667 valid_acc: 0.9840302\n",
      "epoch: 787 train_loss: 0.5453239 valid_loss: 2.0023038 train_acc: 0.9946213 valid_acc: 0.98391926\n",
      "epoch: 788 train_loss: 0.54334927 valid_loss: 1.9984987 train_acc: 0.9948985 valid_acc: 0.9840302\n",
      "epoch: 789 train_loss: 0.54010224 valid_loss: 1.9966474 train_acc: 0.99456584 valid_acc: 0.98380834\n",
      "epoch: 790 train_loss: 0.54205817 valid_loss: 1.9944549 train_acc: 0.99428856 valid_acc: 0.9840302\n",
      "epoch: 791 train_loss: 0.53677464 valid_loss: 1.9776853 train_acc: 0.9941222 valid_acc: 0.98414105\n",
      "epoch: 792 train_loss: 0.5359012 valid_loss: 1.9824934 train_acc: 0.994954 valid_acc: 0.9840302\n",
      "epoch: 793 train_loss: 0.53341377 valid_loss: 1.9960409 train_acc: 0.99428856 valid_acc: 0.98380834\n",
      "epoch: 794 train_loss: 0.5312823 valid_loss: 1.9654559 train_acc: 0.99423313 valid_acc: 0.98414105\n",
      "epoch: 795 train_loss: 0.5294831 valid_loss: 1.9816304 train_acc: 0.99451035 valid_acc: 0.984252\n",
      "epoch: 796 train_loss: 0.527516 valid_loss: 1.9806037 train_acc: 0.9943994 valid_acc: 0.984252\n",
      "epoch: 797 train_loss: 0.5265257 valid_loss: 1.9573674 train_acc: 0.9944549 valid_acc: 0.98414105\n",
      "epoch: 798 train_loss: 0.5270762 valid_loss: 1.9771967 train_acc: 0.994344 valid_acc: 0.98414105\n",
      "epoch: 799 train_loss: 0.5192334 valid_loss: 1.9635597 train_acc: 0.9940668 valid_acc: 0.9845847\n",
      "epoch: 800 train_loss: 0.523494 valid_loss: 1.9484528 train_acc: 0.99445486 valid_acc: 0.98469555\n",
      "epoch: 801 train_loss: 0.52038825 valid_loss: 1.9680209 train_acc: 0.9944549 valid_acc: 0.98414105\n",
      "epoch: 802 train_loss: 0.5133805 valid_loss: 1.9659098 train_acc: 0.9943995 valid_acc: 0.98436284\n",
      "epoch: 803 train_loss: 0.51210815 valid_loss: 1.9568274 train_acc: 0.99456584 valid_acc: 0.9848065\n",
      "epoch: 804 train_loss: 0.50981796 valid_loss: 1.9515228 train_acc: 0.99473214 valid_acc: 0.9848065\n",
      "epoch: 805 train_loss: 0.50527316 valid_loss: 1.9604388 train_acc: 0.99478763 valid_acc: 0.9840302\n",
      "epoch: 806 train_loss: 0.5069796 valid_loss: 1.9513447 train_acc: 0.99451035 valid_acc: 0.9845847\n",
      "epoch: 807 train_loss: 0.50818753 valid_loss: 1.9463288 train_acc: 0.99484307 valid_acc: 0.9848065\n",
      "epoch: 808 train_loss: 0.49652243 valid_loss: 1.9533949 train_acc: 0.9948431 valid_acc: 0.98436284\n",
      "epoch: 809 train_loss: 0.50266314 valid_loss: 1.9356853 train_acc: 0.99473214 valid_acc: 0.9849174\n",
      "epoch: 810 train_loss: 0.49859285 valid_loss: 1.9406525 train_acc: 0.9946767 valid_acc: 0.98469555\n",
      "epoch: 811 train_loss: 0.4920155 valid_loss: 1.9472524 train_acc: 0.99478763 valid_acc: 0.98447376\n",
      "epoch: 812 train_loss: 0.49298158 valid_loss: 1.930967 train_acc: 0.9947876 valid_acc: 0.98469555\n",
      "epoch: 813 train_loss: 0.49391162 valid_loss: 1.9349297 train_acc: 0.99489856 valid_acc: 0.98469555\n",
      "epoch: 814 train_loss: 0.49038523 valid_loss: 1.936303 train_acc: 0.99489856 valid_acc: 0.98447376\n",
      "epoch: 815 train_loss: 0.48361766 valid_loss: 1.9314108 train_acc: 0.9946767 valid_acc: 0.98436284\n",
      "epoch: 816 train_loss: 0.4865051 valid_loss: 1.9247084 train_acc: 0.9946767 valid_acc: 0.98502827\n",
      "epoch: 817 train_loss: 0.47827017 valid_loss: 1.933965 train_acc: 0.99489856 valid_acc: 0.9848065\n",
      "epoch: 818 train_loss: 0.4822808 valid_loss: 1.9154897 train_acc: 0.99484307 valid_acc: 0.9845847\n",
      "epoch: 819 train_loss: 0.47771424 valid_loss: 1.9176666 train_acc: 0.994954 valid_acc: 0.98502827\n",
      "epoch: 820 train_loss: 0.47744048 valid_loss: 1.9003935 train_acc: 0.9948431 valid_acc: 0.9849174\n",
      "epoch: 821 train_loss: 0.47473186 valid_loss: 1.9348041 train_acc: 0.99539757 valid_acc: 0.98469555\n",
      "epoch: 822 train_loss: 0.47229636 valid_loss: 1.9120734 train_acc: 0.9944549 valid_acc: 0.98469555\n",
      "epoch: 823 train_loss: 0.4721433 valid_loss: 1.8819045 train_acc: 0.99506485 valid_acc: 0.98502827\n",
      "epoch: 824 train_loss: 0.4711041 valid_loss: 1.9249376 train_acc: 0.9950094 valid_acc: 0.9848065\n",
      "epoch: 825 train_loss: 0.46809977 valid_loss: 1.9145048 train_acc: 0.9947876 valid_acc: 0.9848065\n",
      "epoch: 826 train_loss: 0.46442562 valid_loss: 1.8919545 train_acc: 0.9951758 valid_acc: 0.9848065\n",
      "epoch: 827 train_loss: 0.4615576 valid_loss: 1.9160109 train_acc: 0.9952867 valid_acc: 0.98469555\n",
      "epoch: 828 train_loss: 0.45971596 valid_loss: 1.8907027 train_acc: 0.99484307 valid_acc: 0.9845847\n",
      "epoch: 829 train_loss: 0.46005464 valid_loss: 1.8836728 train_acc: 0.9951758 valid_acc: 0.98469555\n",
      "epoch: 830 train_loss: 0.45839173 valid_loss: 1.8921263 train_acc: 0.9952867 valid_acc: 0.98525006\n",
      "epoch: 831 train_loss: 0.45132297 valid_loss: 1.8945646 train_acc: 0.9952313 valid_acc: 0.9848065\n",
      "epoch: 832 train_loss: 0.45326385 valid_loss: 1.9037647 train_acc: 0.99534214 valid_acc: 0.9845847\n",
      "epoch: 833 train_loss: 0.44867533 valid_loss: 1.898522 train_acc: 0.9955085 valid_acc: 0.9848065\n",
      "epoch: 834 train_loss: 0.44558454 valid_loss: 1.8879751 train_acc: 0.9950094 valid_acc: 0.9848065\n",
      "epoch: 835 train_loss: 0.44631362 valid_loss: 1.888663 train_acc: 0.995453 valid_acc: 0.9851392\n",
      "epoch: 836 train_loss: 0.44200575 valid_loss: 1.8843448 train_acc: 0.9951758 valid_acc: 0.9845847\n",
      "epoch: 837 train_loss: 0.43965885 valid_loss: 1.88853 train_acc: 0.99567485 valid_acc: 0.9845847\n",
      "epoch: 838 train_loss: 0.4376027 valid_loss: 1.8854295 train_acc: 0.99567485 valid_acc: 0.98469555\n",
      "epoch: 839 train_loss: 0.44034064 valid_loss: 1.8952004 train_acc: 0.99478763 valid_acc: 0.985361\n",
      "epoch: 840 train_loss: 0.43450943 valid_loss: 1.8778228 train_acc: 0.99539757 valid_acc: 0.9851392\n",
      "epoch: 841 train_loss: 0.43337446 valid_loss: 1.8799468 train_acc: 0.99567485 valid_acc: 0.98525006\n",
      "epoch: 842 train_loss: 0.43383682 valid_loss: 1.8690603 train_acc: 0.9952313 valid_acc: 0.9845847\n",
      "epoch: 843 train_loss: 0.4295271 valid_loss: 1.8709495 train_acc: 0.9952867 valid_acc: 0.9848065\n",
      "epoch: 844 train_loss: 0.42605475 valid_loss: 1.8679113 train_acc: 0.99539757 valid_acc: 0.9849174\n",
      "epoch: 845 train_loss: 0.4254949 valid_loss: 1.8510482 train_acc: 0.9957857 valid_acc: 0.985361\n",
      "epoch: 846 train_loss: 0.42400897 valid_loss: 1.8618863 train_acc: 0.9957857 valid_acc: 0.9856937\n",
      "epoch: 847 train_loss: 0.41878664 valid_loss: 1.8613825 train_acc: 0.9955639 valid_acc: 0.9848065\n",
      "epoch: 848 train_loss: 0.41921777 valid_loss: 1.8629756 train_acc: 0.9958412 valid_acc: 0.98447376\n",
      "epoch: 849 train_loss: 0.41733593 valid_loss: 1.8573442 train_acc: 0.9952312 valid_acc: 0.9851392\n",
      "epoch: 850 train_loss: 0.4152099 valid_loss: 1.8671875 train_acc: 0.99589664 valid_acc: 0.9854719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 851 train_loss: 0.41465044 valid_loss: 1.853461 train_acc: 0.99534214 valid_acc: 0.98525006\n",
      "epoch: 852 train_loss: 0.41209972 valid_loss: 1.8579634 train_acc: 0.9958412 valid_acc: 0.9848065\n",
      "epoch: 853 train_loss: 0.40913004 valid_loss: 1.8505648 train_acc: 0.9956194 valid_acc: 0.98525006\n",
      "epoch: 854 train_loss: 0.40676707 valid_loss: 1.8520522 train_acc: 0.9958412 valid_acc: 0.98525006\n",
      "epoch: 855 train_loss: 0.40501177 valid_loss: 1.8470892 train_acc: 0.9957303 valid_acc: 0.9854719\n",
      "epoch: 856 train_loss: 0.4038304 valid_loss: 1.8456639 train_acc: 0.9956194 valid_acc: 0.9854719\n",
      "epoch: 857 train_loss: 0.40425116 valid_loss: 1.833356 train_acc: 0.99584115 valid_acc: 0.985361\n",
      "epoch: 858 train_loss: 0.39720047 valid_loss: 1.8530928 train_acc: 0.99589664 valid_acc: 0.9848065\n",
      "epoch: 859 train_loss: 0.40186524 valid_loss: 1.8344014 train_acc: 0.99545306 valid_acc: 0.98502827\n",
      "epoch: 860 train_loss: 0.3991667 valid_loss: 1.8262156 train_acc: 0.99539757 valid_acc: 0.98525006\n",
      "epoch: 861 train_loss: 0.39582908 valid_loss: 1.8412629 train_acc: 0.9959521 valid_acc: 0.9858046\n",
      "epoch: 862 train_loss: 0.3928102 valid_loss: 1.8313247 train_acc: 0.99534214 valid_acc: 0.98525006\n",
      "epoch: 863 train_loss: 0.39447126 valid_loss: 1.8324801 train_acc: 0.9959521 valid_acc: 0.98525006\n",
      "epoch: 864 train_loss: 0.3887179 valid_loss: 1.83682 train_acc: 0.99539757 valid_acc: 0.98502827\n",
      "epoch: 865 train_loss: 0.38997075 valid_loss: 1.8262458 train_acc: 0.9952313 valid_acc: 0.9858046\n",
      "epoch: 866 train_loss: 0.39093244 valid_loss: 1.819923 train_acc: 0.9955639 valid_acc: 0.9856937\n",
      "epoch: 867 train_loss: 0.3816074 valid_loss: 1.8349875 train_acc: 0.99567485 valid_acc: 0.9851392\n",
      "epoch: 868 train_loss: 0.38819045 valid_loss: 1.8128359 train_acc: 0.9952867 valid_acc: 0.9860264\n",
      "epoch: 869 train_loss: 0.38662848 valid_loss: 1.799793 train_acc: 0.9955639 valid_acc: 0.98558277\n",
      "epoch: 870 train_loss: 0.38060224 valid_loss: 1.8104197 train_acc: 0.995453 valid_acc: 0.9854719\n",
      "epoch: 871 train_loss: 0.38005087 valid_loss: 1.8151829 train_acc: 0.9955639 valid_acc: 0.9861373\n",
      "epoch: 872 train_loss: 0.3831036 valid_loss: 1.8006558 train_acc: 0.995453 valid_acc: 0.9858046\n",
      "epoch: 873 train_loss: 0.37485102 valid_loss: 1.797258 train_acc: 0.9959521 valid_acc: 0.9856937\n",
      "epoch: 874 train_loss: 0.37284562 valid_loss: 1.8123329 train_acc: 0.99584115 valid_acc: 0.9859155\n",
      "epoch: 875 train_loss: 0.3752547 valid_loss: 1.8002336 train_acc: 0.9951758 valid_acc: 0.98647\n",
      "epoch: 876 train_loss: 0.37295663 valid_loss: 1.800351 train_acc: 0.9957303 valid_acc: 0.985361\n",
      "epoch: 877 train_loss: 0.36590666 valid_loss: 1.8111774 train_acc: 0.9957857 valid_acc: 0.9859155\n",
      "epoch: 878 train_loss: 0.37305033 valid_loss: 1.790081 train_acc: 0.99512035 valid_acc: 0.9863591\n",
      "epoch: 879 train_loss: 0.36755905 valid_loss: 1.7804753 train_acc: 0.9957857 valid_acc: 0.9858046\n",
      "epoch: 880 train_loss: 0.36645818 valid_loss: 1.783249 train_acc: 0.996063 valid_acc: 0.9859155\n",
      "epoch: 881 train_loss: 0.3625642 valid_loss: 1.804643 train_acc: 0.9956194 valid_acc: 0.9861373\n",
      "epoch: 882 train_loss: 0.36426067 valid_loss: 1.7951856 train_acc: 0.9957303 valid_acc: 0.9861373\n",
      "epoch: 883 train_loss: 0.36915874 valid_loss: 1.7792455 train_acc: 0.9955085 valid_acc: 0.98647\n",
      "epoch: 884 train_loss: 0.3537227 valid_loss: 1.7990183 train_acc: 0.99589664 valid_acc: 0.9858046\n",
      "epoch: 885 train_loss: 0.3593742 valid_loss: 1.7764542 train_acc: 0.9955085 valid_acc: 0.9861373\n",
      "epoch: 886 train_loss: 0.3594426 valid_loss: 1.8000551 train_acc: 0.9959521 valid_acc: 0.9861373\n",
      "epoch: 887 train_loss: 0.35495645 valid_loss: 1.7730266 train_acc: 0.9959521 valid_acc: 0.9863591\n",
      "epoch: 888 train_loss: 0.34965003 valid_loss: 1.767761 train_acc: 0.99589664 valid_acc: 0.9865809\n",
      "epoch: 889 train_loss: 0.3519058 valid_loss: 1.7766756 train_acc: 0.99595207 valid_acc: 0.9865809\n",
      "epoch: 890 train_loss: 0.3483413 valid_loss: 1.7605563 train_acc: 0.99622935 valid_acc: 0.9863591\n",
      "epoch: 891 train_loss: 0.34605056 valid_loss: 1.7823585 train_acc: 0.99600756 valid_acc: 0.9863591\n",
      "epoch: 892 train_loss: 0.34148964 valid_loss: 1.7692444 train_acc: 0.996673 valid_acc: 0.9860264\n",
      "epoch: 893 train_loss: 0.3400666 valid_loss: 1.7820222 train_acc: 0.99656206 valid_acc: 0.9863591\n",
      "epoch: 894 train_loss: 0.3402754 valid_loss: 1.7582968 train_acc: 0.9959521 valid_acc: 0.9862482\n",
      "epoch: 895 train_loss: 0.340134 valid_loss: 1.7665046 train_acc: 0.9963957 valid_acc: 0.9861373\n",
      "epoch: 896 train_loss: 0.33855462 valid_loss: 1.7749734 train_acc: 0.99617386 valid_acc: 0.9861373\n",
      "epoch: 897 train_loss: 0.3323344 valid_loss: 1.7499572 train_acc: 0.996673 valid_acc: 0.9865809\n",
      "epoch: 898 train_loss: 0.33137983 valid_loss: 1.7694843 train_acc: 0.996063 valid_acc: 0.9865809\n",
      "epoch: 899 train_loss: 0.333517 valid_loss: 1.7528982 train_acc: 0.9965066 valid_acc: 0.9862482\n",
      "epoch: 900 train_loss: 0.33005673 valid_loss: 1.7516304 train_acc: 0.9965066 valid_acc: 0.9863591\n",
      "epoch: 901 train_loss: 0.3278252 valid_loss: 1.7593697 train_acc: 0.9967284 valid_acc: 0.9865809\n",
      "epoch: 902 train_loss: 0.32383755 valid_loss: 1.7442151 train_acc: 0.9963403 valid_acc: 0.9862482\n",
      "epoch: 903 train_loss: 0.32488126 valid_loss: 1.760465 train_acc: 0.9966175 valid_acc: 0.9861373\n",
      "epoch: 904 train_loss: 0.32287246 valid_loss: 1.7524556 train_acc: 0.996673 valid_acc: 0.9861373\n",
      "epoch: 905 train_loss: 0.3193271 valid_loss: 1.7591856 train_acc: 0.9963403 valid_acc: 0.9868027\n",
      "epoch: 906 train_loss: 0.31916448 valid_loss: 1.7528585 train_acc: 0.99656206 valid_acc: 0.9863591\n",
      "epoch: 907 train_loss: 0.3169982 valid_loss: 1.7521294 train_acc: 0.99678385 valid_acc: 0.9863591\n",
      "epoch: 908 train_loss: 0.31577015 valid_loss: 1.7353075 train_acc: 0.9967284 valid_acc: 0.9865809\n",
      "epoch: 909 train_loss: 0.31515247 valid_loss: 1.7464961 train_acc: 0.99645114 valid_acc: 0.9865809\n",
      "epoch: 910 train_loss: 0.31305718 valid_loss: 1.7507491 train_acc: 0.9967284 valid_acc: 0.9865809\n",
      "epoch: 911 train_loss: 0.31187007 valid_loss: 1.7334985 train_acc: 0.99656206 valid_acc: 0.9862482\n",
      "epoch: 912 train_loss: 0.31498498 valid_loss: 1.7418363 train_acc: 0.99656206 valid_acc: 0.9862482\n",
      "epoch: 913 train_loss: 0.3086408 valid_loss: 1.7346591 train_acc: 0.9965066 valid_acc: 0.98669183\n",
      "epoch: 914 train_loss: 0.3090763 valid_loss: 1.741485 train_acc: 0.99617386 valid_acc: 0.9863591\n",
      "epoch: 915 train_loss: 0.3116412 valid_loss: 1.7137214 train_acc: 0.9968393 valid_acc: 0.98647\n",
      "epoch: 916 train_loss: 0.30712146 valid_loss: 1.7279162 train_acc: 0.99617386 valid_acc: 0.9865809\n",
      "epoch: 917 train_loss: 0.30360186 valid_loss: 1.7452959 train_acc: 0.99656206 valid_acc: 0.98647\n",
      "epoch: 918 train_loss: 0.30321318 valid_loss: 1.7342136 train_acc: 0.9966729 valid_acc: 0.9863591\n",
      "epoch: 919 train_loss: 0.2993002 valid_loss: 1.7378824 train_acc: 0.9965066 valid_acc: 0.9863591\n",
      "epoch: 920 train_loss: 0.2982234 valid_loss: 1.7238888 train_acc: 0.9965066 valid_acc: 0.9869136\n",
      "epoch: 921 train_loss: 0.29745343 valid_loss: 1.7284136 train_acc: 0.99656206 valid_acc: 0.9865809\n",
      "epoch: 922 train_loss: 0.29620233 valid_loss: 1.7240133 train_acc: 0.99645114 valid_acc: 0.9863591\n",
      "epoch: 923 train_loss: 0.29163873 valid_loss: 1.7346001 train_acc: 0.99678385 valid_acc: 0.9861373\n",
      "epoch: 924 train_loss: 0.2911098 valid_loss: 1.7421011 train_acc: 0.9968393 valid_acc: 0.9859155\n",
      "epoch: 925 train_loss: 0.29043087 valid_loss: 1.7216824 train_acc: 0.9968393 valid_acc: 0.98647\n",
      "epoch: 926 train_loss: 0.28737614 valid_loss: 1.7267462 train_acc: 0.99706113 valid_acc: 0.9865809\n",
      "epoch: 927 train_loss: 0.28742963 valid_loss: 1.7184651 train_acc: 0.9969502 valid_acc: 0.98647\n",
      "epoch: 928 train_loss: 0.28520358 valid_loss: 1.7295082 train_acc: 0.9966175 valid_acc: 0.9861373\n",
      "epoch: 929 train_loss: 0.28319424 valid_loss: 1.7282895 train_acc: 0.9970057 valid_acc: 0.9861373\n",
      "epoch: 930 train_loss: 0.28441718 valid_loss: 1.7208604 train_acc: 0.9969502 valid_acc: 0.9865809\n",
      "epoch: 931 train_loss: 0.2820044 valid_loss: 1.7149167 train_acc: 0.9969502 valid_acc: 0.9865809\n",
      "epoch: 932 train_loss: 0.28009987 valid_loss: 1.7140204 train_acc: 0.9968947 valid_acc: 0.98647\n",
      "epoch: 933 train_loss: 0.27847937 valid_loss: 1.72449 train_acc: 0.9969502 valid_acc: 0.98647\n",
      "epoch: 934 train_loss: 0.27973324 valid_loss: 1.7045723 train_acc: 0.9968947 valid_acc: 0.9865809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 935 train_loss: 0.27665254 valid_loss: 1.716566 train_acc: 0.9970057 valid_acc: 0.98669183\n",
      "epoch: 936 train_loss: 0.2766735 valid_loss: 1.7156568 train_acc: 0.9967284 valid_acc: 0.9865809\n",
      "epoch: 937 train_loss: 0.27322888 valid_loss: 1.7093445 train_acc: 0.9967284 valid_acc: 0.9863591\n",
      "epoch: 938 train_loss: 0.2739442 valid_loss: 1.7170762 train_acc: 0.9968947 valid_acc: 0.9861373\n",
      "epoch: 939 train_loss: 0.27168304 valid_loss: 1.7035927 train_acc: 0.99678385 valid_acc: 0.9869136\n",
      "epoch: 940 train_loss: 0.27100852 valid_loss: 1.7135658 train_acc: 0.9967284 valid_acc: 0.9870245\n",
      "epoch: 941 train_loss: 0.26983845 valid_loss: 1.6913445 train_acc: 0.99678385 valid_acc: 0.98669183\n",
      "epoch: 942 train_loss: 0.2681423 valid_loss: 1.7079463 train_acc: 0.9966729 valid_acc: 0.98647\n",
      "epoch: 943 train_loss: 0.26615542 valid_loss: 1.6996549 train_acc: 0.997172 valid_acc: 0.9863591\n",
      "epoch: 944 train_loss: 0.26734352 valid_loss: 1.7002673 train_acc: 0.99678385 valid_acc: 0.9863591\n",
      "epoch: 945 train_loss: 0.2633859 valid_loss: 1.6907398 train_acc: 0.99678385 valid_acc: 0.9863591\n",
      "epoch: 946 train_loss: 0.26241422 valid_loss: 1.6970334 train_acc: 0.99728286 valid_acc: 0.98669183\n",
      "epoch: 947 train_loss: 0.26299706 valid_loss: 1.6928107 train_acc: 0.99706113 valid_acc: 0.9869136\n",
      "epoch: 948 train_loss: 0.2587847 valid_loss: 1.6928551 train_acc: 0.99678385 valid_acc: 0.9869136\n",
      "epoch: 949 train_loss: 0.25863367 valid_loss: 1.701036 train_acc: 0.99711657 valid_acc: 0.98669183\n",
      "epoch: 950 train_loss: 0.25941747 valid_loss: 1.6895505 train_acc: 0.99706113 valid_acc: 0.9865809\n",
      "epoch: 951 train_loss: 0.25550085 valid_loss: 1.6949208 train_acc: 0.9968947 valid_acc: 0.9868027\n",
      "epoch: 952 train_loss: 0.25529933 valid_loss: 1.6950282 train_acc: 0.9968948 valid_acc: 0.9868027\n",
      "epoch: 953 train_loss: 0.25726104 valid_loss: 1.6924299 train_acc: 0.99706113 valid_acc: 0.9868027\n",
      "epoch: 954 train_loss: 0.25270885 valid_loss: 1.6810794 train_acc: 0.9973938 valid_acc: 0.9863591\n",
      "epoch: 955 train_loss: 0.25327873 valid_loss: 1.7085326 train_acc: 0.99678385 valid_acc: 0.9863591\n",
      "epoch: 956 train_loss: 0.2529722 valid_loss: 1.6881733 train_acc: 0.99733835 valid_acc: 0.9862482\n",
      "epoch: 957 train_loss: 0.25274217 valid_loss: 1.7019213 train_acc: 0.9967284 valid_acc: 0.9862482\n",
      "epoch: 958 train_loss: 0.24930423 valid_loss: 1.6734265 train_acc: 0.99728286 valid_acc: 0.9870245\n",
      "epoch: 959 train_loss: 0.25124735 valid_loss: 1.681928 train_acc: 0.99678385 valid_acc: 0.9868027\n",
      "epoch: 960 train_loss: 0.24884614 valid_loss: 1.6923623 train_acc: 0.9969502 valid_acc: 0.98669183\n",
      "epoch: 961 train_loss: 0.24620025 valid_loss: 1.6658677 train_acc: 0.9974493 valid_acc: 0.9870245\n",
      "epoch: 962 train_loss: 0.250824 valid_loss: 1.6912438 train_acc: 0.99711657 valid_acc: 0.98669183\n",
      "epoch: 963 train_loss: 0.2498667 valid_loss: 1.6740636 train_acc: 0.9969502 valid_acc: 0.98669183\n",
      "epoch: 964 train_loss: 0.2489078 valid_loss: 1.6689873 train_acc: 0.99645114 valid_acc: 0.9863591\n",
      "epoch: 965 train_loss: 0.24411507 valid_loss: 1.696438 train_acc: 0.9969502 valid_acc: 0.9862482\n",
      "epoch: 966 train_loss: 0.24144505 valid_loss: 1.6723307 train_acc: 0.99733835 valid_acc: 0.9863591\n",
      "epoch: 967 train_loss: 0.24070087 valid_loss: 1.6746439 train_acc: 0.99711657 valid_acc: 0.98647\n",
      "epoch: 968 train_loss: 0.23749012 valid_loss: 1.6897131 train_acc: 0.99756014 valid_acc: 0.9860264\n",
      "epoch: 969 train_loss: 0.2385399 valid_loss: 1.660334 train_acc: 0.9972829 valid_acc: 0.9861373\n",
      "epoch: 970 train_loss: 0.23727138 valid_loss: 1.6854726 train_acc: 0.9969502 valid_acc: 0.9863591\n",
      "epoch: 971 train_loss: 0.23783913 valid_loss: 1.66154 train_acc: 0.9972829 valid_acc: 0.9863591\n",
      "epoch: 972 train_loss: 0.23719767 valid_loss: 1.6603997 train_acc: 0.99728286 valid_acc: 0.9862482\n",
      "epoch: 973 train_loss: 0.23238546 valid_loss: 1.6935079 train_acc: 0.99706113 valid_acc: 0.9862482\n",
      "epoch: 974 train_loss: 0.23484367 valid_loss: 1.6529193 train_acc: 0.99711657 valid_acc: 0.9868027\n",
      "epoch: 975 train_loss: 0.23407122 valid_loss: 1.6570011 train_acc: 0.99706113 valid_acc: 0.9868027\n",
      "epoch: 976 train_loss: 0.23377754 valid_loss: 1.6564518 train_acc: 0.997172 valid_acc: 0.9865809\n",
      "epoch: 977 train_loss: 0.23137593 valid_loss: 1.6670635 train_acc: 0.99733835 valid_acc: 0.98669183\n",
      "epoch: 978 train_loss: 0.23115596 valid_loss: 1.684982 train_acc: 0.99728286 valid_acc: 0.9868027\n",
      "epoch: 979 train_loss: 0.22939372 valid_loss: 1.6554122 train_acc: 0.9974493 valid_acc: 0.98724633\n",
      "epoch: 980 train_loss: 0.22733213 valid_loss: 1.6703656 train_acc: 0.99645114 valid_acc: 0.9871354\n",
      "epoch: 981 train_loss: 0.22528186 valid_loss: 1.6721843 train_acc: 0.99722743 valid_acc: 0.98669183\n",
      "epoch: 982 train_loss: 0.22264251 valid_loss: 1.6661855 train_acc: 0.99756014 valid_acc: 0.9870245\n",
      "epoch: 983 train_loss: 0.22410229 valid_loss: 1.680422 train_acc: 0.997172 valid_acc: 0.9868027\n",
      "epoch: 984 train_loss: 0.22737408 valid_loss: 1.6487061 train_acc: 0.99756014 valid_acc: 0.98669183\n",
      "epoch: 985 train_loss: 0.22250742 valid_loss: 1.6590574 train_acc: 0.99700564 valid_acc: 0.9870245\n",
      "epoch: 986 train_loss: 0.2212501 valid_loss: 1.6815547 train_acc: 0.99706113 valid_acc: 0.9868027\n",
      "epoch: 987 train_loss: 0.22071385 valid_loss: 1.6624384 train_acc: 0.99739385 valid_acc: 0.9865809\n",
      "epoch: 988 train_loss: 0.21668187 valid_loss: 1.6520551 train_acc: 0.99695015 valid_acc: 0.9868027\n",
      "epoch: 989 train_loss: 0.2176784 valid_loss: 1.641537 train_acc: 0.99772656 valid_acc: 0.9865809\n",
      "epoch: 990 train_loss: 0.21520007 valid_loss: 1.6596336 train_acc: 0.997172 valid_acc: 0.9868027\n",
      "epoch: 991 train_loss: 0.21692736 valid_loss: 1.6654356 train_acc: 0.99728286 valid_acc: 0.9870245\n",
      "epoch: 992 train_loss: 0.2156874 valid_loss: 1.6303581 train_acc: 0.99767107 valid_acc: 0.9871354\n",
      "epoch: 993 train_loss: 0.21299045 valid_loss: 1.6560869 train_acc: 0.99728286 valid_acc: 0.98669183\n",
      "epoch: 994 train_loss: 0.21820183 valid_loss: 1.644327 train_acc: 0.9975047 valid_acc: 0.9870245\n",
      "epoch: 995 train_loss: 0.2130755 valid_loss: 1.6469007 train_acc: 0.99722743 valid_acc: 0.9873572\n",
      "epoch: 996 train_loss: 0.21021678 valid_loss: 1.6621741 train_acc: 0.99722743 valid_acc: 0.9871354\n",
      "epoch: 997 train_loss: 0.21000683 valid_loss: 1.6291064 train_acc: 0.9974493 valid_acc: 0.9871354\n",
      "epoch: 998 train_loss: 0.20952204 valid_loss: 1.65196 train_acc: 0.99706113 valid_acc: 0.98724633\n",
      "epoch: 999 train_loss: 0.20813024 valid_loss: 1.6494051 train_acc: 0.9973938 valid_acc: 0.9871354\n",
      "epoch: 1000 train_loss: 0.20554937 valid_loss: 1.6367865 train_acc: 0.99733835 valid_acc: 0.9870245\n"
     ]
    }
   ],
   "source": [
    "# We should save the after training and validation\n",
    "saver = tf.train.Saver() \n",
    "train_loss_mean, valid_loss_mean = [], []\n",
    "train_acc_mean, valid_acc_mean = [], []\n",
    "\n",
    "# now that we can calculate loss and optimize, we can start a session for calculating the error.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "    \n",
    "    # for every epoch start feeding the arrays into the tensors in the model\n",
    "    for epoch in range(0, 1000, 1):\n",
    "        train_loss, valid_loss = [], []\n",
    "        train_acc, valid_acc = [], []\n",
    "        \n",
    "        # Training minibatches and feed them into the tensor\n",
    "        for Xarr, Yarr in get_batches(X=Xtrain, Y=Ytrain, batch_size=Xvalid.shape[0]):\n",
    "            # X_NxWxCin, Y_NxCout\n",
    "            feed_dict = {X:Xarr, Y:Yarr}\n",
    "            lossarr, _, accarr = sess.run(feed_dict=feed_dict, fetches=[loss, opt, acc])\n",
    "            train_loss.append(lossarr)\n",
    "            train_acc.append(accarr)\n",
    "            \n",
    "        # Validation now which is one batch on every iteration\n",
    "        for Xarr, Yarr in get_batches(X=Xvalid, Y=Yvalid, batch_size=Xvalid.shape[0]): \n",
    "            # X_NxWxCin, Y_NxCout\n",
    "            feed_dict = {X:Xarr, Y:Yarr}\n",
    "            lossarr, accarr = sess.run(feed_dict=feed_dict, fetches=[loss, acc])\n",
    "            valid_loss.append(lossarr)\n",
    "            valid_acc.append(accarr)\n",
    "        \n",
    "        # printing out train and validation loss\n",
    "        print('epoch:', epoch+1, 'train_loss:', np.mean(train_loss), 'valid_loss:', np.mean(valid_loss),\n",
    "             'train_acc:', np.mean(train_acc), 'valid_acc:', np.mean(valid_acc))\n",
    "        \n",
    "        # Every epoch, for drawing the plot and their learning curve\n",
    "        train_loss_mean.append(np.mean(train_loss))\n",
    "        valid_loss_mean.append(np.mean(valid_loss))\n",
    "        train_acc_mean.append(np.mean(train_acc))\n",
    "        valid_acc_mean.append(np.mean(valid_acc))\n",
    "        \n",
    "    # After all epochs and at the end of training and validation\n",
    "    saver.save(sess,'checkpoints/cnn-fnirs-har.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fadc014b198>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "%matplotlib inline\n",
    "\n",
    "mplot.plot(train_loss_mean, label='train_loss_mean')\n",
    "mplot.plot(valid_loss_mean, label='valid_loss_mean')\n",
    "mplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fadc00f35f8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mplot.plot(train_acc_mean, label='train_acc_mean')\n",
    "mplot.plot(valid_acc_mean, label='valid_acc_mean')\n",
    "mplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/cnn-fnirs-har.ckpt\n",
      "test_loss: 1.6345682 test acc 0.9859155\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "    \n",
    "    # Loading the trained and validated model\n",
    "    saver.restore(save_path=tf.train.latest_checkpoint(checkpoint_dir='checkpoints/'), sess=sess)\n",
    "    \n",
    "    # Saving the test loss for every batch/minibtch\n",
    "    test_loss, test_acc = [], []\n",
    "    \n",
    "    # applying the loaded model on test data\n",
    "    for Xarr, Yarr in get_batches(X=Xtest, Y=Ytest, batch_size=Xvalid.shape[0]): \n",
    "        # X_NxWXCin, Y_NxCout\n",
    "        feed_dict={X:Xarr, Y:Yarr}\n",
    "        lossarr, accarr = sess.run(feed_dict=feed_dict, fetches=[loss, acc])\n",
    "        test_loss.append(lossarr)\n",
    "        test_acc.append(accarr)\n",
    "        \n",
    "    # Printing the test loss\n",
    "    print('test_loss:', np.mean(test_loss), 'test acc', np.mean(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
